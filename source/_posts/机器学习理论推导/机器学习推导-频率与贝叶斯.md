---
title: 频率学派与贝叶斯学派
date: 2019-12-26 10:39:09
tags: 机器学习理论推导
categories: 学习
---
数据$X$
$$
X = \begin{pmatrix}
{x_{1}}&{x_{2}}&{\cdots}&{x_{N}}
\end{pmatrix}^T 
= \begin{pmatrix}
{x_{11}}&{x_{12}}&{\cdots}&{x_{1p}}\\\\
{x_{21}}&{x_{22}}&{\cdots}&{x_{2p}}\\\\
{\vdots}&{\vdots}&{\ddots}&{\vdots}\\\\
{x_{N1}}&{x_{N2}}&{\cdots}&{x_{Np}}\\\\
\end{pmatrix}$$

$\theta$为参数，$x\sim p(x|\theta)$
# 频率学派
频率学派认为，$\theta$为未知的常量，X为随机变量。
频率学派常用最大似然估计：
$$\theta_{MLE} = \operatorname{argmax}_{\theta} log(p(X|\theta))$$

# 贝叶斯学派
贝叶斯学派与频率学派不同，$\theta$为随机变量，$\theta\sim p(\theta)$
贝叶斯公式：

$$p(\theta | x)=\frac{p(x | \theta) \cdot p(\theta)}{p(x)} \propto p(x | \theta) \cdot p(\theta)$$

贝叶斯学派通常使用最大后验估计：
$$\theta_{MAP} = argmax_{\theta} p(\theta | X)=argmax_{\theta} p(X | \theta)p(\theta)$$

贝叶斯估计：
$${p(\theta | x)}=\frac{p(X | \theta) \cdot p(\theta)}{\int_{\theta} p(X | \theta) p(\theta) d \theta}$$

贝叶斯预测：
$$p(\tilde{x}|X)=\int_{\theta}p(\tilde{x}, \theta | X) d \theta = \int_{\theta} p(\tilde{x} | \theta) {p(\theta | X)} d \theta$$

# 总结
频率学派通常将问题转化为最优化问题，贝叶斯学派通常将为你转化为求边缘概率的积分问题。