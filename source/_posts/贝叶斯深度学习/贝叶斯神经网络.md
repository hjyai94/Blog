---
title: 贝叶斯神经网络
date: 2020-11-07 16:26:03
tags: 不确定性量化
categories: 工作
---
# 引言
本系列旨在回顾一下当前深度学习领域常用的不确定性量化方法，本系列所包含文章数可能多也可能不多，随意参考，本文主要参考文献来自下面的参考文献目录。

# 神经网络中的点估计
所谓贝叶斯神经网络就是指将原本神经网络的权重看成随机变量，这些变量可能满足某个概率分布。
首先我们将神经网络看成一个概率模型$P(\mathbf{y} \mid \mathbf{x}, \mathbf{w})$：给定输入$\mathbf{x}$，输出预测值$\mathbf{y}$的分布，$\mathbf{w}$为神经网络的权重。
我们可以通过最大似然函数估计（MLE）来估计出前面的权重$\mathbf{w}$：给定训练样本集$\mathcal{D}=(\mathbf{x}_i, \mathbf{y}_i)_i$。最大似然估计权重$\mathbf{w}^{\mathrm{MLE}}$通过下面的公式计算：
$$
\begin{aligned}
\mathbf{w}^{\mathrm{MLE}} &=\arg \max _{\mathbf{w}} \log P(\mathcal{D} \mid \mathbf{w}) \\\\
&=\arg \max _{\mathbf{w}} \sum_i \log P(\mathbf{y}_i \mid \mathbf{x}_i, \mathbf{w})
\end{aligned}
$$
上面的公式很容易通过梯度下降法计算（假定$\log P(\mathcal{D} \mid \mathbf{w})$对$\mathbf{w}$可微）。
另外，神经网络中经常使用的正则化技术可以通过最大后验分布进行推导：
$$
\begin{aligned}
\mathbf{w}^{\mathrm{MAP}} &=\arg \max _{\mathbf{w}} \log P(\mathbf{w} \mid \mathcal{D}) \\\\
&=\arg \max _{\mathbf{w}} \log P(\mathcal{D} \mid \mathbf{w})+\log P(\mathbf{w})
\end{aligned}
$$
我们注意到只要$\mathbf{w}$给定高斯先验，这样就变成L2正则；如果给定拉普拉斯先验，那么我们就能推导出L1正则。

# 通过反向传播求解贝叶斯神经网络
对于贝叶斯神经网络，我们最重要的是计算给定训练集的后验概率$P(\mathbf{w} \mid \mathcal{D})$。然后我们对于一个未知标签的测试数据可以进行如下的推断：
$$
P(\hat{\mathbf{y}} \mid \hat{\mathbf{x}})=\mathbb{E}_{P(\mathbf{w} \mid \mathcal{D})}[P(\hat{\mathbf{y}} \mid \hat{\mathbf{x}}, \mathbf{w})]
$$
上面的期望可以看作是无穷多个网络进行集成，实际上它是不可解。

## 变分推断
为了求解前面的后验期望，有学者提出采用一个参数为$\theta$的分布$q(\mathbf{w}\mid \theta)$来近似后验分布。
通过最小化二者的KL散度进行计算：
$$
\begin{aligned}
\theta^{\star} &=\arg \min_{\theta} \mathrm{KL}[q(\mathbf{w}\mid\theta)|P(\mathbf{w}\mid \mathcal{D})] \\\\
&=\arg \min _{\theta} \int q(\mathbf{w} \mid \theta) \log \frac{q(\mathbf{w} \mid \theta)}{P(\mathbf{w}) P(\mathcal{D} \mid \mathbf{w})} \mathrm{d} \mathbf{w} \\\\
\end{aligned}
$$

$$
=\arg\min_{\theta} \mathbf{KL}[q(\mathbf{w}|\theta) |P(\mathbf{w})]-\mathbb{E}_{q(\mathbf{w} | \theta)}[\log P(\mathcal{D} \mid \mathbf{w})] 
$$
上式可对对数中的分子分母同时乘以$P(\mathbf{w})$推导得出。写成目标函数形式：

$$
\mathcal{F}(\mathcal{D},\theta)=KL[q(\mathbf{w} |\theta) \|P(\mathbf{w})]-\mathbb{E}_{q(\mathbf{w}| \theta)}[\log P(\mathcal{D}| \mathbf{w})]
$$

* $P(\mathcal{D} \mid \mathbf{w})$可以看作是给定参数下的观测数据的期望。
* $\mathbf{KL}[q(\mathbf{w}|\theta) |P(\mathbf{w})]$可以看作一个正则化项，使得$q(\mathbf{w}|\theta)$与$P(\mathbf{w})$相近。
* 上面期望的梯度可以化为梯度的期望。
首先我们令$f(\mathbf{w},\theta)=\log q(\mathbf{w}\mid\theta)-\log P(\mathbf{w})P(\mathcal{D}\mid\mathbf{w})$，只要存在随机变量$\epsilon$满足$q(\epsilon)d\epsilon=q(\mathbf{w}\mid\theta)d\mathbf{w}$。
下面式子成立：

\begin{aligned}
\frac{\partial}{\partial \theta} \mathbb{E}_{q(\mathbf{w}| \theta)}[f(\mathbf{w}, \theta)]&= \frac{\partial}{\partial \theta}\int f(\mathbf{w}, \theta) q(\mathbf{w} \mid \theta) \mathrm{d} \mathbf{w} \\\\
&=\frac{\partial}{\partial\theta}\int f(\mathbf{w}, \theta) q(\epsilon) \mathrm{d} \epsilon \\\\
\end{aligned}

$$=\mathbb{E}_{q(\epsilon)}[\frac{\partial f(\mathbf{w}, \theta)}{\partial \mathbf{w}} \frac{\partial \mathbf{w}}{\partial \theta}+\frac{\partial f(\mathbf{w}, \theta)}{\partial \theta}]$$
基于前面的推导，我们可以估计损失函数梯度的无偏估计。
然后可以采用蒙特卡洛积分对 $\mathcal{F}(D,\theta)$ 进行近似：

$$
\begin{array}{r}
\mathcal{F}(\mathcal{D}, \theta) \approx \sum_{i=1}^{n} \log q\left(\mathbf{w}^{(i)} \mid \theta\right)-\log P\left(\mathbf{w}^{(i)}\right) \\
-\log P\left(\mathcal{D} \mid \mathbf{w}^{(i)}\right)
\end{array}
$$

#  参考文献
[1] Blundell C, Cornebise J, Kavukcuoglu K, et al. Weight Uncertainty in Neural Network[C]//International Conference on Machine Learning. 2015: 1613-1622.






