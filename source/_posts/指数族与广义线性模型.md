---
title: 指数族与广义线性模型
date: 2018-05-09 10:30:15
tags: 概率图模型
categories: 学习
---
# 指数族
将随机变量X写成指数族的形式：
$$p(X=x;\eta)=h(x)exp(\eta^T T(x)-A(\eta))$$
其中：$\eta$是自然参数向量（natural paramater），T(x)是充分统计量（sufficient statistic），$A(\eta)$是对数判分函数（log partition function）。

## 例子
指数族可以包括许多的例子，比如高斯分布，伯努利分布，多项式分布等。

### 多元正态分布
令向量$X\in R^k$
$$p(x\mid \mu,\Sigma)=\frac{1}{(2\pi)^{k/2}\Sigma^{\frac{1}{2}}}exp \lbrace  \frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \rbrace$$
$$=\frac{1}{(2\pi)^{k/2}} exp\lbrace -\frac{1}{2} tr(\Sigma^{-1}x x^T) + \mu^T \Sigma^{-1}x^T- \frac{1}{2}\mu^T \Sigma^{-1}\mu - log|\Sigma|\rbrace$$
对应的指数族表示：
$$\eta = [\Sigma^{-1}\mu; -\frac{1}{2}vec(\Sigma^{-1})]$$  $$ T(x)=[x;vec(xx^T)]$$  $$ A(\eta)=\frac{1}{2} \mu^T \Sigma^{-1} \mu + log|\Sigma| $$  $$ h(x)= \frac{1} { {2\pi}^{k/2} } $$

### 伯努利分布
$$ p(x;\phi) $$  $$ = \phi^x(1-\phi)^{1-x} $$  $$ = exp(log(\phi^x(1-\phi)^{1-x}) $$  $$ = exp(log(\phi^x)+log((1-\phi)^{1-x})) $$  $$ = exp(xlog(\phi) + (1-x)log(1-\phi)) $$  $$ = exp(xlog(\frac{\phi}{1-\phi})+log(1-\phi))$$
对应于指数族：
$$ \eta = log(\frac{\phi}{1-\phi}) $$  $$ T(x) = x $$  $$ A(\eta) = -log(1-\phi) $$  $$ h(x) = 1 $$

###  其他
很多的分布可以看做是指数族：单变量高斯分布（the univariate Gaussian)，泊松分布（Poisson）， 多项分布（multinomial），线性回归（linear regression），伊辛模型（Ising model），受限波尔兹曼机机（restricted Boltzmann machines），还有条件随机场（contional random field，CRFs）。

#### 条件随机场
![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png)
条件随机场是基于上面图的无向图模型，势函数是定义在成对输出上面的。
$$ p_\theta(y\mid x)=\frac{1}{Z(x)}exp(\Sigma_{e\in E,k} \lambda_k f_k(e,y\mid_e, x) + \Sigma_{v\in V,k} \mu_k g_k(v,y\mid_v, x))$$
其中$f_k$和$g_k$是固定的，$g_k$是波尔顶点特征，$f_k$是波尔边特征。

## 指数族特性
指数族具有如下的特性：
1. 对数配分函数的第d阶导数，是充分统计量的第d阶中心距。
比如：对数配分函数的一阶导数是T(X)的均值，其二阶导是T(X)的方差。
2. 因为对数配分函数的二阶导是正的，所以对数配分函数是凸的，因此方差总是非负的。
3. 我们可以将对数配分函数的一阶导看成自然参数的函数，然后令其为零，反过来利用距参数就可以解决自然参数，记作：$\eta = \psi(\mu)$ 。
4. 在指数族上进行最大似然估计与矩匹配是一致的。
  * 写出一般指数族的对数似然函数:
  $$ const + \eta^T (\Sigma_{i=1}^n T(x_i)) - nA(\eta) $$
  * 求似然函数的梯度：
  $$ \Sigma_{i=1}^n T(x_i)) - n\Delta_\eta A(\eta) $$
  * 令$\Delta_\eta A$为零：
  $$ \Delta_\eta A = \frac{1}{n}\Sigma_{i=1}^T T(x_i) \Rightarrow \mu = \frac{1}{n}\Sigma_{i=1}^T T(x_i) \Rightarrow 矩估计=样本距 $$

### 充分统计量
![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png)
从贝叶斯的观点出发：如果T具备了我们预测参数$\theta$的所有信息（即T是充分统计量），那么$\theta \perp X \mid T \Rightarrow P(\theta \mid X, T)=P(\theta\mid T)$。
从频率学派的角度出发：如果T已知的用来产生数据的参数，那么$ X \perp \theta \mid T \Rightarrow P(X\mid T;\theta) = P(X\mid T) $
从马尔科夫随机场的角度进行考虑：
