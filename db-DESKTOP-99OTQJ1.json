{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/uploads/CRF.png","path":"uploads/CRF.png","modified":1,"renderable":0},{"_id":"source/uploads/LASSO回归.png","path":"uploads/LASSO回归.png","modified":1,"renderable":0},{"_id":"source/uploads/MEMM.png","path":"uploads/MEMM.png","modified":1,"renderable":0},{"_id":"source/uploads/TPandFP.png","path":"uploads/TPandFP.png","modified":1,"renderable":0},{"_id":"source/uploads/Pytorch_Tutorial_output_35_0 .png","path":"uploads/Pytorch_Tutorial_output_35_0 .png","modified":1,"renderable":0},{"_id":"source/uploads/TPandFP.vsdx","path":"uploads/TPandFP.vsdx","modified":1,"renderable":0},{"_id":"source/uploads/Pytorch_Tutorial_output_42_0.png","path":"uploads/Pytorch_Tutorial_output_42_0.png","modified":1,"renderable":0},{"_id":"source/uploads/VGG16处理过程.png","path":"uploads/VGG16处理过程.png","modified":1,"renderable":0},{"_id":"source/uploads/avatar.jpg","path":"uploads/avatar.jpg","modified":1,"renderable":0},{"_id":"source/uploads/充分统计量.png","path":"uploads/充分统计量.png","modified":1,"renderable":0},{"_id":"source/uploads/变量消除-有向图.png","path":"uploads/变量消除-有向图.png","modified":1,"renderable":0},{"_id":"source/uploads/变量消除-无向图.png","path":"uploads/变量消除-无向图.png","modified":1,"renderable":0},{"_id":"source/uploads/无向图变量消除计算过程.png","path":"uploads/无向图变量消除计算过程.png","modified":1,"renderable":0},{"_id":"source/uploads/无向图最大似然估计.png","path":"uploads/无向图最大似然估计.png","modified":1,"renderable":0},{"_id":"source/uploads/概率图模型-无向图.jpg","path":"uploads/概率图模型-无向图.jpg","modified":1,"renderable":0},{"_id":"source/uploads/波尔兹曼机示意图.png","path":"uploads/波尔兹曼机示意图.png","modified":1,"renderable":0},{"_id":"source/uploads/隐马尔可夫模型.png","path":"uploads/隐马尔可夫模型.png","modified":1,"renderable":0},{"_id":"source/uploads/频率学派与贝叶斯学派.png","path":"uploads/频率学派与贝叶斯学派.png","modified":1,"renderable":0},{"_id":"source/uploads/EM算法.png","path":"uploads/EM算法.png","modified":1,"renderable":0},{"_id":"source/uploads/Multimodal Machine Learning.gif","path":"uploads/Multimodal Machine Learning.gif","modified":1,"renderable":0},{"_id":"source/uploads/elimination on a tree.png","path":"uploads/elimination on a tree.png","modified":1,"renderable":0},{"_id":"source/uploads/vgg16.jpg","path":"uploads/vgg16.jpg","modified":1,"renderable":0},{"_id":"source/uploads/微信打赏.png","path":"uploads/微信打赏.png","modified":1,"renderable":0},{"_id":"source/uploads/时变网络.png","path":"uploads/时变网络.png","modified":1,"renderable":0},{"_id":"source/uploads/条件独立场.png","path":"uploads/条件独立场.png","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png","path":"uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/A_Star_result.png","path":"uploads/Algorithms/A_Star_result.png","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/Dijkstra_Animation.gif","path":"uploads/Algorithms/Dijkstra_Animation.gif","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/Selection-Sort-Animation.gif","path":"uploads/Algorithms/Selection-Sort-Animation.gif","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/maze.png","path":"uploads/Algorithms/maze.png","modified":1,"renderable":0},{"_id":"source/uploads/CRF进行图像分割/output_12_0.png","path":"uploads/CRF进行图像分割/output_12_0.png","modified":1,"renderable":0},{"_id":"source/uploads/CRF进行图像分割/output_17_0.png","path":"uploads/CRF进行图像分割/output_17_0.png","modified":1,"renderable":0},{"_id":"source/uploads/CRF进行图像分割/output_18_0.png","path":"uploads/CRF进行图像分割/output_18_0.png","modified":1,"renderable":0},{"_id":"source/uploads/CRF进行图像分割/output_21_0.png","path":"uploads/CRF进行图像分割/output_21_0.png","modified":1,"renderable":0},{"_id":"source/uploads/EM算法实现/噪声图片.png","path":"uploads/EM算法实现/噪声图片.png","modified":1,"renderable":0},{"_id":"source/uploads/EM算法实现/背景1.png","path":"uploads/EM算法实现/背景1.png","modified":1,"renderable":0},{"_id":"source/uploads/EM算法实现/图片结构.png","path":"uploads/EM算法实现/图片结构.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png","path":"uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png","path":"uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png","path":"uploads/brain_tumor_segmentation_CNN/T1_coronal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png","path":"uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png","path":"uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png","path":"uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png","path":"uploads/brain_tumor_segmentation_CNN/mask_coronal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/mask_axis.png","path":"uploads/brain_tumor_segmentation_CNN/mask_axis.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png","path":"uploads/brain_tumor_segmentation_CNN/mask_sagittal.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png","path":"uploads/brain_tumor_segmentation_CNN/t1_sagittal.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/data.png","path":"uploads/gnuplot/data.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/gnu_terminal.png","path":"uploads/gnuplot/gnu_terminal.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/plot1.png","path":"uploads/gnuplot/plot1.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/plot3.png","path":"uploads/gnuplot/plot3.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/plot4.png","path":"uploads/gnuplot/plot4.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/plot2.png","path":"uploads/gnuplot/plot2.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/result.png","path":"uploads/gnuplot/result.png","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/Insertion-sort-example-300px.gif","path":"uploads/Algorithms/Insertion-sort-example-300px.gif","modified":1,"renderable":0},{"_id":"source/uploads/CRF进行图像分割/output_9_1.png","path":"uploads/CRF进行图像分割/output_9_1.png","modified":1,"renderable":0},{"_id":"source/uploads/EM算法实现/人脸1.png","path":"uploads/EM算法实现/人脸1.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png","path":"uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/T1_axis.png","path":"uploads/brain_tumor_segmentation_CNN/T1_axis.png","modified":1,"renderable":0},{"_id":"source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png","path":"uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.jpg","path":"images/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/uploads/Algorithms/BFS_DFS.png","path":"uploads/Algorithms/BFS_DFS.png","modified":1,"renderable":0},{"_id":"source/uploads/gnuplot/hyperdense.png","path":"uploads/gnuplot/hyperdense.png","modified":1,"renderable":0},{"_id":"source/uploads/Algorithms/graph_with_weight.png","path":"uploads/Algorithms/graph_with_weight.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/love.js","path":"js/src/love.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"source/uploads/VGG参数.png","path":"uploads/VGG参数.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"source/uploads/Algorithms/Sorting_heapsort_anim.gif","path":"uploads/Algorithms/Sorting_heapsort_anim.gif","modified":1,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"source/uploads/机器学习理论推导/高斯分布-条件概率与边缘概率.png","path":"uploads/机器学习理论推导/高斯分布-条件概率与边缘概率.png","modified":1,"renderable":0},{"_id":"source/uploads/avatar.png","path":"uploads/avatar.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"20c75704cebdf35f97a0801d5faafb7aa5a7da62","modified":1511370870000},{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1511533722000},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1511533722000},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1511533722000},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1511533722000},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1511533722000},{"_id":"themes/next/.gitignore","hash":"ee0b13c268cc8695d3883a5da84930af02d4ed08","modified":1511533722000},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1511533722000},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1511533722000},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1511533722000},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1511533722000},{"_id":"themes/next/README.cn.md","hash":"419b60d064a4ac66565ddeec1be55802acf68c8b","modified":1511533722000},{"_id":"themes/next/README.md","hash":"631d68e9cbced2f11cd976bf883b7d8b08b9b365","modified":1511533722000},{"_id":"themes/next/_config.yml","hash":"2f613b6ca23ff143d1d5ac3d9b24dfead2163320","modified":1556848682000},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1511533722000},{"_id":"themes/next/bower.json","hash":"47471a8f13528dc4052b746db5b4be2375682173","modified":1511533722000},{"_id":"themes/next/package.json","hash":"39370e2aadf1f9a7c105edff064c6e47682b3932","modified":1511533722000},{"_id":"source/_posts/Brain-tumor-segmentation.md","hash":"f483e4e5b90492aa0dc1049987fd1a6c5beee8c7","modified":1554636194000},{"_id":"source/_posts/CRF进行图像分割.md","hash":"1925e0c83014f72500a303e4b936aa0d0dc28c5a","modified":1543545822000},{"_id":"source/_posts/EM算法.md","hash":"9c21253eb8d4d5bb19e472e792039750e0deee76","modified":1538358956000},{"_id":"source/_posts/EM算法程序实现.md","hash":"054327166ce6473da09a4e1c2552616190573487","modified":1537878194000},{"_id":"source/_posts/GAN.md","hash":"b6fbcd2603d06c67b1b75514e5cb6316279ae500","modified":1522211784000},{"_id":"source/_posts/EnglishPod.md","hash":"dbca5954ff278866b6e5310cb36be1ce94054ea1","modified":1528037022000},{"_id":"source/_posts/KL散度.md","hash":"ac40af944a61d93eae545b7c8787dd899201016d","modified":1543321482000},{"_id":"source/_posts/HMM和CRF.md","hash":"be33c4a65b6232349fe1e7a9b526b3f6b426e6be","modified":1537868012000},{"_id":"source/_posts/MC.md","hash":"d0dad7aed3e02f2946f7dd0bf72996788da747b5","modified":1537597818000},{"_id":"source/_posts/MRI读取与可视化I.md","hash":"fd200c3e5d889f3e72e67055f210a676be05442e","modified":1539864556000},{"_id":"source/_posts/Multimodal-Machine-Learning.md","hash":"2920b04522b0674d2c21fbb24c54c5468c1c2cf9","modified":1539690922000},{"_id":"source/_posts/Pytorch_Tutorial.md","hash":"5b6dac6222d63b96b970738db57554843db921c1","modified":1539401952000},{"_id":"source/_posts/SCI论文绘图方法.md","hash":"bbfc4fa0d5697f4f3e7e32b6690828ed2869381c","modified":1560497394000},{"_id":"source/_posts/Shell学习.md","hash":"8cec002dcb76b782bf423c425e11d63ac85ba7c9","modified":1562853490000},{"_id":"source/_posts/VGG16.md","hash":"c4b7ef55e5d27e1c4c5f7e60e3457cec908b4fb9","modified":1537597918000},{"_id":"source/_posts/Ubuntu中出现的问题.md","hash":"9313ab7fcb39d7553d182e8c3e97a8a1a0942c83","modified":1537597890000},{"_id":"source/_posts/cs131笔记.md","hash":"e2ebe4a9a555e8a2d62bce021e05a5c51b03bf74","modified":1538358966000},{"_id":"source/_posts/git使用.md","hash":"79ebd3e4032f3cd8ee4c255258012f585cad5652","modified":1522211806000},{"_id":"source/_posts/hexo博客使用.md","hash":"1ef6161a5a5a30d172969df03ce851698e4bab5d","modified":1522211822000},{"_id":"source/_posts/message-passing.md","hash":"38885cab7a40ef47beb9af64319989e0d11d3aa0","modified":1537597830000},{"_id":"source/_posts/ubuntu16-04下安装atom.md","hash":"62eae96c91318c66774b8bfab5e377e508c2b187","modified":1537597870000},{"_id":"source/_posts/ubuntu时间同步.md","hash":"33b18b6b5cda6d717a15ed8409e758671e63b5ec","modified":1537597880000},{"_id":"source/_posts/variational-inference.md","hash":"79a738e84efd1857282b57ffac5dd58e136f9d79","modified":1537597900000},{"_id":"source/_posts/典型相关性.md","hash":"2fc5afff4d85436c773026fb55a77b36575e4734","modified":1537926132000},{"_id":"source/_posts/写在感冒之后.md","hash":"02b08a13a7e8541499b4acca2182818803a7b65c","modified":1556716724000},{"_id":"source/_posts/医学图像可视化.md","hash":"69292a289398232e4de89898739ddd517a2bc512","modified":1547185818000},{"_id":"source/_posts/医学图像分析中的常用评价指标与损失函数.md","hash":"944145ba190abf829ee48dbb74bdf32b8b994571","modified":1558682554000},{"_id":"source/_posts/医学图像处理基础.md","hash":"306bdbca55095a219bf2a3922cca453e84bac56e","modified":1565427116000},{"_id":"source/_posts/变量消除.md","hash":"cfa112db62940d65859b3daf3d6393c991fd0666","modified":1537597930000},{"_id":"source/_posts/可观无向图模型中的学习问题.md","hash":"14ec9c86a2b8441937bb2aa08c9be782f8186260","modified":1537598016000},{"_id":"source/_posts/可观贝叶斯网络中的学习问题.md","hash":"ba584c46375ea5a8ae4a18d440515827b26963c9","modified":1537598006000},{"_id":"source/_posts/学期总结.md","hash":"60ed3e332f54938b5bad2aab3cc671549daea7a9","modified":1556716826000},{"_id":"source/_posts/学术词语收集.md","hash":"495c431afce3d2fd9f503ba60218b07723ada389","modified":1524048584000},{"_id":"source/_posts/建博初衷.md","hash":"115c2baa0a4796d26dfc717e7b0c5e9627e2d658","modified":1556716770000},{"_id":"source/_posts/文献整理.md","hash":"f8f3fc96c2e29195177428bcd1126b9a22d74aad","modified":1554636568000},{"_id":"source/_posts/指数族与广义线性模型.md","hash":"2c49349eeeefa0c3ae1a2335a6509d46c8421f3d","modified":1537598028000},{"_id":"source/_posts/概率图模型.md","hash":"e9b3efd9058c6540b84e3b7b44f3a0218689915c","modified":1537597952000},{"_id":"source/_posts/概率论知识点.md","hash":"cdf82d56373d9e3706d49923da6e8211805450cc","modified":1537597940000},{"_id":"source/_posts/汇报list.md","hash":"cb9efcf06c9a38604cfb2bb67fef5651ab4ecc8e","modified":1539248558000},{"_id":"source/_posts/深度学习医学图像方向大佬.md","hash":"867cd93aaa3c4dda86136340e8b60fb645cdd2b3","modified":1556368860000},{"_id":"source/_posts/神经网络.md","hash":"43cdff13858bad46ffc33aa3ce21b050da1626e6","modified":1524143250000},{"_id":"source/_posts/科研三境界.md","hash":"241432ad436f2b538bf2a0aa5bb258e62f8c2add","modified":1556716754000},{"_id":"source/_posts/算法学习一.md","hash":"63ae2dbe51b51721a29303d9d4cfdda096dfec4f","modified":1556716894000},{"_id":"source/_posts/算法学习二.md","hash":"827c3c8c6a7b679048fd3f72dade1566213a7396","modified":1556715330000},{"_id":"source/_posts/计算机视觉回顾.md","hash":"ddb83264e9f5969113fdebadca669b036527da37","modified":1537597982000},{"_id":"source/_posts/论文总结.md","hash":"af3c18b85711ff9f179594c2b68571dab89ae1be","modified":1526779882000},{"_id":"source/_posts/谷歌学术搜索使用技巧.md","hash":"ef5bf7f72fd25d4970dfed1e968c189439261078","modified":1537597970000},{"_id":"source/_posts/进化算法.md","hash":"e2996024a4625977b033a99916d3c6b86b405667","modified":1544187340000},{"_id":"source/_posts/雅思.md_","hash":"b44bc98c7cd3a23106c6a73f61939bba033d1ead","modified":1569805614000},{"_id":"source/_posts/高斯图模型图和伊辛图模型.md","hash":"4c861a38be91a90cf283c5ec1e36ae6c17bcba88","modified":1537597960000},{"_id":"source/_posts/高斯过程.md","hash":"493074f3e14f52a92c4fd2e1857edbe74db7ab8c","modified":1576998360000},{"_id":"source/about/index.md","hash":"6e59aeabcf51f6a30f33c55fdfe4a956ce42d4ba","modified":1511520452000},{"_id":"source/categories/index.md","hash":"8063d95785372843bd58641990abd80549021c66","modified":1522574660000},{"_id":"source/tags/index.md","hash":"83510f46f95bc472b67183b5afafdc5e9477e91e","modified":1511930506000},{"_id":"source/message/index.md","hash":"7ffd6369edad382becee8d6d0cbeab86dad03258","modified":1511522536000},{"_id":"source/uploads/CRF.png","hash":"c8fd8cbba955e7dc18f903c8ff1c0e4330cb5c64","modified":1525871264000},{"_id":"source/uploads/LASSO回归.png","hash":"5a81e17af270124490e6a143bd8681b11cd83016","modified":1528700550000},{"_id":"source/uploads/MEMM.png","hash":"309f433c7d0cbb4126ced0997cc7cd3f52863ee2","modified":1528099554000},{"_id":"source/uploads/TPandFP.png","hash":"b689419947f6402dd6aca6f642f0e28915ab8850","modified":1558594258000},{"_id":"source/uploads/Pytorch_Tutorial_output_35_0 .png","hash":"4eb28736530e7a42f69768a1a849610fca13aff7","modified":1539395626000},{"_id":"source/uploads/TPandFP.vsdx","hash":"37a0f24adc4db90df5260b195d6e8f995ff618dd","modified":1558594260000},{"_id":"source/uploads/Pytorch_Tutorial_output_42_0.png","hash":"38d9efb1bf049c592cb1b949d2721e2f067a237e","modified":1539395626000},{"_id":"source/uploads/VGG16处理过程.png","hash":"24e24847d989813062510840e2e03eb768c340c3","modified":1535709766000},{"_id":"source/uploads/avatar.jpg","hash":"33668147166e59090be386426ed88a343f7dc384","modified":1511421672000},{"_id":"source/uploads/充分统计量.png","hash":"58c5e80d556dc0c7b1aca670c2be0195d2c59186","modified":1525920440000},{"_id":"source/uploads/变量消除-有向图.png","hash":"718c19faea75874085dab269590e3724ca768eb5","modified":1522983246000},{"_id":"source/uploads/变量消除-无向图.png","hash":"09c8292863f18badabeb59cf142b2648587f8783","modified":1523105654000},{"_id":"source/uploads/无向图变量消除计算过程.png","hash":"5fd44399caedbcce11ccc153fbbc8e0cba9fc062","modified":1523107402000},{"_id":"source/uploads/无向图最大似然估计.png","hash":"fff365a542a3a48979a7c69120392d646c22b004","modified":1526805854000},{"_id":"source/uploads/概率图模型-无向图.jpg","hash":"58815e675e695a8d6f9aa7e124be12cb5d7edbd5","modified":1522221830000},{"_id":"source/uploads/波尔兹曼机示意图.png","hash":"2e2d41bde955821f8925dff79da234c6457e4f03","modified":1522633870000},{"_id":"source/uploads/隐马尔可夫模型.png","hash":"47a3a0b3ab2e2b8388041ca9990592bf3149678f","modified":1523104740000},{"_id":"source/uploads/频率学派与贝叶斯学派.png","hash":"58058f38be4fd97d485fcd45fabefc71b3c50aeb","modified":1525769490000},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1511533722000},{"_id":"themes/next/.git/FETCH_HEAD","hash":"5e754a143823f77610ca134cef1b101958def41e","modified":1522160876000},{"_id":"themes/next/.git/ORIG_HEAD","hash":"53814d46a4f19b2e026339024c8c1e2f179bdb6c","modified":1522160876000},{"_id":"themes/next/.git/config","hash":"8e94cc015a498d35202e9fd57e44b3c51e1e5634","modified":1511533722000},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1511533710000},{"_id":"themes/next/.git/index","hash":"234e8900c2a35d9350c1144fc34c90b6387d1fd4","modified":1577595676000},{"_id":"themes/next/.git/packed-refs","hash":"cf194fc694b867dea08824c599c509aa32e1c65b","modified":1511533722000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1511533722000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"b1ec000babd42bb7ffd26f5ad8aac9b5bec79ae5","modified":1511533722000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1511533722000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1511533722000},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1511533722000},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1511533722000},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1511533722000},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1511533722000},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1511533722000},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1511533722000},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1511533722000},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1511533722000},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1511533722000},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1511533722000},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1511533722000},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1511533722000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1511533722000},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1511533722000},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1511533722000},{"_id":"themes/next/layout/_layout.swig","hash":"e1d3565a47e3dcfbc848e78c3c8288cf7ad2bb5b","modified":1522982196000},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1511533722000},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1511533722000},{"_id":"themes/next/layout/index.swig","hash":"a3145d400a968fbd848bd71a99c5b8fdd38059c8","modified":1556694846000},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1511533722000},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1511533722000},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1511533722000},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1511533722000},{"_id":"themes/next/scripts/fold.js","hash":"915bd7e1634c24913aa9c53f39c144c8211d9a6a","modified":1556714998000},{"_id":"themes/next/scripts/merge-configs.js","hash":"5758f8f3f12d17bc80da65bb808a20b3a8aae186","modified":1511533722000},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1511533722000},{"_id":"themes/next/scripts/tags.js","hash":"ce0cc6452a8349b6f959a1417c2cdd2847fd2f10","modified":1556714954000},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1511533722000},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1511533722000},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1511533722000},{"_id":"source/uploads/EM算法.png","hash":"7ba547f6835c0174658846830e8ab222b3389901","modified":1536117768000},{"_id":"source/uploads/Multimodal Machine Learning.gif","hash":"f9bbb4dc39947998aba287e8013b739c0860e2d0","modified":1538558432000},{"_id":"source/uploads/elimination on a tree.png","hash":"4c0ed67f5d4cbd7194ddb125d55ae6caea405c6f","modified":1524359504000},{"_id":"source/uploads/vgg16.jpg","hash":"bd4312abe12e78df9bb66b34355c4ae428e54a9a","modified":1535708824000},{"_id":"source/uploads/微信打赏.png","hash":"6633fa0f11a32d2b54561819c87b475c2fc5c617","modified":1537588268000},{"_id":"source/uploads/时变网络.png","hash":"e2a63d08998d18d231747871e3d0b0c87e45333d","modified":1528702222000},{"_id":"source/uploads/条件独立场.png","hash":"7850c535430a9701e2e1ac2d255e0581c2cb1936","modified":1522650334000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"source/_posts/机器学习理论推导/引言.md","hash":"a03fed2fbc916302f606f6835808408a554b5d9b","modified":1577332090000},{"_id":"source/_posts/机器学习理论推导/线性分类-感知机.md","hash":"0693731e6150a5f5a6888acb4b25ef59805c1769","modified":1577603330000},{"_id":"source/_posts/机器学习理论推导/线性分类-逻辑回归.md","hash":"6f361af10e8cd634272b64cdab7a82ea279d1967","modified":1577617914000},{"_id":"source/_posts/机器学习理论推导/机器学习推导-频率与贝叶斯.md","hash":"7b76ba570e78a3e3fb56ea1505963c8498eb52b6","modified":1577544240000},{"_id":"source/_posts/机器学习理论推导/线性分类-线性判别分析.md","hash":"d70e1da32270dee0824696a64bd265f4515b31cc","modified":1577615668000},{"_id":"source/_posts/机器学习理论推导/线性回归-岭回归.md","hash":"49da02ead0de58c2e0cf8770d5b86bf268b413f9","modified":1577601008000},{"_id":"source/_posts/机器学习理论推导/线性回归-最小二乘法-概率视角.md","hash":"3675a22dead9fe9e2d5ca289862d236d40c8dc64","modified":1577601790000},{"_id":"source/_posts/机器学习理论推导/线性回归-最小二乘法.md","hash":"df3f237ad0a5f92854d4f19ef2f79db51ebf4871","modified":1577544248000},{"_id":"source/_posts/机器学习理论推导/高斯分布-最大似然估计.md","hash":"db6ba8901d3cbac860b6b7576fe06d97361b60ee","modified":1577544254000},{"_id":"source/_posts/机器学习理论推导/高斯分布-条件概率与边缘概率.md","hash":"8a147b62ef0b02ea5d5d67e184927f53e5fd32a4","modified":1577544234000},{"_id":"source/_posts/机器学习理论推导/高斯分布-联合概率.md","hash":"b64174441131630cadd1f67f67f06bd90c4cb087","modified":1577544238000},{"_id":"source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png","hash":"c465300d83977b1f825d91c1c2d3330104b5f0cc","modified":1556585488000},{"_id":"source/uploads/Algorithms/A_Star_result.png","hash":"08cdd15b7ecb0cd5877401f81e76a3781c0cbc6f","modified":1556692226000},{"_id":"source/uploads/Algorithms/Dijkstra_Animation.gif","hash":"e6c1e1b8c4555508d90f08cc76b283c0be358fc9","modified":1556630424000},{"_id":"source/uploads/Algorithms/Selection-Sort-Animation.gif","hash":"ceeff3c8ed5fee2f1998f686a5489a3d52c38a04","modified":1556452020000},{"_id":"source/uploads/Algorithms/maze.png","hash":"a95e0d999087298370ea230d2b3996a14604244a","modified":1556696674000},{"_id":"source/uploads/CRF进行图像分割/output_12_0.png","hash":"213ef258a71bbcc61eae360f766d0c480f8f43a6","modified":1543540956000},{"_id":"source/uploads/CRF进行图像分割/output_17_0.png","hash":"f1d8ca034a1b66b9d5bfe587a440e7a20284e25d","modified":1543540956000},{"_id":"source/uploads/CRF进行图像分割/output_18_0.png","hash":"9b530c50549b92e257e010f36707dfa3201a03fc","modified":1543540956000},{"_id":"source/uploads/CRF进行图像分割/output_21_0.png","hash":"a81f362dfea99d1f6594c2cd897b480c3c764639","modified":1543540956000},{"_id":"source/uploads/EM算法实现/噪声图片.png","hash":"439ffbe3bb163179145ba6772ebddbebe3570cf9","modified":1536376408000},{"_id":"source/uploads/EM算法实现/背景1.png","hash":"5111b86381841cc8380adde1c596a4f7274d6020","modified":1536375244000},{"_id":"source/uploads/EM算法实现/图片结构.png","hash":"68db6cbfce2698c83ce983eed6825c990834ad45","modified":1536376506000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png","hash":"689cf411b6659553a1c38eb7205da7b2a304256f","modified":1551450708000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png","hash":"78525adf34c3c53b4764cfa7d32cf521eb8acd07","modified":1551450676000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png","hash":"53a65bb68fa2dcead022d6a44c65e53827a2516c","modified":1551450948000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png","hash":"b548d537fcf3f985005525eb633f2532c5b659f9","modified":1551599942000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png","hash":"fcfb30bbf1c40970de2b726604dba16e97995a6e","modified":1551600044000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png","hash":"5981cecc2152404987584bd38d2bee162796c164","modified":1551600004000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png","hash":"f4dd17532b8f926762a9f30616e35bb1eca2c4e1","modified":1551599874000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/mask_axis.png","hash":"c8e487ce71d45e43f495740e73e3af38ab06e3af","modified":1551599826000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png","hash":"0b1102c467886df2acd50f77c18e05034e87c6ad","modified":1551599842000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png","hash":"c232ffb514b059313e1da1c00e558b8446cf7c36","modified":1551450866000},{"_id":"source/uploads/gnuplot/data.png","hash":"ac93e3e2143bd864ddd8c459a76b9a20a81ecb7e","modified":1560472682000},{"_id":"source/uploads/gnuplot/gnu_terminal.png","hash":"dc115785f66dd6cbbd23761243f7a0cc8f710aa4","modified":1560407956000},{"_id":"source/uploads/gnuplot/plot1.png","hash":"a083c38a4016343835d9789d957f6cb11f8863b1","modified":1560473280000},{"_id":"source/uploads/gnuplot/plot3.png","hash":"ebec4bddf190a9aade0fc44f2b6d1033a1501def","modified":1560478762000},{"_id":"source/uploads/gnuplot/plot4.png","hash":"3957806aedda2283285eed7774deda0cb1afe4bc","modified":1560493830000},{"_id":"source/uploads/gnuplot/plot2.png","hash":"3bcbe5ee7048802c7ae352c8048701598d640d96","modified":1560475014000},{"_id":"source/uploads/gnuplot/result.png","hash":"97dc8af39c417bca13aed5cf31eeb975f8243c72","modified":1560494276000},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1511533710000},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1511533710000},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1511533710000},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1511533710000},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1511533710000},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1511533710000},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1511533710000},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1511533710000},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1511533710000},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1511533710000},{"_id":"themes/next/.git/logs/HEAD","hash":"2a23980844ea0dc52c0e783ba9c17aef09152475","modified":1511533722000},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1511533722000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1511533722000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1511533722000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1511533722000},{"_id":"themes/next/layout/_macro/post.swig","hash":"4ba938822d56c597490f0731893eaa2443942e0f","modified":1511533722000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1511533722000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"b9f9959225876fb56fb3fba96306d19396e704d4","modified":1511533722000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1511533722000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4adc65a602d1276615da3b887dcbf2ac68e7382b","modified":1511533722000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"26e93336dc57a39590ba8dc80564a1d2ad5ff93b","modified":1511533722000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6907ef335cf4d190e7bf38b00705f264a98f17c3","modified":1556695296000},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1511533722000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1511533722000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1511533722000},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1511533722000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1511533722000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1511533722000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1511533722000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1511533722000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1511533722000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1511533722000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1511533722000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1511533722000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1511533722000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1511533722000},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1511533722000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1511533722000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1511533722000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1511533722000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1511533722000},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1511533722000},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1511533722000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1511533722000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1511533722000},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1511533722000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1511533722000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1511533722000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1511533722000},{"_id":"themes/next/source/images/avatar.jpg","hash":"efd5695c5869c74449c21b030482960589e8e05d","modified":1511707450000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1511533722000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1511533722000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1511533722000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1511533722000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1511533722000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1511533722000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1511533722000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1511533722000},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1511533722000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1511533722000},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1511533722000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1511533722000},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1511533722000},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1511533722000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1511533722000},{"_id":"source/uploads/Algorithms/Insertion-sort-example-300px.gif","hash":"5fc8daa9296837453ccbc8c7f9c2494bbd1fcdda","modified":1556497366000},{"_id":"source/uploads/CRF进行图像分割/output_9_1.png","hash":"9a012379b095d49c49bed150c3ddf3df3588b690","modified":1543540956000},{"_id":"source/uploads/EM算法实现/人脸1.png","hash":"47a88a80249ce7b22eac9df0dc3ea431b40f1ff4","modified":1536375232000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png","hash":"908322cb6d9d793297699b3060251159c8399642","modified":1551450642000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/T1_axis.png","hash":"2bdd2c088c877fe8d261f11621d148043920d7d0","modified":1551450838000},{"_id":"source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png","hash":"30a90d207a46e745a8ab4e8f079ec85c29b1fd95","modified":1551366592000},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1511533710000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1511533722000},{"_id":"source/uploads/Algorithms/BFS_DFS.png","hash":"f0c2adab6b7c71dbc45392ec96ab5c181f8f7bab","modified":1556607738000},{"_id":"source/uploads/gnuplot/hyperdense.png","hash":"8a95ffbecfa12f39db9d8bdccb804daf4f075b87","modified":1560494916000},{"_id":"themes/next/.git/objects/pack/pack-8c78711a0315afcd513625783da0194c993abdec.idx","hash":"97a8a46a00c67b48ea77115e1464ca9d8e14bb77","modified":1522160876000},{"_id":"themes/next/.git/refs/heads/master","hash":"53814d46a4f19b2e026339024c8c1e2f179bdb6c","modified":1511533722000},{"_id":"themes/next/.git/refs/tags/v5.1.4","hash":"66e8b5048a20ce41a8a240072e535d725d62aef4","modified":1522160876000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1511533722000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1511533722000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1511533722000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1511533722000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1511533722000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1511533722000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1511533722000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1511533722000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1511533722000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1511533722000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1511533722000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1511533722000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"493bd5999a1061b981922be92d8277a0f9152447","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1511533722000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1511533722000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1511533722000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1511533722000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1511533722000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1511533722000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"7e13d1943a00a1a38fceaefb55fa6ec98b5c7649","modified":1556715050000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1511533722000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1511533722000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1511533722000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1511533722000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1511533722000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1511533722000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"2e0e5e4aa0c5eb25f6fb1b32768ed8dcf6685a35","modified":1556849776000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"69af79ea610af2a4aa3022f2026d7d8ce3fefe7a","modified":1556851710000},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1511533722000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1511533722000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1511533722000},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1511533722000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1511533722000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1511533722000},{"_id":"themes/next/source/js/src/love.js","hash":"6583037545c7edc355f76f29b3393e250b150032","modified":1522981942000},{"_id":"themes/next/source/js/src/post-details.js","hash":"3795ece52bbe1475b910d1ce5ee94269f219c8b3","modified":1556714818000},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1511533722000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1511533722000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1511533722000},{"_id":"themes/next/source/js/src/utils.js","hash":"b7ddc240208d57596a67c78a04a11b0f0bdecc97","modified":1511533722000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1511533722000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"672d3b5767e0eacd83bb41b188c913f2cf754793","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"9be892a4e14e0da18ff9cb962c9ef71f163b1b22","modified":1511533722000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1511533722000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1511533722000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1511533722000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1511533722000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1511533722000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1511533722000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1511533722000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1511533722000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1511533722000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1511533722000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1511533722000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1511533722000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1511533722000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"14264a210bf94232d58d7599ea2ba93bfa4fb458","modified":1511533722000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"e33aa8fa48b6639d8d8b937d13261597dd473b3a","modified":1511533722000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"2ce5f3bf15c523b9bfc97720d8884bb22602a454","modified":1511533722000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1511533722000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1511533722000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1511533722000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1511533722000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1511533722000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1511533722000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1511533722000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1511533722000},{"_id":"source/uploads/Algorithms/graph_with_weight.png","hash":"ea415f9e0d067b3376a73771f014b7bd56483fa6","modified":1556630548000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1511533722000},{"_id":"source/uploads/VGG参数.png","hash":"283d6559cb5d4eae88586ddbb95fe86bfc22c442","modified":1535711250000},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"2a23980844ea0dc52c0e783ba9c17aef09152475","modified":1511533722000},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1511533722000},{"_id":"themes/next/.git/refs/remotes/origin/master","hash":"8d68aab3ed0ae7f4d76d6a1708ac38ba9c2e121d","modified":1522160876000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1511533722000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1511533722000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1511533722000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1511533722000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1511533722000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1511533722000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1511533722000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1511533722000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"a98ad885ee4f48d85b2578a0b9c2bbf166e96733","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"30561ed60fc64f3e4ce85143bdb55faa814743a6","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1511533722000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1511533722000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1511533722000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1511533722000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1511533722000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1511533722000},{"_id":"themes/next/.git/objects/pack/pack-8c78711a0315afcd513625783da0194c993abdec.pack","hash":"7b0bcd9dd3c4313a95a4256a89a92e5660c97935","modified":1522160876000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1511533722000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1511533722000},{"_id":"source/uploads/Algorithms/Sorting_heapsort_anim.gif","hash":"d70822274ca52ebc2c925fb94e81dc6a11591afa","modified":1556505926000},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"2a23980844ea0dc52c0e783ba9c17aef09152475","modified":1511533722000},{"_id":"themes/next/.git/logs/refs/remotes/origin/master","hash":"71fdafd77afb2323de2c668cbf3497b051635be7","modified":1522160876000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"3159b55f35c40bd08e55b00148c523760a708c51","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"28a8737c090fbffd188d73a00b42e90b9ee57df2","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"62fbbd32cf5a99ae550c45c763a2c4813a138d01","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"3a90382f082ffe64b3bd81a997543e4da5cb3f09","modified":1556849546000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"89d6c3b697efc63de42afd2e89194b1be14152af","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1511533722000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9c8196394a89dfa40b87bf0019e80144365a9c93","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1511533722000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1511533722000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1511533722000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1511533722000},{"_id":"themes/next/.git/objects/pack/pack-4f661259525661ea7a632f52b5dd0b8c0f850a9b.idx","hash":"e0512a8878d227d62a88564be7dff2f7da4e5c65","modified":1511533720000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1511533722000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1511533722000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1511533722000},{"_id":"source/uploads/机器学习理论推导/高斯分布-条件概率与边缘概率.png","hash":"b8a694a038cfcb00ff2ff93b2b4e6a5edb3365c9","modified":1577515550000},{"_id":"source/uploads/avatar.png","hash":"89c2ddabf58db1c7c6ba86d0294ca6687e034ba9","modified":1511422632000},{"_id":"themes/next/.git/objects/pack/pack-4f661259525661ea7a632f52b5dd0b8c0f850a9b.pack","hash":"c25b1dc0c31a974ded4df3af100f4776edcbf165","modified":1511533720000}],"Category":[{"name":"学习","_id":"ck4r40mv0001j1ouzvcwdsym7"},{"name":"工作","_id":"ck4r40mve00261ouz70mn8t1y"},{"name":"技术","_id":"ck4r40mvi002c1ouz0v6ak9yc"},{"name":"随笔","_id":"ck4r40mvr002r1ouzawjuztbe"},{"name":"编程","_id":"ck4r40mwf003x1ouze9i9a0cd"}],"Data":[],"Page":[{"title":"about","date":"2017-11-24T10:45:58.000Z","comments":0,"_content":"here is something about me.\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-11-24 18:45:58\ncomments: false\n---\nhere is something about me.\n","updated":"2017-11-24T10:47:32.000Z","path":"about/index.html","layout":"page","_id":"ck4r40mrt00001ouzu2krqoh7","content":"<p>here is something about me.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>here is something about me.</p>\n"},{"title":"文章分类","date":"2018-03-28T04:29:59.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 文章分类\ndate: 2018-03-28 12:29:59\ntype: \"categories\"\n---\n","updated":"2018-04-01T09:24:20.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ck4r40mry00021ouzml8cava6","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags - python - 随笔 - 机器学习 - ubuntu","date":"2017-11-21T12:30:56.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\n  - python\n  - 随笔\n  - 机器学习\n  - ubuntu\ndate: 2017-11-21 20:30:56\ntype: \"tags\"\n---\n","updated":"2017-11-29T04:41:46.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ck4r40ms000041ouznnv7y1g0","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"message","date":"2017-11-24T10:47:48.000Z","comments":1,"_content":"有事请留言。\n","source":"message/index.md","raw":"---\ntitle: message\ndate: 2017-11-24 18:47:48\ncomments: true 打开评论\n---\n有事请留言。\n","updated":"2017-11-24T11:22:16.000Z","path":"message/index.html","layout":"page","_id":"ck4r40ms200061ouzmt5iiirr","content":"<p>有事请留言。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>有事请留言。</p>\n"}],"Post":[{"title":"基于卷积神经网络的脑肿瘤分割","date":"2019-02-28T14:09:38.000Z","catagories":"学习","_content":"# 前言\n本人一直研究脑肿瘤分割，脑肿瘤分割对于患者的后续治疗以及对疾病的检测有着重要的意义，同时也是人工智能处理医学图像的重要方向之一。目前开源的代码都比较复杂，不适合入门研究，另外 Pytorch 作为一个容易上手的深度学习框架，具有很强的灵活性，适合新手或者是科研工作者，所以本文的代码将使用深度学习框架 Pytorch1.0 和 Python3.6 进行编程构建卷积神经网络来进行脑肿瘤分割。卷积神经网络不仅在自然图像而且在医学图像在内的其他图像都有着广泛地应用。另外，卷积神经网络广泛地应用于图像的分类，检测等计算机视觉任务中。\n\n# 数据\n我们这里使用 BraTs2015 的部分数据集，数据集可以从[这里下载](https://github.com/yaq007/Autofocus-Layer)，完整的BraTs2015 数据集可以在这里[注册下载](https://www.smir.ch/BRATS/Start2015)。\n\n本文使用的数据集共有20例样本用于训练，54例样本用于测试(可自行调整)，每个样本中共有4个模态的数据和Mask和真值数据，其中4个模态分别为FLAIR， T1，T1c，T2。真值数据共有5个标签：\n* label 1: necrosis\n* label 2: edema\n* label 3: non-enhacing tumor\n* label 4: enhancing tumor\n* label 0：everything else\n\n脑肿瘤分割主要有3个部分，Whole tumor， Tumor core， Enhance tumor。这3个部分的标签如下所示：\n* Whole tumor: label 1, 2, 3, 4\n* Enhance tumor: label 4\n* Tumor core: 1, 3, 4\n\nBraTs2015 使用 Dice 作为评价指标，这个评价指标主要是衡量预测结果与真值之间重叠部分。 Dice 的公式计算如下：\n$$ Dice = \\frac{2 TP}{2TP + FP + FN} $$\n\n## 可视化\n前面我们知道 BraTs 2015 共有4个模态的数据，下面我们介绍两个能够在程序中读取医学图像的包：SimpleITK 和 Nibabel。SimpleITK能够读取的格式更加多，具体可以参考 SimpleITK 的文档。\n\n### SimpleITK\nSimpleITK 读取医学图像示例代码：\n```\nimport SimpleITK as sitk\nimage = sitk.ReadImage('image.nii')\nimage = sitk.GetArrayFromImage(image)\n```\nSimpleITK 读取的图片维度是通道优先的，所以图像的维度的第1位是医学图像的维数。另外我还使用到了 SimpleITK 将输出预测结果保存为医学图像格式，这部分代码如下：\n```\nimage = sitk.GetImageFromArray(image)\nsitk.WriteImage(image, 'image.mha')\n```\n\n### Nibabel\nNibabel 读取医学图像示例代码：\n```\nimport nibabel as nib \nimage = nib.load('image.nii.gz').get_fdata()\nimage = image.transpse(1, 0, 2)\n```\n不同于 SimpleITK， Nibabel 读取图像的维度的通道数位于最后 1 位，但是 Nibabel 将图像旋转了 $90^{\\circ}$，可以使用上面代码的第三行旋转为一般维数分布方式。比如脑图中，如果不旋转变换转变 Nibabel 读取的方式，脑图就是横着的。\n\n### 3D Slicer 可视化\nSimpleITK 和 Nibabel 是可以在程序中读取医学图像的包，灵活性不强，另外不适合了解医学图像的基本特性，下面我们使用 3D Slicer 来可视化我们的医学图像数据。\n{% gp 5-4 %}\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png)\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png)\n{% endgp %}\n上图中，第一行为 FLAIR 模态，从左到有依次为横断面(Axis plane)，矢状面(Sagittal plane)，冠状面(Coronal plane)，第二行为 T1 模态，从左到右顺序与 FLAIR 相同，另外两个模态因为篇幅的关系不做具体地展示。下面是脑图的 mask 和手工分割肿瘤的真值(可以看做是金标准，但是个人认为还是有区别的)：\n{% gp 5-4 %}\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png)\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png)\n{% endgp %}\n本人使用的数据库来自于项目[2] 中，具体如何得到的 mask 数据并不是很清楚，不过通过 3D slicer 可以手工生成mask数据，这里时间有限，不准备写了。上图中第二行是三个维度的真值图，其中外围浅蓝色为剔除肿瘤之外的区域(label 0)，绿色为 edema(label 2)，红色为 enhance tumor(label 4)，深蓝色区域为 necrosis(label 1)，黄色区域为 non-enhance tumor(label 3)。注：这里使用的 Brats 2015 采用了这5个标签，之后的该数据集进行了调整，将non-enhncing 和 necrosis 合并为 label 1。\n\n# 模型\n本文使用卷积神经网络，主要结构参考[1]中的结构，不同之处在于为了方便理解，我们只是用了一条通道。模型如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png)\n训练使用交叉熵作为损失函数，利用 RMSprop 作为优化器，学习率设为 $1e-3$，可以对学习率随着epoch进行调整，这里没有改变，读者可以根据自己的想法进行调整。具体代码可以在我的github[3]中查看，喜欢记得点个小星星。\n\n# 训练与测试\n训练部分采用随机裁剪图片大小为 $75\\times75\\times75$ ，输入到神经网络中，最后得到$47\\times47\\times47$ (因为卷积中没有采用padding，所以出现了输出小于输入的情况)。测试部分使用完全大小的图像 $240 \\times 240 \\times 225$，输入到网络中得到大小为$212 \\times 212 \\times 197$，因为脑图的边缘是无效的信息，所以输出的大小与输入和真值维度不一致，不会有影响，只需要补全就行了。\n\n# 结果\n最后网络在三个子区域的分割指标 Dice 为：Whole score 0.6764， Enhancing tumor 0.4478, Tumor core 0.4819，这个结果并不是非常的好，读者如需更高准确度的分割结果，可以调整测试时候的输入图像的维数，将其保持为与训练时输入的图像维数一致，另外可以参考最新的脑肿瘤分割的工作，对代码进行改进。\n\n# 参考文献\n[1] Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.\n[2] https://github.com/yaq007/Autofocus-Layer\n[3] https://github.com/hjyai94/Half_Pathway_DeepMedic\n","source":"_posts/Brain-tumor-segmentation.md","raw":"---\ntitle: 基于卷积神经网络的脑肿瘤分割\ndate: 2019-02-28 22:09:38\ntags: 脑肿瘤分割\ncatagories: 学习\n---\n# 前言\n本人一直研究脑肿瘤分割，脑肿瘤分割对于患者的后续治疗以及对疾病的检测有着重要的意义，同时也是人工智能处理医学图像的重要方向之一。目前开源的代码都比较复杂，不适合入门研究，另外 Pytorch 作为一个容易上手的深度学习框架，具有很强的灵活性，适合新手或者是科研工作者，所以本文的代码将使用深度学习框架 Pytorch1.0 和 Python3.6 进行编程构建卷积神经网络来进行脑肿瘤分割。卷积神经网络不仅在自然图像而且在医学图像在内的其他图像都有着广泛地应用。另外，卷积神经网络广泛地应用于图像的分类，检测等计算机视觉任务中。\n\n# 数据\n我们这里使用 BraTs2015 的部分数据集，数据集可以从[这里下载](https://github.com/yaq007/Autofocus-Layer)，完整的BraTs2015 数据集可以在这里[注册下载](https://www.smir.ch/BRATS/Start2015)。\n\n本文使用的数据集共有20例样本用于训练，54例样本用于测试(可自行调整)，每个样本中共有4个模态的数据和Mask和真值数据，其中4个模态分别为FLAIR， T1，T1c，T2。真值数据共有5个标签：\n* label 1: necrosis\n* label 2: edema\n* label 3: non-enhacing tumor\n* label 4: enhancing tumor\n* label 0：everything else\n\n脑肿瘤分割主要有3个部分，Whole tumor， Tumor core， Enhance tumor。这3个部分的标签如下所示：\n* Whole tumor: label 1, 2, 3, 4\n* Enhance tumor: label 4\n* Tumor core: 1, 3, 4\n\nBraTs2015 使用 Dice 作为评价指标，这个评价指标主要是衡量预测结果与真值之间重叠部分。 Dice 的公式计算如下：\n$$ Dice = \\frac{2 TP}{2TP + FP + FN} $$\n\n## 可视化\n前面我们知道 BraTs 2015 共有4个模态的数据，下面我们介绍两个能够在程序中读取医学图像的包：SimpleITK 和 Nibabel。SimpleITK能够读取的格式更加多，具体可以参考 SimpleITK 的文档。\n\n### SimpleITK\nSimpleITK 读取医学图像示例代码：\n```\nimport SimpleITK as sitk\nimage = sitk.ReadImage('image.nii')\nimage = sitk.GetArrayFromImage(image)\n```\nSimpleITK 读取的图片维度是通道优先的，所以图像的维度的第1位是医学图像的维数。另外我还使用到了 SimpleITK 将输出预测结果保存为医学图像格式，这部分代码如下：\n```\nimage = sitk.GetImageFromArray(image)\nsitk.WriteImage(image, 'image.mha')\n```\n\n### Nibabel\nNibabel 读取医学图像示例代码：\n```\nimport nibabel as nib \nimage = nib.load('image.nii.gz').get_fdata()\nimage = image.transpse(1, 0, 2)\n```\n不同于 SimpleITK， Nibabel 读取图像的维度的通道数位于最后 1 位，但是 Nibabel 将图像旋转了 $90^{\\circ}$，可以使用上面代码的第三行旋转为一般维数分布方式。比如脑图中，如果不旋转变换转变 Nibabel 读取的方式，脑图就是横着的。\n\n### 3D Slicer 可视化\nSimpleITK 和 Nibabel 是可以在程序中读取医学图像的包，灵活性不强，另外不适合了解医学图像的基本特性，下面我们使用 3D Slicer 来可视化我们的医学图像数据。\n{% gp 5-4 %}\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png)\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png)\n{% endgp %}\n上图中，第一行为 FLAIR 模态，从左到有依次为横断面(Axis plane)，矢状面(Sagittal plane)，冠状面(Coronal plane)，第二行为 T1 模态，从左到右顺序与 FLAIR 相同，另外两个模态因为篇幅的关系不做具体地展示。下面是脑图的 mask 和手工分割肿瘤的真值(可以看做是金标准，但是个人认为还是有区别的)：\n{% gp 5-4 %}\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png)\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png)\n{% endgp %}\n本人使用的数据库来自于项目[2] 中，具体如何得到的 mask 数据并不是很清楚，不过通过 3D slicer 可以手工生成mask数据，这里时间有限，不准备写了。上图中第二行是三个维度的真值图，其中外围浅蓝色为剔除肿瘤之外的区域(label 0)，绿色为 edema(label 2)，红色为 enhance tumor(label 4)，深蓝色区域为 necrosis(label 1)，黄色区域为 non-enhance tumor(label 3)。注：这里使用的 Brats 2015 采用了这5个标签，之后的该数据集进行了调整，将non-enhncing 和 necrosis 合并为 label 1。\n\n# 模型\n本文使用卷积神经网络，主要结构参考[1]中的结构，不同之处在于为了方便理解，我们只是用了一条通道。模型如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png)\n训练使用交叉熵作为损失函数，利用 RMSprop 作为优化器，学习率设为 $1e-3$，可以对学习率随着epoch进行调整，这里没有改变，读者可以根据自己的想法进行调整。具体代码可以在我的github[3]中查看，喜欢记得点个小星星。\n\n# 训练与测试\n训练部分采用随机裁剪图片大小为 $75\\times75\\times75$ ，输入到神经网络中，最后得到$47\\times47\\times47$ (因为卷积中没有采用padding，所以出现了输出小于输入的情况)。测试部分使用完全大小的图像 $240 \\times 240 \\times 225$，输入到网络中得到大小为$212 \\times 212 \\times 197$，因为脑图的边缘是无效的信息，所以输出的大小与输入和真值维度不一致，不会有影响，只需要补全就行了。\n\n# 结果\n最后网络在三个子区域的分割指标 Dice 为：Whole score 0.6764， Enhancing tumor 0.4478, Tumor core 0.4819，这个结果并不是非常的好，读者如需更高准确度的分割结果，可以调整测试时候的输入图像的维数，将其保持为与训练时输入的图像维数一致，另外可以参考最新的脑肿瘤分割的工作，对代码进行改进。\n\n# 参考文献\n[1] Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.\n[2] https://github.com/yaq007/Autofocus-Layer\n[3] https://github.com/hjyai94/Half_Pathway_DeepMedic\n","slug":"Brain-tumor-segmentation","published":1,"updated":"2019-04-07T11:23:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mrv00011ouzmk4divyz","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>本人一直研究脑肿瘤分割，脑肿瘤分割对于患者的后续治疗以及对疾病的检测有着重要的意义，同时也是人工智能处理医学图像的重要方向之一。目前开源的代码都比较复杂，不适合入门研究，另外 Pytorch 作为一个容易上手的深度学习框架，具有很强的灵活性，适合新手或者是科研工作者，所以本文的代码将使用深度学习框架 Pytorch1.0 和 Python3.6 进行编程构建卷积神经网络来进行脑肿瘤分割。卷积神经网络不仅在自然图像而且在医学图像在内的其他图像都有着广泛地应用。另外，卷积神经网络广泛地应用于图像的分类，检测等计算机视觉任务中。</p>\n<h1 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h1><p>我们这里使用 BraTs2015 的部分数据集，数据集可以从<a href=\"https://github.com/yaq007/Autofocus-Layer\" target=\"_blank\" rel=\"noopener\">这里下载</a>，完整的BraTs2015 数据集可以在这里<a href=\"https://www.smir.ch/BRATS/Start2015\" target=\"_blank\" rel=\"noopener\">注册下载</a>。</p>\n<p>本文使用的数据集共有20例样本用于训练，54例样本用于测试(可自行调整)，每个样本中共有4个模态的数据和Mask和真值数据，其中4个模态分别为FLAIR， T1，T1c，T2。真值数据共有5个标签：</p>\n<ul>\n<li>label 1: necrosis</li>\n<li>label 2: edema</li>\n<li>label 3: non-enhacing tumor</li>\n<li>label 4: enhancing tumor</li>\n<li>label 0：everything else</li>\n</ul>\n<p>脑肿瘤分割主要有3个部分，Whole tumor， Tumor core， Enhance tumor。这3个部分的标签如下所示：</p>\n<ul>\n<li>Whole tumor: label 1, 2, 3, 4</li>\n<li>Enhance tumor: label 4</li>\n<li>Tumor core: 1, 3, 4</li>\n</ul>\n<p>BraTs2015 使用 Dice 作为评价指标，这个评价指标主要是衡量预测结果与真值之间重叠部分。 Dice 的公式计算如下：<br>$$ Dice = \\frac{2 TP}{2TP + FP + FN} $$</p>\n<h2 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h2><p>前面我们知道 BraTs 2015 共有4个模态的数据，下面我们介绍两个能够在程序中读取医学图像的包：SimpleITK 和 Nibabel。SimpleITK能够读取的格式更加多，具体可以参考 SimpleITK 的文档。</p>\n<h3 id=\"SimpleITK\"><a href=\"#SimpleITK\" class=\"headerlink\" title=\"SimpleITK\"></a>SimpleITK</h3><p>SimpleITK 读取医学图像示例代码：<br><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> SimpleITK as sitk</span><br><span class=\"line\"><span class=\"built_in\">image</span> = sitk.ReadImage(<span class=\"string\">'image.nii'</span>)</span><br><span class=\"line\"><span class=\"built_in\">image</span> = sitk.GetArrayFromImage(<span class=\"built_in\">image</span>)</span><br></pre></td></tr></table></figure></p>\n<p>SimpleITK 读取的图片维度是通道优先的，所以图像的维度的第1位是医学图像的维数。另外我还使用到了 SimpleITK 将输出预测结果保存为医学图像格式，这部分代码如下：<br><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">image</span> = sitk.GetImageFromArray(<span class=\"built_in\">image</span>)</span><br><span class=\"line\">sitk.WriteImage(<span class=\"built_in\">image</span>, <span class=\"string\">'image.mha'</span>)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Nibabel\"><a href=\"#Nibabel\" class=\"headerlink\" title=\"Nibabel\"></a>Nibabel</h3><p>Nibabel 读取医学图像示例代码：<br><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nibabel as nib </span><br><span class=\"line\"><span class=\"built_in\">image</span> = nib.load(<span class=\"string\">'image.nii.gz'</span>).get_fdata()</span><br><span class=\"line\"><span class=\"built_in\">image</span> = <span class=\"built_in\">image</span>.transpse(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure></p>\n<p>不同于 SimpleITK， Nibabel 读取图像的维度的通道数位于最后 1 位，但是 Nibabel 将图像旋转了 $90^{\\circ}$，可以使用上面代码的第三行旋转为一般维数分布方式。比如脑图中，如果不旋转变换转变 Nibabel 读取的方式，脑图就是横着的。</p>\n<h3 id=\"3D-Slicer-可视化\"><a href=\"#3D-Slicer-可视化\" class=\"headerlink\" title=\"3D Slicer 可视化\"></a>3D Slicer 可视化</h3><p>SimpleITK 和 Nibabel 是可以在程序中读取医学图像的包，灵活性不强，另外不适合了解医学图像的基本特性，下面我们使用 3D Slicer 来可视化我们的医学图像数据。<br><div class=\"group-picture\"><div class=\"group-picture-container\"><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png\" alt></div></div><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png\" alt></div></div></div></div><br>上图中，第一行为 FLAIR 模态，从左到有依次为横断面(Axis plane)，矢状面(Sagittal plane)，冠状面(Coronal plane)，第二行为 T1 模态，从左到右顺序与 FLAIR 相同，另外两个模态因为篇幅的关系不做具体地展示。下面是脑图的 mask 和手工分割肿瘤的真值(可以看做是金标准，但是个人认为还是有区别的)：<br><div class=\"group-picture\"><div class=\"group-picture-container\"><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png\" alt></div></div><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png\" alt></div></div></div></div><br>本人使用的数据库来自于项目[2] 中，具体如何得到的 mask 数据并不是很清楚，不过通过 3D slicer 可以手工生成mask数据，这里时间有限，不准备写了。上图中第二行是三个维度的真值图，其中外围浅蓝色为剔除肿瘤之外的区域(label 0)，绿色为 edema(label 2)，红色为 enhance tumor(label 4)，深蓝色区域为 necrosis(label 1)，黄色区域为 non-enhance tumor(label 3)。注：这里使用的 Brats 2015 采用了这5个标签，之后的该数据集进行了调整，将non-enhncing 和 necrosis 合并为 label 1。</p>\n<h1 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h1><p>本文使用卷积神经网络，主要结构参考[1]中的结构，不同之处在于为了方便理解，我们只是用了一条通道。模型如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png\" alt><br>训练使用交叉熵作为损失函数，利用 RMSprop 作为优化器，学习率设为 $1e-3$，可以对学习率随着epoch进行调整，这里没有改变，读者可以根据自己的想法进行调整。具体代码可以在我的github[3]中查看，喜欢记得点个小星星。</p>\n<h1 id=\"训练与测试\"><a href=\"#训练与测试\" class=\"headerlink\" title=\"训练与测试\"></a>训练与测试</h1><p>训练部分采用随机裁剪图片大小为 $75\\times75\\times75$ ，输入到神经网络中，最后得到$47\\times47\\times47$ (因为卷积中没有采用padding，所以出现了输出小于输入的情况)。测试部分使用完全大小的图像 $240 \\times 240 \\times 225$，输入到网络中得到大小为$212 \\times 212 \\times 197$，因为脑图的边缘是无效的信息，所以输出的大小与输入和真值维度不一致，不会有影响，只需要补全就行了。</p>\n<h1 id=\"结果\"><a href=\"#结果\" class=\"headerlink\" title=\"结果\"></a>结果</h1><p>最后网络在三个子区域的分割指标 Dice 为：Whole score 0.6764， Enhancing tumor 0.4478, Tumor core 0.4819，这个结果并不是非常的好，读者如需更高准确度的分割结果，可以调整测试时候的输入图像的维数，将其保持为与训练时输入的图像维数一致，另外可以参考最新的脑肿瘤分割的工作，对代码进行改进。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.<br>[2] <a href=\"https://github.com/yaq007/Autofocus-Layer\" target=\"_blank\" rel=\"noopener\">https://github.com/yaq007/Autofocus-Layer</a><br>[3] <a href=\"https://github.com/hjyai94/Half_Pathway_DeepMedic\" target=\"_blank\" rel=\"noopener\">https://github.com/hjyai94/Half_Pathway_DeepMedic</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>本人一直研究脑肿瘤分割，脑肿瘤分割对于患者的后续治疗以及对疾病的检测有着重要的意义，同时也是人工智能处理医学图像的重要方向之一。目前开源的代码都比较复杂，不适合入门研究，另外 Pytorch 作为一个容易上手的深度学习框架，具有很强的灵活性，适合新手或者是科研工作者，所以本文的代码将使用深度学习框架 Pytorch1.0 和 Python3.6 进行编程构建卷积神经网络来进行脑肿瘤分割。卷积神经网络不仅在自然图像而且在医学图像在内的其他图像都有着广泛地应用。另外，卷积神经网络广泛地应用于图像的分类，检测等计算机视觉任务中。</p>\n<h1 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h1><p>我们这里使用 BraTs2015 的部分数据集，数据集可以从<a href=\"https://github.com/yaq007/Autofocus-Layer\" target=\"_blank\" rel=\"noopener\">这里下载</a>，完整的BraTs2015 数据集可以在这里<a href=\"https://www.smir.ch/BRATS/Start2015\" target=\"_blank\" rel=\"noopener\">注册下载</a>。</p>\n<p>本文使用的数据集共有20例样本用于训练，54例样本用于测试(可自行调整)，每个样本中共有4个模态的数据和Mask和真值数据，其中4个模态分别为FLAIR， T1，T1c，T2。真值数据共有5个标签：</p>\n<ul>\n<li>label 1: necrosis</li>\n<li>label 2: edema</li>\n<li>label 3: non-enhacing tumor</li>\n<li>label 4: enhancing tumor</li>\n<li>label 0：everything else</li>\n</ul>\n<p>脑肿瘤分割主要有3个部分，Whole tumor， Tumor core， Enhance tumor。这3个部分的标签如下所示：</p>\n<ul>\n<li>Whole tumor: label 1, 2, 3, 4</li>\n<li>Enhance tumor: label 4</li>\n<li>Tumor core: 1, 3, 4</li>\n</ul>\n<p>BraTs2015 使用 Dice 作为评价指标，这个评价指标主要是衡量预测结果与真值之间重叠部分。 Dice 的公式计算如下：<br>$$ Dice = \\frac{2 TP}{2TP + FP + FN} $$</p>\n<h2 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h2><p>前面我们知道 BraTs 2015 共有4个模态的数据，下面我们介绍两个能够在程序中读取医学图像的包：SimpleITK 和 Nibabel。SimpleITK能够读取的格式更加多，具体可以参考 SimpleITK 的文档。</p>\n<h3 id=\"SimpleITK\"><a href=\"#SimpleITK\" class=\"headerlink\" title=\"SimpleITK\"></a>SimpleITK</h3><p>SimpleITK 读取医学图像示例代码：<br><!--�0--></p>\n<p>SimpleITK 读取的图片维度是通道优先的，所以图像的维度的第1位是医学图像的维数。另外我还使用到了 SimpleITK 将输出预测结果保存为医学图像格式，这部分代码如下：<br><!--�1--></p>\n<h3 id=\"Nibabel\"><a href=\"#Nibabel\" class=\"headerlink\" title=\"Nibabel\"></a>Nibabel</h3><p>Nibabel 读取医学图像示例代码：<br><!--�2--></p>\n<p>不同于 SimpleITK， Nibabel 读取图像的维度的通道数位于最后 1 位，但是 Nibabel 将图像旋转了 $90^{\\circ}$，可以使用上面代码的第三行旋转为一般维数分布方式。比如脑图中，如果不旋转变换转变 Nibabel 读取的方式，脑图就是横着的。</p>\n<h3 id=\"3D-Slicer-可视化\"><a href=\"#3D-Slicer-可视化\" class=\"headerlink\" title=\"3D Slicer 可视化\"></a>3D Slicer 可视化</h3><p>SimpleITK 和 Nibabel 是可以在程序中读取医学图像的包，灵活性不强，另外不适合了解医学图像的基本特性，下面我们使用 3D Slicer 来可视化我们的医学图像数据。<br><div class=\"group-picture\"><div class=\"group-picture-container\"><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png\" alt></div></div><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png\" alt></div></div></div></div><br>上图中，第一行为 FLAIR 模态，从左到有依次为横断面(Axis plane)，矢状面(Sagittal plane)，冠状面(Coronal plane)，第二行为 T1 模态，从左到右顺序与 FLAIR 相同，另外两个模态因为篇幅的关系不做具体地展示。下面是脑图的 mask 和手工分割肿瘤的真值(可以看做是金标准，但是个人认为还是有区别的)：<br><div class=\"group-picture\"><div class=\"group-picture-container\"><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png\" alt></div></div><div class=\"group-picture-row\"><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png\" alt></div><div class=\"group-picture-column\" style=\"width: 33.333333333333336%;\"><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png\" alt></div></div></div></div><br>本人使用的数据库来自于项目[2] 中，具体如何得到的 mask 数据并不是很清楚，不过通过 3D slicer 可以手工生成mask数据，这里时间有限，不准备写了。上图中第二行是三个维度的真值图，其中外围浅蓝色为剔除肿瘤之外的区域(label 0)，绿色为 edema(label 2)，红色为 enhance tumor(label 4)，深蓝色区域为 necrosis(label 1)，黄色区域为 non-enhance tumor(label 3)。注：这里使用的 Brats 2015 采用了这5个标签，之后的该数据集进行了调整，将non-enhncing 和 necrosis 合并为 label 1。</p>\n<h1 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h1><p>本文使用卷积神经网络，主要结构参考[1]中的结构，不同之处在于为了方便理解，我们只是用了一条通道。模型如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png\" alt><br>训练使用交叉熵作为损失函数，利用 RMSprop 作为优化器，学习率设为 $1e-3$，可以对学习率随着epoch进行调整，这里没有改变，读者可以根据自己的想法进行调整。具体代码可以在我的github[3]中查看，喜欢记得点个小星星。</p>\n<h1 id=\"训练与测试\"><a href=\"#训练与测试\" class=\"headerlink\" title=\"训练与测试\"></a>训练与测试</h1><p>训练部分采用随机裁剪图片大小为 $75\\times75\\times75$ ，输入到神经网络中，最后得到$47\\times47\\times47$ (因为卷积中没有采用padding，所以出现了输出小于输入的情况)。测试部分使用完全大小的图像 $240 \\times 240 \\times 225$，输入到网络中得到大小为$212 \\times 212 \\times 197$，因为脑图的边缘是无效的信息，所以输出的大小与输入和真值维度不一致，不会有影响，只需要补全就行了。</p>\n<h1 id=\"结果\"><a href=\"#结果\" class=\"headerlink\" title=\"结果\"></a>结果</h1><p>最后网络在三个子区域的分割指标 Dice 为：Whole score 0.6764， Enhancing tumor 0.4478, Tumor core 0.4819，这个结果并不是非常的好，读者如需更高准确度的分割结果，可以调整测试时候的输入图像的维数，将其保持为与训练时输入的图像维数一致，另外可以参考最新的脑肿瘤分割的工作，对代码进行改进。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.<br>[2] <a href=\"https://github.com/yaq007/Autofocus-Layer\" target=\"_blank\" rel=\"noopener\">https://github.com/yaq007/Autofocus-Layer</a><br>[3] <a href=\"https://github.com/hjyai94/Half_Pathway_DeepMedic\" target=\"_blank\" rel=\"noopener\">https://github.com/hjyai94/Half_Pathway_DeepMedic</a></p>\n"},{"title":"EM算法","date":"2018-05-25T11:45:46.000Z","_content":"# 混合高斯模型\n$$ p(x_n\\mid , \\Sigma) = \\Sigma_k \\pi_k N(x\\mid \\mu, \\Sigma_k) $$\n其中$\\pi_k$是混合参数，$N(x\\mid \\mu_k, \\Sigma_k)$是其对应的高斯分布。\n对于完全可观的独立同分布，对数似然可以分解为和的形式。\n$$ l_c(\\theta;D) = log p(x,z\\mid \\theta) = log p(z\\mid \\theta_z) + log p(z\\mid z, \\theta_x) $$\n因为隐变量的存在，所有的变量会通过边缘概率耦合在一起。\n因为对数里面有和的形式，解决有一定的困难，这样促使我们想到EM算法。\n\n# K-Means\n给定数据集$(x_1, x_2, ..., x_n)$，每个观测量都是d维的向量。k-means的目的是将n个观测量分成k个集合，在给定$z= \\lbrace z_1, z_2, ..., z_n \\rbrace $。为了最小化组内平方和，我们随机的初始化类别向量，然后交替进行两步，知道收敛。\n* E步：将每个观测分配到聚类中，是组内平方和最小。直观上来看就是讲数据点分配到最近的中心。\n$$ z_i^{(t)} = argmin_k (x_i - \\mu_k^{(t)})^T\\Sigma_k^{-1^{(t)}}(x_i - u_k^{(t)}) $$\n* M步：重新计算中心值。\n$$ \\mu_k^{(t+1)} = \\frac{\\Sigma_i \\delta(z_i^{(t)}, k)x_i} {\\Sigma_i \\delta(z_i^{(t)}, k)} $$\n可以这么来理解EM，每个聚类可以看做具有相同的分布，比如$p(x_i\\mid z_i = k)~N(x_i\\mid \\mu_k, \\Sigma_kl) $我们希望可以学习到每个分布的参数$\\mu_k$和$\\Sigma$。\n\n# EM 算法\nEM算法可以有效地迭代计算存在隐变量的最大似然估计。在最大似然估计值中，我们希望能够估计出对于每个观测数据最有可能的参数。\n期望完全对数似然函数：\n$$ \\langle l_c(\\theta;x,z)\\rangle = \\Sigma_n\\langle logp(z_n\\mid \\pi)\\rangle_{p(z\\mid x)} + \\frac{1}{2}\\Sigma_n\\Sigma_k\\langle z_n^k\\rangle((x_n - \\mu_k)^T\\Sigma_K^{-1}(x_n-\\mu_k)+log|\\sigma_k|+C) $$\n\nEM算法是利用迭代地方式最大化$\\langle l_c(\\theta;x,z)\\rangle$。在E步中，我们利用当前参数估计量计算隐变量的充分估计量。\n$$ \\tau_n^{k(t)} = \\langle z_n^k\\rangle_{q(t)} = p(zn^k = 1\\mid x,\\mu^{(t)},\\Sigma^{(t)}) = \\frac{\\pi_k^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})} {\\Sigma_i \\pi_i^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})}$$\n在M步中，使用期望值来计算参数期望的最大值。\n\\begin{equation}\\begin{split} \\pi_k &= \\Sigma_n \\langle z_n^k \\rangle_{q^{(t)}}/N = \\Sigma_n \\tau_n^{k(t)}/N = \\langle n_k \\rangle /N\\\\\\\\\n\\mu_k^{(t+1)} &= \\frac{\\Sigma_n \\tau_n^{k(t)}x_n}{\\Sigma_n \\tau_n^{k(t)}}\\\\\\\\\n\\Sigma_k^{(t+1)} &= \\frac{\\Sigma_n \\tau_n^{k(t)}(x_n-\\mu_k^{(t+1)})(x_n-\\mu_k^{(t+1)})^T}{\\Sigma_n \\tau_n^{(k(t))}}\\\\\\\\\n\\end{split}\\end{equation}\n\n# 比较K-means和EM\nEM算法类似于K-means处理混合高斯模型，对于K-means，在E步中，我们制定每个聚类点，在M中我们假定每个点属于一个聚类重新计算聚类点。在EM算法中，我们使用概率的方式指定点为聚类点，在M步中，我们假定每个点数一个聚类以概率的重新计算聚类中心。\n\n# EM算法理论依据\nX记作观测变量，Z记作隐变量集，分布模型为$p(x,z\\mid \\theta)$。\n如果Z是可观的我们定义对数似然函数为：$ l_c(\\theta;x,z) = log\\ p(x,z\\mid \\theta) $。对于Z是可观的，我们最大化完全对数似然。\n然而，当Z不可观时，我们必须最大化边际似然，也就是不完全对数似然函数。\n$$ l_c(\\theta;x) = log\\ p(x\\mid \\theta) = log\\Sigma_z p(x,z\\theta) $$\n我们必须将不完全对数似然解耦，因为对数里面具有和的形式。\n为了解决这个问题，我们引入了平均分布$q(z\\mid x)$来取代z的随机性。期望完全对数似然可以定义为：\n$$ \\langle l_c(\\theta;x,z)\\rangle_q = \\Sigma_z q(z\\mid x,\\theta)log\\ p(x,z\\mid \\theta) $$\n根据杰西不等式：\n\\begin{equation}\\begin{split} l(\\theta;x) &= log\\ p(x\\theta) \\\\\\\\\n&= log \\Sigma_z p(x,z\\mid \\theta) \\\\\\\\\n&= log \\Sigma_z q(z\\mid x)\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\\\\\\n&\\geqslant \\Sigma_z q(z\\mid x)log \\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\\\\\\n\\end{split}\\end{equation}\n$$ l(\\theta;x) \\geqslant \\langle l_c(\\theta;x,z)\\rangle_q + H_q $$\n固定数据x，定义一个函数叫做自由能：\n$$ F(q,\\theta) = \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\leq l(\\theta;x)$$\n这样EM算法等同于在F上进行坐标上升法：\n* E步：$q^{t+1} = argmax_q F(q,\\theta^t) $\n* M步：$\\theta^{t+1} = argmax_{\\theta} F(q^{t+1},\\theta^t)$\n$q^{t+1}(z\\mid x)$是隐变量在给定数据和参数下的后验分布。$q^{t+1}=argmax_q F(q,\\theta^t)=p(z\\mid x,\\theta^t) $\n证明：这样的设置可以保证$l(\\theta;x)\\geqslant F(q,\\theta)$\n\\begin{equation}\\begin{split} F(p(z\\mid x,\\theta^t), \\theta^t) &= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)}\\\\\\\\\n&= \\Sigma_z q(z\\mid x) log\\ p(x\\mid \\theta^t) \\\\\\\\\n&= log\\ p(x\\mid \\theta^t) \\\\\\\\\n&= l(\\theta^t;x) \\\\\\\\\n\\end{split}\\end{equation}\n同样可以用变分微分来表示：\n$$ l(\\theta;x) - F(q,\\theta) = KL(q||p(z\\mid x, \\theta)) $$\n在不失一般性的情况下，我们可以将$p(x,z\\mid \\theta)$定义为广义指数族分布：\n$$ p(x,z\\mid \\theta) = \\frac{1}{Z(\\theta)} h(x,z) exp \\lbrace \\Sigma_i \\theta_i f_i(x,z) \\rbrace $$\n如果$p(X\\mid Z)$是广义线性模型，那么$f_i(x,z)=\\eta_i^T(z)\\xi_i(x) $。\n在$q^{t+1}=p(z\\mid x,\\theta^t)$下，期望完全对数似然为：\n\\begin{equation}\\begin{split} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} &= \\Sigma_z q(z\\mid x,\\theta^t)log\\ p(x,z\\mid \\theta^t) - A(\\theta) \\\\\\\\\n&= \\Sigma_i \\theta_i^t \\langle f_i(x,z)\\rangle_{q(z\\mid x, \\theta^t)} - A(\\theta) \\\\\\\\\n&= \\Sigma_i \\theta_i^t \\langle \\eta_i(z)\\rangle_{q(z\\mid x, \\theta^t)}\\eta_i(x) - A(\\theta) \\\\\\\\\n\\end{split}\\end{equation}\n下面分析EM算法的M步，M步可以看做是最大化期望对数似然：\n\\begin{equation}\\begin{split} F(q,\\theta) &= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\\\\\\n&= \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) - \\Sigma_z q(z\\mid x)log\\ q(z\\mid x) \\\\\\\\\n&= \\langle l_c(\\theta;x, z) \\rangle_q + H_q\n\\end{split}\\end{equation}\n这样将自由能分解成两个部分，第一部分是期望完全对数似然，第二部分是熵，并且与变量$\\theta$无关，这样最大自由能就等价于最大化期望完全对数似然。\n$$ \\theta^{t+1} = argmax_{\\theta} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} = argmax_{\\theta} \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) $$\n在最优的$q^{t+1}$的情况下，这样就等同于解决标准的完全可观模型$p(x,z\\mid \\theta)$的最大似然问题，用$p(z\\mid x, \\theta)$取代包含z的充分统计量。\n\n# 总结\nEM算法是一种对隐变量模型最大似然函数的一种方法，将比较难以解决的问题分解为两步：\n1. 基于当前参数和可观数据对隐变量进行估计。\n2. 基于观测数据和隐变量对参数做极大似然估计。\n\n* EM算法好的方面\n * 没有学习率参数\n * 自动限制参数\n * 低维速度快\n * 每代都可以确保调高似然\n* 不好的方面\n * 会陷入局部极优\n * 比共轭梯度慢，特别是接近收敛时\n * 需要代价高的推测过程\n * 是一种最大似然或者最大后验的方法\n","source":"_posts/EM算法.md","raw":"---\ntitle: EM算法\ndate: 2018-05-25 19:45:46\ntags: 概率图模型\ncategories: 学习\n---\n# 混合高斯模型\n$$ p(x_n\\mid , \\Sigma) = \\Sigma_k \\pi_k N(x\\mid \\mu, \\Sigma_k) $$\n其中$\\pi_k$是混合参数，$N(x\\mid \\mu_k, \\Sigma_k)$是其对应的高斯分布。\n对于完全可观的独立同分布，对数似然可以分解为和的形式。\n$$ l_c(\\theta;D) = log p(x,z\\mid \\theta) = log p(z\\mid \\theta_z) + log p(z\\mid z, \\theta_x) $$\n因为隐变量的存在，所有的变量会通过边缘概率耦合在一起。\n因为对数里面有和的形式，解决有一定的困难，这样促使我们想到EM算法。\n\n# K-Means\n给定数据集$(x_1, x_2, ..., x_n)$，每个观测量都是d维的向量。k-means的目的是将n个观测量分成k个集合，在给定$z= \\lbrace z_1, z_2, ..., z_n \\rbrace $。为了最小化组内平方和，我们随机的初始化类别向量，然后交替进行两步，知道收敛。\n* E步：将每个观测分配到聚类中，是组内平方和最小。直观上来看就是讲数据点分配到最近的中心。\n$$ z_i^{(t)} = argmin_k (x_i - \\mu_k^{(t)})^T\\Sigma_k^{-1^{(t)}}(x_i - u_k^{(t)}) $$\n* M步：重新计算中心值。\n$$ \\mu_k^{(t+1)} = \\frac{\\Sigma_i \\delta(z_i^{(t)}, k)x_i} {\\Sigma_i \\delta(z_i^{(t)}, k)} $$\n可以这么来理解EM，每个聚类可以看做具有相同的分布，比如$p(x_i\\mid z_i = k)~N(x_i\\mid \\mu_k, \\Sigma_kl) $我们希望可以学习到每个分布的参数$\\mu_k$和$\\Sigma$。\n\n# EM 算法\nEM算法可以有效地迭代计算存在隐变量的最大似然估计。在最大似然估计值中，我们希望能够估计出对于每个观测数据最有可能的参数。\n期望完全对数似然函数：\n$$ \\langle l_c(\\theta;x,z)\\rangle = \\Sigma_n\\langle logp(z_n\\mid \\pi)\\rangle_{p(z\\mid x)} + \\frac{1}{2}\\Sigma_n\\Sigma_k\\langle z_n^k\\rangle((x_n - \\mu_k)^T\\Sigma_K^{-1}(x_n-\\mu_k)+log|\\sigma_k|+C) $$\n\nEM算法是利用迭代地方式最大化$\\langle l_c(\\theta;x,z)\\rangle$。在E步中，我们利用当前参数估计量计算隐变量的充分估计量。\n$$ \\tau_n^{k(t)} = \\langle z_n^k\\rangle_{q(t)} = p(zn^k = 1\\mid x,\\mu^{(t)},\\Sigma^{(t)}) = \\frac{\\pi_k^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})} {\\Sigma_i \\pi_i^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})}$$\n在M步中，使用期望值来计算参数期望的最大值。\n\\begin{equation}\\begin{split} \\pi_k &= \\Sigma_n \\langle z_n^k \\rangle_{q^{(t)}}/N = \\Sigma_n \\tau_n^{k(t)}/N = \\langle n_k \\rangle /N\\\\\\\\\n\\mu_k^{(t+1)} &= \\frac{\\Sigma_n \\tau_n^{k(t)}x_n}{\\Sigma_n \\tau_n^{k(t)}}\\\\\\\\\n\\Sigma_k^{(t+1)} &= \\frac{\\Sigma_n \\tau_n^{k(t)}(x_n-\\mu_k^{(t+1)})(x_n-\\mu_k^{(t+1)})^T}{\\Sigma_n \\tau_n^{(k(t))}}\\\\\\\\\n\\end{split}\\end{equation}\n\n# 比较K-means和EM\nEM算法类似于K-means处理混合高斯模型，对于K-means，在E步中，我们制定每个聚类点，在M中我们假定每个点属于一个聚类重新计算聚类点。在EM算法中，我们使用概率的方式指定点为聚类点，在M步中，我们假定每个点数一个聚类以概率的重新计算聚类中心。\n\n# EM算法理论依据\nX记作观测变量，Z记作隐变量集，分布模型为$p(x,z\\mid \\theta)$。\n如果Z是可观的我们定义对数似然函数为：$ l_c(\\theta;x,z) = log\\ p(x,z\\mid \\theta) $。对于Z是可观的，我们最大化完全对数似然。\n然而，当Z不可观时，我们必须最大化边际似然，也就是不完全对数似然函数。\n$$ l_c(\\theta;x) = log\\ p(x\\mid \\theta) = log\\Sigma_z p(x,z\\theta) $$\n我们必须将不完全对数似然解耦，因为对数里面具有和的形式。\n为了解决这个问题，我们引入了平均分布$q(z\\mid x)$来取代z的随机性。期望完全对数似然可以定义为：\n$$ \\langle l_c(\\theta;x,z)\\rangle_q = \\Sigma_z q(z\\mid x,\\theta)log\\ p(x,z\\mid \\theta) $$\n根据杰西不等式：\n\\begin{equation}\\begin{split} l(\\theta;x) &= log\\ p(x\\theta) \\\\\\\\\n&= log \\Sigma_z p(x,z\\mid \\theta) \\\\\\\\\n&= log \\Sigma_z q(z\\mid x)\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\\\\\\n&\\geqslant \\Sigma_z q(z\\mid x)log \\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\\\\\\n\\end{split}\\end{equation}\n$$ l(\\theta;x) \\geqslant \\langle l_c(\\theta;x,z)\\rangle_q + H_q $$\n固定数据x，定义一个函数叫做自由能：\n$$ F(q,\\theta) = \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\leq l(\\theta;x)$$\n这样EM算法等同于在F上进行坐标上升法：\n* E步：$q^{t+1} = argmax_q F(q,\\theta^t) $\n* M步：$\\theta^{t+1} = argmax_{\\theta} F(q^{t+1},\\theta^t)$\n$q^{t+1}(z\\mid x)$是隐变量在给定数据和参数下的后验分布。$q^{t+1}=argmax_q F(q,\\theta^t)=p(z\\mid x,\\theta^t) $\n证明：这样的设置可以保证$l(\\theta;x)\\geqslant F(q,\\theta)$\n\\begin{equation}\\begin{split} F(p(z\\mid x,\\theta^t), \\theta^t) &= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)}\\\\\\\\\n&= \\Sigma_z q(z\\mid x) log\\ p(x\\mid \\theta^t) \\\\\\\\\n&= log\\ p(x\\mid \\theta^t) \\\\\\\\\n&= l(\\theta^t;x) \\\\\\\\\n\\end{split}\\end{equation}\n同样可以用变分微分来表示：\n$$ l(\\theta;x) - F(q,\\theta) = KL(q||p(z\\mid x, \\theta)) $$\n在不失一般性的情况下，我们可以将$p(x,z\\mid \\theta)$定义为广义指数族分布：\n$$ p(x,z\\mid \\theta) = \\frac{1}{Z(\\theta)} h(x,z) exp \\lbrace \\Sigma_i \\theta_i f_i(x,z) \\rbrace $$\n如果$p(X\\mid Z)$是广义线性模型，那么$f_i(x,z)=\\eta_i^T(z)\\xi_i(x) $。\n在$q^{t+1}=p(z\\mid x,\\theta^t)$下，期望完全对数似然为：\n\\begin{equation}\\begin{split} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} &= \\Sigma_z q(z\\mid x,\\theta^t)log\\ p(x,z\\mid \\theta^t) - A(\\theta) \\\\\\\\\n&= \\Sigma_i \\theta_i^t \\langle f_i(x,z)\\rangle_{q(z\\mid x, \\theta^t)} - A(\\theta) \\\\\\\\\n&= \\Sigma_i \\theta_i^t \\langle \\eta_i(z)\\rangle_{q(z\\mid x, \\theta^t)}\\eta_i(x) - A(\\theta) \\\\\\\\\n\\end{split}\\end{equation}\n下面分析EM算法的M步，M步可以看做是最大化期望对数似然：\n\\begin{equation}\\begin{split} F(q,\\theta) &= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\\\\\\n&= \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) - \\Sigma_z q(z\\mid x)log\\ q(z\\mid x) \\\\\\\\\n&= \\langle l_c(\\theta;x, z) \\rangle_q + H_q\n\\end{split}\\end{equation}\n这样将自由能分解成两个部分，第一部分是期望完全对数似然，第二部分是熵，并且与变量$\\theta$无关，这样最大自由能就等价于最大化期望完全对数似然。\n$$ \\theta^{t+1} = argmax_{\\theta} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} = argmax_{\\theta} \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) $$\n在最优的$q^{t+1}$的情况下，这样就等同于解决标准的完全可观模型$p(x,z\\mid \\theta)$的最大似然问题，用$p(z\\mid x, \\theta)$取代包含z的充分统计量。\n\n# 总结\nEM算法是一种对隐变量模型最大似然函数的一种方法，将比较难以解决的问题分解为两步：\n1. 基于当前参数和可观数据对隐变量进行估计。\n2. 基于观测数据和隐变量对参数做极大似然估计。\n\n* EM算法好的方面\n * 没有学习率参数\n * 自动限制参数\n * 低维速度快\n * 每代都可以确保调高似然\n* 不好的方面\n * 会陷入局部极优\n * 比共轭梯度慢，特别是接近收敛时\n * 需要代价高的推测过程\n * 是一种最大似然或者最大后验的方法\n","slug":"EM算法","published":1,"updated":"2018-10-01T01:55:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mrz00031ouz8gjvxifs","content":"<h1 id=\"混合高斯模型\"><a href=\"#混合高斯模型\" class=\"headerlink\" title=\"混合高斯模型\"></a>混合高斯模型</h1><p>$$ p(x_n\\mid , \\Sigma) = \\Sigma_k \\pi_k N(x\\mid \\mu, \\Sigma_k) $$<br>其中$\\pi_k$是混合参数，$N(x\\mid \\mu_k, \\Sigma_k)$是其对应的高斯分布。<br>对于完全可观的独立同分布，对数似然可以分解为和的形式。<br>$$ l_c(\\theta;D) = log p(x,z\\mid \\theta) = log p(z\\mid \\theta_z) + log p(z\\mid z, \\theta_x) $$<br>因为隐变量的存在，所有的变量会通过边缘概率耦合在一起。<br>因为对数里面有和的形式，解决有一定的困难，这样促使我们想到EM算法。</p>\n<h1 id=\"K-Means\"><a href=\"#K-Means\" class=\"headerlink\" title=\"K-Means\"></a>K-Means</h1><p>给定数据集$(x_1, x_2, …, x_n)$，每个观测量都是d维的向量。k-means的目的是将n个观测量分成k个集合，在给定$z= \\lbrace z_1, z_2, …, z_n \\rbrace $。为了最小化组内平方和，我们随机的初始化类别向量，然后交替进行两步，知道收敛。</p>\n<ul>\n<li>E步：将每个观测分配到聚类中，是组内平方和最小。直观上来看就是讲数据点分配到最近的中心。<br>$$ z_i^{(t)} = argmin_k (x_i - \\mu_k^{(t)})^T\\Sigma_k^{-1^{(t)}}(x_i - u_k^{(t)}) $$</li>\n<li>M步：重新计算中心值。<br>$$ \\mu_k^{(t+1)} = \\frac{\\Sigma_i \\delta(z_i^{(t)}, k)x_i} {\\Sigma_i \\delta(z_i^{(t)}, k)} $$<br>可以这么来理解EM，每个聚类可以看做具有相同的分布，比如$p(x_i\\mid z_i = k)~N(x_i\\mid \\mu_k, \\Sigma_kl) $我们希望可以学习到每个分布的参数$\\mu_k$和$\\Sigma$。</li>\n</ul>\n<h1 id=\"EM-算法\"><a href=\"#EM-算法\" class=\"headerlink\" title=\"EM 算法\"></a>EM 算法</h1><p>EM算法可以有效地迭代计算存在隐变量的最大似然估计。在最大似然估计值中，我们希望能够估计出对于每个观测数据最有可能的参数。<br>期望完全对数似然函数：<br>$$ \\langle l_c(\\theta;x,z)\\rangle = \\Sigma_n\\langle logp(z_n\\mid \\pi)\\rangle_{p(z\\mid x)} + \\frac{1}{2}\\Sigma_n\\Sigma_k\\langle z_n^k\\rangle((x_n - \\mu_k)^T\\Sigma_K^{-1}(x_n-\\mu_k)+log|\\sigma_k|+C) $$</p>\n<p>EM算法是利用迭代地方式最大化$\\langle l_c(\\theta;x,z)\\rangle$。在E步中，我们利用当前参数估计量计算隐变量的充分估计量。<br>$$ \\tau_n^{k(t)} = \\langle z_n^k\\rangle_{q(t)} = p(zn^k = 1\\mid x,\\mu^{(t)},\\Sigma^{(t)}) = \\frac{\\pi_k^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})} {\\Sigma_i \\pi_i^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})}$$<br>在M步中，使用期望值来计算参数期望的最大值。<br>\\begin{equation}\\begin{split} \\pi_k &amp;= \\Sigma_n \\langle z_n^k \\rangle_{q^{(t)}}/N = \\Sigma_n \\tau_n^{k(t)}/N = \\langle n_k \\rangle /N\\\\<br>\\mu_k^{(t+1)} &amp;= \\frac{\\Sigma_n \\tau_n^{k(t)}x_n}{\\Sigma_n \\tau_n^{k(t)}}\\\\<br>\\Sigma_k^{(t+1)} &amp;= \\frac{\\Sigma_n \\tau_n^{k(t)}(x_n-\\mu_k^{(t+1)})(x_n-\\mu_k^{(t+1)})^T}{\\Sigma_n \\tau_n^{(k(t))}}\\\\<br>\\end{split}\\end{equation}</p>\n<h1 id=\"比较K-means和EM\"><a href=\"#比较K-means和EM\" class=\"headerlink\" title=\"比较K-means和EM\"></a>比较K-means和EM</h1><p>EM算法类似于K-means处理混合高斯模型，对于K-means，在E步中，我们制定每个聚类点，在M中我们假定每个点属于一个聚类重新计算聚类点。在EM算法中，我们使用概率的方式指定点为聚类点，在M步中，我们假定每个点数一个聚类以概率的重新计算聚类中心。</p>\n<h1 id=\"EM算法理论依据\"><a href=\"#EM算法理论依据\" class=\"headerlink\" title=\"EM算法理论依据\"></a>EM算法理论依据</h1><p>X记作观测变量，Z记作隐变量集，分布模型为$p(x,z\\mid \\theta)$。<br>如果Z是可观的我们定义对数似然函数为：$ l_c(\\theta;x,z) = log\\ p(x,z\\mid \\theta) $。对于Z是可观的，我们最大化完全对数似然。<br>然而，当Z不可观时，我们必须最大化边际似然，也就是不完全对数似然函数。<br>$$ l_c(\\theta;x) = log\\ p(x\\mid \\theta) = log\\Sigma_z p(x,z\\theta) $$<br>我们必须将不完全对数似然解耦，因为对数里面具有和的形式。<br>为了解决这个问题，我们引入了平均分布$q(z\\mid x)$来取代z的随机性。期望完全对数似然可以定义为：<br>$$ \\langle l_c(\\theta;x,z)\\rangle_q = \\Sigma_z q(z\\mid x,\\theta)log\\ p(x,z\\mid \\theta) $$<br>根据杰西不等式：<br>\\begin{equation}\\begin{split} l(\\theta;x) &amp;= log\\ p(x\\theta) \\\\<br>&amp;= log \\Sigma_z p(x,z\\mid \\theta) \\\\<br>&amp;= log \\Sigma_z q(z\\mid x)\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\<br>&amp;\\geqslant \\Sigma_z q(z\\mid x)log \\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\<br>\\end{split}\\end{equation}<br>$$ l(\\theta;x) \\geqslant \\langle l_c(\\theta;x,z)\\rangle_q + H_q $$<br>固定数据x，定义一个函数叫做自由能：<br>$$ F(q,\\theta) = \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\leq l(\\theta;x)$$<br>这样EM算法等同于在F上进行坐标上升法：</p>\n<ul>\n<li>E步：$q^{t+1} = argmax_q F(q,\\theta^t) $</li>\n<li>M步：$\\theta^{t+1} = argmax_{\\theta} F(q^{t+1},\\theta^t)$<br>$q^{t+1}(z\\mid x)$是隐变量在给定数据和参数下的后验分布。$q^{t+1}=argmax_q F(q,\\theta^t)=p(z\\mid x,\\theta^t) $<br>证明：这样的设置可以保证$l(\\theta;x)\\geqslant F(q,\\theta)$<br>\\begin{equation}\\begin{split} F(p(z\\mid x,\\theta^t), \\theta^t) &amp;= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)}\\\\<br>&amp;= \\Sigma_z q(z\\mid x) log\\ p(x\\mid \\theta^t) \\\\<br>&amp;= log\\ p(x\\mid \\theta^t) \\\\<br>&amp;= l(\\theta^t;x) \\\\<br>\\end{split}\\end{equation}<br>同样可以用变分微分来表示：<br>$$ l(\\theta;x) - F(q,\\theta) = KL(q||p(z\\mid x, \\theta)) $$<br>在不失一般性的情况下，我们可以将$p(x,z\\mid \\theta)$定义为广义指数族分布：<br>$$ p(x,z\\mid \\theta) = \\frac{1}{Z(\\theta)} h(x,z) exp \\lbrace \\Sigma_i \\theta_i f_i(x,z) \\rbrace $$<br>如果$p(X\\mid Z)$是广义线性模型，那么$f_i(x,z)=\\eta_i^T(z)\\xi_i(x) $。<br>在$q^{t+1}=p(z\\mid x,\\theta^t)$下，期望完全对数似然为：<br>\\begin{equation}\\begin{split} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} &amp;= \\Sigma_z q(z\\mid x,\\theta^t)log\\ p(x,z\\mid \\theta^t) - A(\\theta) \\\\<br>&amp;= \\Sigma_i \\theta_i^t \\langle f_i(x,z)\\rangle_{q(z\\mid x, \\theta^t)} - A(\\theta) \\\\<br>&amp;= \\Sigma_i \\theta_i^t \\langle \\eta_i(z)\\rangle_{q(z\\mid x, \\theta^t)}\\eta_i(x) - A(\\theta) \\\\<br>\\end{split}\\end{equation}<br>下面分析EM算法的M步，M步可以看做是最大化期望对数似然：<br>\\begin{equation}\\begin{split} F(q,\\theta) &amp;= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\<br>&amp;= \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) - \\Sigma_z q(z\\mid x)log\\ q(z\\mid x) \\\\<br>&amp;= \\langle l_c(\\theta;x, z) \\rangle_q + H_q<br>\\end{split}\\end{equation}<br>这样将自由能分解成两个部分，第一部分是期望完全对数似然，第二部分是熵，并且与变量$\\theta$无关，这样最大自由能就等价于最大化期望完全对数似然。<br>$$ \\theta^{t+1} = argmax_{\\theta} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} = argmax_{\\theta} \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) $$<br>在最优的$q^{t+1}$的情况下，这样就等同于解决标准的完全可观模型$p(x,z\\mid \\theta)$的最大似然问题，用$p(z\\mid x, \\theta)$取代包含z的充分统计量。</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>EM算法是一种对隐变量模型最大似然函数的一种方法，将比较难以解决的问题分解为两步：</p>\n<ol>\n<li>基于当前参数和可观数据对隐变量进行估计。</li>\n<li>基于观测数据和隐变量对参数做极大似然估计。</li>\n</ol>\n<ul>\n<li>EM算法好的方面<ul>\n<li>没有学习率参数</li>\n<li>自动限制参数</li>\n<li>低维速度快</li>\n<li>每代都可以确保调高似然</li>\n</ul>\n</li>\n<li>不好的方面<ul>\n<li>会陷入局部极优</li>\n<li>比共轭梯度慢，特别是接近收敛时</li>\n<li>需要代价高的推测过程</li>\n<li>是一种最大似然或者最大后验的方法</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"混合高斯模型\"><a href=\"#混合高斯模型\" class=\"headerlink\" title=\"混合高斯模型\"></a>混合高斯模型</h1><p>$$ p(x_n\\mid , \\Sigma) = \\Sigma_k \\pi_k N(x\\mid \\mu, \\Sigma_k) $$<br>其中$\\pi_k$是混合参数，$N(x\\mid \\mu_k, \\Sigma_k)$是其对应的高斯分布。<br>对于完全可观的独立同分布，对数似然可以分解为和的形式。<br>$$ l_c(\\theta;D) = log p(x,z\\mid \\theta) = log p(z\\mid \\theta_z) + log p(z\\mid z, \\theta_x) $$<br>因为隐变量的存在，所有的变量会通过边缘概率耦合在一起。<br>因为对数里面有和的形式，解决有一定的困难，这样促使我们想到EM算法。</p>\n<h1 id=\"K-Means\"><a href=\"#K-Means\" class=\"headerlink\" title=\"K-Means\"></a>K-Means</h1><p>给定数据集$(x_1, x_2, …, x_n)$，每个观测量都是d维的向量。k-means的目的是将n个观测量分成k个集合，在给定$z= \\lbrace z_1, z_2, …, z_n \\rbrace $。为了最小化组内平方和，我们随机的初始化类别向量，然后交替进行两步，知道收敛。</p>\n<ul>\n<li>E步：将每个观测分配到聚类中，是组内平方和最小。直观上来看就是讲数据点分配到最近的中心。<br>$$ z_i^{(t)} = argmin_k (x_i - \\mu_k^{(t)})^T\\Sigma_k^{-1^{(t)}}(x_i - u_k^{(t)}) $$</li>\n<li>M步：重新计算中心值。<br>$$ \\mu_k^{(t+1)} = \\frac{\\Sigma_i \\delta(z_i^{(t)}, k)x_i} {\\Sigma_i \\delta(z_i^{(t)}, k)} $$<br>可以这么来理解EM，每个聚类可以看做具有相同的分布，比如$p(x_i\\mid z_i = k)~N(x_i\\mid \\mu_k, \\Sigma_kl) $我们希望可以学习到每个分布的参数$\\mu_k$和$\\Sigma$。</li>\n</ul>\n<h1 id=\"EM-算法\"><a href=\"#EM-算法\" class=\"headerlink\" title=\"EM 算法\"></a>EM 算法</h1><p>EM算法可以有效地迭代计算存在隐变量的最大似然估计。在最大似然估计值中，我们希望能够估计出对于每个观测数据最有可能的参数。<br>期望完全对数似然函数：<br>$$ \\langle l_c(\\theta;x,z)\\rangle = \\Sigma_n\\langle logp(z_n\\mid \\pi)\\rangle_{p(z\\mid x)} + \\frac{1}{2}\\Sigma_n\\Sigma_k\\langle z_n^k\\rangle((x_n - \\mu_k)^T\\Sigma_K^{-1}(x_n-\\mu_k)+log|\\sigma_k|+C) $$</p>\n<p>EM算法是利用迭代地方式最大化$\\langle l_c(\\theta;x,z)\\rangle$。在E步中，我们利用当前参数估计量计算隐变量的充分估计量。<br>$$ \\tau_n^{k(t)} = \\langle z_n^k\\rangle_{q(t)} = p(zn^k = 1\\mid x,\\mu^{(t)},\\Sigma^{(t)}) = \\frac{\\pi_k^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})} {\\Sigma_i \\pi_i^{(t)}N(x_n\\mid \\mu_k^{(t)},\\Sigma_k^{(t)})}$$<br>在M步中，使用期望值来计算参数期望的最大值。<br>\\begin{equation}\\begin{split} \\pi_k &amp;= \\Sigma_n \\langle z_n^k \\rangle_{q^{(t)}}/N = \\Sigma_n \\tau_n^{k(t)}/N = \\langle n_k \\rangle /N\\\\<br>\\mu_k^{(t+1)} &amp;= \\frac{\\Sigma_n \\tau_n^{k(t)}x_n}{\\Sigma_n \\tau_n^{k(t)}}\\\\<br>\\Sigma_k^{(t+1)} &amp;= \\frac{\\Sigma_n \\tau_n^{k(t)}(x_n-\\mu_k^{(t+1)})(x_n-\\mu_k^{(t+1)})^T}{\\Sigma_n \\tau_n^{(k(t))}}\\\\<br>\\end{split}\\end{equation}</p>\n<h1 id=\"比较K-means和EM\"><a href=\"#比较K-means和EM\" class=\"headerlink\" title=\"比较K-means和EM\"></a>比较K-means和EM</h1><p>EM算法类似于K-means处理混合高斯模型，对于K-means，在E步中，我们制定每个聚类点，在M中我们假定每个点属于一个聚类重新计算聚类点。在EM算法中，我们使用概率的方式指定点为聚类点，在M步中，我们假定每个点数一个聚类以概率的重新计算聚类中心。</p>\n<h1 id=\"EM算法理论依据\"><a href=\"#EM算法理论依据\" class=\"headerlink\" title=\"EM算法理论依据\"></a>EM算法理论依据</h1><p>X记作观测变量，Z记作隐变量集，分布模型为$p(x,z\\mid \\theta)$。<br>如果Z是可观的我们定义对数似然函数为：$ l_c(\\theta;x,z) = log\\ p(x,z\\mid \\theta) $。对于Z是可观的，我们最大化完全对数似然。<br>然而，当Z不可观时，我们必须最大化边际似然，也就是不完全对数似然函数。<br>$$ l_c(\\theta;x) = log\\ p(x\\mid \\theta) = log\\Sigma_z p(x,z\\theta) $$<br>我们必须将不完全对数似然解耦，因为对数里面具有和的形式。<br>为了解决这个问题，我们引入了平均分布$q(z\\mid x)$来取代z的随机性。期望完全对数似然可以定义为：<br>$$ \\langle l_c(\\theta;x,z)\\rangle_q = \\Sigma_z q(z\\mid x,\\theta)log\\ p(x,z\\mid \\theta) $$<br>根据杰西不等式：<br>\\begin{equation}\\begin{split} l(\\theta;x) &amp;= log\\ p(x\\theta) \\\\<br>&amp;= log \\Sigma_z p(x,z\\mid \\theta) \\\\<br>&amp;= log \\Sigma_z q(z\\mid x)\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\<br>&amp;\\geqslant \\Sigma_z q(z\\mid x)log \\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\<br>\\end{split}\\end{equation}<br>$$ l(\\theta;x) \\geqslant \\langle l_c(\\theta;x,z)\\rangle_q + H_q $$<br>固定数据x，定义一个函数叫做自由能：<br>$$ F(q,\\theta) = \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\leq l(\\theta;x)$$<br>这样EM算法等同于在F上进行坐标上升法：</p>\n<ul>\n<li>E步：$q^{t+1} = argmax_q F(q,\\theta^t) $</li>\n<li>M步：$\\theta^{t+1} = argmax_{\\theta} F(q^{t+1},\\theta^t)$<br>$q^{t+1}(z\\mid x)$是隐变量在给定数据和参数下的后验分布。$q^{t+1}=argmax_q F(q,\\theta^t)=p(z\\mid x,\\theta^t) $<br>证明：这样的设置可以保证$l(\\theta;x)\\geqslant F(q,\\theta)$<br>\\begin{equation}\\begin{split} F(p(z\\mid x,\\theta^t), \\theta^t) &amp;= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)}\\\\<br>&amp;= \\Sigma_z q(z\\mid x) log\\ p(x\\mid \\theta^t) \\\\<br>&amp;= log\\ p(x\\mid \\theta^t) \\\\<br>&amp;= l(\\theta^t;x) \\\\<br>\\end{split}\\end{equation}<br>同样可以用变分微分来表示：<br>$$ l(\\theta;x) - F(q,\\theta) = KL(q||p(z\\mid x, \\theta)) $$<br>在不失一般性的情况下，我们可以将$p(x,z\\mid \\theta)$定义为广义指数族分布：<br>$$ p(x,z\\mid \\theta) = \\frac{1}{Z(\\theta)} h(x,z) exp \\lbrace \\Sigma_i \\theta_i f_i(x,z) \\rbrace $$<br>如果$p(X\\mid Z)$是广义线性模型，那么$f_i(x,z)=\\eta_i^T(z)\\xi_i(x) $。<br>在$q^{t+1}=p(z\\mid x,\\theta^t)$下，期望完全对数似然为：<br>\\begin{equation}\\begin{split} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} &amp;= \\Sigma_z q(z\\mid x,\\theta^t)log\\ p(x,z\\mid \\theta^t) - A(\\theta) \\\\<br>&amp;= \\Sigma_i \\theta_i^t \\langle f_i(x,z)\\rangle_{q(z\\mid x, \\theta^t)} - A(\\theta) \\\\<br>&amp;= \\Sigma_i \\theta_i^t \\langle \\eta_i(z)\\rangle_{q(z\\mid x, \\theta^t)}\\eta_i(x) - A(\\theta) \\\\<br>\\end{split}\\end{equation}<br>下面分析EM算法的M步，M步可以看做是最大化期望对数似然：<br>\\begin{equation}\\begin{split} F(q,\\theta) &amp;= \\Sigma_z q(z\\mid x) log\\frac{p(x,z\\mid \\theta)}{q(z\\mid x)} \\\\<br>&amp;= \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) - \\Sigma_z q(z\\mid x)log\\ q(z\\mid x) \\\\<br>&amp;= \\langle l_c(\\theta;x, z) \\rangle_q + H_q<br>\\end{split}\\end{equation}<br>这样将自由能分解成两个部分，第一部分是期望完全对数似然，第二部分是熵，并且与变量$\\theta$无关，这样最大自由能就等价于最大化期望完全对数似然。<br>$$ \\theta^{t+1} = argmax_{\\theta} \\langle l_c(\\theta;x,z)\\rangle_{q^{t+1}} = argmax_{\\theta} \\Sigma_z q(z\\mid x)log\\ p(x,z\\mid \\theta) $$<br>在最优的$q^{t+1}$的情况下，这样就等同于解决标准的完全可观模型$p(x,z\\mid \\theta)$的最大似然问题，用$p(z\\mid x, \\theta)$取代包含z的充分统计量。</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>EM算法是一种对隐变量模型最大似然函数的一种方法，将比较难以解决的问题分解为两步：</p>\n<ol>\n<li>基于当前参数和可观数据对隐变量进行估计。</li>\n<li>基于观测数据和隐变量对参数做极大似然估计。</li>\n</ol>\n<ul>\n<li>EM算法好的方面<ul>\n<li>没有学习率参数</li>\n<li>自动限制参数</li>\n<li>低维速度快</li>\n<li>每代都可以确保调高似然</li>\n</ul>\n</li>\n<li>不好的方面<ul>\n<li>会陷入局部极优</li>\n<li>比共轭梯度慢，特别是接近收敛时</li>\n<li>需要代价高的推测过程</li>\n<li>是一种最大似然或者最大后验的方法</li>\n</ul>\n</li>\n</ul>\n"},{"title":"EM算法实现","date":"2018-09-05T02:42:01.000Z","_content":"# EM算法\n之前在看概率图模型的时候，写过关于EM算法的内容，不过已经忘记差不多了，最近在看[1]中的材料，感觉有了新的理解，特将这些内容整理成这篇博客。\nEM算法适用于存在隐变量的情况，或者说是假设存在因变量对系统进行推导。\n\\begin{equation}\\begin{split} log\\ p(X\\mid \\theta) &= \\int q(Z)log\\ p(X\\mid \\theta)dZ \\\\\\\\\n&= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{p(Z\\mid X, \\theta)}dZ \\\\\\\\\n&= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{q(Z)}dZ + \\int q(Z) log \\frac{q(Z)}{p(Z\\mid X, \\theta)}dZ\\\\\\\\\n&= L(q, \\theta) + KL(q\\mid\\mid p) \\geqslant L(q, \\theta)\\\\\\\\\n\\end{split}\\end{equation}\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95.png)\nE步是为了获得隐变量的最优值，M步是对参数求最大似然。\n\n# [问题描述](https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start)\n有$K$张受噪声污染的图片，每张图片大小为$H\\times W$，每张图片上都有$H\\times w$大小的人脸，每张人脸的位置不固定，但是高度相同，都与图片的高度一样。如下图所示，每张图片都是受严重受噪声污染的，可以看成是高斯噪声。可以从这里得到[数据集](https://drive.google.com/open?id=1NLOHNhqdDBG6rWk8lOjzm3u3vDyS_9WZ)，该数据集为.mat格式，其中包含有500张$45\\times 60$的图片，其中人脸大小为$45\\times 36$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%99%AA%E5%A3%B0%E5%9B%BE%E7%89%87.png)\n下图是图片的结构，其中$d_k$的位置是不固定的，$F$是不含噪声的人脸图片，$B$是不含噪声的背景图片。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%9B%BE%E7%89%87%E7%BB%93%E6%9E%84.png)\n下面基于EM算法来思考该问题：\n可观数据：$K$张受污染的图片，$X = \\lbrace X_1, ..., X_K \\rbrace$\n隐变量：$F$的位置，$d = \\lbrace d_1, ..., d_K \\rbrace$\n参数：$\\theta = \\lbrace B, F, s^2\\rbrace$\n似然函数：\n$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), & \\text {if $[i, j]\\in faceArea(d_k)$} \\\\\\\\ N(X_k[i, j]\\mid B[i, j], s^2), & \\text{otherwise} \\end{cases} $$\n因为每张图片中$F$和$B$部分减去对应的$F$和$B$，这样就是纯粹的噪声，我们将噪声看做是高斯分布，所以上式就是上面的形式。\n以及先验：\n$p(d_k\\mid a) = a[d_k] $， $\\sum_j a[j] = 1$,，$a\\in R^{W-w+1}$\n概率模型可以写成：\n$$ p(X, d\\mid \\theta, a) = \\prod_k p(X_k\\mid d_k, \\theta)p(d_k\\mid a) $$\n按照第一张图中的EM算法步骤，进行EM算法的推导：\nE步：确定隐变量的最优值\n\\begin{equation}\\begin{split} q(d) = p(d\\mid X, \\theta, a) &= \\prod_k p(d_k\\mid x_k, \\theta, a)\\\\\\\\\n&= \\prod_k\\frac{p(X_k, d_k\\mid \\theta, a)}{\\sum_{d_k'} p(X_k, d_k'\\mid \\theta, a)} \\\\\\\\\n&= \\prod_k\\frac{p(X_k\\mid d_k, theta)p(d_k\\mid a)}{\\sum_{d_k'} p(X_k\\mid d_k', theta)p(d_k'\\mid a)} \\\\\\\\\n\\end{split}\\end{equation}\nM步：对参数求最大似然。\n$$ Q(\\theta, a) = E_{q(d)}log\\ p(X, d\\mid \\theta, a) \\rightarrow max_{\\theta, a} $$\n具体推导这里就不再详细的描述了，可以参照参考文献[1]中的推导过程，最后的推导结果如下：\n$$a[j] = \\frac{\\sum_k q( d_k = j )}{\\sum_{j'}  \\sum_{k'} q( d_{k'} = j')}$$\n$$F[i, m] = \\frac 1 K  \\sum_k \\sum_{d_k} q(d_k)\\, X^k[i,\\, m+d_k]$$\n$$B[i, j] = \\frac {\\sum_k \\sum_{ d_k:\\, (i, \\,j) \\,\\not\\in faceArea(d_k)} q(d_k)\\, X^k[i, j]}\n\t  \t{\\sum_k \\sum_{d_k: \\,(i, \\,j)\\, \\not\\in faceArea(d_k)} q(d_k)}$$\n$$s^2 = \\frac 1 {HWK}   \\sum_k \\sum_{d_k} q(d_k)\n\t  \t\\sum_{i,\\, j}  (X^k[i, \\,j] - Model^{d_k}[i, \\,j])^2$$\n 其中$Model^{d_k}[i, j]$表示由$F$和$B$组成的图片，其中$F$处于$d_k$位置。\n\n# 程序实现\n下面用EM算法来是处理对受噪声污染影响的图片，从而恢复其中的人脸图像。\n程序思路为\n1. 实现对数似然；\n2. 实现variational lower bound；\n3. 实现E步；\n4. 实现M步；\n5. 将循环执行EM步，知道满足结束条件。\n## 具体程序\n* 实现对数似然，似然函数为：$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), & \\text {if $[i, j]\\in faceArea(d_k)$} \\\\\\\\ N(X_k[i, j]\\mid B[i, j], s^2), & \\text{otherwise} \\end{cases} $$\n```\ndef calculate_log_probability(X, F, B, s):\n    \"\"\"\n    Calculates log p(X_k|d_k, F, B, s) for all images X_k in X and\n    all possible face position d_k.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n\n    Returns\n    -------\n    ll : array, shape(W-w+1, K)\n        ll[dw, k] - log-likelihood of observing image X_k given\n        that the prankster's face F is located at position dw\n    \"\"\"\n    # your code here\n    H, W, K = np.shape(X)\n    _, w = np.shape(F)\n    ll = np.zeros((W-w+1, K), dtype=float)\n    for dw in range(W-w+1):\n        for k in range(K):\n            ll[dw, k] = H*w*np.log(1/(s*np.sqrt(2*np.pi))) - np.sum((X[:, dw:dw+w, k] - F)**2/(2 * s**2)) + \\\n            H*dw*np.log(1/(s*np.sqrt(2*np.pi))) - np.sum((X[:, 0:dw, k] - B[:, 0:dw])**2/(2 * s**2)) + \\\n            H*(W-w-dw)*np.log(1/(s*np.sqrt(2*np.pi))) - np.sum((X[:, dw+w:, k] - B[:, dw+w:])**2/(2 * s**2))\n    return ll\n```\n* 实现Variational lower bound\n ```\n def calculate_lower_bound(X, F, B, s, a, q):\n    \"\"\"\n    Calculates the lower bound L(q, F, B, s, a) for\n    the marginal log likelihood.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n    a : array, shape (W-w+1)\n        Estimate of prior on position of face in any image.\n    q : array\n        q[dw, k] - estimate of posterior\n                   of position dw\n                   of prankster's face given image Xk\n\n    Returns\n    -------\n    L : float\n        The lower bound L(q, F, B, s, a)\n        for the marginal log likelihood.\n    \"\"\"\n    # your code here\n    ll = calculate_log_probability(X, F, B, s)\n    L = np.sum(q*ll) + np.sum(q.T*np.log(a)) - np.sum(q*np.log(q))\n    return L\n    ```\n* E步\n```\ndef run_e_step(X, F, B, s, a):\n    \"\"\"\n    Given the current esitmate of the parameters, for each image Xk\n    esitmates the probability p(d_k|X_k, F, B, s, a).\n\n    Parameters\n    ----------\n    X : array, shape(H, W, K)\n        K images of size H x W.\n    F  : array_like, shape(H, w)\n        Estimate of prankster's face.\n    B : array shape(H, W)\n        Estimate of background.\n    s : float\n        Eestimate of standard deviation of Gaussian noise.\n    a : array, shape(W-w+1)\n        Estimate of prior on face position in any image.\n\n    Returns\n    -------\n    q : array\n        shape (W-w+1, K)\n        q[dw, k] - estimate of posterior of position dw\n        of prankster's face given image Xk\n    \"\"\"\n    # your code here\n    # 使用logsumexp的方法\n    # ad = log p(x_k| d_k, F, B, s) + log p(d_k,|a)\n    # d* = argmax_d{ad}\n    # log \\sum exp(ad)= ad* + log\\sum_d exp(ad-ad*)\n    ll = calculate_log_probability(X, F, B, s)\n    ad = ll + np.log(a).T.reshape(a.shape[0], 1)\n    ad_max = np.max(ad, axis=0)\n    q = ad - ad_max - np.log(np.sum(np.exp(ad - ad_max), axis=0))\n    q = np.exp(q)\n    return q\n```\n* M步\n```\ndef run_m_step(X, q, w):\n    \"\"\"\n    Estimates F, B, s, a given esitmate of posteriors defined by q.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    q  :\n        q[dw, k] - estimate of posterior of position dw\n                   of prankster's face given image Xk\n    w : int\n        Face mask width.\n\n    Returns\n    -------\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n    a : array, shape (W-w+1)\n        Estimate of prior on position of face in any image.\n    \"\"\"\n    # your code here\n    H, W, K = X.shape\n    F = np.zeros((H, w))\n    B = np.zeros((H, W))\n    s = 0.0\n    # a\n    a = np.sum(q, axis=1)/np.sum(q)\n    # F\n    for m in range(w):\n        for k in range(K):\n            F[:, m] = (1/K*np.sum(q[:, k]*X[:, m:W-w+1+m, k], axis=1)) + F[:, m]\n\n    # B\n    B1 = np.zeros((H, W))\n    B2 = np.zeros((H, W))\n    for dw in range(W-w+1):\n        for k in range(K):\n            B1[:, :dw] = q[dw, k] * X[:, :dw, k] + B1[:, :dw]\n            B1[:, dw+w:] = q[dw, k] * X[:, dw+w:, k] + B1[:, dw+w:]\n            B2[:, :dw] = q[dw, k] + B2[:, :dw]\n            B2[:, dw+w:] = q[dw, k] + B2[:, dw+w:]\n\n    B = B1/B2\n\n    # s\n    s_square = 0\n    for dw in range(W-w+1):\n        for k in range(K):\n            s_square = q[dw, k] * (np.sum((X[:, :dw, k] - B[:, :dw])**2) + np.sum((X[:, dw:dw+w, k] - F)**2)+ \\\n            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**2)) + s_square\n    s = np.sqrt(1/(K*W*H) *  s_square)\n\n    return F, B, s, a\n```\n* 对&E&步与&M&步交替运行，当$L(q, \\,F, \\,B, \\,s, \\,a)$增加值小于提前设定好的阈值时，程序结束。\n```\ndef run_m_step(X, q, w):\n    \"\"\"\n    Estimates F, B, s, a given esitmate of posteriors defined by q.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    q  :\n        q[dw, k] - estimate of posterior of position dw\n                   of prankster's face given image Xk\n    w : int\n        Face mask width.\n\n    Returns\n    -------\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n    a : array, shape (W-w+1)\n        Estimate of prior on position of face in any image.\n    \"\"\"\n    # your code here\n    H, W, K = X.shape\n    F = np.zeros((H, w))\n    B = np.zeros((H, W))\n    s = 0.0\n    # a\n    a = np.sum(q, axis=1)/np.sum(q)\n    # F\n    for m in range(w):\n        for k in range(K):\n            F[:, m] = (1/K*np.sum(q[:, k]*X[:, m:W-w+1+m, k], axis=1)) + F[:, m]\n\n    # B\n    B1 = np.zeros((H, W))\n    B2 = np.zeros((H, W))\n    for dw in range(W-w+1):\n        for k in range(K):\n            B1[:, :dw] = q[dw, k] * X[:, :dw, k] + B1[:, :dw]\n            B1[:, dw+w:] = q[dw, k] * X[:, dw+w:, k] + B1[:, dw+w:]\n            B2[:, :dw] = q[dw, k] + B2[:, :dw]\n            B2[:, dw+w:] = q[dw, k] + B2[:, dw+w:]\n\n    B = B1/B2\n\n    # s\n    s_square = 0\n    for dw in range(W-w+1):\n        for k in range(K):\n            s_square = q[dw, k] * (np.sum((X[:, :dw, k] - B[:, :dw])**2) + np.sum((X[:, dw:dw+w, k] - F)**2)+ \\\n            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**2)) + s_square\n    s = np.sqrt(1/(K*W*H) *  s_square)\n\n    return F, B, s, a\n```\n最终实验结果，人脸图片和背景图如下所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E4%BA%BA%E8%84%B81.png)  ![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E8%83%8C%E6%99%AF1.png)\n\n# 问题与总结\n变成中遇到了一个问题，就是求解q时会出现0的情况，这样就会导致$log\\ 0$的情况出现，出现错误，不知道怎么结果，但是结果却可以跑出了，不过图片并不是特别清晰，我想如果用deep learning的方法训练估计可以达到一个比较好的结果。EM算法可以看成特殊的坐标下降发，对lower bound按照隐变量和参数进行坐标寻优。\n\n# 参考资料\n[1] http://deepbayes.ru/ 主要来自其中的slide\n[2] https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start\n","source":"_posts/EM算法程序实现.md","raw":"---\ntitle: EM算法实现\ndate: 2018-09-05 10:42:01\ntags: deep bayes\ncategories: 学习\n---\n# EM算法\n之前在看概率图模型的时候，写过关于EM算法的内容，不过已经忘记差不多了，最近在看[1]中的材料，感觉有了新的理解，特将这些内容整理成这篇博客。\nEM算法适用于存在隐变量的情况，或者说是假设存在因变量对系统进行推导。\n\\begin{equation}\\begin{split} log\\ p(X\\mid \\theta) &= \\int q(Z)log\\ p(X\\mid \\theta)dZ \\\\\\\\\n&= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{p(Z\\mid X, \\theta)}dZ \\\\\\\\\n&= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{q(Z)}dZ + \\int q(Z) log \\frac{q(Z)}{p(Z\\mid X, \\theta)}dZ\\\\\\\\\n&= L(q, \\theta) + KL(q\\mid\\mid p) \\geqslant L(q, \\theta)\\\\\\\\\n\\end{split}\\end{equation}\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95.png)\nE步是为了获得隐变量的最优值，M步是对参数求最大似然。\n\n# [问题描述](https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start)\n有$K$张受噪声污染的图片，每张图片大小为$H\\times W$，每张图片上都有$H\\times w$大小的人脸，每张人脸的位置不固定，但是高度相同，都与图片的高度一样。如下图所示，每张图片都是受严重受噪声污染的，可以看成是高斯噪声。可以从这里得到[数据集](https://drive.google.com/open?id=1NLOHNhqdDBG6rWk8lOjzm3u3vDyS_9WZ)，该数据集为.mat格式，其中包含有500张$45\\times 60$的图片，其中人脸大小为$45\\times 36$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%99%AA%E5%A3%B0%E5%9B%BE%E7%89%87.png)\n下图是图片的结构，其中$d_k$的位置是不固定的，$F$是不含噪声的人脸图片，$B$是不含噪声的背景图片。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%9B%BE%E7%89%87%E7%BB%93%E6%9E%84.png)\n下面基于EM算法来思考该问题：\n可观数据：$K$张受污染的图片，$X = \\lbrace X_1, ..., X_K \\rbrace$\n隐变量：$F$的位置，$d = \\lbrace d_1, ..., d_K \\rbrace$\n参数：$\\theta = \\lbrace B, F, s^2\\rbrace$\n似然函数：\n$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), & \\text {if $[i, j]\\in faceArea(d_k)$} \\\\\\\\ N(X_k[i, j]\\mid B[i, j], s^2), & \\text{otherwise} \\end{cases} $$\n因为每张图片中$F$和$B$部分减去对应的$F$和$B$，这样就是纯粹的噪声，我们将噪声看做是高斯分布，所以上式就是上面的形式。\n以及先验：\n$p(d_k\\mid a) = a[d_k] $， $\\sum_j a[j] = 1$,，$a\\in R^{W-w+1}$\n概率模型可以写成：\n$$ p(X, d\\mid \\theta, a) = \\prod_k p(X_k\\mid d_k, \\theta)p(d_k\\mid a) $$\n按照第一张图中的EM算法步骤，进行EM算法的推导：\nE步：确定隐变量的最优值\n\\begin{equation}\\begin{split} q(d) = p(d\\mid X, \\theta, a) &= \\prod_k p(d_k\\mid x_k, \\theta, a)\\\\\\\\\n&= \\prod_k\\frac{p(X_k, d_k\\mid \\theta, a)}{\\sum_{d_k'} p(X_k, d_k'\\mid \\theta, a)} \\\\\\\\\n&= \\prod_k\\frac{p(X_k\\mid d_k, theta)p(d_k\\mid a)}{\\sum_{d_k'} p(X_k\\mid d_k', theta)p(d_k'\\mid a)} \\\\\\\\\n\\end{split}\\end{equation}\nM步：对参数求最大似然。\n$$ Q(\\theta, a) = E_{q(d)}log\\ p(X, d\\mid \\theta, a) \\rightarrow max_{\\theta, a} $$\n具体推导这里就不再详细的描述了，可以参照参考文献[1]中的推导过程，最后的推导结果如下：\n$$a[j] = \\frac{\\sum_k q( d_k = j )}{\\sum_{j'}  \\sum_{k'} q( d_{k'} = j')}$$\n$$F[i, m] = \\frac 1 K  \\sum_k \\sum_{d_k} q(d_k)\\, X^k[i,\\, m+d_k]$$\n$$B[i, j] = \\frac {\\sum_k \\sum_{ d_k:\\, (i, \\,j) \\,\\not\\in faceArea(d_k)} q(d_k)\\, X^k[i, j]}\n\t  \t{\\sum_k \\sum_{d_k: \\,(i, \\,j)\\, \\not\\in faceArea(d_k)} q(d_k)}$$\n$$s^2 = \\frac 1 {HWK}   \\sum_k \\sum_{d_k} q(d_k)\n\t  \t\\sum_{i,\\, j}  (X^k[i, \\,j] - Model^{d_k}[i, \\,j])^2$$\n 其中$Model^{d_k}[i, j]$表示由$F$和$B$组成的图片，其中$F$处于$d_k$位置。\n\n# 程序实现\n下面用EM算法来是处理对受噪声污染影响的图片，从而恢复其中的人脸图像。\n程序思路为\n1. 实现对数似然；\n2. 实现variational lower bound；\n3. 实现E步；\n4. 实现M步；\n5. 将循环执行EM步，知道满足结束条件。\n## 具体程序\n* 实现对数似然，似然函数为：$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), & \\text {if $[i, j]\\in faceArea(d_k)$} \\\\\\\\ N(X_k[i, j]\\mid B[i, j], s^2), & \\text{otherwise} \\end{cases} $$\n```\ndef calculate_log_probability(X, F, B, s):\n    \"\"\"\n    Calculates log p(X_k|d_k, F, B, s) for all images X_k in X and\n    all possible face position d_k.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n\n    Returns\n    -------\n    ll : array, shape(W-w+1, K)\n        ll[dw, k] - log-likelihood of observing image X_k given\n        that the prankster's face F is located at position dw\n    \"\"\"\n    # your code here\n    H, W, K = np.shape(X)\n    _, w = np.shape(F)\n    ll = np.zeros((W-w+1, K), dtype=float)\n    for dw in range(W-w+1):\n        for k in range(K):\n            ll[dw, k] = H*w*np.log(1/(s*np.sqrt(2*np.pi))) - np.sum((X[:, dw:dw+w, k] - F)**2/(2 * s**2)) + \\\n            H*dw*np.log(1/(s*np.sqrt(2*np.pi))) - np.sum((X[:, 0:dw, k] - B[:, 0:dw])**2/(2 * s**2)) + \\\n            H*(W-w-dw)*np.log(1/(s*np.sqrt(2*np.pi))) - np.sum((X[:, dw+w:, k] - B[:, dw+w:])**2/(2 * s**2))\n    return ll\n```\n* 实现Variational lower bound\n ```\n def calculate_lower_bound(X, F, B, s, a, q):\n    \"\"\"\n    Calculates the lower bound L(q, F, B, s, a) for\n    the marginal log likelihood.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n    a : array, shape (W-w+1)\n        Estimate of prior on position of face in any image.\n    q : array\n        q[dw, k] - estimate of posterior\n                   of position dw\n                   of prankster's face given image Xk\n\n    Returns\n    -------\n    L : float\n        The lower bound L(q, F, B, s, a)\n        for the marginal log likelihood.\n    \"\"\"\n    # your code here\n    ll = calculate_log_probability(X, F, B, s)\n    L = np.sum(q*ll) + np.sum(q.T*np.log(a)) - np.sum(q*np.log(q))\n    return L\n    ```\n* E步\n```\ndef run_e_step(X, F, B, s, a):\n    \"\"\"\n    Given the current esitmate of the parameters, for each image Xk\n    esitmates the probability p(d_k|X_k, F, B, s, a).\n\n    Parameters\n    ----------\n    X : array, shape(H, W, K)\n        K images of size H x W.\n    F  : array_like, shape(H, w)\n        Estimate of prankster's face.\n    B : array shape(H, W)\n        Estimate of background.\n    s : float\n        Eestimate of standard deviation of Gaussian noise.\n    a : array, shape(W-w+1)\n        Estimate of prior on face position in any image.\n\n    Returns\n    -------\n    q : array\n        shape (W-w+1, K)\n        q[dw, k] - estimate of posterior of position dw\n        of prankster's face given image Xk\n    \"\"\"\n    # your code here\n    # 使用logsumexp的方法\n    # ad = log p(x_k| d_k, F, B, s) + log p(d_k,|a)\n    # d* = argmax_d{ad}\n    # log \\sum exp(ad)= ad* + log\\sum_d exp(ad-ad*)\n    ll = calculate_log_probability(X, F, B, s)\n    ad = ll + np.log(a).T.reshape(a.shape[0], 1)\n    ad_max = np.max(ad, axis=0)\n    q = ad - ad_max - np.log(np.sum(np.exp(ad - ad_max), axis=0))\n    q = np.exp(q)\n    return q\n```\n* M步\n```\ndef run_m_step(X, q, w):\n    \"\"\"\n    Estimates F, B, s, a given esitmate of posteriors defined by q.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    q  :\n        q[dw, k] - estimate of posterior of position dw\n                   of prankster's face given image Xk\n    w : int\n        Face mask width.\n\n    Returns\n    -------\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n    a : array, shape (W-w+1)\n        Estimate of prior on position of face in any image.\n    \"\"\"\n    # your code here\n    H, W, K = X.shape\n    F = np.zeros((H, w))\n    B = np.zeros((H, W))\n    s = 0.0\n    # a\n    a = np.sum(q, axis=1)/np.sum(q)\n    # F\n    for m in range(w):\n        for k in range(K):\n            F[:, m] = (1/K*np.sum(q[:, k]*X[:, m:W-w+1+m, k], axis=1)) + F[:, m]\n\n    # B\n    B1 = np.zeros((H, W))\n    B2 = np.zeros((H, W))\n    for dw in range(W-w+1):\n        for k in range(K):\n            B1[:, :dw] = q[dw, k] * X[:, :dw, k] + B1[:, :dw]\n            B1[:, dw+w:] = q[dw, k] * X[:, dw+w:, k] + B1[:, dw+w:]\n            B2[:, :dw] = q[dw, k] + B2[:, :dw]\n            B2[:, dw+w:] = q[dw, k] + B2[:, dw+w:]\n\n    B = B1/B2\n\n    # s\n    s_square = 0\n    for dw in range(W-w+1):\n        for k in range(K):\n            s_square = q[dw, k] * (np.sum((X[:, :dw, k] - B[:, :dw])**2) + np.sum((X[:, dw:dw+w, k] - F)**2)+ \\\n            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**2)) + s_square\n    s = np.sqrt(1/(K*W*H) *  s_square)\n\n    return F, B, s, a\n```\n* 对&E&步与&M&步交替运行，当$L(q, \\,F, \\,B, \\,s, \\,a)$增加值小于提前设定好的阈值时，程序结束。\n```\ndef run_m_step(X, q, w):\n    \"\"\"\n    Estimates F, B, s, a given esitmate of posteriors defined by q.\n\n    Parameters\n    ----------\n    X : array, shape (H, W, K)\n        K images of size H x W.\n    q  :\n        q[dw, k] - estimate of posterior of position dw\n                   of prankster's face given image Xk\n    w : int\n        Face mask width.\n\n    Returns\n    -------\n    F : array, shape (H, w)\n        Estimate of prankster's face.\n    B : array, shape (H, W)\n        Estimate of background.\n    s : float\n        Estimate of standard deviation of Gaussian noise.\n    a : array, shape (W-w+1)\n        Estimate of prior on position of face in any image.\n    \"\"\"\n    # your code here\n    H, W, K = X.shape\n    F = np.zeros((H, w))\n    B = np.zeros((H, W))\n    s = 0.0\n    # a\n    a = np.sum(q, axis=1)/np.sum(q)\n    # F\n    for m in range(w):\n        for k in range(K):\n            F[:, m] = (1/K*np.sum(q[:, k]*X[:, m:W-w+1+m, k], axis=1)) + F[:, m]\n\n    # B\n    B1 = np.zeros((H, W))\n    B2 = np.zeros((H, W))\n    for dw in range(W-w+1):\n        for k in range(K):\n            B1[:, :dw] = q[dw, k] * X[:, :dw, k] + B1[:, :dw]\n            B1[:, dw+w:] = q[dw, k] * X[:, dw+w:, k] + B1[:, dw+w:]\n            B2[:, :dw] = q[dw, k] + B2[:, :dw]\n            B2[:, dw+w:] = q[dw, k] + B2[:, dw+w:]\n\n    B = B1/B2\n\n    # s\n    s_square = 0\n    for dw in range(W-w+1):\n        for k in range(K):\n            s_square = q[dw, k] * (np.sum((X[:, :dw, k] - B[:, :dw])**2) + np.sum((X[:, dw:dw+w, k] - F)**2)+ \\\n            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**2)) + s_square\n    s = np.sqrt(1/(K*W*H) *  s_square)\n\n    return F, B, s, a\n```\n最终实验结果，人脸图片和背景图如下所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E4%BA%BA%E8%84%B81.png)  ![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E8%83%8C%E6%99%AF1.png)\n\n# 问题与总结\n变成中遇到了一个问题，就是求解q时会出现0的情况，这样就会导致$log\\ 0$的情况出现，出现错误，不知道怎么结果，但是结果却可以跑出了，不过图片并不是特别清晰，我想如果用deep learning的方法训练估计可以达到一个比较好的结果。EM算法可以看成特殊的坐标下降发，对lower bound按照隐变量和参数进行坐标寻优。\n\n# 参考资料\n[1] http://deepbayes.ru/ 主要来自其中的slide\n[2] https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start\n","slug":"EM算法程序实现","published":1,"updated":"2018-09-25T12:23:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms100051ouzxtxrwg8t","content":"<h1 id=\"EM算法\"><a href=\"#EM算法\" class=\"headerlink\" title=\"EM算法\"></a>EM算法</h1><p>之前在看概率图模型的时候，写过关于EM算法的内容，不过已经忘记差不多了，最近在看[1]中的材料，感觉有了新的理解，特将这些内容整理成这篇博客。<br>EM算法适用于存在隐变量的情况，或者说是假设存在因变量对系统进行推导。<br>\\begin{equation}\\begin{split} log\\ p(X\\mid \\theta) &amp;= \\int q(Z)log\\ p(X\\mid \\theta)dZ \\\\<br>&amp;= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{p(Z\\mid X, \\theta)}dZ \\\\<br>&amp;= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{q(Z)}dZ + \\int q(Z) log \\frac{q(Z)}{p(Z\\mid X, \\theta)}dZ\\\\<br>&amp;= L(q, \\theta) + KL(q\\mid\\mid p) \\geqslant L(q, \\theta)\\\\<br>\\end{split}\\end{equation}<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95.png\" alt><br>E步是为了获得隐变量的最优值，M步是对参数求最大似然。</p>\n<h1 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a><a href=\"https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start\" target=\"_blank\" rel=\"noopener\">问题描述</a></h1><p>有$K$张受噪声污染的图片，每张图片大小为$H\\times W$，每张图片上都有$H\\times w$大小的人脸，每张人脸的位置不固定，但是高度相同，都与图片的高度一样。如下图所示，每张图片都是受严重受噪声污染的，可以看成是高斯噪声。可以从这里得到<a href=\"https://drive.google.com/open?id=1NLOHNhqdDBG6rWk8lOjzm3u3vDyS_9WZ\" target=\"_blank\" rel=\"noopener\">数据集</a>，该数据集为.mat格式，其中包含有500张$45\\times 60$的图片，其中人脸大小为$45\\times 36$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%99%AA%E5%A3%B0%E5%9B%BE%E7%89%87.png\" alt><br>下图是图片的结构，其中$d_k$的位置是不固定的，$F$是不含噪声的人脸图片，$B$是不含噪声的背景图片。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%9B%BE%E7%89%87%E7%BB%93%E6%9E%84.png\" alt><br>下面基于EM算法来思考该问题：<br>可观数据：$K$张受污染的图片，$X = \\lbrace X_1, …, X_K \\rbrace$<br>隐变量：$F$的位置，$d = \\lbrace d_1, …, d_K \\rbrace$<br>参数：$\\theta = \\lbrace B, F, s^2\\rbrace$<br>似然函数：<br>$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), &amp; \\text {if $[i, j]\\in faceArea(d_k)$} \\\\ N(X_k[i, j]\\mid B[i, j], s^2), &amp; \\text{otherwise} \\end{cases} $$<br>因为每张图片中$F$和$B$部分减去对应的$F$和$B$，这样就是纯粹的噪声，我们将噪声看做是高斯分布，所以上式就是上面的形式。<br>以及先验：<br>$p(d_k\\mid a) = a[d_k] $， $\\sum_j a[j] = 1$,，$a\\in R^{W-w+1}$<br>概率模型可以写成：<br>$$ p(X, d\\mid \\theta, a) = \\prod_k p(X_k\\mid d_k, \\theta)p(d_k\\mid a) $$<br>按照第一张图中的EM算法步骤，进行EM算法的推导：<br>E步：确定隐变量的最优值<br>\\begin{equation}\\begin{split} q(d) = p(d\\mid X, \\theta, a) &amp;= \\prod_k p(d_k\\mid x_k, \\theta, a)\\\\<br>&amp;= \\prod_k\\frac{p(X_k, d_k\\mid \\theta, a)}{\\sum_{d_k’} p(X_k, d_k’\\mid \\theta, a)} \\\\<br>&amp;= \\prod_k\\frac{p(X_k\\mid d_k, theta)p(d_k\\mid a)}{\\sum_{d_k’} p(X_k\\mid d_k’, theta)p(d_k’\\mid a)} \\\\<br>\\end{split}\\end{equation}<br>M步：对参数求最大似然。<br>$$ Q(\\theta, a) = E_{q(d)}log\\ p(X, d\\mid \\theta, a) \\rightarrow max_{\\theta, a} $$<br>具体推导这里就不再详细的描述了，可以参照参考文献[1]中的推导过程，最后的推导结果如下：<br>$$a[j] = \\frac{\\sum_k q( d_k = j )}{\\sum_{j’}  \\sum_{k’} q( d_{k’} = j’)}$$<br>$$F[i, m] = \\frac 1 K  \\sum_k \\sum_{d_k} q(d_k)\\, X^k[i,\\, m+d_k]$$<br>$$B[i, j] = \\frac {\\sum_k \\sum_{ d_k:\\, (i, \\,j) \\,\\not\\in faceArea(d_k)} q(d_k)\\, X^k[i, j]}<br>          {\\sum_k \\sum_{d_k: \\,(i, \\,j)\\, \\not\\in faceArea(d_k)} q(d_k)}$$<br>$$s^2 = \\frac 1 {HWK}   \\sum_k \\sum_{d_k} q(d_k)<br>          \\sum_{i,\\, j}  (X^k[i, \\,j] - Model^{d_k}[i, \\,j])^2$$<br> 其中$Model^{d_k}[i, j]$表示由$F$和$B$组成的图片，其中$F$处于$d_k$位置。</p>\n<h1 id=\"程序实现\"><a href=\"#程序实现\" class=\"headerlink\" title=\"程序实现\"></a>程序实现</h1><p>下面用EM算法来是处理对受噪声污染影响的图片，从而恢复其中的人脸图像。<br>程序思路为</p>\n<ol>\n<li>实现对数似然；</li>\n<li>实现variational lower bound；</li>\n<li>实现E步；</li>\n<li>实现M步；</li>\n<li>将循环执行EM步，知道满足结束条件。<h2 id=\"具体程序\"><a href=\"#具体程序\" class=\"headerlink\" title=\"具体程序\"></a>具体程序</h2></li>\n</ol>\n<ul>\n<li><p>实现对数似然，似然函数为：$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), &amp; \\text {if $[i, j]\\in faceArea(d_k)$} \\\\ N(X_k[i, j]\\mid B[i, j], s^2), &amp; \\text{otherwise} \\end{cases} $$</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def calculate_log_probability(X, F, B, s):</span><br><span class=\"line\">    <span class=\"string\">\"\"</span>\"</span><br><span class=\"line\">    Calculates <span class=\"keyword\">log</span> p(X_k|d_k, F, B, s) <span class=\"keyword\">for</span> all images X_k <span class=\"keyword\">in</span> X and</span><br><span class=\"line\">    all possible face position d_k.</span><br><span class=\"line\"></span><br><span class=\"line\">    Parameters</span><br><span class=\"line\">    ----------</span><br><span class=\"line\">    X : array, shape (<span class=\"keyword\">H</span>, W, K)</span><br><span class=\"line\">        K images of size <span class=\"keyword\">H</span> x W.</span><br><span class=\"line\">    F : array, shape (<span class=\"keyword\">H</span>, w)</span><br><span class=\"line\">        Estimate of prankster's face.</span><br><span class=\"line\">    B : array, shape (<span class=\"keyword\">H</span>, W)</span><br><span class=\"line\">        Estimate of background.</span><br><span class=\"line\">    s : float</span><br><span class=\"line\">        Estimate of standard deviation of Gaussian noise.</span><br><span class=\"line\"></span><br><span class=\"line\">    Returns</span><br><span class=\"line\">    -------</span><br><span class=\"line\">    ll : array, shape(W-w+1, K)</span><br><span class=\"line\">        ll[dw, k] - <span class=\"keyword\">log</span>-likelihood of observing image X_k given</span><br><span class=\"line\">        that the prankster's face F is located at position dw</span><br><span class=\"line\">    <span class=\"string\">\"\"</span>\"</span><br><span class=\"line\">    # your code here</span><br><span class=\"line\">    <span class=\"keyword\">H</span>, W, K = np.shape(X)</span><br><span class=\"line\">    _, w = np.shape(F)</span><br><span class=\"line\">    ll = np.zeros((W-w+1, K), dtype=float)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> dw <span class=\"keyword\">in</span> <span class=\"keyword\">range</span>(W-w+1):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"keyword\">range</span>(K):</span><br><span class=\"line\">            ll[dw, k] = <span class=\"keyword\">H</span>*w*np.<span class=\"built_in\">log</span>(1/(s*np.<span class=\"built_in\">sqrt</span>(2*np.pi))) - np.<span class=\"built_in\">sum</span>((X[:, dw:dw+w, k] - F)**2/(2 * s**2)) + \\</span><br><span class=\"line\">            <span class=\"keyword\">H</span>*dw*np.<span class=\"built_in\">log</span>(1/(s*np.<span class=\"built_in\">sqrt</span>(2*np.pi))) - np.<span class=\"built_in\">sum</span>((X[:, 0:dw, k] - B[:, 0:dw])**2/(2 * s**2)) + \\</span><br><span class=\"line\">            <span class=\"keyword\">H</span>*(W-w-dw)*np.<span class=\"built_in\">log</span>(1/(s*np.<span class=\"built_in\">sqrt</span>(2*np.pi))) - np.<span class=\"built_in\">sum</span>((X[:, dw+w:, k] - B[:, dw+w:])**2/(2 * s**2))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ll</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>实现Variational lower bound</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calculate_lower_bound</span><span class=\"params\">(X, F, B, s, a, q)</span>:</span></span><br><span class=\"line\">   <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">   Calculates the lower bound L(q, F, B, s, a) for</span></span><br><span class=\"line\"><span class=\"string\">   the marginal log likelihood.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">   Parameters</span></span><br><span class=\"line\"><span class=\"string\">   ----------</span></span><br><span class=\"line\"><span class=\"string\">   X : array, shape (H, W, K)</span></span><br><span class=\"line\"><span class=\"string\">       K images of size H x W.</span></span><br><span class=\"line\"><span class=\"string\">   F : array, shape (H, w)</span></span><br><span class=\"line\"><span class=\"string\">       Estimate of prankster's face.</span></span><br><span class=\"line\"><span class=\"string\">   B : array, shape (H, W)</span></span><br><span class=\"line\"><span class=\"string\">       Estimate of background.</span></span><br><span class=\"line\"><span class=\"string\">   s : float</span></span><br><span class=\"line\"><span class=\"string\">       Estimate of standard deviation of Gaussian noise.</span></span><br><span class=\"line\"><span class=\"string\">   a : array, shape (W-w+1)</span></span><br><span class=\"line\"><span class=\"string\">       Estimate of prior on position of face in any image.</span></span><br><span class=\"line\"><span class=\"string\">   q : array</span></span><br><span class=\"line\"><span class=\"string\">       q[dw, k] - estimate of posterior</span></span><br><span class=\"line\"><span class=\"string\">                  of position dw</span></span><br><span class=\"line\"><span class=\"string\">                  of prankster's face given image Xk</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">   Returns</span></span><br><span class=\"line\"><span class=\"string\">   -------</span></span><br><span class=\"line\"><span class=\"string\">   L : float</span></span><br><span class=\"line\"><span class=\"string\">       The lower bound L(q, F, B, s, a)</span></span><br><span class=\"line\"><span class=\"string\">       for the marginal log likelihood.</span></span><br><span class=\"line\"><span class=\"string\">   \"\"\"</span></span><br><span class=\"line\">   <span class=\"comment\"># your code here</span></span><br><span class=\"line\">   ll = calculate_log_probability(X, F, B, s)</span><br><span class=\"line\">   L = np.sum(q*ll) + np.sum(q.T*np.log(a)) - np.sum(q*np.log(q))</span><br><span class=\"line\">   <span class=\"keyword\">return</span> L</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>E步</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_e_step</span><span class=\"params\">(X, F, B, s, a)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Given the current esitmate of the parameters, for each image Xk</span></span><br><span class=\"line\"><span class=\"string\">    esitmates the probability p(d_k|X_k, F, B, s, a).</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Parameters</span></span><br><span class=\"line\"><span class=\"string\">    ----------</span></span><br><span class=\"line\"><span class=\"string\">    X : array, shape(H, W, K)</span></span><br><span class=\"line\"><span class=\"string\">        K images of size H x W.</span></span><br><span class=\"line\"><span class=\"string\">    F  : array_like, shape(H, w)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of prankster's face.</span></span><br><span class=\"line\"><span class=\"string\">    B : array shape(H, W)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of background.</span></span><br><span class=\"line\"><span class=\"string\">    s : float</span></span><br><span class=\"line\"><span class=\"string\">        Eestimate of standard deviation of Gaussian noise.</span></span><br><span class=\"line\"><span class=\"string\">    a : array, shape(W-w+1)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of prior on face position in any image.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns</span></span><br><span class=\"line\"><span class=\"string\">    -------</span></span><br><span class=\"line\"><span class=\"string\">    q : array</span></span><br><span class=\"line\"><span class=\"string\">        shape (W-w+1, K)</span></span><br><span class=\"line\"><span class=\"string\">        q[dw, k] - estimate of posterior of position dw</span></span><br><span class=\"line\"><span class=\"string\">        of prankster's face given image Xk</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"comment\"># your code here</span></span><br><span class=\"line\">    <span class=\"comment\"># 使用logsumexp的方法</span></span><br><span class=\"line\">    <span class=\"comment\"># ad = log p(x_k| d_k, F, B, s) + log p(d_k,|a)</span></span><br><span class=\"line\">    <span class=\"comment\"># d* = argmax_d&#123;ad&#125;</span></span><br><span class=\"line\">    <span class=\"comment\"># log \\sum exp(ad)= ad* + log\\sum_d exp(ad-ad*)</span></span><br><span class=\"line\">    ll = calculate_log_probability(X, F, B, s)</span><br><span class=\"line\">    ad = ll + np.log(a).T.reshape(a.shape[<span class=\"number\">0</span>], <span class=\"number\">1</span>)</span><br><span class=\"line\">    ad_max = np.max(ad, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    q = ad - ad_max - np.log(np.sum(np.exp(ad - ad_max), axis=<span class=\"number\">0</span>))</span><br><span class=\"line\">    q = np.exp(q)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> q</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>M步</p>\n<figure class=\"highlight perl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def run_m_step(X, <span class=\"keyword\">q</span>, w):</span><br><span class=\"line\">    <span class=\"string\">\"\"</span><span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">    Estimates F, B, s, a given esitmate of posteriors defined by q.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Parameters</span></span><br><span class=\"line\"><span class=\"string\">    ----------</span></span><br><span class=\"line\"><span class=\"string\">    X : array, shape (H, W, K)</span></span><br><span class=\"line\"><span class=\"string\">        K images of size H x W.</span></span><br><span class=\"line\"><span class=\"string\">    q  :</span></span><br><span class=\"line\"><span class=\"string\">        q[dw, k] - estimate of posterior of position dw</span></span><br><span class=\"line\"><span class=\"string\">                   of prankster's face given image Xk</span></span><br><span class=\"line\"><span class=\"string\">    w : int</span></span><br><span class=\"line\"><span class=\"string\">        Face mask width.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns</span></span><br><span class=\"line\"><span class=\"string\">    -------</span></span><br><span class=\"line\"><span class=\"string\">    F : array, shape (H, w)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of prankster's face.</span></span><br><span class=\"line\"><span class=\"string\">    B : array, shape (H, W)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of background.</span></span><br><span class=\"line\"><span class=\"string\">    s : float</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of standard deviation of Gaussian noise.</span></span><br><span class=\"line\"><span class=\"string\">    a : array, shape (W-w+1)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of prior on position of face in any image.</span></span><br><span class=\"line\"><span class=\"string\">    \"</span><span class=\"string\">\"\"</span></span><br><span class=\"line\">    <span class=\"comment\"># your code here</span></span><br><span class=\"line\">    H, W, K = X.shape</span><br><span class=\"line\">    F = np.zeros((H, w))</span><br><span class=\"line\">    B = np.zeros((H, W))</span><br><span class=\"line\">    <span class=\"keyword\">s</span> = <span class=\"number\">0</span>.<span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># a</span></span><br><span class=\"line\">    a = np.sum(<span class=\"keyword\">q</span>, axis=<span class=\"number\">1</span>)/np.sum(<span class=\"keyword\">q</span>)</span><br><span class=\"line\">    <span class=\"comment\"># F</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> <span class=\"keyword\">m</span> in range(w):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k in range(K):</span><br><span class=\"line\">            F[:, <span class=\"keyword\">m</span>] = (<span class=\"number\">1</span>/K*np.sum(<span class=\"string\">q[:, k]</span>*X[:, <span class=\"keyword\">m</span>:W-w+<span class=\"number\">1</span>+<span class=\"keyword\">m</span>, k], axis=<span class=\"number\">1</span>)) + F[:, <span class=\"keyword\">m</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># B</span></span><br><span class=\"line\">    B1 = np.zeros((H, W))</span><br><span class=\"line\">    B2 = np.zeros((H, W))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> dw in range(W-w+<span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k in range(K):</span><br><span class=\"line\">            B1[:, :dw] = <span class=\"string\">q[dw, k]</span> * X[:, :dw, k] + B1[:, :dw]</span><br><span class=\"line\">            B1[:, dw+w:] = <span class=\"string\">q[dw, k]</span> * X[:, dw+w:, k] + B1[:, dw+w:]</span><br><span class=\"line\">            B2[:, :dw] = <span class=\"string\">q[dw, k]</span> + B2[:, :dw]</span><br><span class=\"line\">            B2[:, dw+w:] = <span class=\"string\">q[dw, k]</span> + B2[:, dw+w:]</span><br><span class=\"line\"></span><br><span class=\"line\">    B = B1/B2</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># s</span></span><br><span class=\"line\">    s_square = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> dw in range(W-w+<span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k in range(K):</span><br><span class=\"line\">            s_square = <span class=\"string\">q[dw, k]</span> * (np.sum((X[:, :dw, k] - B[:, :dw])**<span class=\"number\">2</span>) + np.sum((X[:, dw:dw+w, k] - F)**<span class=\"number\">2</span>)+ \\</span><br><span class=\"line\">            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**<span class=\"number\">2</span>)) + s_square</span><br><span class=\"line\">    <span class=\"keyword\">s</span> = np.sqrt(<span class=\"number\">1</span>/(K*W*H) *  s_square)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> F, B, <span class=\"keyword\">s</span>, a</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>对&amp;E&amp;步与&amp;M&amp;步交替运行，当$L(q, \\,F, \\,B, \\,s, \\,a)$增加值小于提前设定好的阈值时，程序结束。</p>\n<figure class=\"highlight perl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def run_m_step(X, <span class=\"keyword\">q</span>, w):</span><br><span class=\"line\">    <span class=\"string\">\"\"</span><span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">    Estimates F, B, s, a given esitmate of posteriors defined by q.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Parameters</span></span><br><span class=\"line\"><span class=\"string\">    ----------</span></span><br><span class=\"line\"><span class=\"string\">    X : array, shape (H, W, K)</span></span><br><span class=\"line\"><span class=\"string\">        K images of size H x W.</span></span><br><span class=\"line\"><span class=\"string\">    q  :</span></span><br><span class=\"line\"><span class=\"string\">        q[dw, k] - estimate of posterior of position dw</span></span><br><span class=\"line\"><span class=\"string\">                   of prankster's face given image Xk</span></span><br><span class=\"line\"><span class=\"string\">    w : int</span></span><br><span class=\"line\"><span class=\"string\">        Face mask width.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns</span></span><br><span class=\"line\"><span class=\"string\">    -------</span></span><br><span class=\"line\"><span class=\"string\">    F : array, shape (H, w)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of prankster's face.</span></span><br><span class=\"line\"><span class=\"string\">    B : array, shape (H, W)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of background.</span></span><br><span class=\"line\"><span class=\"string\">    s : float</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of standard deviation of Gaussian noise.</span></span><br><span class=\"line\"><span class=\"string\">    a : array, shape (W-w+1)</span></span><br><span class=\"line\"><span class=\"string\">        Estimate of prior on position of face in any image.</span></span><br><span class=\"line\"><span class=\"string\">    \"</span><span class=\"string\">\"\"</span></span><br><span class=\"line\">    <span class=\"comment\"># your code here</span></span><br><span class=\"line\">    H, W, K = X.shape</span><br><span class=\"line\">    F = np.zeros((H, w))</span><br><span class=\"line\">    B = np.zeros((H, W))</span><br><span class=\"line\">    <span class=\"keyword\">s</span> = <span class=\"number\">0</span>.<span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># a</span></span><br><span class=\"line\">    a = np.sum(<span class=\"keyword\">q</span>, axis=<span class=\"number\">1</span>)/np.sum(<span class=\"keyword\">q</span>)</span><br><span class=\"line\">    <span class=\"comment\"># F</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> <span class=\"keyword\">m</span> in range(w):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k in range(K):</span><br><span class=\"line\">            F[:, <span class=\"keyword\">m</span>] = (<span class=\"number\">1</span>/K*np.sum(<span class=\"string\">q[:, k]</span>*X[:, <span class=\"keyword\">m</span>:W-w+<span class=\"number\">1</span>+<span class=\"keyword\">m</span>, k], axis=<span class=\"number\">1</span>)) + F[:, <span class=\"keyword\">m</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># B</span></span><br><span class=\"line\">    B1 = np.zeros((H, W))</span><br><span class=\"line\">    B2 = np.zeros((H, W))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> dw in range(W-w+<span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k in range(K):</span><br><span class=\"line\">            B1[:, :dw] = <span class=\"string\">q[dw, k]</span> * X[:, :dw, k] + B1[:, :dw]</span><br><span class=\"line\">            B1[:, dw+w:] = <span class=\"string\">q[dw, k]</span> * X[:, dw+w:, k] + B1[:, dw+w:]</span><br><span class=\"line\">            B2[:, :dw] = <span class=\"string\">q[dw, k]</span> + B2[:, :dw]</span><br><span class=\"line\">            B2[:, dw+w:] = <span class=\"string\">q[dw, k]</span> + B2[:, dw+w:]</span><br><span class=\"line\"></span><br><span class=\"line\">    B = B1/B2</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># s</span></span><br><span class=\"line\">    s_square = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> dw in range(W-w+<span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k in range(K):</span><br><span class=\"line\">            s_square = <span class=\"string\">q[dw, k]</span> * (np.sum((X[:, :dw, k] - B[:, :dw])**<span class=\"number\">2</span>) + np.sum((X[:, dw:dw+w, k] - F)**<span class=\"number\">2</span>)+ \\</span><br><span class=\"line\">            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**<span class=\"number\">2</span>)) + s_square</span><br><span class=\"line\">    <span class=\"keyword\">s</span> = np.sqrt(<span class=\"number\">1</span>/(K*W*H) *  s_square)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> F, B, <span class=\"keyword\">s</span>, a</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>最终实验结果，人脸图片和背景图如下所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E4%BA%BA%E8%84%B81.png\" alt>  <img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E8%83%8C%E6%99%AF1.png\" alt></p>\n<h1 id=\"问题与总结\"><a href=\"#问题与总结\" class=\"headerlink\" title=\"问题与总结\"></a>问题与总结</h1><p>变成中遇到了一个问题，就是求解q时会出现0的情况，这样就会导致$log\\ 0$的情况出现，出现错误，不知道怎么结果，但是结果却可以跑出了，不过图片并不是特别清晰，我想如果用deep learning的方法训练估计可以达到一个比较好的结果。EM算法可以看成特殊的坐标下降发，对lower bound按照隐变量和参数进行坐标寻优。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] <a href=\"http://deepbayes.ru/\" target=\"_blank\" rel=\"noopener\">http://deepbayes.ru/</a> 主要来自其中的slide<br>[2] <a href=\"https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start\" target=\"_blank\" rel=\"noopener\">https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"EM算法\"><a href=\"#EM算法\" class=\"headerlink\" title=\"EM算法\"></a>EM算法</h1><p>之前在看概率图模型的时候，写过关于EM算法的内容，不过已经忘记差不多了，最近在看[1]中的材料，感觉有了新的理解，特将这些内容整理成这篇博客。<br>EM算法适用于存在隐变量的情况，或者说是假设存在因变量对系统进行推导。<br>\\begin{equation}\\begin{split} log\\ p(X\\mid \\theta) &amp;= \\int q(Z)log\\ p(X\\mid \\theta)dZ \\\\<br>&amp;= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{p(Z\\mid X, \\theta)}dZ \\\\<br>&amp;= \\int q(Z)log \\frac{p(X, Z\\mid \\theta)}{q(Z)}dZ + \\int q(Z) log \\frac{q(Z)}{p(Z\\mid X, \\theta)}dZ\\\\<br>&amp;= L(q, \\theta) + KL(q\\mid\\mid p) \\geqslant L(q, \\theta)\\\\<br>\\end{split}\\end{equation}<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95.png\" alt><br>E步是为了获得隐变量的最优值，M步是对参数求最大似然。</p>\n<h1 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a><a href=\"https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start\" target=\"_blank\" rel=\"noopener\">问题描述</a></h1><p>有$K$张受噪声污染的图片，每张图片大小为$H\\times W$，每张图片上都有$H\\times w$大小的人脸，每张人脸的位置不固定，但是高度相同，都与图片的高度一样。如下图所示，每张图片都是受严重受噪声污染的，可以看成是高斯噪声。可以从这里得到<a href=\"https://drive.google.com/open?id=1NLOHNhqdDBG6rWk8lOjzm3u3vDyS_9WZ\" target=\"_blank\" rel=\"noopener\">数据集</a>，该数据集为.mat格式，其中包含有500张$45\\times 60$的图片，其中人脸大小为$45\\times 36$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%99%AA%E5%A3%B0%E5%9B%BE%E7%89%87.png\" alt><br>下图是图片的结构，其中$d_k$的位置是不固定的，$F$是不含噪声的人脸图片，$B$是不含噪声的背景图片。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%9B%BE%E7%89%87%E7%BB%93%E6%9E%84.png\" alt><br>下面基于EM算法来思考该问题：<br>可观数据：$K$张受污染的图片，$X = \\lbrace X_1, …, X_K \\rbrace$<br>隐变量：$F$的位置，$d = \\lbrace d_1, …, d_K \\rbrace$<br>参数：$\\theta = \\lbrace B, F, s^2\\rbrace$<br>似然函数：<br>$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), &amp; \\text {if $[i, j]\\in faceArea(d_k)$} \\\\ N(X_k[i, j]\\mid B[i, j], s^2), &amp; \\text{otherwise} \\end{cases} $$<br>因为每张图片中$F$和$B$部分减去对应的$F$和$B$，这样就是纯粹的噪声，我们将噪声看做是高斯分布，所以上式就是上面的形式。<br>以及先验：<br>$p(d_k\\mid a) = a[d_k] $， $\\sum_j a[j] = 1$,，$a\\in R^{W-w+1}$<br>概率模型可以写成：<br>$$ p(X, d\\mid \\theta, a) = \\prod_k p(X_k\\mid d_k, \\theta)p(d_k\\mid a) $$<br>按照第一张图中的EM算法步骤，进行EM算法的推导：<br>E步：确定隐变量的最优值<br>\\begin{equation}\\begin{split} q(d) = p(d\\mid X, \\theta, a) &amp;= \\prod_k p(d_k\\mid x_k, \\theta, a)\\\\<br>&amp;= \\prod_k\\frac{p(X_k, d_k\\mid \\theta, a)}{\\sum_{d_k’} p(X_k, d_k’\\mid \\theta, a)} \\\\<br>&amp;= \\prod_k\\frac{p(X_k\\mid d_k, theta)p(d_k\\mid a)}{\\sum_{d_k’} p(X_k\\mid d_k’, theta)p(d_k’\\mid a)} \\\\<br>\\end{split}\\end{equation}<br>M步：对参数求最大似然。<br>$$ Q(\\theta, a) = E_{q(d)}log\\ p(X, d\\mid \\theta, a) \\rightarrow max_{\\theta, a} $$<br>具体推导这里就不再详细的描述了，可以参照参考文献[1]中的推导过程，最后的推导结果如下：<br>$$a[j] = \\frac{\\sum_k q( d_k = j )}{\\sum_{j’}  \\sum_{k’} q( d_{k’} = j’)}$$<br>$$F[i, m] = \\frac 1 K  \\sum_k \\sum_{d_k} q(d_k)\\, X^k[i,\\, m+d_k]$$<br>$$B[i, j] = \\frac {\\sum_k \\sum_{ d_k:\\, (i, \\,j) \\,\\not\\in faceArea(d_k)} q(d_k)\\, X^k[i, j]}<br>          {\\sum_k \\sum_{d_k: \\,(i, \\,j)\\, \\not\\in faceArea(d_k)} q(d_k)}$$<br>$$s^2 = \\frac 1 {HWK}   \\sum_k \\sum_{d_k} q(d_k)<br>          \\sum_{i,\\, j}  (X^k[i, \\,j] - Model^{d_k}[i, \\,j])^2$$<br> 其中$Model^{d_k}[i, j]$表示由$F$和$B$组成的图片，其中$F$处于$d_k$位置。</p>\n<h1 id=\"程序实现\"><a href=\"#程序实现\" class=\"headerlink\" title=\"程序实现\"></a>程序实现</h1><p>下面用EM算法来是处理对受噪声污染影响的图片，从而恢复其中的人脸图像。<br>程序思路为</p>\n<ol>\n<li>实现对数似然；</li>\n<li>实现variational lower bound；</li>\n<li>实现E步；</li>\n<li>实现M步；</li>\n<li>将循环执行EM步，知道满足结束条件。<h2 id=\"具体程序\"><a href=\"#具体程序\" class=\"headerlink\" title=\"具体程序\"></a>具体程序</h2></li>\n</ol>\n<ul>\n<li><p>实现对数似然，似然函数为：$$ p(X_k\\mid d_k, \\theta) = \\prod_{ij}\\begin{cases} N(X_k[i, j]\\mid F[i,j-d_k], s^2), &amp; \\text {if $[i, j]\\in faceArea(d_k)$} \\\\ N(X_k[i, j]\\mid B[i, j], s^2), &amp; \\text{otherwise} \\end{cases} $$</p>\n<!--�3-->\n</li>\n<li><p>实现Variational lower bound</p>\n<!--�4-->\n</li>\n<li><p>E步</p>\n<!--�5-->\n</li>\n<li><p>M步</p>\n<!--�6-->\n</li>\n<li><p>对&amp;E&amp;步与&amp;M&amp;步交替运行，当$L(q, \\,F, \\,B, \\,s, \\,a)$增加值小于提前设定好的阈值时，程序结束。</p>\n<!--�7-->\n</li>\n</ul>\n<p>最终实验结果，人脸图片和背景图如下所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E4%BA%BA%E8%84%B81.png\" alt>  <img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E8%83%8C%E6%99%AF1.png\" alt></p>\n<h1 id=\"问题与总结\"><a href=\"#问题与总结\" class=\"headerlink\" title=\"问题与总结\"></a>问题与总结</h1><p>变成中遇到了一个问题，就是求解q时会出现0的情况，这样就会导致$log\\ 0$的情况出现，出现错误，不知道怎么结果，但是结果却可以跑出了，不过图片并不是特别清晰，我想如果用deep learning的方法训练估计可以达到一个比较好的结果。EM算法可以看成特殊的坐标下降发，对lower bound按照隐变量和参数进行坐标寻优。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] <a href=\"http://deepbayes.ru/\" target=\"_blank\" rel=\"noopener\">http://deepbayes.ru/</a> 主要来自其中的slide<br>[2] <a href=\"https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start\" target=\"_blank\" rel=\"noopener\">https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start</a></p>\n"},{"title":"CRF进行图像分割","date":"2018-11-29T07:58:49.000Z","_content":"# 写在前面的话\n最近，十分困惑条件随机场是如何工作的，为什么可以加在卷积神经网络的后面作为后处理的部分。虽然理论部分前面的博客也有写过，做过一些总结，不过因为没有实现过代码，所以仍有困惑解决不了，每念至此，心绪不宁，遂作此文，以供参考。\n\n# 具体实现\n本文将实现全连接随机场对非RGB的图像进行分割，主要参考文献[1]以及对应的[github](https://github.com/lucasb-eyer/pydensecrf)代码，另外本文需要安装pydensecrf，可以通过`pip install pydensecrf`安装，安装时需注意，pydensecrf依赖于cython，需要先安装cython。\n\n\n## 对非RGB图像分割\n本文的代码放在了我的github中命名为CRF的仓库库中，[链接地址](https://github.com/hjyai94/CRF/blob/master/examples/Non%20RGB%20Example.ipynb)，这里的代码来自于[pydensecrf](https://github.com/lucasb-eyer/pydensecrf)。\n\n### 一元势\n一元势包含了每个像素对应的类别，这些可以来自随机森林或者是深度神经网络的softmax。这里，我们共有两个类别，一个是前景，一个是背景，这里大小设置为$400\\times 512$。我们建立了两个二维的高斯分布，并且平面显示。\n\n```python\nfrom scipy.stats import multivariate_normal\n\nH, W, NLABELS = 400, 512, 2\n\n# This creates a gaussian blob...\npos = np.stack(np.mgrid[0:H, 0:W], axis=2)\nprint(pos.shape)\nrv = multivariate_normal([H//2, W//2], (H//4)*(W//4))\nprobs = rv.pdf(pos)\nprint(probs.shape)\n# ...which we project into the range [0.4, 0.6]\nprobs = (probs-probs.min()) / (probs.max()-probs.min())\nprobs = 0.5 + 0.2 * (probs-0.5)\n\n# The first dimension needs to be equal to the number of classes.\n# Let's have one \"foreground\" and one \"background\" class.\n# So replicate the gaussian blob but invert it to create the probability\n# of the \"background\" class to be the opposite of \"foreground\".\nprobs = np.tile(probs[np.newaxis,:,:],(2,1,1))\nprobs[1,:,:] = 1 - probs[0,:,:]\n\n# Let's have a look:\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1); plt.imshow(probs[0,:,:]); plt.title('Foreground probability'); plt.axis('off'); plt.colorbar();\nplt.subplot(1,2,2); plt.imshow(probs[1,:,:]); plt.title('Background probability'); plt.axis('off'); plt.colorbar();\n```\n![output_9_1.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_9_1.png)\n\n\n### 使用一元势进行推断\n这里我们可以使用一元势进行推断，也就是说这里我们不考虑像素间的相互关联。这样做并不是很好的推断，但是可以这么做。\n```python\n# Inference without pair-wise terms\nU = unary_from_softmax(probs)  # note: num classes is first dim\nd = dcrf.DenseCRF2D(W, H, NLABELS)\nd.setUnaryEnergy(U)\n\n# Run inference for 10 iterations\nQ_unary = d.inference(10)\n\n# The Q is now the approximate posterior, we can get a MAP estimate using argmax.\nmap_soln_unary = np.argmax(Q_unary, axis=0)\n\n# Unfortunately, the DenseCRF flattens everything, so get it back into picture form.\nmap_soln_unary = map_soln_unary.reshape((H,W))\n# And let's have a look.\nplt.imshow(map_soln_unary); plt.axis('off'); plt.title('MAP Solution without pairwise terms');\n```\n![output_12_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_12_0.png)\n\n### 二元势\n图像处理中，我们经常使用像素间的双边关系，也就是说，我们认为有相似颜色的或者是相似的位置的像素认为是同一类。下面我们建立这样的双边关系。\n\n```python\nNCHAN=1\n\n# Create simple image which will serve as bilateral.\n# Note that we put the channel dimension last here,\n# but we could also have it be the first dimension and\n# just change the `chdim` parameter to `0` further down.\nimg = np.zeros((H,W,NCHAN), np.uint8)\nimg[H//3:2*H//3,W//4:3*W//4,:] = 1\n\nplt.imshow(img[:,:,0]); plt.title('Bilateral image'); plt.axis('off'); plt.colorbar();\n\n# Create the pairwise bilateral term from the above image.\n# The two `s{dims,chan}` parameters are model hyper-parameters defining\n# the strength of the location and image content bilaterals, respectively.\npairwise_energy = create_pairwise_bilateral(sdims=(10,10), schan=(0.01,), img=img, chdim=2)\n\n# pairwise_energy now contains as many dimensions as the DenseCRF has features,\n# which in this case is 3: (x,y,channel1)\nimg_en = pairwise_energy.reshape((-1, H, W))  # Reshape just for plotting\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1); plt.imshow(img_en[0]); plt.title('Pairwise bilateral [x]'); plt.axis('off'); plt.colorbar();\nplt.subplot(1,3,2); plt.imshow(img_en[1]); plt.title('Pairwise bilateral [y]'); plt.axis('off'); plt.colorbar();\nplt.subplot(1,3,3); plt.imshow(img_en[2]); plt.title('Pairwise bilateral [c]'); plt.axis('off'); plt.colorbar();\n```\n![output_17_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_17_0.png)\n![output_17_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_18_0.png)\n\n### 使用完整的条件随机场进行推断\n下面我们将一元势与二元势结合起来进行推断，执行不同的迭代次数，有下面的结果。\n```python\nd = dcrf.DenseCRF2D(W, H, NLABELS)\nd.setUnaryEnergy(U)\nd.addPairwiseEnergy(pairwise_energy, compat=10)  # `compat` is the \"strength\" of this potential.\n\n# This time, let's do inference in steps ourselves\n# so that we can look at intermediate solutions\n# as well as monitor KL-divergence, which indicates\n# how well we have converged.\n# PyDenseCRF also requires us to keep track of two\n# temporary buffers it needs for computations.\nQ, tmp1, tmp2 = d.startInference()\nfor _ in range(5):\n    d.stepInference(Q, tmp1, tmp2)\nkl1 = d.klDivergence(Q) / (H*W)\nmap_soln1 = np.argmax(Q, axis=0).reshape((H,W))\n\nfor _ in range(20):\n    d.stepInference(Q, tmp1, tmp2)\nkl2 = d.klDivergence(Q) / (H*W)\nmap_soln2 = np.argmax(Q, axis=0).reshape((H,W))\n\nfor _ in range(50):\n    d.stepInference(Q, tmp1, tmp2)\nkl3 = d.klDivergence(Q) / (H*W)\nmap_soln3 = np.argmax(Q, axis=0).reshape((H,W))\n\nimg_en = pairwise_energy.reshape((-1, H, W))  # Reshape just for plotting\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1); plt.imshow(map_soln1);\nplt.title('MAP Solution with DenseCRF\\n(5 steps, KL={:.2f})'.format(kl1)); plt.axis('off');\nplt.subplot(1,3,2); plt.imshow(map_soln2);\nplt.title('MAP Solution with DenseCRF\\n(20 steps, KL={:.2f})'.format(kl2)); plt.axis('off');\nplt.subplot(1,3,3); plt.imshow(map_soln3);\nplt.title('MAP Solution with DenseCRF\\n(75 steps, KL={:.2f})'.format(kl3)); plt.axis('off');\n```\n![output_21_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_21_0.png)\n\n\n# 参考文献\n[1] Krähenbühl P, Koltun V. Efficient inference in fully connected crfs with gaussian edge potentials[C]//Advances in neural information processing systems. 2011: 109-117.","source":"_posts/CRF进行图像分割.md","raw":"---\ntitle: CRF进行图像分割\ndate: 2018-11-29 15:58:49\ntags: 概率图模型\ncategories: 学习\n---\n# 写在前面的话\n最近，十分困惑条件随机场是如何工作的，为什么可以加在卷积神经网络的后面作为后处理的部分。虽然理论部分前面的博客也有写过，做过一些总结，不过因为没有实现过代码，所以仍有困惑解决不了，每念至此，心绪不宁，遂作此文，以供参考。\n\n# 具体实现\n本文将实现全连接随机场对非RGB的图像进行分割，主要参考文献[1]以及对应的[github](https://github.com/lucasb-eyer/pydensecrf)代码，另外本文需要安装pydensecrf，可以通过`pip install pydensecrf`安装，安装时需注意，pydensecrf依赖于cython，需要先安装cython。\n\n\n## 对非RGB图像分割\n本文的代码放在了我的github中命名为CRF的仓库库中，[链接地址](https://github.com/hjyai94/CRF/blob/master/examples/Non%20RGB%20Example.ipynb)，这里的代码来自于[pydensecrf](https://github.com/lucasb-eyer/pydensecrf)。\n\n### 一元势\n一元势包含了每个像素对应的类别，这些可以来自随机森林或者是深度神经网络的softmax。这里，我们共有两个类别，一个是前景，一个是背景，这里大小设置为$400\\times 512$。我们建立了两个二维的高斯分布，并且平面显示。\n\n```python\nfrom scipy.stats import multivariate_normal\n\nH, W, NLABELS = 400, 512, 2\n\n# This creates a gaussian blob...\npos = np.stack(np.mgrid[0:H, 0:W], axis=2)\nprint(pos.shape)\nrv = multivariate_normal([H//2, W//2], (H//4)*(W//4))\nprobs = rv.pdf(pos)\nprint(probs.shape)\n# ...which we project into the range [0.4, 0.6]\nprobs = (probs-probs.min()) / (probs.max()-probs.min())\nprobs = 0.5 + 0.2 * (probs-0.5)\n\n# The first dimension needs to be equal to the number of classes.\n# Let's have one \"foreground\" and one \"background\" class.\n# So replicate the gaussian blob but invert it to create the probability\n# of the \"background\" class to be the opposite of \"foreground\".\nprobs = np.tile(probs[np.newaxis,:,:],(2,1,1))\nprobs[1,:,:] = 1 - probs[0,:,:]\n\n# Let's have a look:\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1); plt.imshow(probs[0,:,:]); plt.title('Foreground probability'); plt.axis('off'); plt.colorbar();\nplt.subplot(1,2,2); plt.imshow(probs[1,:,:]); plt.title('Background probability'); plt.axis('off'); plt.colorbar();\n```\n![output_9_1.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_9_1.png)\n\n\n### 使用一元势进行推断\n这里我们可以使用一元势进行推断，也就是说这里我们不考虑像素间的相互关联。这样做并不是很好的推断，但是可以这么做。\n```python\n# Inference without pair-wise terms\nU = unary_from_softmax(probs)  # note: num classes is first dim\nd = dcrf.DenseCRF2D(W, H, NLABELS)\nd.setUnaryEnergy(U)\n\n# Run inference for 10 iterations\nQ_unary = d.inference(10)\n\n# The Q is now the approximate posterior, we can get a MAP estimate using argmax.\nmap_soln_unary = np.argmax(Q_unary, axis=0)\n\n# Unfortunately, the DenseCRF flattens everything, so get it back into picture form.\nmap_soln_unary = map_soln_unary.reshape((H,W))\n# And let's have a look.\nplt.imshow(map_soln_unary); plt.axis('off'); plt.title('MAP Solution without pairwise terms');\n```\n![output_12_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_12_0.png)\n\n### 二元势\n图像处理中，我们经常使用像素间的双边关系，也就是说，我们认为有相似颜色的或者是相似的位置的像素认为是同一类。下面我们建立这样的双边关系。\n\n```python\nNCHAN=1\n\n# Create simple image which will serve as bilateral.\n# Note that we put the channel dimension last here,\n# but we could also have it be the first dimension and\n# just change the `chdim` parameter to `0` further down.\nimg = np.zeros((H,W,NCHAN), np.uint8)\nimg[H//3:2*H//3,W//4:3*W//4,:] = 1\n\nplt.imshow(img[:,:,0]); plt.title('Bilateral image'); plt.axis('off'); plt.colorbar();\n\n# Create the pairwise bilateral term from the above image.\n# The two `s{dims,chan}` parameters are model hyper-parameters defining\n# the strength of the location and image content bilaterals, respectively.\npairwise_energy = create_pairwise_bilateral(sdims=(10,10), schan=(0.01,), img=img, chdim=2)\n\n# pairwise_energy now contains as many dimensions as the DenseCRF has features,\n# which in this case is 3: (x,y,channel1)\nimg_en = pairwise_energy.reshape((-1, H, W))  # Reshape just for plotting\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1); plt.imshow(img_en[0]); plt.title('Pairwise bilateral [x]'); plt.axis('off'); plt.colorbar();\nplt.subplot(1,3,2); plt.imshow(img_en[1]); plt.title('Pairwise bilateral [y]'); plt.axis('off'); plt.colorbar();\nplt.subplot(1,3,3); plt.imshow(img_en[2]); plt.title('Pairwise bilateral [c]'); plt.axis('off'); plt.colorbar();\n```\n![output_17_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_17_0.png)\n![output_17_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_18_0.png)\n\n### 使用完整的条件随机场进行推断\n下面我们将一元势与二元势结合起来进行推断，执行不同的迭代次数，有下面的结果。\n```python\nd = dcrf.DenseCRF2D(W, H, NLABELS)\nd.setUnaryEnergy(U)\nd.addPairwiseEnergy(pairwise_energy, compat=10)  # `compat` is the \"strength\" of this potential.\n\n# This time, let's do inference in steps ourselves\n# so that we can look at intermediate solutions\n# as well as monitor KL-divergence, which indicates\n# how well we have converged.\n# PyDenseCRF also requires us to keep track of two\n# temporary buffers it needs for computations.\nQ, tmp1, tmp2 = d.startInference()\nfor _ in range(5):\n    d.stepInference(Q, tmp1, tmp2)\nkl1 = d.klDivergence(Q) / (H*W)\nmap_soln1 = np.argmax(Q, axis=0).reshape((H,W))\n\nfor _ in range(20):\n    d.stepInference(Q, tmp1, tmp2)\nkl2 = d.klDivergence(Q) / (H*W)\nmap_soln2 = np.argmax(Q, axis=0).reshape((H,W))\n\nfor _ in range(50):\n    d.stepInference(Q, tmp1, tmp2)\nkl3 = d.klDivergence(Q) / (H*W)\nmap_soln3 = np.argmax(Q, axis=0).reshape((H,W))\n\nimg_en = pairwise_energy.reshape((-1, H, W))  # Reshape just for plotting\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1); plt.imshow(map_soln1);\nplt.title('MAP Solution with DenseCRF\\n(5 steps, KL={:.2f})'.format(kl1)); plt.axis('off');\nplt.subplot(1,3,2); plt.imshow(map_soln2);\nplt.title('MAP Solution with DenseCRF\\n(20 steps, KL={:.2f})'.format(kl2)); plt.axis('off');\nplt.subplot(1,3,3); plt.imshow(map_soln3);\nplt.title('MAP Solution with DenseCRF\\n(75 steps, KL={:.2f})'.format(kl3)); plt.axis('off');\n```\n![output_21_0.png](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_21_0.png)\n\n\n# 参考文献\n[1] Krähenbühl P, Koltun V. Efficient inference in fully connected crfs with gaussian edge potentials[C]//Advances in neural information processing systems. 2011: 109-117.","slug":"CRF进行图像分割","published":1,"updated":"2018-11-30T02:43:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms300071ouz25hl0t52","content":"<h1 id=\"写在前面的话\"><a href=\"#写在前面的话\" class=\"headerlink\" title=\"写在前面的话\"></a>写在前面的话</h1><p>最近，十分困惑条件随机场是如何工作的，为什么可以加在卷积神经网络的后面作为后处理的部分。虽然理论部分前面的博客也有写过，做过一些总结，不过因为没有实现过代码，所以仍有困惑解决不了，每念至此，心绪不宁，遂作此文，以供参考。</p>\n<h1 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h1><p>本文将实现全连接随机场对非RGB的图像进行分割，主要参考文献[1]以及对应的<a href=\"https://github.com/lucasb-eyer/pydensecrf\" target=\"_blank\" rel=\"noopener\">github</a>代码，另外本文需要安装pydensecrf，可以通过<code>pip install pydensecrf</code>安装，安装时需注意，pydensecrf依赖于cython，需要先安装cython。</p>\n<h2 id=\"对非RGB图像分割\"><a href=\"#对非RGB图像分割\" class=\"headerlink\" title=\"对非RGB图像分割\"></a>对非RGB图像分割</h2><p>本文的代码放在了我的github中命名为CRF的仓库库中，<a href=\"https://github.com/hjyai94/CRF/blob/master/examples/Non%20RGB%20Example.ipynb\" target=\"_blank\" rel=\"noopener\">链接地址</a>，这里的代码来自于<a href=\"https://github.com/lucasb-eyer/pydensecrf\" target=\"_blank\" rel=\"noopener\">pydensecrf</a>。</p>\n<h3 id=\"一元势\"><a href=\"#一元势\" class=\"headerlink\" title=\"一元势\"></a>一元势</h3><p>一元势包含了每个像素对应的类别，这些可以来自随机森林或者是深度神经网络的softmax。这里，我们共有两个类别，一个是前景，一个是背景，这里大小设置为$400\\times 512$。我们建立了两个二维的高斯分布，并且平面显示。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> multivariate_normal</span><br><span class=\"line\"></span><br><span class=\"line\">H, W, NLABELS = <span class=\"number\">400</span>, <span class=\"number\">512</span>, <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This creates a gaussian blob...</span></span><br><span class=\"line\">pos = np.stack(np.mgrid[<span class=\"number\">0</span>:H, <span class=\"number\">0</span>:W], axis=<span class=\"number\">2</span>)</span><br><span class=\"line\">print(pos.shape)</span><br><span class=\"line\">rv = multivariate_normal([H//<span class=\"number\">2</span>, W//<span class=\"number\">2</span>], (H//<span class=\"number\">4</span>)*(W//<span class=\"number\">4</span>))</span><br><span class=\"line\">probs = rv.pdf(pos)</span><br><span class=\"line\">print(probs.shape)</span><br><span class=\"line\"><span class=\"comment\"># ...which we project into the range [0.4, 0.6]</span></span><br><span class=\"line\">probs = (probs-probs.min()) / (probs.max()-probs.min())</span><br><span class=\"line\">probs = <span class=\"number\">0.5</span> + <span class=\"number\">0.2</span> * (probs<span class=\"number\">-0.5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The first dimension needs to be equal to the number of classes.</span></span><br><span class=\"line\"><span class=\"comment\"># Let's have one \"foreground\" and one \"background\" class.</span></span><br><span class=\"line\"><span class=\"comment\"># So replicate the gaussian blob but invert it to create the probability</span></span><br><span class=\"line\"><span class=\"comment\"># of the \"background\" class to be the opposite of \"foreground\".</span></span><br><span class=\"line\">probs = np.tile(probs[np.newaxis,:,:],(<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>))</span><br><span class=\"line\">probs[<span class=\"number\">1</span>,:,:] = <span class=\"number\">1</span> - probs[<span class=\"number\">0</span>,:,:]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Let's have a look:</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>); plt.imshow(probs[<span class=\"number\">0</span>,:,:]); plt.title(<span class=\"string\">'Foreground probability'</span>); plt.axis(<span class=\"string\">'off'</span>); plt.colorbar();</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>); plt.imshow(probs[<span class=\"number\">1</span>,:,:]); plt.title(<span class=\"string\">'Background probability'</span>); plt.axis(<span class=\"string\">'off'</span>); plt.colorbar();</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_9_1.png\" alt=\"output_9_1.png\"></p>\n<h3 id=\"使用一元势进行推断\"><a href=\"#使用一元势进行推断\" class=\"headerlink\" title=\"使用一元势进行推断\"></a>使用一元势进行推断</h3><p>这里我们可以使用一元势进行推断，也就是说这里我们不考虑像素间的相互关联。这样做并不是很好的推断，但是可以这么做。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Inference without pair-wise terms</span></span><br><span class=\"line\">U = unary_from_softmax(probs)  <span class=\"comment\"># <span class=\"doctag\">note:</span> num classes is first dim</span></span><br><span class=\"line\">d = dcrf.DenseCRF2D(W, H, NLABELS)</span><br><span class=\"line\">d.setUnaryEnergy(U)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Run inference for 10 iterations</span></span><br><span class=\"line\">Q_unary = d.inference(<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The Q is now the approximate posterior, we can get a MAP estimate using argmax.</span></span><br><span class=\"line\">map_soln_unary = np.argmax(Q_unary, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Unfortunately, the DenseCRF flattens everything, so get it back into picture form.</span></span><br><span class=\"line\">map_soln_unary = map_soln_unary.reshape((H,W))</span><br><span class=\"line\"><span class=\"comment\"># And let's have a look.</span></span><br><span class=\"line\">plt.imshow(map_soln_unary); plt.axis(<span class=\"string\">'off'</span>); plt.title(<span class=\"string\">'MAP Solution without pairwise terms'</span>);</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_12_0.png\" alt=\"output_12_0.png\"></p>\n<h3 id=\"二元势\"><a href=\"#二元势\" class=\"headerlink\" title=\"二元势\"></a>二元势</h3><p>图像处理中，我们经常使用像素间的双边关系，也就是说，我们认为有相似颜色的或者是相似的位置的像素认为是同一类。下面我们建立这样的双边关系。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NCHAN=<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create simple image which will serve as bilateral.</span></span><br><span class=\"line\"><span class=\"comment\"># Note that we put the channel dimension last here,</span></span><br><span class=\"line\"><span class=\"comment\"># but we could also have it be the first dimension and</span></span><br><span class=\"line\"><span class=\"comment\"># just change the `chdim` parameter to `0` further down.</span></span><br><span class=\"line\">img = np.zeros((H,W,NCHAN), np.uint8)</span><br><span class=\"line\">img[H//<span class=\"number\">3</span>:<span class=\"number\">2</span>*H//<span class=\"number\">3</span>,W//<span class=\"number\">4</span>:<span class=\"number\">3</span>*W//<span class=\"number\">4</span>,:] = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(img[:,:,<span class=\"number\">0</span>]); plt.title(<span class=\"string\">'Bilateral image'</span>); plt.axis(<span class=\"string\">'off'</span>); plt.colorbar();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create the pairwise bilateral term from the above image.</span></span><br><span class=\"line\"><span class=\"comment\"># The two `s&#123;dims,chan&#125;` parameters are model hyper-parameters defining</span></span><br><span class=\"line\"><span class=\"comment\"># the strength of the location and image content bilaterals, respectively.</span></span><br><span class=\"line\">pairwise_energy = create_pairwise_bilateral(sdims=(<span class=\"number\">10</span>,<span class=\"number\">10</span>), schan=(<span class=\"number\">0.01</span>,), img=img, chdim=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># pairwise_energy now contains as many dimensions as the DenseCRF has features,</span></span><br><span class=\"line\"><span class=\"comment\"># which in this case is 3: (x,y,channel1)</span></span><br><span class=\"line\">img_en = pairwise_energy.reshape((<span class=\"number\">-1</span>, H, W))  <span class=\"comment\"># Reshape just for plotting</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">1</span>); plt.imshow(img_en[<span class=\"number\">0</span>]); plt.title(<span class=\"string\">'Pairwise bilateral [x]'</span>); plt.axis(<span class=\"string\">'off'</span>); plt.colorbar();</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>); plt.imshow(img_en[<span class=\"number\">1</span>]); plt.title(<span class=\"string\">'Pairwise bilateral [y]'</span>); plt.axis(<span class=\"string\">'off'</span>); plt.colorbar();</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>); plt.imshow(img_en[<span class=\"number\">2</span>]); plt.title(<span class=\"string\">'Pairwise bilateral [c]'</span>); plt.axis(<span class=\"string\">'off'</span>); plt.colorbar();</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_17_0.png\" alt=\"output_17_0.png\"><br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_18_0.png\" alt=\"output_17_0.png\"></p>\n<h3 id=\"使用完整的条件随机场进行推断\"><a href=\"#使用完整的条件随机场进行推断\" class=\"headerlink\" title=\"使用完整的条件随机场进行推断\"></a>使用完整的条件随机场进行推断</h3><p>下面我们将一元势与二元势结合起来进行推断，执行不同的迭代次数，有下面的结果。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d = dcrf.DenseCRF2D(W, H, NLABELS)</span><br><span class=\"line\">d.setUnaryEnergy(U)</span><br><span class=\"line\">d.addPairwiseEnergy(pairwise_energy, compat=<span class=\"number\">10</span>)  <span class=\"comment\"># `compat` is the \"strength\" of this potential.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This time, let's do inference in steps ourselves</span></span><br><span class=\"line\"><span class=\"comment\"># so that we can look at intermediate solutions</span></span><br><span class=\"line\"><span class=\"comment\"># as well as monitor KL-divergence, which indicates</span></span><br><span class=\"line\"><span class=\"comment\"># how well we have converged.</span></span><br><span class=\"line\"><span class=\"comment\"># PyDenseCRF also requires us to keep track of two</span></span><br><span class=\"line\"><span class=\"comment\"># temporary buffers it needs for computations.</span></span><br><span class=\"line\">Q, tmp1, tmp2 = d.startInference()</span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>):</span><br><span class=\"line\">    d.stepInference(Q, tmp1, tmp2)</span><br><span class=\"line\">kl1 = d.klDivergence(Q) / (H*W)</span><br><span class=\"line\">map_soln1 = np.argmax(Q, axis=<span class=\"number\">0</span>).reshape((H,W))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(<span class=\"number\">20</span>):</span><br><span class=\"line\">    d.stepInference(Q, tmp1, tmp2)</span><br><span class=\"line\">kl2 = d.klDivergence(Q) / (H*W)</span><br><span class=\"line\">map_soln2 = np.argmax(Q, axis=<span class=\"number\">0</span>).reshape((H,W))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(<span class=\"number\">50</span>):</span><br><span class=\"line\">    d.stepInference(Q, tmp1, tmp2)</span><br><span class=\"line\">kl3 = d.klDivergence(Q) / (H*W)</span><br><span class=\"line\">map_soln3 = np.argmax(Q, axis=<span class=\"number\">0</span>).reshape((H,W))</span><br><span class=\"line\"></span><br><span class=\"line\">img_en = pairwise_energy.reshape((<span class=\"number\">-1</span>, H, W))  <span class=\"comment\"># Reshape just for plotting</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">1</span>); plt.imshow(map_soln1);</span><br><span class=\"line\">plt.title(<span class=\"string\">'MAP Solution with DenseCRF\\n(5 steps, KL=&#123;:.2f&#125;)'</span>.format(kl1)); plt.axis(<span class=\"string\">'off'</span>);</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>); plt.imshow(map_soln2);</span><br><span class=\"line\">plt.title(<span class=\"string\">'MAP Solution with DenseCRF\\n(20 steps, KL=&#123;:.2f&#125;)'</span>.format(kl2)); plt.axis(<span class=\"string\">'off'</span>);</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>); plt.imshow(map_soln3);</span><br><span class=\"line\">plt.title(<span class=\"string\">'MAP Solution with DenseCRF\\n(75 steps, KL=&#123;:.2f&#125;)'</span>.format(kl3)); plt.axis(<span class=\"string\">'off'</span>);</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_21_0.png\" alt=\"output_21_0.png\"></p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] Krähenbühl P, Koltun V. Efficient inference in fully connected crfs with gaussian edge potentials[C]//Advances in neural information processing systems. 2011: 109-117.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"写在前面的话\"><a href=\"#写在前面的话\" class=\"headerlink\" title=\"写在前面的话\"></a>写在前面的话</h1><p>最近，十分困惑条件随机场是如何工作的，为什么可以加在卷积神经网络的后面作为后处理的部分。虽然理论部分前面的博客也有写过，做过一些总结，不过因为没有实现过代码，所以仍有困惑解决不了，每念至此，心绪不宁，遂作此文，以供参考。</p>\n<h1 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h1><p>本文将实现全连接随机场对非RGB的图像进行分割，主要参考文献[1]以及对应的<a href=\"https://github.com/lucasb-eyer/pydensecrf\" target=\"_blank\" rel=\"noopener\">github</a>代码，另外本文需要安装pydensecrf，可以通过<code>pip install pydensecrf</code>安装，安装时需注意，pydensecrf依赖于cython，需要先安装cython。</p>\n<h2 id=\"对非RGB图像分割\"><a href=\"#对非RGB图像分割\" class=\"headerlink\" title=\"对非RGB图像分割\"></a>对非RGB图像分割</h2><p>本文的代码放在了我的github中命名为CRF的仓库库中，<a href=\"https://github.com/hjyai94/CRF/blob/master/examples/Non%20RGB%20Example.ipynb\" target=\"_blank\" rel=\"noopener\">链接地址</a>，这里的代码来自于<a href=\"https://github.com/lucasb-eyer/pydensecrf\" target=\"_blank\" rel=\"noopener\">pydensecrf</a>。</p>\n<h3 id=\"一元势\"><a href=\"#一元势\" class=\"headerlink\" title=\"一元势\"></a>一元势</h3><p>一元势包含了每个像素对应的类别，这些可以来自随机森林或者是深度神经网络的softmax。这里，我们共有两个类别，一个是前景，一个是背景，这里大小设置为$400\\times 512$。我们建立了两个二维的高斯分布，并且平面显示。</p>\n<!--�8-->\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_9_1.png\" alt=\"output_9_1.png\"></p>\n<h3 id=\"使用一元势进行推断\"><a href=\"#使用一元势进行推断\" class=\"headerlink\" title=\"使用一元势进行推断\"></a>使用一元势进行推断</h3><p>这里我们可以使用一元势进行推断，也就是说这里我们不考虑像素间的相互关联。这样做并不是很好的推断，但是可以这么做。<br><!--�9--></p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_12_0.png\" alt=\"output_12_0.png\"></p>\n<h3 id=\"二元势\"><a href=\"#二元势\" class=\"headerlink\" title=\"二元势\"></a>二元势</h3><p>图像处理中，我们经常使用像素间的双边关系，也就是说，我们认为有相似颜色的或者是相似的位置的像素认为是同一类。下面我们建立这样的双边关系。</p>\n<!--�10-->\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_17_0.png\" alt=\"output_17_0.png\"><br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_18_0.png\" alt=\"output_17_0.png\"></p>\n<h3 id=\"使用完整的条件随机场进行推断\"><a href=\"#使用完整的条件随机场进行推断\" class=\"headerlink\" title=\"使用完整的条件随机场进行推断\"></a>使用完整的条件随机场进行推断</h3><p>下面我们将一元势与二元势结合起来进行推断，执行不同的迭代次数，有下面的结果。<br><!--�11--></p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_21_0.png\" alt=\"output_21_0.png\"></p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] Krähenbühl P, Koltun V. Efficient inference in fully connected crfs with gaussian edge potentials[C]//Advances in neural information processing systems. 2011: 109-117.</p>\n"},{"title":"GAN（生成对抗网络）","date":"2018-01-30T07:01:17.000Z","_content":"生成对抗网络（Generative Adersarial nets），基本思想就是同步训练生成模型G和判别模型D，\n生成模型G服从数据分布，判别模型D用来判断样本是来自于生成模型G还是训练数据。\n\n\n完全可以编成一段相声，从南边来了一个生成模型生成数据，从北边来了一个鉴别模型鉴别数据，\n生成模型拼命生成数据不让鉴别模型鉴别数据，鉴别模型偏要鉴别生成模型生成的数据。\n\n# Refercence\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).\n","source":"_posts/GAN.md","raw":"---\ntitle: GAN（生成对抗网络）\ndate: 2018-01-30 15:01:17\ntags: GAN\ncategories: 学习\n---\n生成对抗网络（Generative Adersarial nets），基本思想就是同步训练生成模型G和判别模型D，\n生成模型G服从数据分布，判别模型D用来判断样本是来自于生成模型G还是训练数据。\n\n\n完全可以编成一段相声，从南边来了一个生成模型生成数据，从北边来了一个鉴别模型鉴别数据，\n生成模型拼命生成数据不让鉴别模型鉴别数据，鉴别模型偏要鉴别生成模型生成的数据。\n\n# Refercence\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).\n","slug":"GAN","published":1,"updated":"2018-03-28T04:36:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms400081ouz4k6yd91c","content":"<p>生成对抗网络（Generative Adersarial nets），基本思想就是同步训练生成模型G和判别模型D，<br>生成模型G服从数据分布，判别模型D用来判断样本是来自于生成模型G还是训练数据。</p>\n<p>完全可以编成一段相声，从南边来了一个生成模型生成数据，从北边来了一个鉴别模型鉴别数据，<br>生成模型拼命生成数据不让鉴别模型鉴别数据，鉴别模型偏要鉴别生成模型生成的数据。</p>\n<h1 id=\"Refercence\"><a href=\"#Refercence\" class=\"headerlink\" title=\"Refercence\"></a>Refercence</h1><p>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</p>\n","site":{"data":{}},"excerpt":"","more":"<p>生成对抗网络（Generative Adersarial nets），基本思想就是同步训练生成模型G和判别模型D，<br>生成模型G服从数据分布，判别模型D用来判断样本是来自于生成模型G还是训练数据。</p>\n<p>完全可以编成一段相声，从南边来了一个生成模型生成数据，从北边来了一个鉴别模型鉴别数据，<br>生成模型拼命生成数据不让鉴别模型鉴别数据，鉴别模型偏要鉴别生成模型生成的数据。</p>\n<h1 id=\"Refercence\"><a href=\"#Refercence\" class=\"headerlink\" title=\"Refercence\"></a>Refercence</h1><p>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</p>\n"},{"title":"EnglishPod","date":"2018-04-10T08:33:23.000Z","_content":"# englishpod_B0001\n* I'm still working on it.\nI still need more time.\n* complimentray\nfree\n* I'll go with.\nI'll take. I'll choose.\n* grab  \nget quickly\n\n# englishpod_B0002\n* headache\n* sore throat\nit hurts\n* runny nose\n* feverish\nfeeling your body being very hot.\n* quite ill\nvery sick\n* come down with flu\nI'm coming with cold.Begining to feel sick.\n* calling in  sick\nYou call to your office,and you are sick and won't go to work.\n* take the day off\n\n# englishpod_C0003\n* I have the reservation under the name\n* mix up\nconfusion\n* overbooked\nfull\n* complimentray upgrade\nfree\n\n# englishpod_C0004\n* resources\nmoney\n* understaffed\nnot enough people to do the job\n* the timing is just not right\nit is not the right now\n* weight off my sholders\nremove pressure or stress\n* give me a hand\nhelp out\n* keep our cost down\nto not to spend much money\n* intern\n实习生\n\n# englishpod_C0005\n* unbelievable\nsomething is amazing\n* a mile long\nthis line is really long\n* there is no way\nit is not possible\n* cut in line\nsomebody get in front of you\n\n# englishpod_C0006\n* road trip\nthe car is packed. everything you need is in the car\n* fill up the tank.\n* we got all our bases coverd\n* let's get going\n\n# englishpod_C0007\n* computer virus\n* froze\nstopping working\n* infective file\n* up to date\n* I'll be right there/down/out\n* It turns out that\n\n# englishpod_C0008\n* in a bit of hurry\n* contact details\n* slip my mind\n* around there\n* I'm terrible with names/faces\n\n# englishpd_C0009\n* inconsiderate\nnot thinking about other's feeling\n* keep it down\n* not such a big deal\n* not a big problem\n* switch it off\n* I can't hear a thing\n\n# englishpod_C0010\n* drive sales\n* promotion\n* match the competitor\n* in the market\nin the insustry\n* It'll never fly\nit won't work\n\n# englishpod_C0011\n* weird\nstrange  odd\n* housewarming\n* a bad feeling\n* kicked me out\nforce me to leave\n* creep me out\nmake me feel uncomfortable\n* scared and\n* I don't know if you heard\ngossip\n* fill me in\ngive me information\n* you scared the heck out of me\n\n# englishpod_C0012\n* such a mess\n* chore\n* tidy up\n* spotless\n一尘不染\n* mall\nmany stores in there\n* grocery\ngrocery list\ngrocery shopping\n* I'm in the middle of something now.\n* I'll be there in a second\n\n# englishpod_C0013\n* expenses\n* through the roof\noff the charts\n* expenditure\n* out of control\n* go over\n* profit and loss statement\n\n# englishpod_B0014\n* recession\n* broke\n* loan\n* mortgage\na loan to help you buy an apartment\n* hit me pretty hard\n* tuition\n* can I help you?\nwhat can I do for you?\n* I'm sorry to trouble you\n* on top of that\n* data debt date\n\n# englishpod_C0015\n* knock over\nslip something down\n* explode\n* familiar\n* coincidence\n* I feel terrible\nplease accept my apologies\n* I don't mean knocking over\n\n# englishpod_B0016\n* step on it\nspeed up slow down\ngo fast\n* have a fit\nget angry\n* cut through\ngo through\n* short cut\ntake a short way\n* make a left/right\nmake a u turn\n* take a side street\ntake the freeway\n\n# englishpod_B0017\n* groom\nman\n* bride\nwoman\n* It's about time\nfinally at last\n* aisle\n* bridemaids\n* flower girl\n* ring bearer\n* niece nephew\n* gorgeous\nbeautiful\n* get married\n* priest\n\n# englishpod_D0018\n* bankrupt\n* bail out\n* injustice\n* outrage\n* break out  \nto begin suddenlly\n* have the nerve to\ndare to do\n* financial\n\n# englishpod_C0019\n* eggnog\n* vehicle\ncar\n* lawer\n* appoint\nchoose\n* sleigh\n* step out\nstep out the vehicle\n* get a load of\nlook at\n* Don't take the tone with me\n* invoice\n发票\n\n# englishpod_B0020\n* struggle\ntry real hard\n* blurry\nnot clear\n* prescription\n* 20-20 vision\nPerfect eyesight\n* far sighted\nnear sighted\n* make out\nsee clearly\n* as blind as a bat\n* what seems to be the problem\n* head on\nhead on over\nhead on in\n\n# englishpod_C0021\n* VP\nthe vice president\n* fortune 500 company\n* implement\n* policy\n* oversee\n* go on about him\n* How's going?\n* what do you do for a living?\n\n# englishpod_C0022\n* candy canes\n* booked\n* speeding\ngo too fast\n* impounded\nheld by the police\ntake your car to car jail\n* ruined\ndestoried\n* backup\nhelp\n\n# englishpod_B0023\n* financial adviser\n* available\n* double check\ncheck it again\n* sheduled\nbook it at that time\n* booked solid\n\n# englishpod_B0024\n* food po\nnot a good thing\n* allergic\nIt make you sick\n* check out\nlook at\n* be\n* not all that crazy about\n* tasty\ndelicious\n* in the mood for\nhave a desire\n* Do  you have any suggentions/ideas?\n* I reconmend giving it a try.\nYou've got to give a try.\n* platter\n* decor\ndecoration\n\n# englishpod_D0025\n* converage\n* pain de\nscary\n* critical\nimportant\n* outbreak\n* forcast\npredict\n* Let's move to the next order of business.\ncome up\nmove on\n* head up\ntake charge of\n* I'll leave it to you.\n* contingency plan\na plan that prepares for a situation where things go wrong\n* vaccine\n疫苗\n\n# englishpod_B0026\n* eating habits\nthe regular way you eat\n* junk food\n* transform\n* I'm stuffed\n* stick to it\nkeep doing it\n* I mean it.\nI'm serious.\n* cut out\n* wait and see\n\n# englishpod_B0027\n* vacation day\n* overseas\n* unpaid leave\n* notice\n* Do you have a second?\nDo you have a minute/sec?\n* Would you be OK with that?\nwill it be OK with that?\n* I was just wondering\nI was just hoping that\n\n# englishpod_C0028\n* relieved\n* pick me up\ncome and get me\n* ordinary\n* make it up to you\n* my treat\n* twist of fate\n\n# englishpod_E0029\n* merging market\ndeveloping\n* turmoil\na state of confusion\n* proposed\n* hit up\nask for money\n* inevitable\n\n# englishpod_C0030\n* thoughtful\n* give me the creeps\nmake me feel uncomfortable\n* rope me into something\n* appetite\nstrong desire for food\n* get to know someone\n* why on earth\n\n# englishpod_B0031\n* reshedule\nchange for another day or time\n* inconvenience\n* postpone\ndelay\n* can not make it\ncan't do something\n* this thing comes up\n\n# englishpod_C0032\n* chequing account\n* savings account\n* transaction\n* balance\n* overdraft\n* debit card\n* I'll get you to\n* I need your insurace number.\n* If you could sign here?\n\n# englishpod_B0033\n* foul\n* ref\n* free throw\n* make a shot\nto successful\n* 3 pointer shot\n* travel\ntake more than two steps with the ball\n* screw up\nto make a mistake\n* beer run\nto go and get a beer\n\n# englishpod_D0034\n* swear in\nswore in\n* oath\na promise\n* deliver\nsay a speech\n* who's who\n* palpable\n* in a word\n* go down in history\n* my fellow Americans\ndear\n\n# englishpod_C0035\n* a good fit\nsuitable for the job\n* performance\n* unreliable\nreliable\n* productive\n* work ethic\n* coach\ntrain\n* the bottom of line\nthe most important point\n* overall\n* perfectly good\n\n# englishpod_B0036\n* get a hold\n* stand me up\nfail to keep the appointment to meet someone\n* priority\n* heading\ngoing\n* Do you have any idea how\n* I heard it before\n* take a break\nstop their relationship\n* decency\npolite or moral bahavior\n* get your priorities straight\nrealize what is more important\n\n# englishpod_C0037\n* dumping\n水饺\n* firecracker\n* set off\n* I can't wait to\n* I bet\n* red envelope\n* mahjong\n\n# englishpod_C0038\n* vehicle\n* sedan\na car with four doors\n* gas mileage\nthe amount of gas used per mile\n* airbags\n* brake\n* reinforce\nmake stronger\n* I'm just browsing\n* sleep on it\nto think about it\n\n# englishpod_B0039\n* heard\n* fill me in\ntell me about something\n* career path\n* In  his early 30s\n\n# englishpod_B0040\n* on board\nwelcome to the company\n* about to\n* instead\nin the  place of\n* intrepret\n\n# englishpod_C0041\n* posses\n* survival\n* defend\nprotect\n* rough\nhard\n* at all costs\nno matter what\n* stand in one's way\n\n# englishpod_B0042\n* deadline\n* extension\n* run into\nrun into some problem\n* delay\n* be under control\n* put this off\n* press kit\ngroups of photos, documents, articals, and information about company given to reporters, newspapers,magazines,etc.\n* finalize\nfinish\n\n# englishpod_C0043\n* visa\n签证\n* sponsor\n* invitation letter\n* ties\n* financially independent\n\n# englishpod_B0044\n* barely even\n* catch the news\nhear the news\n* by the way\n* take the stairs\n* do you happen to\nby chance\n\n# englishpod_C0045\n* on a break\n* seeing someone\ndating or going out with someone\n* cheat on\n* mess this up\n* immature  \n* selfish\n* everything is going to work out just fine.\n* pull yourself together\ncalm down\n* It's going to be alright.\n\n# englishpod_D0046\n* CPR\n* BP\nblood pressure\n* hook up\n* out of woods\nfree from danger\n* defibrillator\n\n# englishpod_C0048\n* ticket scalper\n黄牛\n* prestigious\nbeing respected and admired for being successful or important\n* float\n* once in the lifetime\n* good thing\n* no kidding\nI totally agree with you\n\n# englishpod_C0049\n* concert\n* hottest\n* fine then\n* I was wondering can I\nDo you think\nwould you mind\n\n# englishpod_C0050\n* appetite\n* poison\n* points\nsuggestions\n* aroma\nspecial smell\n* bitter\n* pass out\nbecome unconscious\n* make yourself at home\n\n# englishpod_C0051\n* price range\n* shop around\n* pricey\n* a better deal\n* That's my best offer.\nThat's my last offer.\n* exclusive\nnot common, unique\n\n# englishpod_C0052\n* medium\n12 inch\nlarger\n* pepperoni\na spicy sausage usually on pizza\n* olives\n* extra cheese\n* ham\n* pineapple\n* thin crust\n* would you like\n\n# englishpod_C0053\n* head chef\nthe main cook\n* cuisine\n* peel\nremove the outside\n* chop\n* stir\nmix\n* butcher\n* butter\n* in the weeds\nyou are really busy\n* run low on\nnot something left\n* do really well\n\n# englishpod_C0054\n* blaze\nfire\n* in the middle of nowhere\n* first thing in the morning\n* everything seems to be order\n\n# englishpod_C0055\n* puck\n* key game\n* finals\n* face-off\n* goalie\nsaver\n* breakaway\n\n# englishpod_C0056\n* fill in\n* replicas\n* tap\n* map out\n* screw it up\n* lose your cool\n\n# englishpod_C0057\n* malfunction\n* ASAP\nas soon as possible\n* practical joke\n* never mind\n* out of to\n* on your way up\n* break down\nbreak in\nbreak out\n* toner\nink used in a printer or photocopier\n\n# englishpod_C0058\n* turbulence\n* flight crew\n* bumpy ride\n* fasten\nfasten your seat belt\n* lavatory\n* stow\n* refrain\n* remain seated\n* patch\n* suspend\nstop for a short time\n\n# englishpod_E0059\n* CRM\ncustom relationship manager\n* custom designed\ncustom built house\n* core values\n* undisputed\nthe is no doubt\n* growth oppotunity\n* read up\n* unleash potential\n* resonate\n\n# englishpod_C0060\n* drag\n* tie somebody up\n* fools\n* fell for it\n* the cat is out of the bag\nthe truth is out\n* pretend\n* gullible\neasily beliving something that is not true, eaily fooled\n\n# englishpod_C0061\n* sail\n* anchor\n* doggy-paddling\nswim like a dog\n* breast stroke\n* backstroke\n* take a dip\n* for a little while\n\n# englishpod_C0062\n* major\nmain subject\n* minor\n* course of study\n* track\npath\n* hence\n* pursued\nto chase\n* strive\nto try real hard\n* breadth\n* implement\n* postgraduate\nmasters or PH.D;\n* initiative\n倡议\n* churn rate\n客户流失率\n* coordinate\n协调\n\n# englishpod_C0063\n* certainly\n* may I take your name?\n* monmentarily\nin a short\n* ready for\n\n# englishpod_C0064\n* sleep with\n* confess\nyou tell a secret that you are hiding\n* overwhelm\n* jelousy\n* jerk\nstupid and mean person\n* bastard\n* bun in the oven\npregnant\n* I can't help myself\n* come into the picture\nappear into one's life\n* cheerleading squad\n啦啦队\n\n# englishpod_C0065\n* technical acument\n* excel\n* head\n* struggle\n* punctual\npunctuality\n* adress\ndeal with\n* fit\n* acumen\nthe ability to think clearly and make good decisions\n\n# englishpod_C0067\n* wingman\n* tired\n* foul\n* kick off\n* out of bounds\n* throw in\n* offside\n* on the brink of\nat a critical point\n* no question about it\nno doubt\n* by a mile\n* penalty kick\na kick against only the goalkeepwe as a reward for a foul\n\n# englishpod_C0068\n* irrefutable\n* flaw\n* systemetic\nfollowing the certain order\n* extensive research\n* conclusive evidence\nfinal decision\n* investigative approch\n* definite conclusion\n* oblivious to\nunware or don't know\n* proposterous\ncrazy, foolish, or silly\n\n# englishpod_C0069\n* picky\n* yolk\negg yolk\nthe white\n* sunny side up\n* fried egg\n* soft boiled egg\n* hard boiled egg\n* egg and soilders\n* scrible eggs\n* feel like\nhave desire to do\n* drive me crazy\nmake you angry\n* muffin\na small break or cake people usually eat for breakfast\n\n# englishpod_F0070\n* lingerie\n* awkward\n* granny panties\n* sleepwear\n* nighties\nsilky nighties\n* undies\n* mortifying\nextremely embarassing\n* get the hell out of here\nleave\n* get this over with\n\n# englishpod_C0071\n* on tap\nbeer served from a barrel; not in a bottle or can\n* happy hour\n* pint\n* appetizer\na small dish served before meal\n* what about\nbe used in making suggestions\n\n# englishopod_C0072\n* preoccupied\nworried\n* direct impact\n* resent\nfind something very insulting\n* beat around the bush\navoid saying something by about other things\ncome out with it\n\n# englishpod_C0073\n* pinkie\n* the ring finger\n* the middle finger\ngiving the middle finger\n* index finger\n* thumb\n* abide\nlive\n\n# englishpod_C0074\n* famished\nvery hungry\n* sexist\n* dumbass\n* moron\nsomeone is stupid\n* tool\nuseless\n* chill\n* scream\n* what the hell\n\n# englishpod_C0075\n* toothache\n* x-ray\n* swollen\n* cavity\na hole in a tooth\n* crown\nthe part of the tooth which can be seen\n* filling\n* what seems to be the problem?\nwhat's wrong?\n\n# englishpod_C0076\n* plus add\nminus\ntimes\ndevided by\n* square root\n* teacher's pet\nsuck up\n* smarty pants\nfor children\n* konw it all\n\n# englishpod_C0077\n* jam on the breaks\n* spin out\n(a car)slides and makes a turn rapidly in an uncontrolled way\n* the pace car\n* cleanup crew\nthe construction crew\n* to tow\n* my partner in crime\na person you always do things together with\n* a close one\n* stretch\nthe final time period\n\n# englishpod_E0078\n* brutality\nviolent treatment or behavior\n* important aspect\n* genesis\n* comprehend\n* appalling\nterrible, horrible, shocking\n* hostility\nthe attitde of treating something as enemy\n* drastic\nsudden and severe\n* constitute\nform, consist\n* fire into\nshoot guns into a place\n\n# englishpod_B0079\n* spacecraft\n* break through\n* settle this\n* accelerate\n* no loger be\n* once and for all\n* obscure\n\n# englishpod_C0080\n* show up\n* stalk\nfollow someone for a long time\n* nut job\n* get worked up\n* soul mate\n* over nothing\nno reason\n* not a day goes by\n* no matter what\n\n# englishpod_B0081\n* trim\na short cut of hair to make one look clean\n* fancy\n* silky\nsilk hair\n* grow out\n* don't just stand there\n* take a little off the top\ntake a little off the side\n* curly\n* a million bucks\nvery good. To look great\n* sideburns\nhari thar grows on the sides of man\n* fluffy\nsoft  \n\n# englishpod_C0082\n* creature\n* break free\n* kidnapper\n* rapist\n* rape\n* lemme see your eyes\nlet me see your eyes\ngimme - give me\n* make it out\nable to escape or flee\n\n# englishpod_C0083\n* ATM\nautomatic teller machine\n* the local authority\n* slot\n* digit\n* withdraw\n* transfer money\n* pound key\nthe push botton marked with #\n\n# englishpod_B0084\n* pharmacy\nmedicine\n* milligram\n* price check\n* prescription\n* capsule\n* tablet\n* overdose\n* eye drop\n* be sure not to\n* get a price check\n\n# englishpod_B0085\n* the national anthem\n* pitcher\nthrow the ball\n* wind up\n* line drive\na hit that travels low along the baseline     \n* scramble\n* up at bat\nget ready to hit the ball\n* strike\n* curve ball\n\n# englishpod_C0086\n* landlord\nthe owner of house\n* tenant\nthe person that rents a house\n* renovate\nmake a new again\n* airy\nspacious so that air moves freely\n* square footage\n* applicance\n* gas range\na stove that uses to cook\n* prefessional greed\n* spaciou\nlatge; having lots of space\n* walk-in closet\na room containedf in a bedroom for storing clothes\n* en suit bathroom\na bathroom within the main bedroom\n\n# englishpod_B0087\n* unidentified ship\n* seach party\n* a deep voice\n* offentic\n* wig\nartificial hair\n* under attack\nunder fire\n* sustain\ndamage\n* the nature of\n* warp drive\n\n# englishpod_B0088\n* here's the thing\ngive somebody some information\n* I can't take it anymore\n* Are you serious?\n* have guts to\ncourage\n* just two of us\njust three of us\n* give me a shot\ngive me an oppotunity\n* pros and cons\ngood things and bad things about a person\n\n# englishpod_C0089\n* piece of luggage\n* carryon luggage\n* overhead compa\n* how am I be supposed to\n* There's nothing I can do\n* next to nothing\nvery cheap\n\n# englishpod_D0090\n* spy\n* come clean\nconfess\n* renource\n* approach someone\n* claim\n* vow\nmake a strong promise\n* whereabouts\nthe approximate place, where a person or thing is\n* I haven't been completely honest with you\n* I wasn't supposed to\nI shouldn't\n* bureau\n* millennium\n1000 years\n* renowned\nwell known\n\n# englishpod_D0091\n* constellation\na particular shape formed by a group of stars\n* consequence\nnegative results\n* downdfall\nfailure\n* anguish\nangry, aggressive, wanting to fight\n* a wonder\n* what gives you the right to\n* to play God\n* who are you to\n\n# englishpod_C0095\n* in ages\n* run into\n* freak out\n* stare\n* shriek\nscreaming in a very high voice\n* catch up with\nlearn about recent past events\n* hilarious\n\n# englishpod_C0096\n* pad\n* far out\n* crash\n* split\n* dig it\nappreciate, like\n* throw a bash\nparty  \nhost a party\n* take care of business\n* happening scene\nan extremely exciting moment\n* peace out\nsee you later\n* groovy\nreally cool\n\n# englishpod_D0097\n* weather forcast\n* shower\na short time rain\n* scattered shower\n* hover around\nstay near a certain level or place\n* temperature\n* isolated downpour\n* gust\nstrong, sudden increase in wind speed\n* sleet\na mix of rain and snow\n* cold front\n* It's going to a tough one\n* mixed bag\na collection of different kinds of things\n* cloud cover\nthe amount of sky that is covered with cloud\n* partly-cloudy skies\nhaving some cloud and some sun\n\n# englishpod_C0098\n* the bar exam\nthe exam to qualify as a lawer\n* flatter\n* I love what you have done with your hair\n* get his look from his mother\n* by the way\n* You haven't aged a day\nyou haven't gotten older\n* obnoxious\nreally annoying\n\n# englishpod_E0099\n* depict\n* portrayal\n* what's your impression of the film?\n* lack\n* rightfully\naccording to law\n* erudite\nhaving a lot of knowledge\n* fable\nbeauriful story about animals that has moral or lesson\n* eternal\nlasting forever\n* accusation\naction of caliming something is wrong\n* plagiarism\npractice of copying other's ideas\n* enchanting  \nattractive, holding one's attention\n* grim\nunpleasant\n* linear\nmoving in logical way, from start to end\n* cliche\nsomething that is to often used so that it loses meaning or importance\n* time-honoured\nsomething that survives the testing of time\n\n# englishpod_C0100\n* If your don't mind me saying so.\n* Don't get me wrong\n* sure thing\n* born and raised\n* nosy\ntoo interested in others' private matters\n* the good old U.S of A\nthe United States\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\n","source":"_posts/EnglishPod.md","raw":"---\ntitle: EnglishPod\ndate: 2018-04-10 16:33:23\ntags: English Pod\ncategories: 学习\n---\n# englishpod_B0001\n* I'm still working on it.\nI still need more time.\n* complimentray\nfree\n* I'll go with.\nI'll take. I'll choose.\n* grab  \nget quickly\n\n# englishpod_B0002\n* headache\n* sore throat\nit hurts\n* runny nose\n* feverish\nfeeling your body being very hot.\n* quite ill\nvery sick\n* come down with flu\nI'm coming with cold.Begining to feel sick.\n* calling in  sick\nYou call to your office,and you are sick and won't go to work.\n* take the day off\n\n# englishpod_C0003\n* I have the reservation under the name\n* mix up\nconfusion\n* overbooked\nfull\n* complimentray upgrade\nfree\n\n# englishpod_C0004\n* resources\nmoney\n* understaffed\nnot enough people to do the job\n* the timing is just not right\nit is not the right now\n* weight off my sholders\nremove pressure or stress\n* give me a hand\nhelp out\n* keep our cost down\nto not to spend much money\n* intern\n实习生\n\n# englishpod_C0005\n* unbelievable\nsomething is amazing\n* a mile long\nthis line is really long\n* there is no way\nit is not possible\n* cut in line\nsomebody get in front of you\n\n# englishpod_C0006\n* road trip\nthe car is packed. everything you need is in the car\n* fill up the tank.\n* we got all our bases coverd\n* let's get going\n\n# englishpod_C0007\n* computer virus\n* froze\nstopping working\n* infective file\n* up to date\n* I'll be right there/down/out\n* It turns out that\n\n# englishpod_C0008\n* in a bit of hurry\n* contact details\n* slip my mind\n* around there\n* I'm terrible with names/faces\n\n# englishpd_C0009\n* inconsiderate\nnot thinking about other's feeling\n* keep it down\n* not such a big deal\n* not a big problem\n* switch it off\n* I can't hear a thing\n\n# englishpod_C0010\n* drive sales\n* promotion\n* match the competitor\n* in the market\nin the insustry\n* It'll never fly\nit won't work\n\n# englishpod_C0011\n* weird\nstrange  odd\n* housewarming\n* a bad feeling\n* kicked me out\nforce me to leave\n* creep me out\nmake me feel uncomfortable\n* scared and\n* I don't know if you heard\ngossip\n* fill me in\ngive me information\n* you scared the heck out of me\n\n# englishpod_C0012\n* such a mess\n* chore\n* tidy up\n* spotless\n一尘不染\n* mall\nmany stores in there\n* grocery\ngrocery list\ngrocery shopping\n* I'm in the middle of something now.\n* I'll be there in a second\n\n# englishpod_C0013\n* expenses\n* through the roof\noff the charts\n* expenditure\n* out of control\n* go over\n* profit and loss statement\n\n# englishpod_B0014\n* recession\n* broke\n* loan\n* mortgage\na loan to help you buy an apartment\n* hit me pretty hard\n* tuition\n* can I help you?\nwhat can I do for you?\n* I'm sorry to trouble you\n* on top of that\n* data debt date\n\n# englishpod_C0015\n* knock over\nslip something down\n* explode\n* familiar\n* coincidence\n* I feel terrible\nplease accept my apologies\n* I don't mean knocking over\n\n# englishpod_B0016\n* step on it\nspeed up slow down\ngo fast\n* have a fit\nget angry\n* cut through\ngo through\n* short cut\ntake a short way\n* make a left/right\nmake a u turn\n* take a side street\ntake the freeway\n\n# englishpod_B0017\n* groom\nman\n* bride\nwoman\n* It's about time\nfinally at last\n* aisle\n* bridemaids\n* flower girl\n* ring bearer\n* niece nephew\n* gorgeous\nbeautiful\n* get married\n* priest\n\n# englishpod_D0018\n* bankrupt\n* bail out\n* injustice\n* outrage\n* break out  \nto begin suddenlly\n* have the nerve to\ndare to do\n* financial\n\n# englishpod_C0019\n* eggnog\n* vehicle\ncar\n* lawer\n* appoint\nchoose\n* sleigh\n* step out\nstep out the vehicle\n* get a load of\nlook at\n* Don't take the tone with me\n* invoice\n发票\n\n# englishpod_B0020\n* struggle\ntry real hard\n* blurry\nnot clear\n* prescription\n* 20-20 vision\nPerfect eyesight\n* far sighted\nnear sighted\n* make out\nsee clearly\n* as blind as a bat\n* what seems to be the problem\n* head on\nhead on over\nhead on in\n\n# englishpod_C0021\n* VP\nthe vice president\n* fortune 500 company\n* implement\n* policy\n* oversee\n* go on about him\n* How's going?\n* what do you do for a living?\n\n# englishpod_C0022\n* candy canes\n* booked\n* speeding\ngo too fast\n* impounded\nheld by the police\ntake your car to car jail\n* ruined\ndestoried\n* backup\nhelp\n\n# englishpod_B0023\n* financial adviser\n* available\n* double check\ncheck it again\n* sheduled\nbook it at that time\n* booked solid\n\n# englishpod_B0024\n* food po\nnot a good thing\n* allergic\nIt make you sick\n* check out\nlook at\n* be\n* not all that crazy about\n* tasty\ndelicious\n* in the mood for\nhave a desire\n* Do  you have any suggentions/ideas?\n* I reconmend giving it a try.\nYou've got to give a try.\n* platter\n* decor\ndecoration\n\n# englishpod_D0025\n* converage\n* pain de\nscary\n* critical\nimportant\n* outbreak\n* forcast\npredict\n* Let's move to the next order of business.\ncome up\nmove on\n* head up\ntake charge of\n* I'll leave it to you.\n* contingency plan\na plan that prepares for a situation where things go wrong\n* vaccine\n疫苗\n\n# englishpod_B0026\n* eating habits\nthe regular way you eat\n* junk food\n* transform\n* I'm stuffed\n* stick to it\nkeep doing it\n* I mean it.\nI'm serious.\n* cut out\n* wait and see\n\n# englishpod_B0027\n* vacation day\n* overseas\n* unpaid leave\n* notice\n* Do you have a second?\nDo you have a minute/sec?\n* Would you be OK with that?\nwill it be OK with that?\n* I was just wondering\nI was just hoping that\n\n# englishpod_C0028\n* relieved\n* pick me up\ncome and get me\n* ordinary\n* make it up to you\n* my treat\n* twist of fate\n\n# englishpod_E0029\n* merging market\ndeveloping\n* turmoil\na state of confusion\n* proposed\n* hit up\nask for money\n* inevitable\n\n# englishpod_C0030\n* thoughtful\n* give me the creeps\nmake me feel uncomfortable\n* rope me into something\n* appetite\nstrong desire for food\n* get to know someone\n* why on earth\n\n# englishpod_B0031\n* reshedule\nchange for another day or time\n* inconvenience\n* postpone\ndelay\n* can not make it\ncan't do something\n* this thing comes up\n\n# englishpod_C0032\n* chequing account\n* savings account\n* transaction\n* balance\n* overdraft\n* debit card\n* I'll get you to\n* I need your insurace number.\n* If you could sign here?\n\n# englishpod_B0033\n* foul\n* ref\n* free throw\n* make a shot\nto successful\n* 3 pointer shot\n* travel\ntake more than two steps with the ball\n* screw up\nto make a mistake\n* beer run\nto go and get a beer\n\n# englishpod_D0034\n* swear in\nswore in\n* oath\na promise\n* deliver\nsay a speech\n* who's who\n* palpable\n* in a word\n* go down in history\n* my fellow Americans\ndear\n\n# englishpod_C0035\n* a good fit\nsuitable for the job\n* performance\n* unreliable\nreliable\n* productive\n* work ethic\n* coach\ntrain\n* the bottom of line\nthe most important point\n* overall\n* perfectly good\n\n# englishpod_B0036\n* get a hold\n* stand me up\nfail to keep the appointment to meet someone\n* priority\n* heading\ngoing\n* Do you have any idea how\n* I heard it before\n* take a break\nstop their relationship\n* decency\npolite or moral bahavior\n* get your priorities straight\nrealize what is more important\n\n# englishpod_C0037\n* dumping\n水饺\n* firecracker\n* set off\n* I can't wait to\n* I bet\n* red envelope\n* mahjong\n\n# englishpod_C0038\n* vehicle\n* sedan\na car with four doors\n* gas mileage\nthe amount of gas used per mile\n* airbags\n* brake\n* reinforce\nmake stronger\n* I'm just browsing\n* sleep on it\nto think about it\n\n# englishpod_B0039\n* heard\n* fill me in\ntell me about something\n* career path\n* In  his early 30s\n\n# englishpod_B0040\n* on board\nwelcome to the company\n* about to\n* instead\nin the  place of\n* intrepret\n\n# englishpod_C0041\n* posses\n* survival\n* defend\nprotect\n* rough\nhard\n* at all costs\nno matter what\n* stand in one's way\n\n# englishpod_B0042\n* deadline\n* extension\n* run into\nrun into some problem\n* delay\n* be under control\n* put this off\n* press kit\ngroups of photos, documents, articals, and information about company given to reporters, newspapers,magazines,etc.\n* finalize\nfinish\n\n# englishpod_C0043\n* visa\n签证\n* sponsor\n* invitation letter\n* ties\n* financially independent\n\n# englishpod_B0044\n* barely even\n* catch the news\nhear the news\n* by the way\n* take the stairs\n* do you happen to\nby chance\n\n# englishpod_C0045\n* on a break\n* seeing someone\ndating or going out with someone\n* cheat on\n* mess this up\n* immature  \n* selfish\n* everything is going to work out just fine.\n* pull yourself together\ncalm down\n* It's going to be alright.\n\n# englishpod_D0046\n* CPR\n* BP\nblood pressure\n* hook up\n* out of woods\nfree from danger\n* defibrillator\n\n# englishpod_C0048\n* ticket scalper\n黄牛\n* prestigious\nbeing respected and admired for being successful or important\n* float\n* once in the lifetime\n* good thing\n* no kidding\nI totally agree with you\n\n# englishpod_C0049\n* concert\n* hottest\n* fine then\n* I was wondering can I\nDo you think\nwould you mind\n\n# englishpod_C0050\n* appetite\n* poison\n* points\nsuggestions\n* aroma\nspecial smell\n* bitter\n* pass out\nbecome unconscious\n* make yourself at home\n\n# englishpod_C0051\n* price range\n* shop around\n* pricey\n* a better deal\n* That's my best offer.\nThat's my last offer.\n* exclusive\nnot common, unique\n\n# englishpod_C0052\n* medium\n12 inch\nlarger\n* pepperoni\na spicy sausage usually on pizza\n* olives\n* extra cheese\n* ham\n* pineapple\n* thin crust\n* would you like\n\n# englishpod_C0053\n* head chef\nthe main cook\n* cuisine\n* peel\nremove the outside\n* chop\n* stir\nmix\n* butcher\n* butter\n* in the weeds\nyou are really busy\n* run low on\nnot something left\n* do really well\n\n# englishpod_C0054\n* blaze\nfire\n* in the middle of nowhere\n* first thing in the morning\n* everything seems to be order\n\n# englishpod_C0055\n* puck\n* key game\n* finals\n* face-off\n* goalie\nsaver\n* breakaway\n\n# englishpod_C0056\n* fill in\n* replicas\n* tap\n* map out\n* screw it up\n* lose your cool\n\n# englishpod_C0057\n* malfunction\n* ASAP\nas soon as possible\n* practical joke\n* never mind\n* out of to\n* on your way up\n* break down\nbreak in\nbreak out\n* toner\nink used in a printer or photocopier\n\n# englishpod_C0058\n* turbulence\n* flight crew\n* bumpy ride\n* fasten\nfasten your seat belt\n* lavatory\n* stow\n* refrain\n* remain seated\n* patch\n* suspend\nstop for a short time\n\n# englishpod_E0059\n* CRM\ncustom relationship manager\n* custom designed\ncustom built house\n* core values\n* undisputed\nthe is no doubt\n* growth oppotunity\n* read up\n* unleash potential\n* resonate\n\n# englishpod_C0060\n* drag\n* tie somebody up\n* fools\n* fell for it\n* the cat is out of the bag\nthe truth is out\n* pretend\n* gullible\neasily beliving something that is not true, eaily fooled\n\n# englishpod_C0061\n* sail\n* anchor\n* doggy-paddling\nswim like a dog\n* breast stroke\n* backstroke\n* take a dip\n* for a little while\n\n# englishpod_C0062\n* major\nmain subject\n* minor\n* course of study\n* track\npath\n* hence\n* pursued\nto chase\n* strive\nto try real hard\n* breadth\n* implement\n* postgraduate\nmasters or PH.D;\n* initiative\n倡议\n* churn rate\n客户流失率\n* coordinate\n协调\n\n# englishpod_C0063\n* certainly\n* may I take your name?\n* monmentarily\nin a short\n* ready for\n\n# englishpod_C0064\n* sleep with\n* confess\nyou tell a secret that you are hiding\n* overwhelm\n* jelousy\n* jerk\nstupid and mean person\n* bastard\n* bun in the oven\npregnant\n* I can't help myself\n* come into the picture\nappear into one's life\n* cheerleading squad\n啦啦队\n\n# englishpod_C0065\n* technical acument\n* excel\n* head\n* struggle\n* punctual\npunctuality\n* adress\ndeal with\n* fit\n* acumen\nthe ability to think clearly and make good decisions\n\n# englishpod_C0067\n* wingman\n* tired\n* foul\n* kick off\n* out of bounds\n* throw in\n* offside\n* on the brink of\nat a critical point\n* no question about it\nno doubt\n* by a mile\n* penalty kick\na kick against only the goalkeepwe as a reward for a foul\n\n# englishpod_C0068\n* irrefutable\n* flaw\n* systemetic\nfollowing the certain order\n* extensive research\n* conclusive evidence\nfinal decision\n* investigative approch\n* definite conclusion\n* oblivious to\nunware or don't know\n* proposterous\ncrazy, foolish, or silly\n\n# englishpod_C0069\n* picky\n* yolk\negg yolk\nthe white\n* sunny side up\n* fried egg\n* soft boiled egg\n* hard boiled egg\n* egg and soilders\n* scrible eggs\n* feel like\nhave desire to do\n* drive me crazy\nmake you angry\n* muffin\na small break or cake people usually eat for breakfast\n\n# englishpod_F0070\n* lingerie\n* awkward\n* granny panties\n* sleepwear\n* nighties\nsilky nighties\n* undies\n* mortifying\nextremely embarassing\n* get the hell out of here\nleave\n* get this over with\n\n# englishpod_C0071\n* on tap\nbeer served from a barrel; not in a bottle or can\n* happy hour\n* pint\n* appetizer\na small dish served before meal\n* what about\nbe used in making suggestions\n\n# englishopod_C0072\n* preoccupied\nworried\n* direct impact\n* resent\nfind something very insulting\n* beat around the bush\navoid saying something by about other things\ncome out with it\n\n# englishpod_C0073\n* pinkie\n* the ring finger\n* the middle finger\ngiving the middle finger\n* index finger\n* thumb\n* abide\nlive\n\n# englishpod_C0074\n* famished\nvery hungry\n* sexist\n* dumbass\n* moron\nsomeone is stupid\n* tool\nuseless\n* chill\n* scream\n* what the hell\n\n# englishpod_C0075\n* toothache\n* x-ray\n* swollen\n* cavity\na hole in a tooth\n* crown\nthe part of the tooth which can be seen\n* filling\n* what seems to be the problem?\nwhat's wrong?\n\n# englishpod_C0076\n* plus add\nminus\ntimes\ndevided by\n* square root\n* teacher's pet\nsuck up\n* smarty pants\nfor children\n* konw it all\n\n# englishpod_C0077\n* jam on the breaks\n* spin out\n(a car)slides and makes a turn rapidly in an uncontrolled way\n* the pace car\n* cleanup crew\nthe construction crew\n* to tow\n* my partner in crime\na person you always do things together with\n* a close one\n* stretch\nthe final time period\n\n# englishpod_E0078\n* brutality\nviolent treatment or behavior\n* important aspect\n* genesis\n* comprehend\n* appalling\nterrible, horrible, shocking\n* hostility\nthe attitde of treating something as enemy\n* drastic\nsudden and severe\n* constitute\nform, consist\n* fire into\nshoot guns into a place\n\n# englishpod_B0079\n* spacecraft\n* break through\n* settle this\n* accelerate\n* no loger be\n* once and for all\n* obscure\n\n# englishpod_C0080\n* show up\n* stalk\nfollow someone for a long time\n* nut job\n* get worked up\n* soul mate\n* over nothing\nno reason\n* not a day goes by\n* no matter what\n\n# englishpod_B0081\n* trim\na short cut of hair to make one look clean\n* fancy\n* silky\nsilk hair\n* grow out\n* don't just stand there\n* take a little off the top\ntake a little off the side\n* curly\n* a million bucks\nvery good. To look great\n* sideburns\nhari thar grows on the sides of man\n* fluffy\nsoft  \n\n# englishpod_C0082\n* creature\n* break free\n* kidnapper\n* rapist\n* rape\n* lemme see your eyes\nlet me see your eyes\ngimme - give me\n* make it out\nable to escape or flee\n\n# englishpod_C0083\n* ATM\nautomatic teller machine\n* the local authority\n* slot\n* digit\n* withdraw\n* transfer money\n* pound key\nthe push botton marked with #\n\n# englishpod_B0084\n* pharmacy\nmedicine\n* milligram\n* price check\n* prescription\n* capsule\n* tablet\n* overdose\n* eye drop\n* be sure not to\n* get a price check\n\n# englishpod_B0085\n* the national anthem\n* pitcher\nthrow the ball\n* wind up\n* line drive\na hit that travels low along the baseline     \n* scramble\n* up at bat\nget ready to hit the ball\n* strike\n* curve ball\n\n# englishpod_C0086\n* landlord\nthe owner of house\n* tenant\nthe person that rents a house\n* renovate\nmake a new again\n* airy\nspacious so that air moves freely\n* square footage\n* applicance\n* gas range\na stove that uses to cook\n* prefessional greed\n* spaciou\nlatge; having lots of space\n* walk-in closet\na room containedf in a bedroom for storing clothes\n* en suit bathroom\na bathroom within the main bedroom\n\n# englishpod_B0087\n* unidentified ship\n* seach party\n* a deep voice\n* offentic\n* wig\nartificial hair\n* under attack\nunder fire\n* sustain\ndamage\n* the nature of\n* warp drive\n\n# englishpod_B0088\n* here's the thing\ngive somebody some information\n* I can't take it anymore\n* Are you serious?\n* have guts to\ncourage\n* just two of us\njust three of us\n* give me a shot\ngive me an oppotunity\n* pros and cons\ngood things and bad things about a person\n\n# englishpod_C0089\n* piece of luggage\n* carryon luggage\n* overhead compa\n* how am I be supposed to\n* There's nothing I can do\n* next to nothing\nvery cheap\n\n# englishpod_D0090\n* spy\n* come clean\nconfess\n* renource\n* approach someone\n* claim\n* vow\nmake a strong promise\n* whereabouts\nthe approximate place, where a person or thing is\n* I haven't been completely honest with you\n* I wasn't supposed to\nI shouldn't\n* bureau\n* millennium\n1000 years\n* renowned\nwell known\n\n# englishpod_D0091\n* constellation\na particular shape formed by a group of stars\n* consequence\nnegative results\n* downdfall\nfailure\n* anguish\nangry, aggressive, wanting to fight\n* a wonder\n* what gives you the right to\n* to play God\n* who are you to\n\n# englishpod_C0095\n* in ages\n* run into\n* freak out\n* stare\n* shriek\nscreaming in a very high voice\n* catch up with\nlearn about recent past events\n* hilarious\n\n# englishpod_C0096\n* pad\n* far out\n* crash\n* split\n* dig it\nappreciate, like\n* throw a bash\nparty  \nhost a party\n* take care of business\n* happening scene\nan extremely exciting moment\n* peace out\nsee you later\n* groovy\nreally cool\n\n# englishpod_D0097\n* weather forcast\n* shower\na short time rain\n* scattered shower\n* hover around\nstay near a certain level or place\n* temperature\n* isolated downpour\n* gust\nstrong, sudden increase in wind speed\n* sleet\na mix of rain and snow\n* cold front\n* It's going to a tough one\n* mixed bag\na collection of different kinds of things\n* cloud cover\nthe amount of sky that is covered with cloud\n* partly-cloudy skies\nhaving some cloud and some sun\n\n# englishpod_C0098\n* the bar exam\nthe exam to qualify as a lawer\n* flatter\n* I love what you have done with your hair\n* get his look from his mother\n* by the way\n* You haven't aged a day\nyou haven't gotten older\n* obnoxious\nreally annoying\n\n# englishpod_E0099\n* depict\n* portrayal\n* what's your impression of the film?\n* lack\n* rightfully\naccording to law\n* erudite\nhaving a lot of knowledge\n* fable\nbeauriful story about animals that has moral or lesson\n* eternal\nlasting forever\n* accusation\naction of caliming something is wrong\n* plagiarism\npractice of copying other's ideas\n* enchanting  \nattractive, holding one's attention\n* grim\nunpleasant\n* linear\nmoving in logical way, from start to end\n* cliche\nsomething that is to often used so that it loses meaning or importance\n* time-honoured\nsomething that survives the testing of time\n\n# englishpod_C0100\n* If your don't mind me saying so.\n* Don't get me wrong\n* sure thing\n* born and raised\n* nosy\ntoo interested in others' private matters\n* the good old U.S of A\nthe United States\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\n","slug":"EnglishPod","published":1,"updated":"2018-06-03T14:43:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms400091ouzaf7p0x5z","content":"<h1 id=\"englishpod-B0001\"><a href=\"#englishpod-B0001\" class=\"headerlink\" title=\"englishpod_B0001\"></a>englishpod_B0001</h1><ul>\n<li>I’m still working on it.<br>I still need more time.</li>\n<li>complimentray<br>free</li>\n<li>I’ll go with.<br>I’ll take. I’ll choose.</li>\n<li>grab<br>get quickly</li>\n</ul>\n<h1 id=\"englishpod-B0002\"><a href=\"#englishpod-B0002\" class=\"headerlink\" title=\"englishpod_B0002\"></a>englishpod_B0002</h1><ul>\n<li>headache</li>\n<li>sore throat<br>it hurts</li>\n<li>runny nose</li>\n<li>feverish<br>feeling your body being very hot.</li>\n<li>quite ill<br>very sick</li>\n<li>come down with flu<br>I’m coming with cold.Begining to feel sick.</li>\n<li>calling in  sick<br>You call to your office,and you are sick and won’t go to work.</li>\n<li>take the day off</li>\n</ul>\n<h1 id=\"englishpod-C0003\"><a href=\"#englishpod-C0003\" class=\"headerlink\" title=\"englishpod_C0003\"></a>englishpod_C0003</h1><ul>\n<li>I have the reservation under the name</li>\n<li>mix up<br>confusion</li>\n<li>overbooked<br>full</li>\n<li>complimentray upgrade<br>free</li>\n</ul>\n<h1 id=\"englishpod-C0004\"><a href=\"#englishpod-C0004\" class=\"headerlink\" title=\"englishpod_C0004\"></a>englishpod_C0004</h1><ul>\n<li>resources<br>money</li>\n<li>understaffed<br>not enough people to do the job</li>\n<li>the timing is just not right<br>it is not the right now</li>\n<li>weight off my sholders<br>remove pressure or stress</li>\n<li>give me a hand<br>help out</li>\n<li>keep our cost down<br>to not to spend much money</li>\n<li>intern<br>实习生</li>\n</ul>\n<h1 id=\"englishpod-C0005\"><a href=\"#englishpod-C0005\" class=\"headerlink\" title=\"englishpod_C0005\"></a>englishpod_C0005</h1><ul>\n<li>unbelievable<br>something is amazing</li>\n<li>a mile long<br>this line is really long</li>\n<li>there is no way<br>it is not possible</li>\n<li>cut in line<br>somebody get in front of you</li>\n</ul>\n<h1 id=\"englishpod-C0006\"><a href=\"#englishpod-C0006\" class=\"headerlink\" title=\"englishpod_C0006\"></a>englishpod_C0006</h1><ul>\n<li>road trip<br>the car is packed. everything you need is in the car</li>\n<li>fill up the tank.</li>\n<li>we got all our bases coverd</li>\n<li>let’s get going</li>\n</ul>\n<h1 id=\"englishpod-C0007\"><a href=\"#englishpod-C0007\" class=\"headerlink\" title=\"englishpod_C0007\"></a>englishpod_C0007</h1><ul>\n<li>computer virus</li>\n<li>froze<br>stopping working</li>\n<li>infective file</li>\n<li>up to date</li>\n<li>I’ll be right there/down/out</li>\n<li>It turns out that</li>\n</ul>\n<h1 id=\"englishpod-C0008\"><a href=\"#englishpod-C0008\" class=\"headerlink\" title=\"englishpod_C0008\"></a>englishpod_C0008</h1><ul>\n<li>in a bit of hurry</li>\n<li>contact details</li>\n<li>slip my mind</li>\n<li>around there</li>\n<li>I’m terrible with names/faces</li>\n</ul>\n<h1 id=\"englishpd-C0009\"><a href=\"#englishpd-C0009\" class=\"headerlink\" title=\"englishpd_C0009\"></a>englishpd_C0009</h1><ul>\n<li>inconsiderate<br>not thinking about other’s feeling</li>\n<li>keep it down</li>\n<li>not such a big deal</li>\n<li>not a big problem</li>\n<li>switch it off</li>\n<li>I can’t hear a thing</li>\n</ul>\n<h1 id=\"englishpod-C0010\"><a href=\"#englishpod-C0010\" class=\"headerlink\" title=\"englishpod_C0010\"></a>englishpod_C0010</h1><ul>\n<li>drive sales</li>\n<li>promotion</li>\n<li>match the competitor</li>\n<li>in the market<br>in the insustry</li>\n<li>It’ll never fly<br>it won’t work</li>\n</ul>\n<h1 id=\"englishpod-C0011\"><a href=\"#englishpod-C0011\" class=\"headerlink\" title=\"englishpod_C0011\"></a>englishpod_C0011</h1><ul>\n<li>weird<br>strange  odd</li>\n<li>housewarming</li>\n<li>a bad feeling</li>\n<li>kicked me out<br>force me to leave</li>\n<li>creep me out<br>make me feel uncomfortable</li>\n<li>scared and</li>\n<li>I don’t know if you heard<br>gossip</li>\n<li>fill me in<br>give me information</li>\n<li>you scared the heck out of me</li>\n</ul>\n<h1 id=\"englishpod-C0012\"><a href=\"#englishpod-C0012\" class=\"headerlink\" title=\"englishpod_C0012\"></a>englishpod_C0012</h1><ul>\n<li>such a mess</li>\n<li>chore</li>\n<li>tidy up</li>\n<li>spotless<br>一尘不染</li>\n<li>mall<br>many stores in there</li>\n<li>grocery<br>grocery list<br>grocery shopping</li>\n<li>I’m in the middle of something now.</li>\n<li>I’ll be there in a second</li>\n</ul>\n<h1 id=\"englishpod-C0013\"><a href=\"#englishpod-C0013\" class=\"headerlink\" title=\"englishpod_C0013\"></a>englishpod_C0013</h1><ul>\n<li>expenses</li>\n<li>through the roof<br>off the charts</li>\n<li>expenditure</li>\n<li>out of control</li>\n<li>go over</li>\n<li>profit and loss statement</li>\n</ul>\n<h1 id=\"englishpod-B0014\"><a href=\"#englishpod-B0014\" class=\"headerlink\" title=\"englishpod_B0014\"></a>englishpod_B0014</h1><ul>\n<li>recession</li>\n<li>broke</li>\n<li>loan</li>\n<li>mortgage<br>a loan to help you buy an apartment</li>\n<li>hit me pretty hard</li>\n<li>tuition</li>\n<li>can I help you?<br>what can I do for you?</li>\n<li>I’m sorry to trouble you</li>\n<li>on top of that</li>\n<li>data debt date</li>\n</ul>\n<h1 id=\"englishpod-C0015\"><a href=\"#englishpod-C0015\" class=\"headerlink\" title=\"englishpod_C0015\"></a>englishpod_C0015</h1><ul>\n<li>knock over<br>slip something down</li>\n<li>explode</li>\n<li>familiar</li>\n<li>coincidence</li>\n<li>I feel terrible<br>please accept my apologies</li>\n<li>I don’t mean knocking over</li>\n</ul>\n<h1 id=\"englishpod-B0016\"><a href=\"#englishpod-B0016\" class=\"headerlink\" title=\"englishpod_B0016\"></a>englishpod_B0016</h1><ul>\n<li>step on it<br>speed up slow down<br>go fast</li>\n<li>have a fit<br>get angry</li>\n<li>cut through<br>go through</li>\n<li>short cut<br>take a short way</li>\n<li>make a left/right<br>make a u turn</li>\n<li>take a side street<br>take the freeway</li>\n</ul>\n<h1 id=\"englishpod-B0017\"><a href=\"#englishpod-B0017\" class=\"headerlink\" title=\"englishpod_B0017\"></a>englishpod_B0017</h1><ul>\n<li>groom<br>man</li>\n<li>bride<br>woman</li>\n<li>It’s about time<br>finally at last</li>\n<li>aisle</li>\n<li>bridemaids</li>\n<li>flower girl</li>\n<li>ring bearer</li>\n<li>niece nephew</li>\n<li>gorgeous<br>beautiful</li>\n<li>get married</li>\n<li>priest</li>\n</ul>\n<h1 id=\"englishpod-D0018\"><a href=\"#englishpod-D0018\" class=\"headerlink\" title=\"englishpod_D0018\"></a>englishpod_D0018</h1><ul>\n<li>bankrupt</li>\n<li>bail out</li>\n<li>injustice</li>\n<li>outrage</li>\n<li>break out<br>to begin suddenlly</li>\n<li>have the nerve to<br>dare to do</li>\n<li>financial</li>\n</ul>\n<h1 id=\"englishpod-C0019\"><a href=\"#englishpod-C0019\" class=\"headerlink\" title=\"englishpod_C0019\"></a>englishpod_C0019</h1><ul>\n<li>eggnog</li>\n<li>vehicle<br>car</li>\n<li>lawer</li>\n<li>appoint<br>choose</li>\n<li>sleigh</li>\n<li>step out<br>step out the vehicle</li>\n<li>get a load of<br>look at</li>\n<li>Don’t take the tone with me</li>\n<li>invoice<br>发票</li>\n</ul>\n<h1 id=\"englishpod-B0020\"><a href=\"#englishpod-B0020\" class=\"headerlink\" title=\"englishpod_B0020\"></a>englishpod_B0020</h1><ul>\n<li>struggle<br>try real hard</li>\n<li>blurry<br>not clear</li>\n<li>prescription</li>\n<li>20-20 vision<br>Perfect eyesight</li>\n<li>far sighted<br>near sighted</li>\n<li>make out<br>see clearly</li>\n<li>as blind as a bat</li>\n<li>what seems to be the problem</li>\n<li>head on<br>head on over<br>head on in</li>\n</ul>\n<h1 id=\"englishpod-C0021\"><a href=\"#englishpod-C0021\" class=\"headerlink\" title=\"englishpod_C0021\"></a>englishpod_C0021</h1><ul>\n<li>VP<br>the vice president</li>\n<li>fortune 500 company</li>\n<li>implement</li>\n<li>policy</li>\n<li>oversee</li>\n<li>go on about him</li>\n<li>How’s going?</li>\n<li>what do you do for a living?</li>\n</ul>\n<h1 id=\"englishpod-C0022\"><a href=\"#englishpod-C0022\" class=\"headerlink\" title=\"englishpod_C0022\"></a>englishpod_C0022</h1><ul>\n<li>candy canes</li>\n<li>booked</li>\n<li>speeding<br>go too fast</li>\n<li>impounded<br>held by the police<br>take your car to car jail</li>\n<li>ruined<br>destoried</li>\n<li>backup<br>help</li>\n</ul>\n<h1 id=\"englishpod-B0023\"><a href=\"#englishpod-B0023\" class=\"headerlink\" title=\"englishpod_B0023\"></a>englishpod_B0023</h1><ul>\n<li>financial adviser</li>\n<li>available</li>\n<li>double check<br>check it again</li>\n<li>sheduled<br>book it at that time</li>\n<li>booked solid</li>\n</ul>\n<h1 id=\"englishpod-B0024\"><a href=\"#englishpod-B0024\" class=\"headerlink\" title=\"englishpod_B0024\"></a>englishpod_B0024</h1><ul>\n<li>food po<br>not a good thing</li>\n<li>allergic<br>It make you sick</li>\n<li>check out<br>look at</li>\n<li>be</li>\n<li>not all that crazy about</li>\n<li>tasty<br>delicious</li>\n<li>in the mood for<br>have a desire</li>\n<li>Do  you have any suggentions/ideas?</li>\n<li>I reconmend giving it a try.<br>You’ve got to give a try.</li>\n<li>platter</li>\n<li>decor<br>decoration</li>\n</ul>\n<h1 id=\"englishpod-D0025\"><a href=\"#englishpod-D0025\" class=\"headerlink\" title=\"englishpod_D0025\"></a>englishpod_D0025</h1><ul>\n<li>converage</li>\n<li>pain de<br>scary</li>\n<li>critical<br>important</li>\n<li>outbreak</li>\n<li>forcast<br>predict</li>\n<li>Let’s move to the next order of business.<br>come up<br>move on</li>\n<li>head up<br>take charge of</li>\n<li>I’ll leave it to you.</li>\n<li>contingency plan<br>a plan that prepares for a situation where things go wrong</li>\n<li>vaccine<br>疫苗</li>\n</ul>\n<h1 id=\"englishpod-B0026\"><a href=\"#englishpod-B0026\" class=\"headerlink\" title=\"englishpod_B0026\"></a>englishpod_B0026</h1><ul>\n<li>eating habits<br>the regular way you eat</li>\n<li>junk food</li>\n<li>transform</li>\n<li>I’m stuffed</li>\n<li>stick to it<br>keep doing it</li>\n<li>I mean it.<br>I’m serious.</li>\n<li>cut out</li>\n<li>wait and see</li>\n</ul>\n<h1 id=\"englishpod-B0027\"><a href=\"#englishpod-B0027\" class=\"headerlink\" title=\"englishpod_B0027\"></a>englishpod_B0027</h1><ul>\n<li>vacation day</li>\n<li>overseas</li>\n<li>unpaid leave</li>\n<li>notice</li>\n<li>Do you have a second?<br>Do you have a minute/sec?</li>\n<li>Would you be OK with that?<br>will it be OK with that?</li>\n<li>I was just wondering<br>I was just hoping that</li>\n</ul>\n<h1 id=\"englishpod-C0028\"><a href=\"#englishpod-C0028\" class=\"headerlink\" title=\"englishpod_C0028\"></a>englishpod_C0028</h1><ul>\n<li>relieved</li>\n<li>pick me up<br>come and get me</li>\n<li>ordinary</li>\n<li>make it up to you</li>\n<li>my treat</li>\n<li>twist of fate</li>\n</ul>\n<h1 id=\"englishpod-E0029\"><a href=\"#englishpod-E0029\" class=\"headerlink\" title=\"englishpod_E0029\"></a>englishpod_E0029</h1><ul>\n<li>merging market<br>developing</li>\n<li>turmoil<br>a state of confusion</li>\n<li>proposed</li>\n<li>hit up<br>ask for money</li>\n<li>inevitable</li>\n</ul>\n<h1 id=\"englishpod-C0030\"><a href=\"#englishpod-C0030\" class=\"headerlink\" title=\"englishpod_C0030\"></a>englishpod_C0030</h1><ul>\n<li>thoughtful</li>\n<li>give me the creeps<br>make me feel uncomfortable</li>\n<li>rope me into something</li>\n<li>appetite<br>strong desire for food</li>\n<li>get to know someone</li>\n<li>why on earth</li>\n</ul>\n<h1 id=\"englishpod-B0031\"><a href=\"#englishpod-B0031\" class=\"headerlink\" title=\"englishpod_B0031\"></a>englishpod_B0031</h1><ul>\n<li>reshedule<br>change for another day or time</li>\n<li>inconvenience</li>\n<li>postpone<br>delay</li>\n<li>can not make it<br>can’t do something</li>\n<li>this thing comes up</li>\n</ul>\n<h1 id=\"englishpod-C0032\"><a href=\"#englishpod-C0032\" class=\"headerlink\" title=\"englishpod_C0032\"></a>englishpod_C0032</h1><ul>\n<li>chequing account</li>\n<li>savings account</li>\n<li>transaction</li>\n<li>balance</li>\n<li>overdraft</li>\n<li>debit card</li>\n<li>I’ll get you to</li>\n<li>I need your insurace number.</li>\n<li>If you could sign here?</li>\n</ul>\n<h1 id=\"englishpod-B0033\"><a href=\"#englishpod-B0033\" class=\"headerlink\" title=\"englishpod_B0033\"></a>englishpod_B0033</h1><ul>\n<li>foul</li>\n<li>ref</li>\n<li>free throw</li>\n<li>make a shot<br>to successful</li>\n<li>3 pointer shot</li>\n<li>travel<br>take more than two steps with the ball</li>\n<li>screw up<br>to make a mistake</li>\n<li>beer run<br>to go and get a beer</li>\n</ul>\n<h1 id=\"englishpod-D0034\"><a href=\"#englishpod-D0034\" class=\"headerlink\" title=\"englishpod_D0034\"></a>englishpod_D0034</h1><ul>\n<li>swear in<br>swore in</li>\n<li>oath<br>a promise</li>\n<li>deliver<br>say a speech</li>\n<li>who’s who</li>\n<li>palpable</li>\n<li>in a word</li>\n<li>go down in history</li>\n<li>my fellow Americans<br>dear</li>\n</ul>\n<h1 id=\"englishpod-C0035\"><a href=\"#englishpod-C0035\" class=\"headerlink\" title=\"englishpod_C0035\"></a>englishpod_C0035</h1><ul>\n<li>a good fit<br>suitable for the job</li>\n<li>performance</li>\n<li>unreliable<br>reliable</li>\n<li>productive</li>\n<li>work ethic</li>\n<li>coach<br>train</li>\n<li>the bottom of line<br>the most important point</li>\n<li>overall</li>\n<li>perfectly good</li>\n</ul>\n<h1 id=\"englishpod-B0036\"><a href=\"#englishpod-B0036\" class=\"headerlink\" title=\"englishpod_B0036\"></a>englishpod_B0036</h1><ul>\n<li>get a hold</li>\n<li>stand me up<br>fail to keep the appointment to meet someone</li>\n<li>priority</li>\n<li>heading<br>going</li>\n<li>Do you have any idea how</li>\n<li>I heard it before</li>\n<li>take a break<br>stop their relationship</li>\n<li>decency<br>polite or moral bahavior</li>\n<li>get your priorities straight<br>realize what is more important</li>\n</ul>\n<h1 id=\"englishpod-C0037\"><a href=\"#englishpod-C0037\" class=\"headerlink\" title=\"englishpod_C0037\"></a>englishpod_C0037</h1><ul>\n<li>dumping<br>水饺</li>\n<li>firecracker</li>\n<li>set off</li>\n<li>I can’t wait to</li>\n<li>I bet</li>\n<li>red envelope</li>\n<li>mahjong</li>\n</ul>\n<h1 id=\"englishpod-C0038\"><a href=\"#englishpod-C0038\" class=\"headerlink\" title=\"englishpod_C0038\"></a>englishpod_C0038</h1><ul>\n<li>vehicle</li>\n<li>sedan<br>a car with four doors</li>\n<li>gas mileage<br>the amount of gas used per mile</li>\n<li>airbags</li>\n<li>brake</li>\n<li>reinforce<br>make stronger</li>\n<li>I’m just browsing</li>\n<li>sleep on it<br>to think about it</li>\n</ul>\n<h1 id=\"englishpod-B0039\"><a href=\"#englishpod-B0039\" class=\"headerlink\" title=\"englishpod_B0039\"></a>englishpod_B0039</h1><ul>\n<li>heard</li>\n<li>fill me in<br>tell me about something</li>\n<li>career path</li>\n<li>In  his early 30s</li>\n</ul>\n<h1 id=\"englishpod-B0040\"><a href=\"#englishpod-B0040\" class=\"headerlink\" title=\"englishpod_B0040\"></a>englishpod_B0040</h1><ul>\n<li>on board<br>welcome to the company</li>\n<li>about to</li>\n<li>instead<br>in the  place of</li>\n<li>intrepret</li>\n</ul>\n<h1 id=\"englishpod-C0041\"><a href=\"#englishpod-C0041\" class=\"headerlink\" title=\"englishpod_C0041\"></a>englishpod_C0041</h1><ul>\n<li>posses</li>\n<li>survival</li>\n<li>defend<br>protect</li>\n<li>rough<br>hard</li>\n<li>at all costs<br>no matter what</li>\n<li>stand in one’s way</li>\n</ul>\n<h1 id=\"englishpod-B0042\"><a href=\"#englishpod-B0042\" class=\"headerlink\" title=\"englishpod_B0042\"></a>englishpod_B0042</h1><ul>\n<li>deadline</li>\n<li>extension</li>\n<li>run into<br>run into some problem</li>\n<li>delay</li>\n<li>be under control</li>\n<li>put this off</li>\n<li>press kit<br>groups of photos, documents, articals, and information about company given to reporters, newspapers,magazines,etc.</li>\n<li>finalize<br>finish</li>\n</ul>\n<h1 id=\"englishpod-C0043\"><a href=\"#englishpod-C0043\" class=\"headerlink\" title=\"englishpod_C0043\"></a>englishpod_C0043</h1><ul>\n<li>visa<br>签证</li>\n<li>sponsor</li>\n<li>invitation letter</li>\n<li>ties</li>\n<li>financially independent</li>\n</ul>\n<h1 id=\"englishpod-B0044\"><a href=\"#englishpod-B0044\" class=\"headerlink\" title=\"englishpod_B0044\"></a>englishpod_B0044</h1><ul>\n<li>barely even</li>\n<li>catch the news<br>hear the news</li>\n<li>by the way</li>\n<li>take the stairs</li>\n<li>do you happen to<br>by chance</li>\n</ul>\n<h1 id=\"englishpod-C0045\"><a href=\"#englishpod-C0045\" class=\"headerlink\" title=\"englishpod_C0045\"></a>englishpod_C0045</h1><ul>\n<li>on a break</li>\n<li>seeing someone<br>dating or going out with someone</li>\n<li>cheat on</li>\n<li>mess this up</li>\n<li>immature  </li>\n<li>selfish</li>\n<li>everything is going to work out just fine.</li>\n<li>pull yourself together<br>calm down</li>\n<li>It’s going to be alright.</li>\n</ul>\n<h1 id=\"englishpod-D0046\"><a href=\"#englishpod-D0046\" class=\"headerlink\" title=\"englishpod_D0046\"></a>englishpod_D0046</h1><ul>\n<li>CPR</li>\n<li>BP<br>blood pressure</li>\n<li>hook up</li>\n<li>out of woods<br>free from danger</li>\n<li>defibrillator</li>\n</ul>\n<h1 id=\"englishpod-C0048\"><a href=\"#englishpod-C0048\" class=\"headerlink\" title=\"englishpod_C0048\"></a>englishpod_C0048</h1><ul>\n<li>ticket scalper<br>黄牛</li>\n<li>prestigious<br>being respected and admired for being successful or important</li>\n<li>float</li>\n<li>once in the lifetime</li>\n<li>good thing</li>\n<li>no kidding<br>I totally agree with you</li>\n</ul>\n<h1 id=\"englishpod-C0049\"><a href=\"#englishpod-C0049\" class=\"headerlink\" title=\"englishpod_C0049\"></a>englishpod_C0049</h1><ul>\n<li>concert</li>\n<li>hottest</li>\n<li>fine then</li>\n<li>I was wondering can I<br>Do you think<br>would you mind</li>\n</ul>\n<h1 id=\"englishpod-C0050\"><a href=\"#englishpod-C0050\" class=\"headerlink\" title=\"englishpod_C0050\"></a>englishpod_C0050</h1><ul>\n<li>appetite</li>\n<li>poison</li>\n<li>points<br>suggestions</li>\n<li>aroma<br>special smell</li>\n<li>bitter</li>\n<li>pass out<br>become unconscious</li>\n<li>make yourself at home</li>\n</ul>\n<h1 id=\"englishpod-C0051\"><a href=\"#englishpod-C0051\" class=\"headerlink\" title=\"englishpod_C0051\"></a>englishpod_C0051</h1><ul>\n<li>price range</li>\n<li>shop around</li>\n<li>pricey</li>\n<li>a better deal</li>\n<li>That’s my best offer.<br>That’s my last offer.</li>\n<li>exclusive<br>not common, unique</li>\n</ul>\n<h1 id=\"englishpod-C0052\"><a href=\"#englishpod-C0052\" class=\"headerlink\" title=\"englishpod_C0052\"></a>englishpod_C0052</h1><ul>\n<li>medium<br>12 inch<br>larger</li>\n<li>pepperoni<br>a spicy sausage usually on pizza</li>\n<li>olives</li>\n<li>extra cheese</li>\n<li>ham</li>\n<li>pineapple</li>\n<li>thin crust</li>\n<li>would you like</li>\n</ul>\n<h1 id=\"englishpod-C0053\"><a href=\"#englishpod-C0053\" class=\"headerlink\" title=\"englishpod_C0053\"></a>englishpod_C0053</h1><ul>\n<li>head chef<br>the main cook</li>\n<li>cuisine</li>\n<li>peel<br>remove the outside</li>\n<li>chop</li>\n<li>stir<br>mix</li>\n<li>butcher</li>\n<li>butter</li>\n<li>in the weeds<br>you are really busy</li>\n<li>run low on<br>not something left</li>\n<li>do really well</li>\n</ul>\n<h1 id=\"englishpod-C0054\"><a href=\"#englishpod-C0054\" class=\"headerlink\" title=\"englishpod_C0054\"></a>englishpod_C0054</h1><ul>\n<li>blaze<br>fire</li>\n<li>in the middle of nowhere</li>\n<li>first thing in the morning</li>\n<li>everything seems to be order</li>\n</ul>\n<h1 id=\"englishpod-C0055\"><a href=\"#englishpod-C0055\" class=\"headerlink\" title=\"englishpod_C0055\"></a>englishpod_C0055</h1><ul>\n<li>puck</li>\n<li>key game</li>\n<li>finals</li>\n<li>face-off</li>\n<li>goalie<br>saver</li>\n<li>breakaway</li>\n</ul>\n<h1 id=\"englishpod-C0056\"><a href=\"#englishpod-C0056\" class=\"headerlink\" title=\"englishpod_C0056\"></a>englishpod_C0056</h1><ul>\n<li>fill in</li>\n<li>replicas</li>\n<li>tap</li>\n<li>map out</li>\n<li>screw it up</li>\n<li>lose your cool</li>\n</ul>\n<h1 id=\"englishpod-C0057\"><a href=\"#englishpod-C0057\" class=\"headerlink\" title=\"englishpod_C0057\"></a>englishpod_C0057</h1><ul>\n<li>malfunction</li>\n<li>ASAP<br>as soon as possible</li>\n<li>practical joke</li>\n<li>never mind</li>\n<li>out of to</li>\n<li>on your way up</li>\n<li>break down<br>break in<br>break out</li>\n<li>toner<br>ink used in a printer or photocopier</li>\n</ul>\n<h1 id=\"englishpod-C0058\"><a href=\"#englishpod-C0058\" class=\"headerlink\" title=\"englishpod_C0058\"></a>englishpod_C0058</h1><ul>\n<li>turbulence</li>\n<li>flight crew</li>\n<li>bumpy ride</li>\n<li>fasten<br>fasten your seat belt</li>\n<li>lavatory</li>\n<li>stow</li>\n<li>refrain</li>\n<li>remain seated</li>\n<li>patch</li>\n<li>suspend<br>stop for a short time</li>\n</ul>\n<h1 id=\"englishpod-E0059\"><a href=\"#englishpod-E0059\" class=\"headerlink\" title=\"englishpod_E0059\"></a>englishpod_E0059</h1><ul>\n<li>CRM<br>custom relationship manager</li>\n<li>custom designed<br>custom built house</li>\n<li>core values</li>\n<li>undisputed<br>the is no doubt</li>\n<li>growth oppotunity</li>\n<li>read up</li>\n<li>unleash potential</li>\n<li>resonate</li>\n</ul>\n<h1 id=\"englishpod-C0060\"><a href=\"#englishpod-C0060\" class=\"headerlink\" title=\"englishpod_C0060\"></a>englishpod_C0060</h1><ul>\n<li>drag</li>\n<li>tie somebody up</li>\n<li>fools</li>\n<li>fell for it</li>\n<li>the cat is out of the bag<br>the truth is out</li>\n<li>pretend</li>\n<li>gullible<br>easily beliving something that is not true, eaily fooled</li>\n</ul>\n<h1 id=\"englishpod-C0061\"><a href=\"#englishpod-C0061\" class=\"headerlink\" title=\"englishpod_C0061\"></a>englishpod_C0061</h1><ul>\n<li>sail</li>\n<li>anchor</li>\n<li>doggy-paddling<br>swim like a dog</li>\n<li>breast stroke</li>\n<li>backstroke</li>\n<li>take a dip</li>\n<li>for a little while</li>\n</ul>\n<h1 id=\"englishpod-C0062\"><a href=\"#englishpod-C0062\" class=\"headerlink\" title=\"englishpod_C0062\"></a>englishpod_C0062</h1><ul>\n<li>major<br>main subject</li>\n<li>minor</li>\n<li>course of study</li>\n<li>track<br>path</li>\n<li>hence</li>\n<li>pursued<br>to chase</li>\n<li>strive<br>to try real hard</li>\n<li>breadth</li>\n<li>implement</li>\n<li>postgraduate<br>masters or PH.D;</li>\n<li>initiative<br>倡议</li>\n<li>churn rate<br>客户流失率</li>\n<li>coordinate<br>协调</li>\n</ul>\n<h1 id=\"englishpod-C0063\"><a href=\"#englishpod-C0063\" class=\"headerlink\" title=\"englishpod_C0063\"></a>englishpod_C0063</h1><ul>\n<li>certainly</li>\n<li>may I take your name?</li>\n<li>monmentarily<br>in a short</li>\n<li>ready for</li>\n</ul>\n<h1 id=\"englishpod-C0064\"><a href=\"#englishpod-C0064\" class=\"headerlink\" title=\"englishpod_C0064\"></a>englishpod_C0064</h1><ul>\n<li>sleep with</li>\n<li>confess<br>you tell a secret that you are hiding</li>\n<li>overwhelm</li>\n<li>jelousy</li>\n<li>jerk<br>stupid and mean person</li>\n<li>bastard</li>\n<li>bun in the oven<br>pregnant</li>\n<li>I can’t help myself</li>\n<li>come into the picture<br>appear into one’s life</li>\n<li>cheerleading squad<br>啦啦队</li>\n</ul>\n<h1 id=\"englishpod-C0065\"><a href=\"#englishpod-C0065\" class=\"headerlink\" title=\"englishpod_C0065\"></a>englishpod_C0065</h1><ul>\n<li>technical acument</li>\n<li>excel</li>\n<li>head</li>\n<li>struggle</li>\n<li>punctual<br>punctuality</li>\n<li>adress<br>deal with</li>\n<li>fit</li>\n<li>acumen<br>the ability to think clearly and make good decisions</li>\n</ul>\n<h1 id=\"englishpod-C0067\"><a href=\"#englishpod-C0067\" class=\"headerlink\" title=\"englishpod_C0067\"></a>englishpod_C0067</h1><ul>\n<li>wingman</li>\n<li>tired</li>\n<li>foul</li>\n<li>kick off</li>\n<li>out of bounds</li>\n<li>throw in</li>\n<li>offside</li>\n<li>on the brink of<br>at a critical point</li>\n<li>no question about it<br>no doubt</li>\n<li>by a mile</li>\n<li>penalty kick<br>a kick against only the goalkeepwe as a reward for a foul</li>\n</ul>\n<h1 id=\"englishpod-C0068\"><a href=\"#englishpod-C0068\" class=\"headerlink\" title=\"englishpod_C0068\"></a>englishpod_C0068</h1><ul>\n<li>irrefutable</li>\n<li>flaw</li>\n<li>systemetic<br>following the certain order</li>\n<li>extensive research</li>\n<li>conclusive evidence<br>final decision</li>\n<li>investigative approch</li>\n<li>definite conclusion</li>\n<li>oblivious to<br>unware or don’t know</li>\n<li>proposterous<br>crazy, foolish, or silly</li>\n</ul>\n<h1 id=\"englishpod-C0069\"><a href=\"#englishpod-C0069\" class=\"headerlink\" title=\"englishpod_C0069\"></a>englishpod_C0069</h1><ul>\n<li>picky</li>\n<li>yolk<br>egg yolk<br>the white</li>\n<li>sunny side up</li>\n<li>fried egg</li>\n<li>soft boiled egg</li>\n<li>hard boiled egg</li>\n<li>egg and soilders</li>\n<li>scrible eggs</li>\n<li>feel like<br>have desire to do</li>\n<li>drive me crazy<br>make you angry</li>\n<li>muffin<br>a small break or cake people usually eat for breakfast</li>\n</ul>\n<h1 id=\"englishpod-F0070\"><a href=\"#englishpod-F0070\" class=\"headerlink\" title=\"englishpod_F0070\"></a>englishpod_F0070</h1><ul>\n<li>lingerie</li>\n<li>awkward</li>\n<li>granny panties</li>\n<li>sleepwear</li>\n<li>nighties<br>silky nighties</li>\n<li>undies</li>\n<li>mortifying<br>extremely embarassing</li>\n<li>get the hell out of here<br>leave</li>\n<li>get this over with</li>\n</ul>\n<h1 id=\"englishpod-C0071\"><a href=\"#englishpod-C0071\" class=\"headerlink\" title=\"englishpod_C0071\"></a>englishpod_C0071</h1><ul>\n<li>on tap<br>beer served from a barrel; not in a bottle or can</li>\n<li>happy hour</li>\n<li>pint</li>\n<li>appetizer<br>a small dish served before meal</li>\n<li>what about<br>be used in making suggestions</li>\n</ul>\n<h1 id=\"englishopod-C0072\"><a href=\"#englishopod-C0072\" class=\"headerlink\" title=\"englishopod_C0072\"></a>englishopod_C0072</h1><ul>\n<li>preoccupied<br>worried</li>\n<li>direct impact</li>\n<li>resent<br>find something very insulting</li>\n<li>beat around the bush<br>avoid saying something by about other things<br>come out with it</li>\n</ul>\n<h1 id=\"englishpod-C0073\"><a href=\"#englishpod-C0073\" class=\"headerlink\" title=\"englishpod_C0073\"></a>englishpod_C0073</h1><ul>\n<li>pinkie</li>\n<li>the ring finger</li>\n<li>the middle finger<br>giving the middle finger</li>\n<li>index finger</li>\n<li>thumb</li>\n<li>abide<br>live</li>\n</ul>\n<h1 id=\"englishpod-C0074\"><a href=\"#englishpod-C0074\" class=\"headerlink\" title=\"englishpod_C0074\"></a>englishpod_C0074</h1><ul>\n<li>famished<br>very hungry</li>\n<li>sexist</li>\n<li>dumbass</li>\n<li>moron<br>someone is stupid</li>\n<li>tool<br>useless</li>\n<li>chill</li>\n<li>scream</li>\n<li>what the hell</li>\n</ul>\n<h1 id=\"englishpod-C0075\"><a href=\"#englishpod-C0075\" class=\"headerlink\" title=\"englishpod_C0075\"></a>englishpod_C0075</h1><ul>\n<li>toothache</li>\n<li>x-ray</li>\n<li>swollen</li>\n<li>cavity<br>a hole in a tooth</li>\n<li>crown<br>the part of the tooth which can be seen</li>\n<li>filling</li>\n<li>what seems to be the problem?<br>what’s wrong?</li>\n</ul>\n<h1 id=\"englishpod-C0076\"><a href=\"#englishpod-C0076\" class=\"headerlink\" title=\"englishpod_C0076\"></a>englishpod_C0076</h1><ul>\n<li>plus add<br>minus<br>times<br>devided by</li>\n<li>square root</li>\n<li>teacher’s pet<br>suck up</li>\n<li>smarty pants<br>for children</li>\n<li>konw it all</li>\n</ul>\n<h1 id=\"englishpod-C0077\"><a href=\"#englishpod-C0077\" class=\"headerlink\" title=\"englishpod_C0077\"></a>englishpod_C0077</h1><ul>\n<li>jam on the breaks</li>\n<li>spin out<br>(a car)slides and makes a turn rapidly in an uncontrolled way</li>\n<li>the pace car</li>\n<li>cleanup crew<br>the construction crew</li>\n<li>to tow</li>\n<li>my partner in crime<br>a person you always do things together with</li>\n<li>a close one</li>\n<li>stretch<br>the final time period</li>\n</ul>\n<h1 id=\"englishpod-E0078\"><a href=\"#englishpod-E0078\" class=\"headerlink\" title=\"englishpod_E0078\"></a>englishpod_E0078</h1><ul>\n<li>brutality<br>violent treatment or behavior</li>\n<li>important aspect</li>\n<li>genesis</li>\n<li>comprehend</li>\n<li>appalling<br>terrible, horrible, shocking</li>\n<li>hostility<br>the attitde of treating something as enemy</li>\n<li>drastic<br>sudden and severe</li>\n<li>constitute<br>form, consist</li>\n<li>fire into<br>shoot guns into a place</li>\n</ul>\n<h1 id=\"englishpod-B0079\"><a href=\"#englishpod-B0079\" class=\"headerlink\" title=\"englishpod_B0079\"></a>englishpod_B0079</h1><ul>\n<li>spacecraft</li>\n<li>break through</li>\n<li>settle this</li>\n<li>accelerate</li>\n<li>no loger be</li>\n<li>once and for all</li>\n<li>obscure</li>\n</ul>\n<h1 id=\"englishpod-C0080\"><a href=\"#englishpod-C0080\" class=\"headerlink\" title=\"englishpod_C0080\"></a>englishpod_C0080</h1><ul>\n<li>show up</li>\n<li>stalk<br>follow someone for a long time</li>\n<li>nut job</li>\n<li>get worked up</li>\n<li>soul mate</li>\n<li>over nothing<br>no reason</li>\n<li>not a day goes by</li>\n<li>no matter what</li>\n</ul>\n<h1 id=\"englishpod-B0081\"><a href=\"#englishpod-B0081\" class=\"headerlink\" title=\"englishpod_B0081\"></a>englishpod_B0081</h1><ul>\n<li>trim<br>a short cut of hair to make one look clean</li>\n<li>fancy</li>\n<li>silky<br>silk hair</li>\n<li>grow out</li>\n<li>don’t just stand there</li>\n<li>take a little off the top<br>take a little off the side</li>\n<li>curly</li>\n<li>a million bucks<br>very good. To look great</li>\n<li>sideburns<br>hari thar grows on the sides of man</li>\n<li>fluffy<br>soft  </li>\n</ul>\n<h1 id=\"englishpod-C0082\"><a href=\"#englishpod-C0082\" class=\"headerlink\" title=\"englishpod_C0082\"></a>englishpod_C0082</h1><ul>\n<li>creature</li>\n<li>break free</li>\n<li>kidnapper</li>\n<li>rapist</li>\n<li>rape</li>\n<li>lemme see your eyes<br>let me see your eyes<br>gimme - give me</li>\n<li>make it out<br>able to escape or flee</li>\n</ul>\n<h1 id=\"englishpod-C0083\"><a href=\"#englishpod-C0083\" class=\"headerlink\" title=\"englishpod_C0083\"></a>englishpod_C0083</h1><ul>\n<li>ATM<br>automatic teller machine</li>\n<li>the local authority</li>\n<li>slot</li>\n<li>digit</li>\n<li>withdraw</li>\n<li>transfer money</li>\n<li>pound key<br>the push botton marked with #</li>\n</ul>\n<h1 id=\"englishpod-B0084\"><a href=\"#englishpod-B0084\" class=\"headerlink\" title=\"englishpod_B0084\"></a>englishpod_B0084</h1><ul>\n<li>pharmacy<br>medicine</li>\n<li>milligram</li>\n<li>price check</li>\n<li>prescription</li>\n<li>capsule</li>\n<li>tablet</li>\n<li>overdose</li>\n<li>eye drop</li>\n<li>be sure not to</li>\n<li>get a price check</li>\n</ul>\n<h1 id=\"englishpod-B0085\"><a href=\"#englishpod-B0085\" class=\"headerlink\" title=\"englishpod_B0085\"></a>englishpod_B0085</h1><ul>\n<li>the national anthem</li>\n<li>pitcher<br>throw the ball</li>\n<li>wind up</li>\n<li>line drive<br>a hit that travels low along the baseline     </li>\n<li>scramble</li>\n<li>up at bat<br>get ready to hit the ball</li>\n<li>strike</li>\n<li>curve ball</li>\n</ul>\n<h1 id=\"englishpod-C0086\"><a href=\"#englishpod-C0086\" class=\"headerlink\" title=\"englishpod_C0086\"></a>englishpod_C0086</h1><ul>\n<li>landlord<br>the owner of house</li>\n<li>tenant<br>the person that rents a house</li>\n<li>renovate<br>make a new again</li>\n<li>airy<br>spacious so that air moves freely</li>\n<li>square footage</li>\n<li>applicance</li>\n<li>gas range<br>a stove that uses to cook</li>\n<li>prefessional greed</li>\n<li>spaciou<br>latge; having lots of space</li>\n<li>walk-in closet<br>a room containedf in a bedroom for storing clothes</li>\n<li>en suit bathroom<br>a bathroom within the main bedroom</li>\n</ul>\n<h1 id=\"englishpod-B0087\"><a href=\"#englishpod-B0087\" class=\"headerlink\" title=\"englishpod_B0087\"></a>englishpod_B0087</h1><ul>\n<li>unidentified ship</li>\n<li>seach party</li>\n<li>a deep voice</li>\n<li>offentic</li>\n<li>wig<br>artificial hair</li>\n<li>under attack<br>under fire</li>\n<li>sustain<br>damage</li>\n<li>the nature of</li>\n<li>warp drive</li>\n</ul>\n<h1 id=\"englishpod-B0088\"><a href=\"#englishpod-B0088\" class=\"headerlink\" title=\"englishpod_B0088\"></a>englishpod_B0088</h1><ul>\n<li>here’s the thing<br>give somebody some information</li>\n<li>I can’t take it anymore</li>\n<li>Are you serious?</li>\n<li>have guts to<br>courage</li>\n<li>just two of us<br>just three of us</li>\n<li>give me a shot<br>give me an oppotunity</li>\n<li>pros and cons<br>good things and bad things about a person</li>\n</ul>\n<h1 id=\"englishpod-C0089\"><a href=\"#englishpod-C0089\" class=\"headerlink\" title=\"englishpod_C0089\"></a>englishpod_C0089</h1><ul>\n<li>piece of luggage</li>\n<li>carryon luggage</li>\n<li>overhead compa</li>\n<li>how am I be supposed to</li>\n<li>There’s nothing I can do</li>\n<li>next to nothing<br>very cheap</li>\n</ul>\n<h1 id=\"englishpod-D0090\"><a href=\"#englishpod-D0090\" class=\"headerlink\" title=\"englishpod_D0090\"></a>englishpod_D0090</h1><ul>\n<li>spy</li>\n<li>come clean<br>confess</li>\n<li>renource</li>\n<li>approach someone</li>\n<li>claim</li>\n<li>vow<br>make a strong promise</li>\n<li>whereabouts<br>the approximate place, where a person or thing is</li>\n<li>I haven’t been completely honest with you</li>\n<li>I wasn’t supposed to<br>I shouldn’t</li>\n<li>bureau</li>\n<li>millennium<br>1000 years</li>\n<li>renowned<br>well known</li>\n</ul>\n<h1 id=\"englishpod-D0091\"><a href=\"#englishpod-D0091\" class=\"headerlink\" title=\"englishpod_D0091\"></a>englishpod_D0091</h1><ul>\n<li>constellation<br>a particular shape formed by a group of stars</li>\n<li>consequence<br>negative results</li>\n<li>downdfall<br>failure</li>\n<li>anguish<br>angry, aggressive, wanting to fight</li>\n<li>a wonder</li>\n<li>what gives you the right to</li>\n<li>to play God</li>\n<li>who are you to</li>\n</ul>\n<h1 id=\"englishpod-C0095\"><a href=\"#englishpod-C0095\" class=\"headerlink\" title=\"englishpod_C0095\"></a>englishpod_C0095</h1><ul>\n<li>in ages</li>\n<li>run into</li>\n<li>freak out</li>\n<li>stare</li>\n<li>shriek<br>screaming in a very high voice</li>\n<li>catch up with<br>learn about recent past events</li>\n<li>hilarious</li>\n</ul>\n<h1 id=\"englishpod-C0096\"><a href=\"#englishpod-C0096\" class=\"headerlink\" title=\"englishpod_C0096\"></a>englishpod_C0096</h1><ul>\n<li>pad</li>\n<li>far out</li>\n<li>crash</li>\n<li>split</li>\n<li>dig it<br>appreciate, like</li>\n<li>throw a bash<br>party<br>host a party</li>\n<li>take care of business</li>\n<li>happening scene<br>an extremely exciting moment</li>\n<li>peace out<br>see you later</li>\n<li>groovy<br>really cool</li>\n</ul>\n<h1 id=\"englishpod-D0097\"><a href=\"#englishpod-D0097\" class=\"headerlink\" title=\"englishpod_D0097\"></a>englishpod_D0097</h1><ul>\n<li>weather forcast</li>\n<li>shower<br>a short time rain</li>\n<li>scattered shower</li>\n<li>hover around<br>stay near a certain level or place</li>\n<li>temperature</li>\n<li>isolated downpour</li>\n<li>gust<br>strong, sudden increase in wind speed</li>\n<li>sleet<br>a mix of rain and snow</li>\n<li>cold front</li>\n<li>It’s going to a tough one</li>\n<li>mixed bag<br>a collection of different kinds of things</li>\n<li>cloud cover<br>the amount of sky that is covered with cloud</li>\n<li>partly-cloudy skies<br>having some cloud and some sun</li>\n</ul>\n<h1 id=\"englishpod-C0098\"><a href=\"#englishpod-C0098\" class=\"headerlink\" title=\"englishpod_C0098\"></a>englishpod_C0098</h1><ul>\n<li>the bar exam<br>the exam to qualify as a lawer</li>\n<li>flatter</li>\n<li>I love what you have done with your hair</li>\n<li>get his look from his mother</li>\n<li>by the way</li>\n<li>You haven’t aged a day<br>you haven’t gotten older</li>\n<li>obnoxious<br>really annoying</li>\n</ul>\n<h1 id=\"englishpod-E0099\"><a href=\"#englishpod-E0099\" class=\"headerlink\" title=\"englishpod_E0099\"></a>englishpod_E0099</h1><ul>\n<li>depict</li>\n<li>portrayal</li>\n<li>what’s your impression of the film?</li>\n<li>lack</li>\n<li>rightfully<br>according to law</li>\n<li>erudite<br>having a lot of knowledge</li>\n<li>fable<br>beauriful story about animals that has moral or lesson</li>\n<li>eternal<br>lasting forever</li>\n<li>accusation<br>action of caliming something is wrong</li>\n<li>plagiarism<br>practice of copying other’s ideas</li>\n<li>enchanting<br>attractive, holding one’s attention</li>\n<li>grim<br>unpleasant</li>\n<li>linear<br>moving in logical way, from start to end</li>\n<li>cliche<br>something that is to often used so that it loses meaning or importance</li>\n<li>time-honoured<br>something that survives the testing of time</li>\n</ul>\n<h1 id=\"englishpod-C0100\"><a href=\"#englishpod-C0100\" class=\"headerlink\" title=\"englishpod_C0100\"></a>englishpod_C0100</h1><ul>\n<li>If your don’t mind me saying so.</li>\n<li>Don’t get me wrong</li>\n<li>sure thing</li>\n<li>born and raised</li>\n<li>nosy<br>too interested in others’ private matters</li>\n<li>the good old U.S of A<br>the United States</li>\n</ul>\n<p>#</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"englishpod-B0001\"><a href=\"#englishpod-B0001\" class=\"headerlink\" title=\"englishpod_B0001\"></a>englishpod_B0001</h1><ul>\n<li>I’m still working on it.<br>I still need more time.</li>\n<li>complimentray<br>free</li>\n<li>I’ll go with.<br>I’ll take. I’ll choose.</li>\n<li>grab<br>get quickly</li>\n</ul>\n<h1 id=\"englishpod-B0002\"><a href=\"#englishpod-B0002\" class=\"headerlink\" title=\"englishpod_B0002\"></a>englishpod_B0002</h1><ul>\n<li>headache</li>\n<li>sore throat<br>it hurts</li>\n<li>runny nose</li>\n<li>feverish<br>feeling your body being very hot.</li>\n<li>quite ill<br>very sick</li>\n<li>come down with flu<br>I’m coming with cold.Begining to feel sick.</li>\n<li>calling in  sick<br>You call to your office,and you are sick and won’t go to work.</li>\n<li>take the day off</li>\n</ul>\n<h1 id=\"englishpod-C0003\"><a href=\"#englishpod-C0003\" class=\"headerlink\" title=\"englishpod_C0003\"></a>englishpod_C0003</h1><ul>\n<li>I have the reservation under the name</li>\n<li>mix up<br>confusion</li>\n<li>overbooked<br>full</li>\n<li>complimentray upgrade<br>free</li>\n</ul>\n<h1 id=\"englishpod-C0004\"><a href=\"#englishpod-C0004\" class=\"headerlink\" title=\"englishpod_C0004\"></a>englishpod_C0004</h1><ul>\n<li>resources<br>money</li>\n<li>understaffed<br>not enough people to do the job</li>\n<li>the timing is just not right<br>it is not the right now</li>\n<li>weight off my sholders<br>remove pressure or stress</li>\n<li>give me a hand<br>help out</li>\n<li>keep our cost down<br>to not to spend much money</li>\n<li>intern<br>实习生</li>\n</ul>\n<h1 id=\"englishpod-C0005\"><a href=\"#englishpod-C0005\" class=\"headerlink\" title=\"englishpod_C0005\"></a>englishpod_C0005</h1><ul>\n<li>unbelievable<br>something is amazing</li>\n<li>a mile long<br>this line is really long</li>\n<li>there is no way<br>it is not possible</li>\n<li>cut in line<br>somebody get in front of you</li>\n</ul>\n<h1 id=\"englishpod-C0006\"><a href=\"#englishpod-C0006\" class=\"headerlink\" title=\"englishpod_C0006\"></a>englishpod_C0006</h1><ul>\n<li>road trip<br>the car is packed. everything you need is in the car</li>\n<li>fill up the tank.</li>\n<li>we got all our bases coverd</li>\n<li>let’s get going</li>\n</ul>\n<h1 id=\"englishpod-C0007\"><a href=\"#englishpod-C0007\" class=\"headerlink\" title=\"englishpod_C0007\"></a>englishpod_C0007</h1><ul>\n<li>computer virus</li>\n<li>froze<br>stopping working</li>\n<li>infective file</li>\n<li>up to date</li>\n<li>I’ll be right there/down/out</li>\n<li>It turns out that</li>\n</ul>\n<h1 id=\"englishpod-C0008\"><a href=\"#englishpod-C0008\" class=\"headerlink\" title=\"englishpod_C0008\"></a>englishpod_C0008</h1><ul>\n<li>in a bit of hurry</li>\n<li>contact details</li>\n<li>slip my mind</li>\n<li>around there</li>\n<li>I’m terrible with names/faces</li>\n</ul>\n<h1 id=\"englishpd-C0009\"><a href=\"#englishpd-C0009\" class=\"headerlink\" title=\"englishpd_C0009\"></a>englishpd_C0009</h1><ul>\n<li>inconsiderate<br>not thinking about other’s feeling</li>\n<li>keep it down</li>\n<li>not such a big deal</li>\n<li>not a big problem</li>\n<li>switch it off</li>\n<li>I can’t hear a thing</li>\n</ul>\n<h1 id=\"englishpod-C0010\"><a href=\"#englishpod-C0010\" class=\"headerlink\" title=\"englishpod_C0010\"></a>englishpod_C0010</h1><ul>\n<li>drive sales</li>\n<li>promotion</li>\n<li>match the competitor</li>\n<li>in the market<br>in the insustry</li>\n<li>It’ll never fly<br>it won’t work</li>\n</ul>\n<h1 id=\"englishpod-C0011\"><a href=\"#englishpod-C0011\" class=\"headerlink\" title=\"englishpod_C0011\"></a>englishpod_C0011</h1><ul>\n<li>weird<br>strange  odd</li>\n<li>housewarming</li>\n<li>a bad feeling</li>\n<li>kicked me out<br>force me to leave</li>\n<li>creep me out<br>make me feel uncomfortable</li>\n<li>scared and</li>\n<li>I don’t know if you heard<br>gossip</li>\n<li>fill me in<br>give me information</li>\n<li>you scared the heck out of me</li>\n</ul>\n<h1 id=\"englishpod-C0012\"><a href=\"#englishpod-C0012\" class=\"headerlink\" title=\"englishpod_C0012\"></a>englishpod_C0012</h1><ul>\n<li>such a mess</li>\n<li>chore</li>\n<li>tidy up</li>\n<li>spotless<br>一尘不染</li>\n<li>mall<br>many stores in there</li>\n<li>grocery<br>grocery list<br>grocery shopping</li>\n<li>I’m in the middle of something now.</li>\n<li>I’ll be there in a second</li>\n</ul>\n<h1 id=\"englishpod-C0013\"><a href=\"#englishpod-C0013\" class=\"headerlink\" title=\"englishpod_C0013\"></a>englishpod_C0013</h1><ul>\n<li>expenses</li>\n<li>through the roof<br>off the charts</li>\n<li>expenditure</li>\n<li>out of control</li>\n<li>go over</li>\n<li>profit and loss statement</li>\n</ul>\n<h1 id=\"englishpod-B0014\"><a href=\"#englishpod-B0014\" class=\"headerlink\" title=\"englishpod_B0014\"></a>englishpod_B0014</h1><ul>\n<li>recession</li>\n<li>broke</li>\n<li>loan</li>\n<li>mortgage<br>a loan to help you buy an apartment</li>\n<li>hit me pretty hard</li>\n<li>tuition</li>\n<li>can I help you?<br>what can I do for you?</li>\n<li>I’m sorry to trouble you</li>\n<li>on top of that</li>\n<li>data debt date</li>\n</ul>\n<h1 id=\"englishpod-C0015\"><a href=\"#englishpod-C0015\" class=\"headerlink\" title=\"englishpod_C0015\"></a>englishpod_C0015</h1><ul>\n<li>knock over<br>slip something down</li>\n<li>explode</li>\n<li>familiar</li>\n<li>coincidence</li>\n<li>I feel terrible<br>please accept my apologies</li>\n<li>I don’t mean knocking over</li>\n</ul>\n<h1 id=\"englishpod-B0016\"><a href=\"#englishpod-B0016\" class=\"headerlink\" title=\"englishpod_B0016\"></a>englishpod_B0016</h1><ul>\n<li>step on it<br>speed up slow down<br>go fast</li>\n<li>have a fit<br>get angry</li>\n<li>cut through<br>go through</li>\n<li>short cut<br>take a short way</li>\n<li>make a left/right<br>make a u turn</li>\n<li>take a side street<br>take the freeway</li>\n</ul>\n<h1 id=\"englishpod-B0017\"><a href=\"#englishpod-B0017\" class=\"headerlink\" title=\"englishpod_B0017\"></a>englishpod_B0017</h1><ul>\n<li>groom<br>man</li>\n<li>bride<br>woman</li>\n<li>It’s about time<br>finally at last</li>\n<li>aisle</li>\n<li>bridemaids</li>\n<li>flower girl</li>\n<li>ring bearer</li>\n<li>niece nephew</li>\n<li>gorgeous<br>beautiful</li>\n<li>get married</li>\n<li>priest</li>\n</ul>\n<h1 id=\"englishpod-D0018\"><a href=\"#englishpod-D0018\" class=\"headerlink\" title=\"englishpod_D0018\"></a>englishpod_D0018</h1><ul>\n<li>bankrupt</li>\n<li>bail out</li>\n<li>injustice</li>\n<li>outrage</li>\n<li>break out<br>to begin suddenlly</li>\n<li>have the nerve to<br>dare to do</li>\n<li>financial</li>\n</ul>\n<h1 id=\"englishpod-C0019\"><a href=\"#englishpod-C0019\" class=\"headerlink\" title=\"englishpod_C0019\"></a>englishpod_C0019</h1><ul>\n<li>eggnog</li>\n<li>vehicle<br>car</li>\n<li>lawer</li>\n<li>appoint<br>choose</li>\n<li>sleigh</li>\n<li>step out<br>step out the vehicle</li>\n<li>get a load of<br>look at</li>\n<li>Don’t take the tone with me</li>\n<li>invoice<br>发票</li>\n</ul>\n<h1 id=\"englishpod-B0020\"><a href=\"#englishpod-B0020\" class=\"headerlink\" title=\"englishpod_B0020\"></a>englishpod_B0020</h1><ul>\n<li>struggle<br>try real hard</li>\n<li>blurry<br>not clear</li>\n<li>prescription</li>\n<li>20-20 vision<br>Perfect eyesight</li>\n<li>far sighted<br>near sighted</li>\n<li>make out<br>see clearly</li>\n<li>as blind as a bat</li>\n<li>what seems to be the problem</li>\n<li>head on<br>head on over<br>head on in</li>\n</ul>\n<h1 id=\"englishpod-C0021\"><a href=\"#englishpod-C0021\" class=\"headerlink\" title=\"englishpod_C0021\"></a>englishpod_C0021</h1><ul>\n<li>VP<br>the vice president</li>\n<li>fortune 500 company</li>\n<li>implement</li>\n<li>policy</li>\n<li>oversee</li>\n<li>go on about him</li>\n<li>How’s going?</li>\n<li>what do you do for a living?</li>\n</ul>\n<h1 id=\"englishpod-C0022\"><a href=\"#englishpod-C0022\" class=\"headerlink\" title=\"englishpod_C0022\"></a>englishpod_C0022</h1><ul>\n<li>candy canes</li>\n<li>booked</li>\n<li>speeding<br>go too fast</li>\n<li>impounded<br>held by the police<br>take your car to car jail</li>\n<li>ruined<br>destoried</li>\n<li>backup<br>help</li>\n</ul>\n<h1 id=\"englishpod-B0023\"><a href=\"#englishpod-B0023\" class=\"headerlink\" title=\"englishpod_B0023\"></a>englishpod_B0023</h1><ul>\n<li>financial adviser</li>\n<li>available</li>\n<li>double check<br>check it again</li>\n<li>sheduled<br>book it at that time</li>\n<li>booked solid</li>\n</ul>\n<h1 id=\"englishpod-B0024\"><a href=\"#englishpod-B0024\" class=\"headerlink\" title=\"englishpod_B0024\"></a>englishpod_B0024</h1><ul>\n<li>food po<br>not a good thing</li>\n<li>allergic<br>It make you sick</li>\n<li>check out<br>look at</li>\n<li>be</li>\n<li>not all that crazy about</li>\n<li>tasty<br>delicious</li>\n<li>in the mood for<br>have a desire</li>\n<li>Do  you have any suggentions/ideas?</li>\n<li>I reconmend giving it a try.<br>You’ve got to give a try.</li>\n<li>platter</li>\n<li>decor<br>decoration</li>\n</ul>\n<h1 id=\"englishpod-D0025\"><a href=\"#englishpod-D0025\" class=\"headerlink\" title=\"englishpod_D0025\"></a>englishpod_D0025</h1><ul>\n<li>converage</li>\n<li>pain de<br>scary</li>\n<li>critical<br>important</li>\n<li>outbreak</li>\n<li>forcast<br>predict</li>\n<li>Let’s move to the next order of business.<br>come up<br>move on</li>\n<li>head up<br>take charge of</li>\n<li>I’ll leave it to you.</li>\n<li>contingency plan<br>a plan that prepares for a situation where things go wrong</li>\n<li>vaccine<br>疫苗</li>\n</ul>\n<h1 id=\"englishpod-B0026\"><a href=\"#englishpod-B0026\" class=\"headerlink\" title=\"englishpod_B0026\"></a>englishpod_B0026</h1><ul>\n<li>eating habits<br>the regular way you eat</li>\n<li>junk food</li>\n<li>transform</li>\n<li>I’m stuffed</li>\n<li>stick to it<br>keep doing it</li>\n<li>I mean it.<br>I’m serious.</li>\n<li>cut out</li>\n<li>wait and see</li>\n</ul>\n<h1 id=\"englishpod-B0027\"><a href=\"#englishpod-B0027\" class=\"headerlink\" title=\"englishpod_B0027\"></a>englishpod_B0027</h1><ul>\n<li>vacation day</li>\n<li>overseas</li>\n<li>unpaid leave</li>\n<li>notice</li>\n<li>Do you have a second?<br>Do you have a minute/sec?</li>\n<li>Would you be OK with that?<br>will it be OK with that?</li>\n<li>I was just wondering<br>I was just hoping that</li>\n</ul>\n<h1 id=\"englishpod-C0028\"><a href=\"#englishpod-C0028\" class=\"headerlink\" title=\"englishpod_C0028\"></a>englishpod_C0028</h1><ul>\n<li>relieved</li>\n<li>pick me up<br>come and get me</li>\n<li>ordinary</li>\n<li>make it up to you</li>\n<li>my treat</li>\n<li>twist of fate</li>\n</ul>\n<h1 id=\"englishpod-E0029\"><a href=\"#englishpod-E0029\" class=\"headerlink\" title=\"englishpod_E0029\"></a>englishpod_E0029</h1><ul>\n<li>merging market<br>developing</li>\n<li>turmoil<br>a state of confusion</li>\n<li>proposed</li>\n<li>hit up<br>ask for money</li>\n<li>inevitable</li>\n</ul>\n<h1 id=\"englishpod-C0030\"><a href=\"#englishpod-C0030\" class=\"headerlink\" title=\"englishpod_C0030\"></a>englishpod_C0030</h1><ul>\n<li>thoughtful</li>\n<li>give me the creeps<br>make me feel uncomfortable</li>\n<li>rope me into something</li>\n<li>appetite<br>strong desire for food</li>\n<li>get to know someone</li>\n<li>why on earth</li>\n</ul>\n<h1 id=\"englishpod-B0031\"><a href=\"#englishpod-B0031\" class=\"headerlink\" title=\"englishpod_B0031\"></a>englishpod_B0031</h1><ul>\n<li>reshedule<br>change for another day or time</li>\n<li>inconvenience</li>\n<li>postpone<br>delay</li>\n<li>can not make it<br>can’t do something</li>\n<li>this thing comes up</li>\n</ul>\n<h1 id=\"englishpod-C0032\"><a href=\"#englishpod-C0032\" class=\"headerlink\" title=\"englishpod_C0032\"></a>englishpod_C0032</h1><ul>\n<li>chequing account</li>\n<li>savings account</li>\n<li>transaction</li>\n<li>balance</li>\n<li>overdraft</li>\n<li>debit card</li>\n<li>I’ll get you to</li>\n<li>I need your insurace number.</li>\n<li>If you could sign here?</li>\n</ul>\n<h1 id=\"englishpod-B0033\"><a href=\"#englishpod-B0033\" class=\"headerlink\" title=\"englishpod_B0033\"></a>englishpod_B0033</h1><ul>\n<li>foul</li>\n<li>ref</li>\n<li>free throw</li>\n<li>make a shot<br>to successful</li>\n<li>3 pointer shot</li>\n<li>travel<br>take more than two steps with the ball</li>\n<li>screw up<br>to make a mistake</li>\n<li>beer run<br>to go and get a beer</li>\n</ul>\n<h1 id=\"englishpod-D0034\"><a href=\"#englishpod-D0034\" class=\"headerlink\" title=\"englishpod_D0034\"></a>englishpod_D0034</h1><ul>\n<li>swear in<br>swore in</li>\n<li>oath<br>a promise</li>\n<li>deliver<br>say a speech</li>\n<li>who’s who</li>\n<li>palpable</li>\n<li>in a word</li>\n<li>go down in history</li>\n<li>my fellow Americans<br>dear</li>\n</ul>\n<h1 id=\"englishpod-C0035\"><a href=\"#englishpod-C0035\" class=\"headerlink\" title=\"englishpod_C0035\"></a>englishpod_C0035</h1><ul>\n<li>a good fit<br>suitable for the job</li>\n<li>performance</li>\n<li>unreliable<br>reliable</li>\n<li>productive</li>\n<li>work ethic</li>\n<li>coach<br>train</li>\n<li>the bottom of line<br>the most important point</li>\n<li>overall</li>\n<li>perfectly good</li>\n</ul>\n<h1 id=\"englishpod-B0036\"><a href=\"#englishpod-B0036\" class=\"headerlink\" title=\"englishpod_B0036\"></a>englishpod_B0036</h1><ul>\n<li>get a hold</li>\n<li>stand me up<br>fail to keep the appointment to meet someone</li>\n<li>priority</li>\n<li>heading<br>going</li>\n<li>Do you have any idea how</li>\n<li>I heard it before</li>\n<li>take a break<br>stop their relationship</li>\n<li>decency<br>polite or moral bahavior</li>\n<li>get your priorities straight<br>realize what is more important</li>\n</ul>\n<h1 id=\"englishpod-C0037\"><a href=\"#englishpod-C0037\" class=\"headerlink\" title=\"englishpod_C0037\"></a>englishpod_C0037</h1><ul>\n<li>dumping<br>水饺</li>\n<li>firecracker</li>\n<li>set off</li>\n<li>I can’t wait to</li>\n<li>I bet</li>\n<li>red envelope</li>\n<li>mahjong</li>\n</ul>\n<h1 id=\"englishpod-C0038\"><a href=\"#englishpod-C0038\" class=\"headerlink\" title=\"englishpod_C0038\"></a>englishpod_C0038</h1><ul>\n<li>vehicle</li>\n<li>sedan<br>a car with four doors</li>\n<li>gas mileage<br>the amount of gas used per mile</li>\n<li>airbags</li>\n<li>brake</li>\n<li>reinforce<br>make stronger</li>\n<li>I’m just browsing</li>\n<li>sleep on it<br>to think about it</li>\n</ul>\n<h1 id=\"englishpod-B0039\"><a href=\"#englishpod-B0039\" class=\"headerlink\" title=\"englishpod_B0039\"></a>englishpod_B0039</h1><ul>\n<li>heard</li>\n<li>fill me in<br>tell me about something</li>\n<li>career path</li>\n<li>In  his early 30s</li>\n</ul>\n<h1 id=\"englishpod-B0040\"><a href=\"#englishpod-B0040\" class=\"headerlink\" title=\"englishpod_B0040\"></a>englishpod_B0040</h1><ul>\n<li>on board<br>welcome to the company</li>\n<li>about to</li>\n<li>instead<br>in the  place of</li>\n<li>intrepret</li>\n</ul>\n<h1 id=\"englishpod-C0041\"><a href=\"#englishpod-C0041\" class=\"headerlink\" title=\"englishpod_C0041\"></a>englishpod_C0041</h1><ul>\n<li>posses</li>\n<li>survival</li>\n<li>defend<br>protect</li>\n<li>rough<br>hard</li>\n<li>at all costs<br>no matter what</li>\n<li>stand in one’s way</li>\n</ul>\n<h1 id=\"englishpod-B0042\"><a href=\"#englishpod-B0042\" class=\"headerlink\" title=\"englishpod_B0042\"></a>englishpod_B0042</h1><ul>\n<li>deadline</li>\n<li>extension</li>\n<li>run into<br>run into some problem</li>\n<li>delay</li>\n<li>be under control</li>\n<li>put this off</li>\n<li>press kit<br>groups of photos, documents, articals, and information about company given to reporters, newspapers,magazines,etc.</li>\n<li>finalize<br>finish</li>\n</ul>\n<h1 id=\"englishpod-C0043\"><a href=\"#englishpod-C0043\" class=\"headerlink\" title=\"englishpod_C0043\"></a>englishpod_C0043</h1><ul>\n<li>visa<br>签证</li>\n<li>sponsor</li>\n<li>invitation letter</li>\n<li>ties</li>\n<li>financially independent</li>\n</ul>\n<h1 id=\"englishpod-B0044\"><a href=\"#englishpod-B0044\" class=\"headerlink\" title=\"englishpod_B0044\"></a>englishpod_B0044</h1><ul>\n<li>barely even</li>\n<li>catch the news<br>hear the news</li>\n<li>by the way</li>\n<li>take the stairs</li>\n<li>do you happen to<br>by chance</li>\n</ul>\n<h1 id=\"englishpod-C0045\"><a href=\"#englishpod-C0045\" class=\"headerlink\" title=\"englishpod_C0045\"></a>englishpod_C0045</h1><ul>\n<li>on a break</li>\n<li>seeing someone<br>dating or going out with someone</li>\n<li>cheat on</li>\n<li>mess this up</li>\n<li>immature  </li>\n<li>selfish</li>\n<li>everything is going to work out just fine.</li>\n<li>pull yourself together<br>calm down</li>\n<li>It’s going to be alright.</li>\n</ul>\n<h1 id=\"englishpod-D0046\"><a href=\"#englishpod-D0046\" class=\"headerlink\" title=\"englishpod_D0046\"></a>englishpod_D0046</h1><ul>\n<li>CPR</li>\n<li>BP<br>blood pressure</li>\n<li>hook up</li>\n<li>out of woods<br>free from danger</li>\n<li>defibrillator</li>\n</ul>\n<h1 id=\"englishpod-C0048\"><a href=\"#englishpod-C0048\" class=\"headerlink\" title=\"englishpod_C0048\"></a>englishpod_C0048</h1><ul>\n<li>ticket scalper<br>黄牛</li>\n<li>prestigious<br>being respected and admired for being successful or important</li>\n<li>float</li>\n<li>once in the lifetime</li>\n<li>good thing</li>\n<li>no kidding<br>I totally agree with you</li>\n</ul>\n<h1 id=\"englishpod-C0049\"><a href=\"#englishpod-C0049\" class=\"headerlink\" title=\"englishpod_C0049\"></a>englishpod_C0049</h1><ul>\n<li>concert</li>\n<li>hottest</li>\n<li>fine then</li>\n<li>I was wondering can I<br>Do you think<br>would you mind</li>\n</ul>\n<h1 id=\"englishpod-C0050\"><a href=\"#englishpod-C0050\" class=\"headerlink\" title=\"englishpod_C0050\"></a>englishpod_C0050</h1><ul>\n<li>appetite</li>\n<li>poison</li>\n<li>points<br>suggestions</li>\n<li>aroma<br>special smell</li>\n<li>bitter</li>\n<li>pass out<br>become unconscious</li>\n<li>make yourself at home</li>\n</ul>\n<h1 id=\"englishpod-C0051\"><a href=\"#englishpod-C0051\" class=\"headerlink\" title=\"englishpod_C0051\"></a>englishpod_C0051</h1><ul>\n<li>price range</li>\n<li>shop around</li>\n<li>pricey</li>\n<li>a better deal</li>\n<li>That’s my best offer.<br>That’s my last offer.</li>\n<li>exclusive<br>not common, unique</li>\n</ul>\n<h1 id=\"englishpod-C0052\"><a href=\"#englishpod-C0052\" class=\"headerlink\" title=\"englishpod_C0052\"></a>englishpod_C0052</h1><ul>\n<li>medium<br>12 inch<br>larger</li>\n<li>pepperoni<br>a spicy sausage usually on pizza</li>\n<li>olives</li>\n<li>extra cheese</li>\n<li>ham</li>\n<li>pineapple</li>\n<li>thin crust</li>\n<li>would you like</li>\n</ul>\n<h1 id=\"englishpod-C0053\"><a href=\"#englishpod-C0053\" class=\"headerlink\" title=\"englishpod_C0053\"></a>englishpod_C0053</h1><ul>\n<li>head chef<br>the main cook</li>\n<li>cuisine</li>\n<li>peel<br>remove the outside</li>\n<li>chop</li>\n<li>stir<br>mix</li>\n<li>butcher</li>\n<li>butter</li>\n<li>in the weeds<br>you are really busy</li>\n<li>run low on<br>not something left</li>\n<li>do really well</li>\n</ul>\n<h1 id=\"englishpod-C0054\"><a href=\"#englishpod-C0054\" class=\"headerlink\" title=\"englishpod_C0054\"></a>englishpod_C0054</h1><ul>\n<li>blaze<br>fire</li>\n<li>in the middle of nowhere</li>\n<li>first thing in the morning</li>\n<li>everything seems to be order</li>\n</ul>\n<h1 id=\"englishpod-C0055\"><a href=\"#englishpod-C0055\" class=\"headerlink\" title=\"englishpod_C0055\"></a>englishpod_C0055</h1><ul>\n<li>puck</li>\n<li>key game</li>\n<li>finals</li>\n<li>face-off</li>\n<li>goalie<br>saver</li>\n<li>breakaway</li>\n</ul>\n<h1 id=\"englishpod-C0056\"><a href=\"#englishpod-C0056\" class=\"headerlink\" title=\"englishpod_C0056\"></a>englishpod_C0056</h1><ul>\n<li>fill in</li>\n<li>replicas</li>\n<li>tap</li>\n<li>map out</li>\n<li>screw it up</li>\n<li>lose your cool</li>\n</ul>\n<h1 id=\"englishpod-C0057\"><a href=\"#englishpod-C0057\" class=\"headerlink\" title=\"englishpod_C0057\"></a>englishpod_C0057</h1><ul>\n<li>malfunction</li>\n<li>ASAP<br>as soon as possible</li>\n<li>practical joke</li>\n<li>never mind</li>\n<li>out of to</li>\n<li>on your way up</li>\n<li>break down<br>break in<br>break out</li>\n<li>toner<br>ink used in a printer or photocopier</li>\n</ul>\n<h1 id=\"englishpod-C0058\"><a href=\"#englishpod-C0058\" class=\"headerlink\" title=\"englishpod_C0058\"></a>englishpod_C0058</h1><ul>\n<li>turbulence</li>\n<li>flight crew</li>\n<li>bumpy ride</li>\n<li>fasten<br>fasten your seat belt</li>\n<li>lavatory</li>\n<li>stow</li>\n<li>refrain</li>\n<li>remain seated</li>\n<li>patch</li>\n<li>suspend<br>stop for a short time</li>\n</ul>\n<h1 id=\"englishpod-E0059\"><a href=\"#englishpod-E0059\" class=\"headerlink\" title=\"englishpod_E0059\"></a>englishpod_E0059</h1><ul>\n<li>CRM<br>custom relationship manager</li>\n<li>custom designed<br>custom built house</li>\n<li>core values</li>\n<li>undisputed<br>the is no doubt</li>\n<li>growth oppotunity</li>\n<li>read up</li>\n<li>unleash potential</li>\n<li>resonate</li>\n</ul>\n<h1 id=\"englishpod-C0060\"><a href=\"#englishpod-C0060\" class=\"headerlink\" title=\"englishpod_C0060\"></a>englishpod_C0060</h1><ul>\n<li>drag</li>\n<li>tie somebody up</li>\n<li>fools</li>\n<li>fell for it</li>\n<li>the cat is out of the bag<br>the truth is out</li>\n<li>pretend</li>\n<li>gullible<br>easily beliving something that is not true, eaily fooled</li>\n</ul>\n<h1 id=\"englishpod-C0061\"><a href=\"#englishpod-C0061\" class=\"headerlink\" title=\"englishpod_C0061\"></a>englishpod_C0061</h1><ul>\n<li>sail</li>\n<li>anchor</li>\n<li>doggy-paddling<br>swim like a dog</li>\n<li>breast stroke</li>\n<li>backstroke</li>\n<li>take a dip</li>\n<li>for a little while</li>\n</ul>\n<h1 id=\"englishpod-C0062\"><a href=\"#englishpod-C0062\" class=\"headerlink\" title=\"englishpod_C0062\"></a>englishpod_C0062</h1><ul>\n<li>major<br>main subject</li>\n<li>minor</li>\n<li>course of study</li>\n<li>track<br>path</li>\n<li>hence</li>\n<li>pursued<br>to chase</li>\n<li>strive<br>to try real hard</li>\n<li>breadth</li>\n<li>implement</li>\n<li>postgraduate<br>masters or PH.D;</li>\n<li>initiative<br>倡议</li>\n<li>churn rate<br>客户流失率</li>\n<li>coordinate<br>协调</li>\n</ul>\n<h1 id=\"englishpod-C0063\"><a href=\"#englishpod-C0063\" class=\"headerlink\" title=\"englishpod_C0063\"></a>englishpod_C0063</h1><ul>\n<li>certainly</li>\n<li>may I take your name?</li>\n<li>monmentarily<br>in a short</li>\n<li>ready for</li>\n</ul>\n<h1 id=\"englishpod-C0064\"><a href=\"#englishpod-C0064\" class=\"headerlink\" title=\"englishpod_C0064\"></a>englishpod_C0064</h1><ul>\n<li>sleep with</li>\n<li>confess<br>you tell a secret that you are hiding</li>\n<li>overwhelm</li>\n<li>jelousy</li>\n<li>jerk<br>stupid and mean person</li>\n<li>bastard</li>\n<li>bun in the oven<br>pregnant</li>\n<li>I can’t help myself</li>\n<li>come into the picture<br>appear into one’s life</li>\n<li>cheerleading squad<br>啦啦队</li>\n</ul>\n<h1 id=\"englishpod-C0065\"><a href=\"#englishpod-C0065\" class=\"headerlink\" title=\"englishpod_C0065\"></a>englishpod_C0065</h1><ul>\n<li>technical acument</li>\n<li>excel</li>\n<li>head</li>\n<li>struggle</li>\n<li>punctual<br>punctuality</li>\n<li>adress<br>deal with</li>\n<li>fit</li>\n<li>acumen<br>the ability to think clearly and make good decisions</li>\n</ul>\n<h1 id=\"englishpod-C0067\"><a href=\"#englishpod-C0067\" class=\"headerlink\" title=\"englishpod_C0067\"></a>englishpod_C0067</h1><ul>\n<li>wingman</li>\n<li>tired</li>\n<li>foul</li>\n<li>kick off</li>\n<li>out of bounds</li>\n<li>throw in</li>\n<li>offside</li>\n<li>on the brink of<br>at a critical point</li>\n<li>no question about it<br>no doubt</li>\n<li>by a mile</li>\n<li>penalty kick<br>a kick against only the goalkeepwe as a reward for a foul</li>\n</ul>\n<h1 id=\"englishpod-C0068\"><a href=\"#englishpod-C0068\" class=\"headerlink\" title=\"englishpod_C0068\"></a>englishpod_C0068</h1><ul>\n<li>irrefutable</li>\n<li>flaw</li>\n<li>systemetic<br>following the certain order</li>\n<li>extensive research</li>\n<li>conclusive evidence<br>final decision</li>\n<li>investigative approch</li>\n<li>definite conclusion</li>\n<li>oblivious to<br>unware or don’t know</li>\n<li>proposterous<br>crazy, foolish, or silly</li>\n</ul>\n<h1 id=\"englishpod-C0069\"><a href=\"#englishpod-C0069\" class=\"headerlink\" title=\"englishpod_C0069\"></a>englishpod_C0069</h1><ul>\n<li>picky</li>\n<li>yolk<br>egg yolk<br>the white</li>\n<li>sunny side up</li>\n<li>fried egg</li>\n<li>soft boiled egg</li>\n<li>hard boiled egg</li>\n<li>egg and soilders</li>\n<li>scrible eggs</li>\n<li>feel like<br>have desire to do</li>\n<li>drive me crazy<br>make you angry</li>\n<li>muffin<br>a small break or cake people usually eat for breakfast</li>\n</ul>\n<h1 id=\"englishpod-F0070\"><a href=\"#englishpod-F0070\" class=\"headerlink\" title=\"englishpod_F0070\"></a>englishpod_F0070</h1><ul>\n<li>lingerie</li>\n<li>awkward</li>\n<li>granny panties</li>\n<li>sleepwear</li>\n<li>nighties<br>silky nighties</li>\n<li>undies</li>\n<li>mortifying<br>extremely embarassing</li>\n<li>get the hell out of here<br>leave</li>\n<li>get this over with</li>\n</ul>\n<h1 id=\"englishpod-C0071\"><a href=\"#englishpod-C0071\" class=\"headerlink\" title=\"englishpod_C0071\"></a>englishpod_C0071</h1><ul>\n<li>on tap<br>beer served from a barrel; not in a bottle or can</li>\n<li>happy hour</li>\n<li>pint</li>\n<li>appetizer<br>a small dish served before meal</li>\n<li>what about<br>be used in making suggestions</li>\n</ul>\n<h1 id=\"englishopod-C0072\"><a href=\"#englishopod-C0072\" class=\"headerlink\" title=\"englishopod_C0072\"></a>englishopod_C0072</h1><ul>\n<li>preoccupied<br>worried</li>\n<li>direct impact</li>\n<li>resent<br>find something very insulting</li>\n<li>beat around the bush<br>avoid saying something by about other things<br>come out with it</li>\n</ul>\n<h1 id=\"englishpod-C0073\"><a href=\"#englishpod-C0073\" class=\"headerlink\" title=\"englishpod_C0073\"></a>englishpod_C0073</h1><ul>\n<li>pinkie</li>\n<li>the ring finger</li>\n<li>the middle finger<br>giving the middle finger</li>\n<li>index finger</li>\n<li>thumb</li>\n<li>abide<br>live</li>\n</ul>\n<h1 id=\"englishpod-C0074\"><a href=\"#englishpod-C0074\" class=\"headerlink\" title=\"englishpod_C0074\"></a>englishpod_C0074</h1><ul>\n<li>famished<br>very hungry</li>\n<li>sexist</li>\n<li>dumbass</li>\n<li>moron<br>someone is stupid</li>\n<li>tool<br>useless</li>\n<li>chill</li>\n<li>scream</li>\n<li>what the hell</li>\n</ul>\n<h1 id=\"englishpod-C0075\"><a href=\"#englishpod-C0075\" class=\"headerlink\" title=\"englishpod_C0075\"></a>englishpod_C0075</h1><ul>\n<li>toothache</li>\n<li>x-ray</li>\n<li>swollen</li>\n<li>cavity<br>a hole in a tooth</li>\n<li>crown<br>the part of the tooth which can be seen</li>\n<li>filling</li>\n<li>what seems to be the problem?<br>what’s wrong?</li>\n</ul>\n<h1 id=\"englishpod-C0076\"><a href=\"#englishpod-C0076\" class=\"headerlink\" title=\"englishpod_C0076\"></a>englishpod_C0076</h1><ul>\n<li>plus add<br>minus<br>times<br>devided by</li>\n<li>square root</li>\n<li>teacher’s pet<br>suck up</li>\n<li>smarty pants<br>for children</li>\n<li>konw it all</li>\n</ul>\n<h1 id=\"englishpod-C0077\"><a href=\"#englishpod-C0077\" class=\"headerlink\" title=\"englishpod_C0077\"></a>englishpod_C0077</h1><ul>\n<li>jam on the breaks</li>\n<li>spin out<br>(a car)slides and makes a turn rapidly in an uncontrolled way</li>\n<li>the pace car</li>\n<li>cleanup crew<br>the construction crew</li>\n<li>to tow</li>\n<li>my partner in crime<br>a person you always do things together with</li>\n<li>a close one</li>\n<li>stretch<br>the final time period</li>\n</ul>\n<h1 id=\"englishpod-E0078\"><a href=\"#englishpod-E0078\" class=\"headerlink\" title=\"englishpod_E0078\"></a>englishpod_E0078</h1><ul>\n<li>brutality<br>violent treatment or behavior</li>\n<li>important aspect</li>\n<li>genesis</li>\n<li>comprehend</li>\n<li>appalling<br>terrible, horrible, shocking</li>\n<li>hostility<br>the attitde of treating something as enemy</li>\n<li>drastic<br>sudden and severe</li>\n<li>constitute<br>form, consist</li>\n<li>fire into<br>shoot guns into a place</li>\n</ul>\n<h1 id=\"englishpod-B0079\"><a href=\"#englishpod-B0079\" class=\"headerlink\" title=\"englishpod_B0079\"></a>englishpod_B0079</h1><ul>\n<li>spacecraft</li>\n<li>break through</li>\n<li>settle this</li>\n<li>accelerate</li>\n<li>no loger be</li>\n<li>once and for all</li>\n<li>obscure</li>\n</ul>\n<h1 id=\"englishpod-C0080\"><a href=\"#englishpod-C0080\" class=\"headerlink\" title=\"englishpod_C0080\"></a>englishpod_C0080</h1><ul>\n<li>show up</li>\n<li>stalk<br>follow someone for a long time</li>\n<li>nut job</li>\n<li>get worked up</li>\n<li>soul mate</li>\n<li>over nothing<br>no reason</li>\n<li>not a day goes by</li>\n<li>no matter what</li>\n</ul>\n<h1 id=\"englishpod-B0081\"><a href=\"#englishpod-B0081\" class=\"headerlink\" title=\"englishpod_B0081\"></a>englishpod_B0081</h1><ul>\n<li>trim<br>a short cut of hair to make one look clean</li>\n<li>fancy</li>\n<li>silky<br>silk hair</li>\n<li>grow out</li>\n<li>don’t just stand there</li>\n<li>take a little off the top<br>take a little off the side</li>\n<li>curly</li>\n<li>a million bucks<br>very good. To look great</li>\n<li>sideburns<br>hari thar grows on the sides of man</li>\n<li>fluffy<br>soft  </li>\n</ul>\n<h1 id=\"englishpod-C0082\"><a href=\"#englishpod-C0082\" class=\"headerlink\" title=\"englishpod_C0082\"></a>englishpod_C0082</h1><ul>\n<li>creature</li>\n<li>break free</li>\n<li>kidnapper</li>\n<li>rapist</li>\n<li>rape</li>\n<li>lemme see your eyes<br>let me see your eyes<br>gimme - give me</li>\n<li>make it out<br>able to escape or flee</li>\n</ul>\n<h1 id=\"englishpod-C0083\"><a href=\"#englishpod-C0083\" class=\"headerlink\" title=\"englishpod_C0083\"></a>englishpod_C0083</h1><ul>\n<li>ATM<br>automatic teller machine</li>\n<li>the local authority</li>\n<li>slot</li>\n<li>digit</li>\n<li>withdraw</li>\n<li>transfer money</li>\n<li>pound key<br>the push botton marked with #</li>\n</ul>\n<h1 id=\"englishpod-B0084\"><a href=\"#englishpod-B0084\" class=\"headerlink\" title=\"englishpod_B0084\"></a>englishpod_B0084</h1><ul>\n<li>pharmacy<br>medicine</li>\n<li>milligram</li>\n<li>price check</li>\n<li>prescription</li>\n<li>capsule</li>\n<li>tablet</li>\n<li>overdose</li>\n<li>eye drop</li>\n<li>be sure not to</li>\n<li>get a price check</li>\n</ul>\n<h1 id=\"englishpod-B0085\"><a href=\"#englishpod-B0085\" class=\"headerlink\" title=\"englishpod_B0085\"></a>englishpod_B0085</h1><ul>\n<li>the national anthem</li>\n<li>pitcher<br>throw the ball</li>\n<li>wind up</li>\n<li>line drive<br>a hit that travels low along the baseline     </li>\n<li>scramble</li>\n<li>up at bat<br>get ready to hit the ball</li>\n<li>strike</li>\n<li>curve ball</li>\n</ul>\n<h1 id=\"englishpod-C0086\"><a href=\"#englishpod-C0086\" class=\"headerlink\" title=\"englishpod_C0086\"></a>englishpod_C0086</h1><ul>\n<li>landlord<br>the owner of house</li>\n<li>tenant<br>the person that rents a house</li>\n<li>renovate<br>make a new again</li>\n<li>airy<br>spacious so that air moves freely</li>\n<li>square footage</li>\n<li>applicance</li>\n<li>gas range<br>a stove that uses to cook</li>\n<li>prefessional greed</li>\n<li>spaciou<br>latge; having lots of space</li>\n<li>walk-in closet<br>a room containedf in a bedroom for storing clothes</li>\n<li>en suit bathroom<br>a bathroom within the main bedroom</li>\n</ul>\n<h1 id=\"englishpod-B0087\"><a href=\"#englishpod-B0087\" class=\"headerlink\" title=\"englishpod_B0087\"></a>englishpod_B0087</h1><ul>\n<li>unidentified ship</li>\n<li>seach party</li>\n<li>a deep voice</li>\n<li>offentic</li>\n<li>wig<br>artificial hair</li>\n<li>under attack<br>under fire</li>\n<li>sustain<br>damage</li>\n<li>the nature of</li>\n<li>warp drive</li>\n</ul>\n<h1 id=\"englishpod-B0088\"><a href=\"#englishpod-B0088\" class=\"headerlink\" title=\"englishpod_B0088\"></a>englishpod_B0088</h1><ul>\n<li>here’s the thing<br>give somebody some information</li>\n<li>I can’t take it anymore</li>\n<li>Are you serious?</li>\n<li>have guts to<br>courage</li>\n<li>just two of us<br>just three of us</li>\n<li>give me a shot<br>give me an oppotunity</li>\n<li>pros and cons<br>good things and bad things about a person</li>\n</ul>\n<h1 id=\"englishpod-C0089\"><a href=\"#englishpod-C0089\" class=\"headerlink\" title=\"englishpod_C0089\"></a>englishpod_C0089</h1><ul>\n<li>piece of luggage</li>\n<li>carryon luggage</li>\n<li>overhead compa</li>\n<li>how am I be supposed to</li>\n<li>There’s nothing I can do</li>\n<li>next to nothing<br>very cheap</li>\n</ul>\n<h1 id=\"englishpod-D0090\"><a href=\"#englishpod-D0090\" class=\"headerlink\" title=\"englishpod_D0090\"></a>englishpod_D0090</h1><ul>\n<li>spy</li>\n<li>come clean<br>confess</li>\n<li>renource</li>\n<li>approach someone</li>\n<li>claim</li>\n<li>vow<br>make a strong promise</li>\n<li>whereabouts<br>the approximate place, where a person or thing is</li>\n<li>I haven’t been completely honest with you</li>\n<li>I wasn’t supposed to<br>I shouldn’t</li>\n<li>bureau</li>\n<li>millennium<br>1000 years</li>\n<li>renowned<br>well known</li>\n</ul>\n<h1 id=\"englishpod-D0091\"><a href=\"#englishpod-D0091\" class=\"headerlink\" title=\"englishpod_D0091\"></a>englishpod_D0091</h1><ul>\n<li>constellation<br>a particular shape formed by a group of stars</li>\n<li>consequence<br>negative results</li>\n<li>downdfall<br>failure</li>\n<li>anguish<br>angry, aggressive, wanting to fight</li>\n<li>a wonder</li>\n<li>what gives you the right to</li>\n<li>to play God</li>\n<li>who are you to</li>\n</ul>\n<h1 id=\"englishpod-C0095\"><a href=\"#englishpod-C0095\" class=\"headerlink\" title=\"englishpod_C0095\"></a>englishpod_C0095</h1><ul>\n<li>in ages</li>\n<li>run into</li>\n<li>freak out</li>\n<li>stare</li>\n<li>shriek<br>screaming in a very high voice</li>\n<li>catch up with<br>learn about recent past events</li>\n<li>hilarious</li>\n</ul>\n<h1 id=\"englishpod-C0096\"><a href=\"#englishpod-C0096\" class=\"headerlink\" title=\"englishpod_C0096\"></a>englishpod_C0096</h1><ul>\n<li>pad</li>\n<li>far out</li>\n<li>crash</li>\n<li>split</li>\n<li>dig it<br>appreciate, like</li>\n<li>throw a bash<br>party<br>host a party</li>\n<li>take care of business</li>\n<li>happening scene<br>an extremely exciting moment</li>\n<li>peace out<br>see you later</li>\n<li>groovy<br>really cool</li>\n</ul>\n<h1 id=\"englishpod-D0097\"><a href=\"#englishpod-D0097\" class=\"headerlink\" title=\"englishpod_D0097\"></a>englishpod_D0097</h1><ul>\n<li>weather forcast</li>\n<li>shower<br>a short time rain</li>\n<li>scattered shower</li>\n<li>hover around<br>stay near a certain level or place</li>\n<li>temperature</li>\n<li>isolated downpour</li>\n<li>gust<br>strong, sudden increase in wind speed</li>\n<li>sleet<br>a mix of rain and snow</li>\n<li>cold front</li>\n<li>It’s going to a tough one</li>\n<li>mixed bag<br>a collection of different kinds of things</li>\n<li>cloud cover<br>the amount of sky that is covered with cloud</li>\n<li>partly-cloudy skies<br>having some cloud and some sun</li>\n</ul>\n<h1 id=\"englishpod-C0098\"><a href=\"#englishpod-C0098\" class=\"headerlink\" title=\"englishpod_C0098\"></a>englishpod_C0098</h1><ul>\n<li>the bar exam<br>the exam to qualify as a lawer</li>\n<li>flatter</li>\n<li>I love what you have done with your hair</li>\n<li>get his look from his mother</li>\n<li>by the way</li>\n<li>You haven’t aged a day<br>you haven’t gotten older</li>\n<li>obnoxious<br>really annoying</li>\n</ul>\n<h1 id=\"englishpod-E0099\"><a href=\"#englishpod-E0099\" class=\"headerlink\" title=\"englishpod_E0099\"></a>englishpod_E0099</h1><ul>\n<li>depict</li>\n<li>portrayal</li>\n<li>what’s your impression of the film?</li>\n<li>lack</li>\n<li>rightfully<br>according to law</li>\n<li>erudite<br>having a lot of knowledge</li>\n<li>fable<br>beauriful story about animals that has moral or lesson</li>\n<li>eternal<br>lasting forever</li>\n<li>accusation<br>action of caliming something is wrong</li>\n<li>plagiarism<br>practice of copying other’s ideas</li>\n<li>enchanting<br>attractive, holding one’s attention</li>\n<li>grim<br>unpleasant</li>\n<li>linear<br>moving in logical way, from start to end</li>\n<li>cliche<br>something that is to often used so that it loses meaning or importance</li>\n<li>time-honoured<br>something that survives the testing of time</li>\n</ul>\n<h1 id=\"englishpod-C0100\"><a href=\"#englishpod-C0100\" class=\"headerlink\" title=\"englishpod_C0100\"></a>englishpod_C0100</h1><ul>\n<li>If your don’t mind me saying so.</li>\n<li>Don’t get me wrong</li>\n<li>sure thing</li>\n<li>born and raised</li>\n<li>nosy<br>too interested in others’ private matters</li>\n<li>the good old U.S of A<br>the United States</li>\n</ul>\n<p>#</p>\n"},{"title":"MC","date":"2018-07-19T07:00:18.000Z","_content":"# Point estimator\n当我们已经获得模型时，我们希望能够估计出模型的参数，这是可以使用点估计的方法。\n共轭先验：在给定似然函数的情况下，先验分布与后验分布时同种分布。\n# MC方法\n为了进行估计复杂后验分布，通过采样的方法对后验概率进行估计。\n","source":"_posts/MC.md","raw":"---\ntitle: MC\ndate: 2018-07-19 15:00:18\ntags: 概率图模型\ncategories: 学习\n---\n# Point estimator\n当我们已经获得模型时，我们希望能够估计出模型的参数，这是可以使用点估计的方法。\n共轭先验：在给定似然函数的情况下，先验分布与后验分布时同种分布。\n# MC方法\n为了进行估计复杂后验分布，通过采样的方法对后验概率进行估计。\n","slug":"MC","published":1,"updated":"2018-09-22T06:30:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms6000a1ouz1hnb21jx","content":"<h1 id=\"Point-estimator\"><a href=\"#Point-estimator\" class=\"headerlink\" title=\"Point estimator\"></a>Point estimator</h1><p>当我们已经获得模型时，我们希望能够估计出模型的参数，这是可以使用点估计的方法。<br>共轭先验：在给定似然函数的情况下，先验分布与后验分布时同种分布。</p>\n<h1 id=\"MC方法\"><a href=\"#MC方法\" class=\"headerlink\" title=\"MC方法\"></a>MC方法</h1><p>为了进行估计复杂后验分布，通过采样的方法对后验概率进行估计。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Point-estimator\"><a href=\"#Point-estimator\" class=\"headerlink\" title=\"Point estimator\"></a>Point estimator</h1><p>当我们已经获得模型时，我们希望能够估计出模型的参数，这是可以使用点估计的方法。<br>共轭先验：在给定似然函数的情况下，先验分布与后验分布时同种分布。</p>\n<h1 id=\"MC方法\"><a href=\"#MC方法\" class=\"headerlink\" title=\"MC方法\"></a>MC方法</h1><p>为了进行估计复杂后验分布，通过采样的方法对后验概率进行估计。</p>\n"},{"title":"HMM和CRF","date":"2018-05-31T01:49:19.000Z","_content":"# 隐马尔可夫模型\n隐马尔可夫模型如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png)\n\n## 公式表达\n对于隐马尔可夫模型，通常有三组参数：\n$$ trasition\\ probability\\ matrix\\ A: p(y_t^j = 1\\mid y_{t-1}^i=1)=a_{i,j} $$   $$ initial\\ probability: p(y_1)\\sim Multinomial(\\pi_1, \\pi_2, ..., \\pi_M) $$    $$ emission\\ probabilies: p(x_t\\mid y_t^i)\\sim Multinomial(b_{i,1}, b_{i,2}, ..., b_{i,K}) $$\n\n## 推断\n* 前向算法\n$$ \\alpha_t^k \\equiv\\mu_{t-1\\rightarrow}(k)=P(x_1, x_2, ..., x_t, y_t^k=1) $$\n$$ \\alpha_t^k = p(x_t\\mid y_t^k=1)\\sum_i \\alpha_{t-1}^ia_{i,k} $$\n\n* 后向算法\n$$ \\beta_t^k \\equiv \\mu_{t\\leftarrow t+1}(k)=P(x_{t+1}, ..., x_T\\mid y_t^k=1) $$\n$$ \\beta_t^k = \\sum_i a_{k,i}p(x_{t+1}\\mid y_{t+1}^i = 1)\\beta_{t+1}^i $$\n\n对于给定观测值下的任意隐变量状态，可以同过点乘前向和后向信息得到。\n$$ \\gamma_t^i = p(y_t^i = 1\\mid x_{1:T})\\propto \\alpha_t^i\\beta_t^i =\\sum_j \\xi_t^{i,j} $$\n其中有定义：\n\\begin{equation}\\begin{split} \\xi_t^{i,j} &= p(y_t^i=1,y_{t-1}^j=1, x_{1:T}) \\\\\\\\\n&\\propto \\mu_{t-1\\rightarrow t}(y_t^i=1)\\mu_{t\\leftarrow t+1}(y_{t+1}^i=1)p(x_{x+1}\\mid y_{t+1})p(y_{t+1}\\mid y_t) \\\\\\\\\n&= \\alpha_t^i\\beta_{t+1}^j a_{i,j} p(x_{t+1}\\mid y_{t+1}^i=1) \\\\\\\\\n\\end{split}\\end{equation}\n具体推导可以参考Youtube上徐亦达老师关于HMM的视频，主要思路就是message passing，运用一些迭代地技巧，可以先从最小的下标开始推导，这样比较容易发现规律，类似于数学归纳法。\n在Matlab中可以将公式用向量表示，这样方便处理。\n\\begin{equation}\\begin{split} &B_t(i)=p(x_t\\mid y_t^i=1)\\\\\\\\\n& A(i,j)=p(y_{t+1}^j=1\\mid y_t^i=1) \\\\\\\\\n& \\alpha_t = (A^T\\alpha_{t-1}).\\ast B_t \\\\\\\\\n& \\beta_t = A(\\beta_{t+1}.\\ast B_{t+1}) \\\\\\\\\n& \\xi_t = (\\alpha_t(\\beta_{t+1}.\\ast B_{t+1})^T).\\ast A  \\\\\\\\\n& \\gamma_t = \\alpha_t.\\ast \\beta_t \\\\\\\\\n\\end{split}\\end{equation}\n\n## 学习\n### 监督学习\n当我们知道实际状态路径时，监督学习并不是一件困难的事情(trival)，我们只需要数出转移概率和发射概率的实例就可以得到最大似然估计。\n$$ a_{ij}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i y_{n,t}^j}{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i} $$\n$$ b_{ik}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t}^i x_{n,t}^k}{\\sum_n\\sum_{t=2}^T y_{n,t}^i} $$\n使用了伪计数的方式，可以避免零概率的出现。对于不是多项分布的情况，特别是高斯分布，我们可以利用采样的方法计算均值和方差。\n\n### 无监督学习\n当隐状态不可观的时候，可以使用Baum Welch算法进行处理完全对数似然函数，这一算法就是EM算法对HMM的求解方法。似然函数可以写成：\n$$ l_c(\\theta;x,y)=lop\\ p(x,y)=log\\prod_n (p(y_{n,1})\\prod_{t=1}^T p(y_{n,t}\\mid y_{n,t-1})\\prod_{t=1}^T p(x_{n,t}\\mid y_{n,t})) $$\n完全对数似然期望是：\n$$ \\langle l_c(\\theta;x,y)\\rangle = \\sum_n (\\langle y_{n,1}^i \\rangle_{p(y_{n,1}\\mid x_n)}log\\ \\pi_i) + \\sum_n\\sum_{t=2}^T (\\langle y_{n,t-1}^i y_{n,t}^j\\rangle_{p(y_{n,t-1},y_{n,t}\\mid x_n)}log\\ a_{i,j}) + \\sum_n\\sum_{t=1}^T (x_{n,t}^k\\langle y_{n,t}^i\\rangle_{p(y_{n,t}\\mid x_n)}log\\ b_{i,k}) $$\n* E步：\n$$ \\gamma_{n,t}^i = \\langle  y_{n,t}^i\\rangle = p(y_{n,t}^i = 1\\mid x_n) $$    $$ \\xi_{n,t}^{i,j} = \\langle y_{n,t-1}^i y_{n,t}^j\\rangle = p(y_{n,t-1}^i=1, y_{n,t}^j=1\\mid x_n) $$\n* M步：\n$$ \\pi_i=\\frac{\\sum_n \\gamma_{n,1}^i}{N}, a_{i,j}=\\frac{\\sum_n\\xi_{n,t}^{i,j}} {\\sum_n\\sum_{t=1}^{i,j} \\gamma_{n,t}^i},  b_{ik}=\\frac{\\sum_N\\sum_{t=1}^T \\gamma_{n,t}^i x_{n,t}^k} {\\sum_n\\sum_{t=1}^{T-1}\\gamma_{n,t}^i} $$\n\n### HMM的缺点\nHMM的缺点也是HMM的最要特征，就是每个观测值只与一个隐状态相关，与其他状态都无关。另外就是预测目标函数与学习目标函数不一致，HMM学习状态和观测值的联合概率$P(Y,X)$，但是我们的预测要求是需要条件概率$P(Y\\mid X)$，通过这样的考虑，有了一个新的模型MEMM。\n\n# MEMM\n## 模型结构\nMEMM结构如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/MEMM.png)\nMEMM的主要特点是，模型中的每个状态都与所有的观测值相关，同时模型是一个判别模型。\n$$ P(y_{1:n}\\mid x_{1:n}) = \\prod_{i=1}^{n} P(y_i\\mid y_{i-1},x_{1:n}) = \\prod_{i=1}^n \\frac{exp(W^T f(y_i,y_{i-1}, x_{1:n}))}{Z(y_{i-1}, x_{1:n})} $$\n\n## 缺点\nMEMM存在着标注偏置的问题(label bias preblem)，主要是因为状态转移的路径多少的问题，MEMM中的状态倾向于转移到转移状态路径少的状态，因为转移路径少的状态总能提供较大的转移概率。\n\n# CRF\n一个比较好的方法解决上面的问题就是改变原来的概率转移的方式，用势函数取代概率来表征局部的信息。\n\n## 模型结构\nCRF结构如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png)\n\\begin{equation}\\begin{split} P(Y\\mid X) &= \\frac{1}{Z(X)}\\prod_{i=1}^n \\phi(y_i,y_{i-1},X) \\\\\\\\\n&= \\frac{1}{Z(X, \\lambda, \\mu)}exp(\\sum_{i=1}^T(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l(y_i, X))) \\\\\\\\\n\\end{split}\\end{equation}\n其中，$Z(X,\\lambda, \\mu)=\\sum_y exp(\\sum_{i=1}(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $，可以看出其中的正规因子是全局的，并不是局部的，这样就保证了对局部信息的处理具有全局一致性。\n\n##　推断\n所谓的推断问题就是在CRF给定参数$\\lambda$和$\\mu$，我们可以找到$y^{\\ast}$使得$P(y\\mid x)$最大。\n$$ y^{\\ast} = argmax_y exp(\\sum_{i=1}^n (\\sum_k \\lambda_k f_k (y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $$\n因为Z与y无关，最大值与y无关。为了解决优化问题，我们可以使用最大积算法在CRF上，这样类似了Viteerbi算法在HMM上的应用。\n\n## 学习\n尽管整个图都是可观的，CRF的学习问题仍然是比较难于解决的。原因是学习中需要进行推断。给定训练集$\\lbrace x_d, y_d\\rbrace_{d=1}^N$，寻找到最优的$\\lambda^{\\ast}$和$\\mu^{\\ast}$。\n\\begin{equation}\\begin{split} \\lambda^{\\ast}, \\mu^{\\ast} &= argmax_{\\lambda, \\mu}\\prod_{d=1}^N P(y_d\\mid x_d, \\lambda, \\mu) \\\\\\\\\n&= argmax_{\\lambda, \\mu}\\prod_{d=1}^N \\frac{1}{Z(x_d, \\lambda, \\mu)}exp(\\sum_{i=1}^n (\\lambda^T f(y_{d, i} y_{d, i-1}, x_d) + \\mu^T g(y_{d,i}, x_d))) \\\\\\\\\n&= argmax_{\\lambda, \\mu}\\sum_{d=1}^T (\\sum_{i=1}^n(\\lambda^T f(y_{d,i}, y_{d, i-1}) + \\mu^T g(y_{d, i}, x_d)) - log\\ Z(x_d, \\lambda, \\mu)) \\\\\\\\\n\\end{split}\\end{equation}\n对$\\lambda$求偏导：\n$$ \\Delta_{\\lambda}L(\\lambda, \\mu) = \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d))) $$\n从上式中可以看出第一项是特征值，第二项是特征值的期望，另外对数判分函数以指数族的形式呈现时，其梯度是特征值的期望。\n解决上面的式子需要处理指数级数量的数据求和，我们可以利用message passing算法来计算对势，这样得到一个闭环的形式。\n\\begin{equation}\\begin{split} \\sum_y (P(y\\mid x_d)\\sum_{i=1}^n f(y_i, y_{i-1}, x_d)) &= \\sum_{i=1}^n(\\sum_y f(y_i, y_{i-1}, x_d) P(y\\mid x_d)) \\\\\\\\\n&= \\sum_{i=1}^n(\\sum_{y_i, y_{i-1}} f(y_i, y_{i-1}, x_d) P(y_i, y_{i-1}\\mid x_d)) \\\\\\\\\n\\end{split}\\end{equation}\n这样意味着，学习过程中包含有推断过程，通过message passing算法，学习过程只需要多项式时间久可以完成。\n下面使用校准势来计算特征期望：\n\\begin{equation}\\begin{split} \\Delta_{\\lambda}L(\\lambda, \\mu) &= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d)))  \\\\\\\\\n&= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d,i}, y_{d,i-1】， x_d} - \\sum_{y_i, y_{i-1}}\\alpha'(y_i, y_{i-1}) f(y_d, y_{d, i-1}, x_d))) \\\\\\\\\n\\end{split}\\end{equation}\n其中$\\alpha'(y_i, y_{i-1}, x_d) = P(y_i, y_{i-1}\\mid x_d)$。我们可以使用梯度上升法学习参数。\n$$ \\lambda^{(t+1)} = \\lambda^{(t)} + \\eta\\Delta_{\\lambda}L(\\lambda^{(t)}, \\mu^{(t)}) $$     $$ \\mu^{(t+1)} = \\mu^{(t)} + \\eta\\Delta_{\\mu}L(\\lambda^{(t)}, \\mu^{(t)}) $$\n在实际中，我们会加入正则项来提高参数的泛化能力。\n$$ \\lambda^{\\ast}, \\mu^{\\ast} = argmax_{\\lambda, \\mu}\\sum_{d=1}^N log\\ P(y_d\\mid x_d, \\lambda, \\mu) - \\frac{1}{2\\sigma^2} (\\lambda^T \\lambda + \\mu^T\\mu) $$\n第二项叫做高斯先验，因为我们想让$\\lambda^{\\ast},\\mu^{\\ast}$趋近于0,这样可以减少特征值的数量。第二项也能叫做拉普拉斯先验，在条件概率中，我们不想看到零概率出现，因为零概率是病态的。梯度上升法收敛速度较慢，以使用共轭梯度法和拟牛顿法来加快速度。\n从经验的表现来看，CRF比HMM和MEMM有所提升，特别是当非局部的影响明显时。虽然提升不够明显，但是CRF为一系列的问题的解决提供了很好的范例。CRF的另一优点是能够让使用者灵活的自己设计随机特征。\n\n# 总结\n* EM算法适应于处理存在隐变量的最大似然估计问题。\n* GMM和HMM被用于对静态和动态混合模型建模。\n* 实现HMM主要需要处理的问题是，学习，推断和最大似然。推断可以通过前向和后向算法(变量去除)实现；最大似然问题可以通过Viterbi算法(最大积)实现；学习问题可以通过直接最大似然后者EM算法解决。\n* HMM具有十分强的马尔科夫性。HMM只能获得局部的关系，对于HMM的扩展MEMM，MEMM可以获得状态和全部可观序列之间的显性关系。但是，MEMM存在着标注偏置的问题。\n* CRF是部分有向的模型，其中转态之间是无向的，CRF使用全局的正规项克服了MEMM的标注偏置的问题。对于线性链式CRF，精确推断并不是困难的。推断问题可以通过最大积算法通过junction tree解决。学习问题可以通过梯度上升来解决最大似然。\n* 具有任意图结构的CRF，精确推断就是比较困难的事情，这时就需要近似推断了，比如：采样，变分推断，loopy belief propagation。\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n[2] Wallach H M. Conditional random fields: An introduction[J]. Technical Reports (CIS), 2004: 22.\n注：本文主要参考[1]中第12讲视频以及笔记。另外，本文中公式的和全部采用\\sum，本文之前使用的都是\\Sigma，后面也会使用\\sum。\n","source":"_posts/HMM和CRF.md","raw":"---\ntitle: HMM和CRF\ndate: 2018-05-31 09:49:19\ntags: 概率图模型\ncategories: 学习\n---\n# 隐马尔可夫模型\n隐马尔可夫模型如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png)\n\n## 公式表达\n对于隐马尔可夫模型，通常有三组参数：\n$$ trasition\\ probability\\ matrix\\ A: p(y_t^j = 1\\mid y_{t-1}^i=1)=a_{i,j} $$   $$ initial\\ probability: p(y_1)\\sim Multinomial(\\pi_1, \\pi_2, ..., \\pi_M) $$    $$ emission\\ probabilies: p(x_t\\mid y_t^i)\\sim Multinomial(b_{i,1}, b_{i,2}, ..., b_{i,K}) $$\n\n## 推断\n* 前向算法\n$$ \\alpha_t^k \\equiv\\mu_{t-1\\rightarrow}(k)=P(x_1, x_2, ..., x_t, y_t^k=1) $$\n$$ \\alpha_t^k = p(x_t\\mid y_t^k=1)\\sum_i \\alpha_{t-1}^ia_{i,k} $$\n\n* 后向算法\n$$ \\beta_t^k \\equiv \\mu_{t\\leftarrow t+1}(k)=P(x_{t+1}, ..., x_T\\mid y_t^k=1) $$\n$$ \\beta_t^k = \\sum_i a_{k,i}p(x_{t+1}\\mid y_{t+1}^i = 1)\\beta_{t+1}^i $$\n\n对于给定观测值下的任意隐变量状态，可以同过点乘前向和后向信息得到。\n$$ \\gamma_t^i = p(y_t^i = 1\\mid x_{1:T})\\propto \\alpha_t^i\\beta_t^i =\\sum_j \\xi_t^{i,j} $$\n其中有定义：\n\\begin{equation}\\begin{split} \\xi_t^{i,j} &= p(y_t^i=1,y_{t-1}^j=1, x_{1:T}) \\\\\\\\\n&\\propto \\mu_{t-1\\rightarrow t}(y_t^i=1)\\mu_{t\\leftarrow t+1}(y_{t+1}^i=1)p(x_{x+1}\\mid y_{t+1})p(y_{t+1}\\mid y_t) \\\\\\\\\n&= \\alpha_t^i\\beta_{t+1}^j a_{i,j} p(x_{t+1}\\mid y_{t+1}^i=1) \\\\\\\\\n\\end{split}\\end{equation}\n具体推导可以参考Youtube上徐亦达老师关于HMM的视频，主要思路就是message passing，运用一些迭代地技巧，可以先从最小的下标开始推导，这样比较容易发现规律，类似于数学归纳法。\n在Matlab中可以将公式用向量表示，这样方便处理。\n\\begin{equation}\\begin{split} &B_t(i)=p(x_t\\mid y_t^i=1)\\\\\\\\\n& A(i,j)=p(y_{t+1}^j=1\\mid y_t^i=1) \\\\\\\\\n& \\alpha_t = (A^T\\alpha_{t-1}).\\ast B_t \\\\\\\\\n& \\beta_t = A(\\beta_{t+1}.\\ast B_{t+1}) \\\\\\\\\n& \\xi_t = (\\alpha_t(\\beta_{t+1}.\\ast B_{t+1})^T).\\ast A  \\\\\\\\\n& \\gamma_t = \\alpha_t.\\ast \\beta_t \\\\\\\\\n\\end{split}\\end{equation}\n\n## 学习\n### 监督学习\n当我们知道实际状态路径时，监督学习并不是一件困难的事情(trival)，我们只需要数出转移概率和发射概率的实例就可以得到最大似然估计。\n$$ a_{ij}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i y_{n,t}^j}{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i} $$\n$$ b_{ik}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t}^i x_{n,t}^k}{\\sum_n\\sum_{t=2}^T y_{n,t}^i} $$\n使用了伪计数的方式，可以避免零概率的出现。对于不是多项分布的情况，特别是高斯分布，我们可以利用采样的方法计算均值和方差。\n\n### 无监督学习\n当隐状态不可观的时候，可以使用Baum Welch算法进行处理完全对数似然函数，这一算法就是EM算法对HMM的求解方法。似然函数可以写成：\n$$ l_c(\\theta;x,y)=lop\\ p(x,y)=log\\prod_n (p(y_{n,1})\\prod_{t=1}^T p(y_{n,t}\\mid y_{n,t-1})\\prod_{t=1}^T p(x_{n,t}\\mid y_{n,t})) $$\n完全对数似然期望是：\n$$ \\langle l_c(\\theta;x,y)\\rangle = \\sum_n (\\langle y_{n,1}^i \\rangle_{p(y_{n,1}\\mid x_n)}log\\ \\pi_i) + \\sum_n\\sum_{t=2}^T (\\langle y_{n,t-1}^i y_{n,t}^j\\rangle_{p(y_{n,t-1},y_{n,t}\\mid x_n)}log\\ a_{i,j}) + \\sum_n\\sum_{t=1}^T (x_{n,t}^k\\langle y_{n,t}^i\\rangle_{p(y_{n,t}\\mid x_n)}log\\ b_{i,k}) $$\n* E步：\n$$ \\gamma_{n,t}^i = \\langle  y_{n,t}^i\\rangle = p(y_{n,t}^i = 1\\mid x_n) $$    $$ \\xi_{n,t}^{i,j} = \\langle y_{n,t-1}^i y_{n,t}^j\\rangle = p(y_{n,t-1}^i=1, y_{n,t}^j=1\\mid x_n) $$\n* M步：\n$$ \\pi_i=\\frac{\\sum_n \\gamma_{n,1}^i}{N}, a_{i,j}=\\frac{\\sum_n\\xi_{n,t}^{i,j}} {\\sum_n\\sum_{t=1}^{i,j} \\gamma_{n,t}^i},  b_{ik}=\\frac{\\sum_N\\sum_{t=1}^T \\gamma_{n,t}^i x_{n,t}^k} {\\sum_n\\sum_{t=1}^{T-1}\\gamma_{n,t}^i} $$\n\n### HMM的缺点\nHMM的缺点也是HMM的最要特征，就是每个观测值只与一个隐状态相关，与其他状态都无关。另外就是预测目标函数与学习目标函数不一致，HMM学习状态和观测值的联合概率$P(Y,X)$，但是我们的预测要求是需要条件概率$P(Y\\mid X)$，通过这样的考虑，有了一个新的模型MEMM。\n\n# MEMM\n## 模型结构\nMEMM结构如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/MEMM.png)\nMEMM的主要特点是，模型中的每个状态都与所有的观测值相关，同时模型是一个判别模型。\n$$ P(y_{1:n}\\mid x_{1:n}) = \\prod_{i=1}^{n} P(y_i\\mid y_{i-1},x_{1:n}) = \\prod_{i=1}^n \\frac{exp(W^T f(y_i,y_{i-1}, x_{1:n}))}{Z(y_{i-1}, x_{1:n})} $$\n\n## 缺点\nMEMM存在着标注偏置的问题(label bias preblem)，主要是因为状态转移的路径多少的问题，MEMM中的状态倾向于转移到转移状态路径少的状态，因为转移路径少的状态总能提供较大的转移概率。\n\n# CRF\n一个比较好的方法解决上面的问题就是改变原来的概率转移的方式，用势函数取代概率来表征局部的信息。\n\n## 模型结构\nCRF结构如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png)\n\\begin{equation}\\begin{split} P(Y\\mid X) &= \\frac{1}{Z(X)}\\prod_{i=1}^n \\phi(y_i,y_{i-1},X) \\\\\\\\\n&= \\frac{1}{Z(X, \\lambda, \\mu)}exp(\\sum_{i=1}^T(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l(y_i, X))) \\\\\\\\\n\\end{split}\\end{equation}\n其中，$Z(X,\\lambda, \\mu)=\\sum_y exp(\\sum_{i=1}(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $，可以看出其中的正规因子是全局的，并不是局部的，这样就保证了对局部信息的处理具有全局一致性。\n\n##　推断\n所谓的推断问题就是在CRF给定参数$\\lambda$和$\\mu$，我们可以找到$y^{\\ast}$使得$P(y\\mid x)$最大。\n$$ y^{\\ast} = argmax_y exp(\\sum_{i=1}^n (\\sum_k \\lambda_k f_k (y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $$\n因为Z与y无关，最大值与y无关。为了解决优化问题，我们可以使用最大积算法在CRF上，这样类似了Viteerbi算法在HMM上的应用。\n\n## 学习\n尽管整个图都是可观的，CRF的学习问题仍然是比较难于解决的。原因是学习中需要进行推断。给定训练集$\\lbrace x_d, y_d\\rbrace_{d=1}^N$，寻找到最优的$\\lambda^{\\ast}$和$\\mu^{\\ast}$。\n\\begin{equation}\\begin{split} \\lambda^{\\ast}, \\mu^{\\ast} &= argmax_{\\lambda, \\mu}\\prod_{d=1}^N P(y_d\\mid x_d, \\lambda, \\mu) \\\\\\\\\n&= argmax_{\\lambda, \\mu}\\prod_{d=1}^N \\frac{1}{Z(x_d, \\lambda, \\mu)}exp(\\sum_{i=1}^n (\\lambda^T f(y_{d, i} y_{d, i-1}, x_d) + \\mu^T g(y_{d,i}, x_d))) \\\\\\\\\n&= argmax_{\\lambda, \\mu}\\sum_{d=1}^T (\\sum_{i=1}^n(\\lambda^T f(y_{d,i}, y_{d, i-1}) + \\mu^T g(y_{d, i}, x_d)) - log\\ Z(x_d, \\lambda, \\mu)) \\\\\\\\\n\\end{split}\\end{equation}\n对$\\lambda$求偏导：\n$$ \\Delta_{\\lambda}L(\\lambda, \\mu) = \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d))) $$\n从上式中可以看出第一项是特征值，第二项是特征值的期望，另外对数判分函数以指数族的形式呈现时，其梯度是特征值的期望。\n解决上面的式子需要处理指数级数量的数据求和，我们可以利用message passing算法来计算对势，这样得到一个闭环的形式。\n\\begin{equation}\\begin{split} \\sum_y (P(y\\mid x_d)\\sum_{i=1}^n f(y_i, y_{i-1}, x_d)) &= \\sum_{i=1}^n(\\sum_y f(y_i, y_{i-1}, x_d) P(y\\mid x_d)) \\\\\\\\\n&= \\sum_{i=1}^n(\\sum_{y_i, y_{i-1}} f(y_i, y_{i-1}, x_d) P(y_i, y_{i-1}\\mid x_d)) \\\\\\\\\n\\end{split}\\end{equation}\n这样意味着，学习过程中包含有推断过程，通过message passing算法，学习过程只需要多项式时间久可以完成。\n下面使用校准势来计算特征期望：\n\\begin{equation}\\begin{split} \\Delta_{\\lambda}L(\\lambda, \\mu) &= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d)))  \\\\\\\\\n&= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d,i}, y_{d,i-1】， x_d} - \\sum_{y_i, y_{i-1}}\\alpha'(y_i, y_{i-1}) f(y_d, y_{d, i-1}, x_d))) \\\\\\\\\n\\end{split}\\end{equation}\n其中$\\alpha'(y_i, y_{i-1}, x_d) = P(y_i, y_{i-1}\\mid x_d)$。我们可以使用梯度上升法学习参数。\n$$ \\lambda^{(t+1)} = \\lambda^{(t)} + \\eta\\Delta_{\\lambda}L(\\lambda^{(t)}, \\mu^{(t)}) $$     $$ \\mu^{(t+1)} = \\mu^{(t)} + \\eta\\Delta_{\\mu}L(\\lambda^{(t)}, \\mu^{(t)}) $$\n在实际中，我们会加入正则项来提高参数的泛化能力。\n$$ \\lambda^{\\ast}, \\mu^{\\ast} = argmax_{\\lambda, \\mu}\\sum_{d=1}^N log\\ P(y_d\\mid x_d, \\lambda, \\mu) - \\frac{1}{2\\sigma^2} (\\lambda^T \\lambda + \\mu^T\\mu) $$\n第二项叫做高斯先验，因为我们想让$\\lambda^{\\ast},\\mu^{\\ast}$趋近于0,这样可以减少特征值的数量。第二项也能叫做拉普拉斯先验，在条件概率中，我们不想看到零概率出现，因为零概率是病态的。梯度上升法收敛速度较慢，以使用共轭梯度法和拟牛顿法来加快速度。\n从经验的表现来看，CRF比HMM和MEMM有所提升，特别是当非局部的影响明显时。虽然提升不够明显，但是CRF为一系列的问题的解决提供了很好的范例。CRF的另一优点是能够让使用者灵活的自己设计随机特征。\n\n# 总结\n* EM算法适应于处理存在隐变量的最大似然估计问题。\n* GMM和HMM被用于对静态和动态混合模型建模。\n* 实现HMM主要需要处理的问题是，学习，推断和最大似然。推断可以通过前向和后向算法(变量去除)实现；最大似然问题可以通过Viterbi算法(最大积)实现；学习问题可以通过直接最大似然后者EM算法解决。\n* HMM具有十分强的马尔科夫性。HMM只能获得局部的关系，对于HMM的扩展MEMM，MEMM可以获得状态和全部可观序列之间的显性关系。但是，MEMM存在着标注偏置的问题。\n* CRF是部分有向的模型，其中转态之间是无向的，CRF使用全局的正规项克服了MEMM的标注偏置的问题。对于线性链式CRF，精确推断并不是困难的。推断问题可以通过最大积算法通过junction tree解决。学习问题可以通过梯度上升来解决最大似然。\n* 具有任意图结构的CRF，精确推断就是比较困难的事情，这时就需要近似推断了，比如：采样，变分推断，loopy belief propagation。\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n[2] Wallach H M. Conditional random fields: An introduction[J]. Technical Reports (CIS), 2004: 22.\n注：本文主要参考[1]中第12讲视频以及笔记。另外，本文中公式的和全部采用\\sum，本文之前使用的都是\\Sigma，后面也会使用\\sum。\n","slug":"HMM和CRF","published":1,"updated":"2018-09-25T09:33:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms7000b1ouzlf0yil5u","content":"<h1 id=\"隐马尔可夫模型\"><a href=\"#隐马尔可夫模型\" class=\"headerlink\" title=\"隐马尔可夫模型\"></a>隐马尔可夫模型</h1><p>隐马尔可夫模型如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h2 id=\"公式表达\"><a href=\"#公式表达\" class=\"headerlink\" title=\"公式表达\"></a>公式表达</h2><p>对于隐马尔可夫模型，通常有三组参数：<br>$$ trasition\\ probability\\ matrix\\ A: p(y_t^j = 1\\mid y_{t-1}^i=1)=a_{i,j} $$   $$ initial\\ probability: p(y_1)\\sim Multinomial(\\pi_1, \\pi_2, …, \\pi_M) $$    $$ emission\\ probabilies: p(x_t\\mid y_t^i)\\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K}) $$</p>\n<h2 id=\"推断\"><a href=\"#推断\" class=\"headerlink\" title=\"推断\"></a>推断</h2><ul>\n<li><p>前向算法<br>$$ \\alpha_t^k \\equiv\\mu_{t-1\\rightarrow}(k)=P(x_1, x_2, …, x_t, y_t^k=1) $$<br>$$ \\alpha_t^k = p(x_t\\mid y_t^k=1)\\sum_i \\alpha_{t-1}^ia_{i,k} $$</p>\n</li>\n<li><p>后向算法<br>$$ \\beta_t^k \\equiv \\mu_{t\\leftarrow t+1}(k)=P(x_{t+1}, …, x_T\\mid y_t^k=1) $$<br>$$ \\beta_t^k = \\sum_i a_{k,i}p(x_{t+1}\\mid y_{t+1}^i = 1)\\beta_{t+1}^i $$</p>\n</li>\n</ul>\n<p>对于给定观测值下的任意隐变量状态，可以同过点乘前向和后向信息得到。<br>$$ \\gamma_t^i = p(y_t^i = 1\\mid x_{1:T})\\propto \\alpha_t^i\\beta_t^i =\\sum_j \\xi_t^{i,j} $$<br>其中有定义：<br>\\begin{equation}\\begin{split} \\xi_t^{i,j} &amp;= p(y_t^i=1,y_{t-1}^j=1, x_{1:T}) \\\\<br>&amp;\\propto \\mu_{t-1\\rightarrow t}(y_t^i=1)\\mu_{t\\leftarrow t+1}(y_{t+1}^i=1)p(x_{x+1}\\mid y_{t+1})p(y_{t+1}\\mid y_t) \\\\<br>&amp;= \\alpha_t^i\\beta_{t+1}^j a_{i,j} p(x_{t+1}\\mid y_{t+1}^i=1) \\\\<br>\\end{split}\\end{equation}<br>具体推导可以参考Youtube上徐亦达老师关于HMM的视频，主要思路就是message passing，运用一些迭代地技巧，可以先从最小的下标开始推导，这样比较容易发现规律，类似于数学归纳法。<br>在Matlab中可以将公式用向量表示，这样方便处理。<br>\\begin{equation}\\begin{split} &amp;B_t(i)=p(x_t\\mid y_t^i=1)\\\\<br>&amp; A(i,j)=p(y_{t+1}^j=1\\mid y_t^i=1) \\\\<br>&amp; \\alpha_t = (A^T\\alpha_{t-1}).\\ast B_t \\\\<br>&amp; \\beta_t = A(\\beta_{t+1}.\\ast B_{t+1}) \\\\<br>&amp; \\xi_t = (\\alpha_t(\\beta_{t+1}.\\ast B_{t+1})^T).\\ast A  \\\\<br>&amp; \\gamma_t = \\alpha_t.\\ast \\beta_t \\\\<br>\\end{split}\\end{equation}</p>\n<h2 id=\"学习\"><a href=\"#学习\" class=\"headerlink\" title=\"学习\"></a>学习</h2><h3 id=\"监督学习\"><a href=\"#监督学习\" class=\"headerlink\" title=\"监督学习\"></a>监督学习</h3><p>当我们知道实际状态路径时，监督学习并不是一件困难的事情(trival)，我们只需要数出转移概率和发射概率的实例就可以得到最大似然估计。<br>$$ a_{ij}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i y_{n,t}^j}{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i} $$<br>$$ b_{ik}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t}^i x_{n,t}^k}{\\sum_n\\sum_{t=2}^T y_{n,t}^i} $$<br>使用了伪计数的方式，可以避免零概率的出现。对于不是多项分布的情况，特别是高斯分布，我们可以利用采样的方法计算均值和方差。</p>\n<h3 id=\"无监督学习\"><a href=\"#无监督学习\" class=\"headerlink\" title=\"无监督学习\"></a>无监督学习</h3><p>当隐状态不可观的时候，可以使用Baum Welch算法进行处理完全对数似然函数，这一算法就是EM算法对HMM的求解方法。似然函数可以写成：<br>$$ l_c(\\theta;x,y)=lop\\ p(x,y)=log\\prod_n (p(y_{n,1})\\prod_{t=1}^T p(y_{n,t}\\mid y_{n,t-1})\\prod_{t=1}^T p(x_{n,t}\\mid y_{n,t})) $$<br>完全对数似然期望是：<br>$$ \\langle l_c(\\theta;x,y)\\rangle = \\sum_n (\\langle y_{n,1}^i \\rangle_{p(y_{n,1}\\mid x_n)}log\\ \\pi_i) + \\sum_n\\sum_{t=2}^T (\\langle y_{n,t-1}^i y_{n,t}^j\\rangle_{p(y_{n,t-1},y_{n,t}\\mid x_n)}log\\ a_{i,j}) + \\sum_n\\sum_{t=1}^T (x_{n,t}^k\\langle y_{n,t}^i\\rangle_{p(y_{n,t}\\mid x_n)}log\\ b_{i,k}) $$</p>\n<ul>\n<li>E步：<br>$$ \\gamma_{n,t}^i = \\langle  y_{n,t}^i\\rangle = p(y_{n,t}^i = 1\\mid x_n) $$    $$ \\xi_{n,t}^{i,j} = \\langle y_{n,t-1}^i y_{n,t}^j\\rangle = p(y_{n,t-1}^i=1, y_{n,t}^j=1\\mid x_n) $$</li>\n<li>M步：<br>$$ \\pi_i=\\frac{\\sum_n \\gamma_{n,1}^i}{N}, a_{i,j}=\\frac{\\sum_n\\xi_{n,t}^{i,j}} {\\sum_n\\sum_{t=1}^{i,j} \\gamma_{n,t}^i},  b_{ik}=\\frac{\\sum_N\\sum_{t=1}^T \\gamma_{n,t}^i x_{n,t}^k} {\\sum_n\\sum_{t=1}^{T-1}\\gamma_{n,t}^i} $$</li>\n</ul>\n<h3 id=\"HMM的缺点\"><a href=\"#HMM的缺点\" class=\"headerlink\" title=\"HMM的缺点\"></a>HMM的缺点</h3><p>HMM的缺点也是HMM的最要特征，就是每个观测值只与一个隐状态相关，与其他状态都无关。另外就是预测目标函数与学习目标函数不一致，HMM学习状态和观测值的联合概率$P(Y,X)$，但是我们的预测要求是需要条件概率$P(Y\\mid X)$，通过这样的考虑，有了一个新的模型MEMM。</p>\n<h1 id=\"MEMM\"><a href=\"#MEMM\" class=\"headerlink\" title=\"MEMM\"></a>MEMM</h1><h2 id=\"模型结构\"><a href=\"#模型结构\" class=\"headerlink\" title=\"模型结构\"></a>模型结构</h2><p>MEMM结构如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/MEMM.png\" alt><br>MEMM的主要特点是，模型中的每个状态都与所有的观测值相关，同时模型是一个判别模型。<br>$$ P(y_{1:n}\\mid x_{1:n}) = \\prod_{i=1}^{n} P(y_i\\mid y_{i-1},x_{1:n}) = \\prod_{i=1}^n \\frac{exp(W^T f(y_i,y_{i-1}, x_{1:n}))}{Z(y_{i-1}, x_{1:n})} $$</p>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>MEMM存在着标注偏置的问题(label bias preblem)，主要是因为状态转移的路径多少的问题，MEMM中的状态倾向于转移到转移状态路径少的状态，因为转移路径少的状态总能提供较大的转移概率。</p>\n<h1 id=\"CRF\"><a href=\"#CRF\" class=\"headerlink\" title=\"CRF\"></a>CRF</h1><p>一个比较好的方法解决上面的问题就是改变原来的概率转移的方式，用势函数取代概率来表征局部的信息。</p>\n<h2 id=\"模型结构-1\"><a href=\"#模型结构-1\" class=\"headerlink\" title=\"模型结构\"></a>模型结构</h2><p>CRF结构如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png\" alt><br>\\begin{equation}\\begin{split} P(Y\\mid X) &amp;= \\frac{1}{Z(X)}\\prod_{i=1}^n \\phi(y_i,y_{i-1},X) \\\\<br>&amp;= \\frac{1}{Z(X, \\lambda, \\mu)}exp(\\sum_{i=1}^T(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l(y_i, X))) \\\\<br>\\end{split}\\end{equation}<br>其中，$Z(X,\\lambda, \\mu)=\\sum_y exp(\\sum_{i=1}(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $，可以看出其中的正规因子是全局的，并不是局部的，这样就保证了对局部信息的处理具有全局一致性。</p>\n<p>##　推断<br>所谓的推断问题就是在CRF给定参数$\\lambda$和$\\mu$，我们可以找到$y^{\\ast}$使得$P(y\\mid x)$最大。<br>$$ y^{\\ast} = argmax_y exp(\\sum_{i=1}^n (\\sum_k \\lambda_k f_k (y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $$<br>因为Z与y无关，最大值与y无关。为了解决优化问题，我们可以使用最大积算法在CRF上，这样类似了Viteerbi算法在HMM上的应用。</p>\n<h2 id=\"学习-1\"><a href=\"#学习-1\" class=\"headerlink\" title=\"学习\"></a>学习</h2><p>尽管整个图都是可观的，CRF的学习问题仍然是比较难于解决的。原因是学习中需要进行推断。给定训练集$\\lbrace x_d, y_d\\rbrace_{d=1}^N$，寻找到最优的$\\lambda^{\\ast}$和$\\mu^{\\ast}$。<br>\\begin{equation}\\begin{split} \\lambda^{\\ast}, \\mu^{\\ast} &amp;= argmax_{\\lambda, \\mu}\\prod_{d=1}^N P(y_d\\mid x_d, \\lambda, \\mu) \\\\<br>&amp;= argmax_{\\lambda, \\mu}\\prod_{d=1}^N \\frac{1}{Z(x_d, \\lambda, \\mu)}exp(\\sum_{i=1}^n (\\lambda^T f(y_{d, i} y_{d, i-1}, x_d) + \\mu^T g(y_{d,i}, x_d))) \\\\<br>&amp;= argmax_{\\lambda, \\mu}\\sum_{d=1}^T (\\sum_{i=1}^n(\\lambda^T f(y_{d,i}, y_{d, i-1}) + \\mu^T g(y_{d, i}, x_d)) - log\\ Z(x_d, \\lambda, \\mu)) \\\\<br>\\end{split}\\end{equation}<br>对$\\lambda$求偏导：<br>$$ \\Delta_{\\lambda}L(\\lambda, \\mu) = \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d))) $$<br>从上式中可以看出第一项是特征值，第二项是特征值的期望，另外对数判分函数以指数族的形式呈现时，其梯度是特征值的期望。<br>解决上面的式子需要处理指数级数量的数据求和，我们可以利用message passing算法来计算对势，这样得到一个闭环的形式。<br>\\begin{equation}\\begin{split} \\sum_y (P(y\\mid x_d)\\sum_{i=1}^n f(y_i, y_{i-1}, x_d)) &amp;= \\sum_{i=1}^n(\\sum_y f(y_i, y_{i-1}, x_d) P(y\\mid x_d)) \\\\<br>&amp;= \\sum_{i=1}^n(\\sum_{y_i, y_{i-1}} f(y_i, y_{i-1}, x_d) P(y_i, y_{i-1}\\mid x_d)) \\\\<br>\\end{split}\\end{equation}<br>这样意味着，学习过程中包含有推断过程，通过message passing算法，学习过程只需要多项式时间久可以完成。<br>下面使用校准势来计算特征期望：<br>\\begin{equation}\\begin{split} \\Delta_{\\lambda}L(\\lambda, \\mu) &amp;= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d)))  \\\\<br>&amp;= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d,i}, y_{d,i-1】， x_d} - \\sum_{y_i, y_{i-1}}\\alpha’(y_i, y_{i-1}) f(y_d, y_{d, i-1}, x_d))) \\\\<br>\\end{split}\\end{equation}<br>其中$\\alpha’(y_i, y_{i-1}, x_d) = P(y_i, y_{i-1}\\mid x_d)$。我们可以使用梯度上升法学习参数。<br>$$ \\lambda^{(t+1)} = \\lambda^{(t)} + \\eta\\Delta_{\\lambda}L(\\lambda^{(t)}, \\mu^{(t)}) $$     $$ \\mu^{(t+1)} = \\mu^{(t)} + \\eta\\Delta_{\\mu}L(\\lambda^{(t)}, \\mu^{(t)}) $$<br>在实际中，我们会加入正则项来提高参数的泛化能力。<br>$$ \\lambda^{\\ast}, \\mu^{\\ast} = argmax_{\\lambda, \\mu}\\sum_{d=1}^N log\\ P(y_d\\mid x_d, \\lambda, \\mu) - \\frac{1}{2\\sigma^2} (\\lambda^T \\lambda + \\mu^T\\mu) $$<br>第二项叫做高斯先验，因为我们想让$\\lambda^{\\ast},\\mu^{\\ast}$趋近于0,这样可以减少特征值的数量。第二项也能叫做拉普拉斯先验，在条件概率中，我们不想看到零概率出现，因为零概率是病态的。梯度上升法收敛速度较慢，以使用共轭梯度法和拟牛顿法来加快速度。<br>从经验的表现来看，CRF比HMM和MEMM有所提升，特别是当非局部的影响明显时。虽然提升不够明显，但是CRF为一系列的问题的解决提供了很好的范例。CRF的另一优点是能够让使用者灵活的自己设计随机特征。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>EM算法适应于处理存在隐变量的最大似然估计问题。</li>\n<li>GMM和HMM被用于对静态和动态混合模型建模。</li>\n<li>实现HMM主要需要处理的问题是，学习，推断和最大似然。推断可以通过前向和后向算法(变量去除)实现；最大似然问题可以通过Viterbi算法(最大积)实现；学习问题可以通过直接最大似然后者EM算法解决。</li>\n<li>HMM具有十分强的马尔科夫性。HMM只能获得局部的关系，对于HMM的扩展MEMM，MEMM可以获得状态和全部可观序列之间的显性关系。但是，MEMM存在着标注偏置的问题。</li>\n<li>CRF是部分有向的模型，其中转态之间是无向的，CRF使用全局的正规项克服了MEMM的标注偏置的问题。对于线性链式CRF，精确推断并不是困难的。推断问题可以通过最大积算法通过junction tree解决。学习问题可以通过梯度上升来解决最大似然。</li>\n<li>具有任意图结构的CRF，精确推断就是比较困难的事情，这时就需要近似推断了，比如：采样，变分推断，loopy belief propagation。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Wallach H M. Conditional random fields: An introduction[J]. Technical Reports (CIS), 2004: 22.<br>注：本文主要参考[1]中第12讲视频以及笔记。另外，本文中公式的和全部采用\\sum，本文之前使用的都是\\Sigma，后面也会使用\\sum。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"隐马尔可夫模型\"><a href=\"#隐马尔可夫模型\" class=\"headerlink\" title=\"隐马尔可夫模型\"></a>隐马尔可夫模型</h1><p>隐马尔可夫模型如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h2 id=\"公式表达\"><a href=\"#公式表达\" class=\"headerlink\" title=\"公式表达\"></a>公式表达</h2><p>对于隐马尔可夫模型，通常有三组参数：<br>$$ trasition\\ probability\\ matrix\\ A: p(y_t^j = 1\\mid y_{t-1}^i=1)=a_{i,j} $$   $$ initial\\ probability: p(y_1)\\sim Multinomial(\\pi_1, \\pi_2, …, \\pi_M) $$    $$ emission\\ probabilies: p(x_t\\mid y_t^i)\\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K}) $$</p>\n<h2 id=\"推断\"><a href=\"#推断\" class=\"headerlink\" title=\"推断\"></a>推断</h2><ul>\n<li><p>前向算法<br>$$ \\alpha_t^k \\equiv\\mu_{t-1\\rightarrow}(k)=P(x_1, x_2, …, x_t, y_t^k=1) $$<br>$$ \\alpha_t^k = p(x_t\\mid y_t^k=1)\\sum_i \\alpha_{t-1}^ia_{i,k} $$</p>\n</li>\n<li><p>后向算法<br>$$ \\beta_t^k \\equiv \\mu_{t\\leftarrow t+1}(k)=P(x_{t+1}, …, x_T\\mid y_t^k=1) $$<br>$$ \\beta_t^k = \\sum_i a_{k,i}p(x_{t+1}\\mid y_{t+1}^i = 1)\\beta_{t+1}^i $$</p>\n</li>\n</ul>\n<p>对于给定观测值下的任意隐变量状态，可以同过点乘前向和后向信息得到。<br>$$ \\gamma_t^i = p(y_t^i = 1\\mid x_{1:T})\\propto \\alpha_t^i\\beta_t^i =\\sum_j \\xi_t^{i,j} $$<br>其中有定义：<br>\\begin{equation}\\begin{split} \\xi_t^{i,j} &amp;= p(y_t^i=1,y_{t-1}^j=1, x_{1:T}) \\\\<br>&amp;\\propto \\mu_{t-1\\rightarrow t}(y_t^i=1)\\mu_{t\\leftarrow t+1}(y_{t+1}^i=1)p(x_{x+1}\\mid y_{t+1})p(y_{t+1}\\mid y_t) \\\\<br>&amp;= \\alpha_t^i\\beta_{t+1}^j a_{i,j} p(x_{t+1}\\mid y_{t+1}^i=1) \\\\<br>\\end{split}\\end{equation}<br>具体推导可以参考Youtube上徐亦达老师关于HMM的视频，主要思路就是message passing，运用一些迭代地技巧，可以先从最小的下标开始推导，这样比较容易发现规律，类似于数学归纳法。<br>在Matlab中可以将公式用向量表示，这样方便处理。<br>\\begin{equation}\\begin{split} &amp;B_t(i)=p(x_t\\mid y_t^i=1)\\\\<br>&amp; A(i,j)=p(y_{t+1}^j=1\\mid y_t^i=1) \\\\<br>&amp; \\alpha_t = (A^T\\alpha_{t-1}).\\ast B_t \\\\<br>&amp; \\beta_t = A(\\beta_{t+1}.\\ast B_{t+1}) \\\\<br>&amp; \\xi_t = (\\alpha_t(\\beta_{t+1}.\\ast B_{t+1})^T).\\ast A  \\\\<br>&amp; \\gamma_t = \\alpha_t.\\ast \\beta_t \\\\<br>\\end{split}\\end{equation}</p>\n<h2 id=\"学习\"><a href=\"#学习\" class=\"headerlink\" title=\"学习\"></a>学习</h2><h3 id=\"监督学习\"><a href=\"#监督学习\" class=\"headerlink\" title=\"监督学习\"></a>监督学习</h3><p>当我们知道实际状态路径时，监督学习并不是一件困难的事情(trival)，我们只需要数出转移概率和发射概率的实例就可以得到最大似然估计。<br>$$ a_{ij}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i y_{n,t}^j}{\\sum_n\\sum_{t=2}^T y_{n,t-1}^i} $$<br>$$ b_{ik}^{ML} = \\frac{\\sum_n\\sum_{t=2}^T y_{n,t}^i x_{n,t}^k}{\\sum_n\\sum_{t=2}^T y_{n,t}^i} $$<br>使用了伪计数的方式，可以避免零概率的出现。对于不是多项分布的情况，特别是高斯分布，我们可以利用采样的方法计算均值和方差。</p>\n<h3 id=\"无监督学习\"><a href=\"#无监督学习\" class=\"headerlink\" title=\"无监督学习\"></a>无监督学习</h3><p>当隐状态不可观的时候，可以使用Baum Welch算法进行处理完全对数似然函数，这一算法就是EM算法对HMM的求解方法。似然函数可以写成：<br>$$ l_c(\\theta;x,y)=lop\\ p(x,y)=log\\prod_n (p(y_{n,1})\\prod_{t=1}^T p(y_{n,t}\\mid y_{n,t-1})\\prod_{t=1}^T p(x_{n,t}\\mid y_{n,t})) $$<br>完全对数似然期望是：<br>$$ \\langle l_c(\\theta;x,y)\\rangle = \\sum_n (\\langle y_{n,1}^i \\rangle_{p(y_{n,1}\\mid x_n)}log\\ \\pi_i) + \\sum_n\\sum_{t=2}^T (\\langle y_{n,t-1}^i y_{n,t}^j\\rangle_{p(y_{n,t-1},y_{n,t}\\mid x_n)}log\\ a_{i,j}) + \\sum_n\\sum_{t=1}^T (x_{n,t}^k\\langle y_{n,t}^i\\rangle_{p(y_{n,t}\\mid x_n)}log\\ b_{i,k}) $$</p>\n<ul>\n<li>E步：<br>$$ \\gamma_{n,t}^i = \\langle  y_{n,t}^i\\rangle = p(y_{n,t}^i = 1\\mid x_n) $$    $$ \\xi_{n,t}^{i,j} = \\langle y_{n,t-1}^i y_{n,t}^j\\rangle = p(y_{n,t-1}^i=1, y_{n,t}^j=1\\mid x_n) $$</li>\n<li>M步：<br>$$ \\pi_i=\\frac{\\sum_n \\gamma_{n,1}^i}{N}, a_{i,j}=\\frac{\\sum_n\\xi_{n,t}^{i,j}} {\\sum_n\\sum_{t=1}^{i,j} \\gamma_{n,t}^i},  b_{ik}=\\frac{\\sum_N\\sum_{t=1}^T \\gamma_{n,t}^i x_{n,t}^k} {\\sum_n\\sum_{t=1}^{T-1}\\gamma_{n,t}^i} $$</li>\n</ul>\n<h3 id=\"HMM的缺点\"><a href=\"#HMM的缺点\" class=\"headerlink\" title=\"HMM的缺点\"></a>HMM的缺点</h3><p>HMM的缺点也是HMM的最要特征，就是每个观测值只与一个隐状态相关，与其他状态都无关。另外就是预测目标函数与学习目标函数不一致，HMM学习状态和观测值的联合概率$P(Y,X)$，但是我们的预测要求是需要条件概率$P(Y\\mid X)$，通过这样的考虑，有了一个新的模型MEMM。</p>\n<h1 id=\"MEMM\"><a href=\"#MEMM\" class=\"headerlink\" title=\"MEMM\"></a>MEMM</h1><h2 id=\"模型结构\"><a href=\"#模型结构\" class=\"headerlink\" title=\"模型结构\"></a>模型结构</h2><p>MEMM结构如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/MEMM.png\" alt><br>MEMM的主要特点是，模型中的每个状态都与所有的观测值相关，同时模型是一个判别模型。<br>$$ P(y_{1:n}\\mid x_{1:n}) = \\prod_{i=1}^{n} P(y_i\\mid y_{i-1},x_{1:n}) = \\prod_{i=1}^n \\frac{exp(W^T f(y_i,y_{i-1}, x_{1:n}))}{Z(y_{i-1}, x_{1:n})} $$</p>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>MEMM存在着标注偏置的问题(label bias preblem)，主要是因为状态转移的路径多少的问题，MEMM中的状态倾向于转移到转移状态路径少的状态，因为转移路径少的状态总能提供较大的转移概率。</p>\n<h1 id=\"CRF\"><a href=\"#CRF\" class=\"headerlink\" title=\"CRF\"></a>CRF</h1><p>一个比较好的方法解决上面的问题就是改变原来的概率转移的方式，用势函数取代概率来表征局部的信息。</p>\n<h2 id=\"模型结构-1\"><a href=\"#模型结构-1\" class=\"headerlink\" title=\"模型结构\"></a>模型结构</h2><p>CRF结构如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png\" alt><br>\\begin{equation}\\begin{split} P(Y\\mid X) &amp;= \\frac{1}{Z(X)}\\prod_{i=1}^n \\phi(y_i,y_{i-1},X) \\\\<br>&amp;= \\frac{1}{Z(X, \\lambda, \\mu)}exp(\\sum_{i=1}^T(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l(y_i, X))) \\\\<br>\\end{split}\\end{equation}<br>其中，$Z(X,\\lambda, \\mu)=\\sum_y exp(\\sum_{i=1}(\\sum_k \\lambda_k f_k(y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $，可以看出其中的正规因子是全局的，并不是局部的，这样就保证了对局部信息的处理具有全局一致性。</p>\n<p>##　推断<br>所谓的推断问题就是在CRF给定参数$\\lambda$和$\\mu$，我们可以找到$y^{\\ast}$使得$P(y\\mid x)$最大。<br>$$ y^{\\ast} = argmax_y exp(\\sum_{i=1}^n (\\sum_k \\lambda_k f_k (y_i, y_{i-1}, X) + \\sum_l \\mu_l g_l (y_i, X))) $$<br>因为Z与y无关，最大值与y无关。为了解决优化问题，我们可以使用最大积算法在CRF上，这样类似了Viteerbi算法在HMM上的应用。</p>\n<h2 id=\"学习-1\"><a href=\"#学习-1\" class=\"headerlink\" title=\"学习\"></a>学习</h2><p>尽管整个图都是可观的，CRF的学习问题仍然是比较难于解决的。原因是学习中需要进行推断。给定训练集$\\lbrace x_d, y_d\\rbrace_{d=1}^N$，寻找到最优的$\\lambda^{\\ast}$和$\\mu^{\\ast}$。<br>\\begin{equation}\\begin{split} \\lambda^{\\ast}, \\mu^{\\ast} &amp;= argmax_{\\lambda, \\mu}\\prod_{d=1}^N P(y_d\\mid x_d, \\lambda, \\mu) \\\\<br>&amp;= argmax_{\\lambda, \\mu}\\prod_{d=1}^N \\frac{1}{Z(x_d, \\lambda, \\mu)}exp(\\sum_{i=1}^n (\\lambda^T f(y_{d, i} y_{d, i-1}, x_d) + \\mu^T g(y_{d,i}, x_d))) \\\\<br>&amp;= argmax_{\\lambda, \\mu}\\sum_{d=1}^T (\\sum_{i=1}^n(\\lambda^T f(y_{d,i}, y_{d, i-1}) + \\mu^T g(y_{d, i}, x_d)) - log\\ Z(x_d, \\lambda, \\mu)) \\\\<br>\\end{split}\\end{equation}<br>对$\\lambda$求偏导：<br>$$ \\Delta_{\\lambda}L(\\lambda, \\mu) = \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d))) $$<br>从上式中可以看出第一项是特征值，第二项是特征值的期望，另外对数判分函数以指数族的形式呈现时，其梯度是特征值的期望。<br>解决上面的式子需要处理指数级数量的数据求和，我们可以利用message passing算法来计算对势，这样得到一个闭环的形式。<br>\\begin{equation}\\begin{split} \\sum_y (P(y\\mid x_d)\\sum_{i=1}^n f(y_i, y_{i-1}, x_d)) &amp;= \\sum_{i=1}^n(\\sum_y f(y_i, y_{i-1}, x_d) P(y\\mid x_d)) \\\\<br>&amp;= \\sum_{i=1}^n(\\sum_{y_i, y_{i-1}} f(y_i, y_{i-1}, x_d) P(y_i, y_{i-1}\\mid x_d)) \\\\<br>\\end{split}\\end{equation}<br>这样意味着，学习过程中包含有推断过程，通过message passing算法，学习过程只需要多项式时间久可以完成。<br>下面使用校准势来计算特征期望：<br>\\begin{equation}\\begin{split} \\Delta_{\\lambda}L(\\lambda, \\mu) &amp;= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \\sum_y (P(y\\mid x_d) \\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d)))  \\\\<br>&amp;= \\sum_{d=1}^N(\\sum_{i=1}^n f(y_{d,i}, y_{d,i-1】， x_d} - \\sum_{y_i, y_{i-1}}\\alpha’(y_i, y_{i-1}) f(y_d, y_{d, i-1}, x_d))) \\\\<br>\\end{split}\\end{equation}<br>其中$\\alpha’(y_i, y_{i-1}, x_d) = P(y_i, y_{i-1}\\mid x_d)$。我们可以使用梯度上升法学习参数。<br>$$ \\lambda^{(t+1)} = \\lambda^{(t)} + \\eta\\Delta_{\\lambda}L(\\lambda^{(t)}, \\mu^{(t)}) $$     $$ \\mu^{(t+1)} = \\mu^{(t)} + \\eta\\Delta_{\\mu}L(\\lambda^{(t)}, \\mu^{(t)}) $$<br>在实际中，我们会加入正则项来提高参数的泛化能力。<br>$$ \\lambda^{\\ast}, \\mu^{\\ast} = argmax_{\\lambda, \\mu}\\sum_{d=1}^N log\\ P(y_d\\mid x_d, \\lambda, \\mu) - \\frac{1}{2\\sigma^2} (\\lambda^T \\lambda + \\mu^T\\mu) $$<br>第二项叫做高斯先验，因为我们想让$\\lambda^{\\ast},\\mu^{\\ast}$趋近于0,这样可以减少特征值的数量。第二项也能叫做拉普拉斯先验，在条件概率中，我们不想看到零概率出现，因为零概率是病态的。梯度上升法收敛速度较慢，以使用共轭梯度法和拟牛顿法来加快速度。<br>从经验的表现来看，CRF比HMM和MEMM有所提升，特别是当非局部的影响明显时。虽然提升不够明显，但是CRF为一系列的问题的解决提供了很好的范例。CRF的另一优点是能够让使用者灵活的自己设计随机特征。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>EM算法适应于处理存在隐变量的最大似然估计问题。</li>\n<li>GMM和HMM被用于对静态和动态混合模型建模。</li>\n<li>实现HMM主要需要处理的问题是，学习，推断和最大似然。推断可以通过前向和后向算法(变量去除)实现；最大似然问题可以通过Viterbi算法(最大积)实现；学习问题可以通过直接最大似然后者EM算法解决。</li>\n<li>HMM具有十分强的马尔科夫性。HMM只能获得局部的关系，对于HMM的扩展MEMM，MEMM可以获得状态和全部可观序列之间的显性关系。但是，MEMM存在着标注偏置的问题。</li>\n<li>CRF是部分有向的模型，其中转态之间是无向的，CRF使用全局的正规项克服了MEMM的标注偏置的问题。对于线性链式CRF，精确推断并不是困难的。推断问题可以通过最大积算法通过junction tree解决。学习问题可以通过梯度上升来解决最大似然。</li>\n<li>具有任意图结构的CRF，精确推断就是比较困难的事情，这时就需要近似推断了，比如：采样，变分推断，loopy belief propagation。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Wallach H M. Conditional random fields: An introduction[J]. Technical Reports (CIS), 2004: 22.<br>注：本文主要参考[1]中第12讲视频以及笔记。另外，本文中公式的和全部采用\\sum，本文之前使用的都是\\Sigma，后面也会使用\\sum。</p>\n"},{"title":"KL散度","date":"2018-11-27T07:59:48.000Z","_content":"很久没有推导过公式了，感觉水平退步显著，今日看变分推断内容，看到了计算两个高斯分布间的KL散度，下面我自己推导了一下。\n\n# 高斯分布间的KL散度\n现有先验分布$p_{\\theta}(z) = \\boldsymbol{N}(0, \\boldsymbol{I})$，后验分布$q_{\\phi}(\\boldsymbol{z}\\mid \\boldsymbol{x}^{(i)})$同样是高斯分布。变量$z$的维数是$J$。其中，$\\boldsymbol{u}$和$\\boldsymbol{\\sigma}$记作点$i$的均值和标准差。另外，$\\mu_j$和$\\sigma_j$是均值和方差向量的第$j$个因子。\nKL散度的公式如下：\n\\begin{equation}\\begin{split}\nD_{KL}(q_{\\phi}(\\boldsymbol{z})|| p_{\\theta}(\\boldsymbol{z})) &= \\int q_{\\phi}(\\boldsymbol{z}) log \\frac{q_{\\phi}(\\boldsymbol{z})} {p_{\\theta}(\\boldsymbol{z})} d\\boldsymbol{z}\\\\\\\\\n&= \\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} - \\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\\\\\\n\\end{split}\\end{equation}\n第二项如下所示(因为先写的第二项，小声bb.jpg)：\n\\begin{equation}\\begin{split}\n\\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} &= \\int \\mathcal{N}(\\boldsymbol{z;\\mu, \\sigma^2}) log \\mathcal{N}(\\boldsymbol{z; 0, I})d \\boldsymbol{z} \\\\\\\\\n&= \\int -\\frac{1}{2} log{2\\pi}\\ q_{\\phi}(\\boldsymbol{z}) -\\frac{z^2}{2} q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) \\boldsymbol{z}^2 d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{z- \\mu + \\mu})^2 d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2 +2(\\boldsymbol{z - \\mu})\\boldsymbol{\\mu}] d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2)] d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{\\sigma}^2 + \\boldsymbol{\\mu}^2) d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2)\n\\end{split}\\end{equation}\n\n同样，第一项可以写成如下的形式：\n\\begin{equation}\\begin{split}\n\\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} &= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2)\n\\end{split}\\end{equation}\n将上面两项合并一起：\n\\begin{equation}\\begin{split}\nD_{KL}(q_{\\phi}(\\boldsymbol{z}) || p_{\\theta}(\\boldsymbol{z})) &= \\int q_{\\phi}(\\boldsymbol{z}) log (q_{\\phi}(\\boldsymbol{z}) - p_{\\theta}(\\boldsymbol{z})) d\\boldsymbol{z}\\\\\\\\\n&= -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2) + \\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2) \\\\\\\\\n&= \\frac{1}{2} \\sum_{j=1}^{J} (-1 - log\\ \\sigma_j^2 + \\mu_j^2 + \\sigma_j^2)\n\\end{split}\\end{equation}\n\n# 参考文献\nKingma D P. Variational inference & deep learning: A new synthesis[D]. 2017.\n","source":"_posts/KL散度.md","raw":"---\ntitle: KL散度\ndate: 2018-11-27 15:59:48\ntags: KL散度\ncategories: 学习\n---\n很久没有推导过公式了，感觉水平退步显著，今日看变分推断内容，看到了计算两个高斯分布间的KL散度，下面我自己推导了一下。\n\n# 高斯分布间的KL散度\n现有先验分布$p_{\\theta}(z) = \\boldsymbol{N}(0, \\boldsymbol{I})$，后验分布$q_{\\phi}(\\boldsymbol{z}\\mid \\boldsymbol{x}^{(i)})$同样是高斯分布。变量$z$的维数是$J$。其中，$\\boldsymbol{u}$和$\\boldsymbol{\\sigma}$记作点$i$的均值和标准差。另外，$\\mu_j$和$\\sigma_j$是均值和方差向量的第$j$个因子。\nKL散度的公式如下：\n\\begin{equation}\\begin{split}\nD_{KL}(q_{\\phi}(\\boldsymbol{z})|| p_{\\theta}(\\boldsymbol{z})) &= \\int q_{\\phi}(\\boldsymbol{z}) log \\frac{q_{\\phi}(\\boldsymbol{z})} {p_{\\theta}(\\boldsymbol{z})} d\\boldsymbol{z}\\\\\\\\\n&= \\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} - \\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\\\\\\n\\end{split}\\end{equation}\n第二项如下所示(因为先写的第二项，小声bb.jpg)：\n\\begin{equation}\\begin{split}\n\\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} &= \\int \\mathcal{N}(\\boldsymbol{z;\\mu, \\sigma^2}) log \\mathcal{N}(\\boldsymbol{z; 0, I})d \\boldsymbol{z} \\\\\\\\\n&= \\int -\\frac{1}{2} log{2\\pi}\\ q_{\\phi}(\\boldsymbol{z}) -\\frac{z^2}{2} q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) \\boldsymbol{z}^2 d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{z- \\mu + \\mu})^2 d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2 +2(\\boldsymbol{z - \\mu})\\boldsymbol{\\mu}] d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2)] d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{\\sigma}^2 + \\boldsymbol{\\mu}^2) d\\boldsymbol{z} \\\\\\\\\n&= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2)\n\\end{split}\\end{equation}\n\n同样，第一项可以写成如下的形式：\n\\begin{equation}\\begin{split}\n\\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} &= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2)\n\\end{split}\\end{equation}\n将上面两项合并一起：\n\\begin{equation}\\begin{split}\nD_{KL}(q_{\\phi}(\\boldsymbol{z}) || p_{\\theta}(\\boldsymbol{z})) &= \\int q_{\\phi}(\\boldsymbol{z}) log (q_{\\phi}(\\boldsymbol{z}) - p_{\\theta}(\\boldsymbol{z})) d\\boldsymbol{z}\\\\\\\\\n&= -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2) + \\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2) \\\\\\\\\n&= \\frac{1}{2} \\sum_{j=1}^{J} (-1 - log\\ \\sigma_j^2 + \\mu_j^2 + \\sigma_j^2)\n\\end{split}\\end{equation}\n\n# 参考文献\nKingma D P. Variational inference & deep learning: A new synthesis[D]. 2017.\n","slug":"KL散度","published":1,"updated":"2018-11-27T12:24:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms8000c1ouzpp39siyq","content":"<p>很久没有推导过公式了，感觉水平退步显著，今日看变分推断内容，看到了计算两个高斯分布间的KL散度，下面我自己推导了一下。</p>\n<h1 id=\"高斯分布间的KL散度\"><a href=\"#高斯分布间的KL散度\" class=\"headerlink\" title=\"高斯分布间的KL散度\"></a>高斯分布间的KL散度</h1><p>现有先验分布$p_{\\theta}(z) = \\boldsymbol{N}(0, \\boldsymbol{I})$，后验分布$q_{\\phi}(\\boldsymbol{z}\\mid \\boldsymbol{x}^{(i)})$同样是高斯分布。变量$z$的维数是$J$。其中，$\\boldsymbol{u}$和$\\boldsymbol{\\sigma}$记作点$i$的均值和标准差。另外，$\\mu_j$和$\\sigma_j$是均值和方差向量的第$j$个因子。<br>KL散度的公式如下：<br>\\begin{equation}\\begin{split}<br>D_{KL}(q_{\\phi}(\\boldsymbol{z})|| p_{\\theta}(\\boldsymbol{z})) &amp;= \\int q_{\\phi}(\\boldsymbol{z}) log \\frac{q_{\\phi}(\\boldsymbol{z})} {p_{\\theta}(\\boldsymbol{z})} d\\boldsymbol{z}\\\\<br>&amp;= \\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} - \\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\<br>\\end{split}\\end{equation}<br>第二项如下所示(因为先写的第二项，小声bb.jpg)：<br>\\begin{equation}\\begin{split}<br>\\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} &amp;= \\int \\mathcal{N}(\\boldsymbol{z;\\mu, \\sigma^2}) log \\mathcal{N}(\\boldsymbol{z; 0, I})d \\boldsymbol{z} \\\\<br>&amp;= \\int -\\frac{1}{2} log{2\\pi}\\ q_{\\phi}(\\boldsymbol{z}) -\\frac{z^2}{2} q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) \\boldsymbol{z}^2 d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{z- \\mu + \\mu})^2 d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2 +2(\\boldsymbol{z - \\mu})\\boldsymbol{\\mu}] d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2)] d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{\\sigma}^2 + \\boldsymbol{\\mu}^2) d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2)<br>\\end{split}\\end{equation}</p>\n<p>同样，第一项可以写成如下的形式：<br>\\begin{equation}\\begin{split}<br>\\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} &amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2)<br>\\end{split}\\end{equation}<br>将上面两项合并一起：<br>\\begin{equation}\\begin{split}<br>D_{KL}(q_{\\phi}(\\boldsymbol{z}) || p_{\\theta}(\\boldsymbol{z})) &amp;= \\int q_{\\phi}(\\boldsymbol{z}) log (q_{\\phi}(\\boldsymbol{z}) - p_{\\theta}(\\boldsymbol{z})) d\\boldsymbol{z}\\\\<br>&amp;= -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2) + \\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2) \\\\<br>&amp;= \\frac{1}{2} \\sum_{j=1}^{J} (-1 - log\\ \\sigma_j^2 + \\mu_j^2 + \\sigma_j^2)<br>\\end{split}\\end{equation}</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>Kingma D P. Variational inference &amp; deep learning: A new synthesis[D]. 2017.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>很久没有推导过公式了，感觉水平退步显著，今日看变分推断内容，看到了计算两个高斯分布间的KL散度，下面我自己推导了一下。</p>\n<h1 id=\"高斯分布间的KL散度\"><a href=\"#高斯分布间的KL散度\" class=\"headerlink\" title=\"高斯分布间的KL散度\"></a>高斯分布间的KL散度</h1><p>现有先验分布$p_{\\theta}(z) = \\boldsymbol{N}(0, \\boldsymbol{I})$，后验分布$q_{\\phi}(\\boldsymbol{z}\\mid \\boldsymbol{x}^{(i)})$同样是高斯分布。变量$z$的维数是$J$。其中，$\\boldsymbol{u}$和$\\boldsymbol{\\sigma}$记作点$i$的均值和标准差。另外，$\\mu_j$和$\\sigma_j$是均值和方差向量的第$j$个因子。<br>KL散度的公式如下：<br>\\begin{equation}\\begin{split}<br>D_{KL}(q_{\\phi}(\\boldsymbol{z})|| p_{\\theta}(\\boldsymbol{z})) &amp;= \\int q_{\\phi}(\\boldsymbol{z}) log \\frac{q_{\\phi}(\\boldsymbol{z})} {p_{\\theta}(\\boldsymbol{z})} d\\boldsymbol{z}\\\\<br>&amp;= \\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} - \\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\<br>\\end{split}\\end{equation}<br>第二项如下所示(因为先写的第二项，小声bb.jpg)：<br>\\begin{equation}\\begin{split}<br>\\int q_{\\phi}(\\boldsymbol{z}) log p_{\\theta}(\\boldsymbol{z}) d\\boldsymbol{z} &amp;= \\int \\mathcal{N}(\\boldsymbol{z;\\mu, \\sigma^2}) log \\mathcal{N}(\\boldsymbol{z; 0, I})d \\boldsymbol{z} \\\\<br>&amp;= \\int -\\frac{1}{2} log{2\\pi}\\ q_{\\phi}(\\boldsymbol{z}) -\\frac{z^2}{2} q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) \\boldsymbol{z}^2 d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{z- \\mu + \\mu})^2 d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2 +2(\\boldsymbol{z - \\mu})\\boldsymbol{\\mu}] d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) [(\\boldsymbol{z- \\mu})^2 + \\boldsymbol{\\mu}^2)] d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\int q_{\\phi}(\\boldsymbol{z}) (\\boldsymbol{\\sigma}^2 + \\boldsymbol{\\mu}^2) d\\boldsymbol{z} \\\\<br>&amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2)<br>\\end{split}\\end{equation}</p>\n<p>同样，第一项可以写成如下的形式：<br>\\begin{equation}\\begin{split}<br>\\int q_{\\phi}(\\boldsymbol{z}) log q_{\\phi}(\\boldsymbol{z}) d\\boldsymbol{z} &amp;= -\\frac{J}{2}log(2\\pi) -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2)<br>\\end{split}\\end{equation}<br>将上面两项合并一起：<br>\\begin{equation}\\begin{split}<br>D_{KL}(q_{\\phi}(\\boldsymbol{z}) || p_{\\theta}(\\boldsymbol{z})) &amp;= \\int q_{\\phi}(\\boldsymbol{z}) log (q_{\\phi}(\\boldsymbol{z}) - p_{\\theta}(\\boldsymbol{z})) d\\boldsymbol{z}\\\\<br>&amp;= -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log\\ \\sigma_j^2) + \\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2) \\\\<br>&amp;= \\frac{1}{2} \\sum_{j=1}^{J} (-1 - log\\ \\sigma_j^2 + \\mu_j^2 + \\sigma_j^2)<br>\\end{split}\\end{equation}</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>Kingma D P. Variational inference &amp; deep learning: A new synthesis[D]. 2017.</p>\n"},{"title":"MRI读取与可视化I","date":"2018-10-18T11:00:40.000Z","_content":"今天在网上看了一些读取MRI文件的方法，中文的博客并不是很多，另外很多并不适合我的文件格式，本文主要是针对MRI中采用NIFTI(.nii.g其中gz是压缩文件)格式的文件，并进行可视化分析。\n# NIBabel\nNIBabel是一个常见的读写神经医学文件的python库，包括ANALYZE, GIFTI, NIfTI2, MINC1, MINC2, MGH和ECAT，还有Philips PAR/REC。\n下面我们用一张大脑的[MRI图片](http://nipy.org/nibabel/_downloads/someones_epi.nii.gz)，来说这个库的使用，以及MRI文件的格式。\n```python\nimport nibabel as nib\nimg = nib.load('downloads/someones_epi.nii.gz')\nimg_header = img.get_header()\nprint('Header: ', img_header)\nimg_data = img.get_fdata()\nprint('img_data shape: ', img_data.shape)\n```\n一个格式为NIFTI的格式文件，通常包括头文件和相应的图像文件。图像文件时三维的，上面的MRI图片的shape为(53, 61, 33)。下面我们将三个维度的中间slice进行可视化(因为不会直接将三维的图像可视化)。\n\n# 可视化\n下面我们显示中间的slice：\n```python\nplt.subplot(1, 3, 1)\nplt.imshow(img_data[26, :, :])\nplt.subplot(1, 3, 2)\nplt.imshow(img_data[:, 30, :])\nplt.subplot(1, 3, 3)\nplt.imshow(img_data[:, :, 15])\nplt.show()\n```\n\n# 下面的工作\n利用pytorch读取文件，训练神机网络。(可能不会上传到本博客中)\n\n\n\n\n# 参考资料\n[1] http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array","source":"_posts/MRI读取与可视化I.md","raw":"---\ntitle: MRI读取与可视化I\ndate: 2018-10-18 19:00:40\ntags: Medical Image\ncategories: 学习\n---\n今天在网上看了一些读取MRI文件的方法，中文的博客并不是很多，另外很多并不适合我的文件格式，本文主要是针对MRI中采用NIFTI(.nii.g其中gz是压缩文件)格式的文件，并进行可视化分析。\n# NIBabel\nNIBabel是一个常见的读写神经医学文件的python库，包括ANALYZE, GIFTI, NIfTI2, MINC1, MINC2, MGH和ECAT，还有Philips PAR/REC。\n下面我们用一张大脑的[MRI图片](http://nipy.org/nibabel/_downloads/someones_epi.nii.gz)，来说这个库的使用，以及MRI文件的格式。\n```python\nimport nibabel as nib\nimg = nib.load('downloads/someones_epi.nii.gz')\nimg_header = img.get_header()\nprint('Header: ', img_header)\nimg_data = img.get_fdata()\nprint('img_data shape: ', img_data.shape)\n```\n一个格式为NIFTI的格式文件，通常包括头文件和相应的图像文件。图像文件时三维的，上面的MRI图片的shape为(53, 61, 33)。下面我们将三个维度的中间slice进行可视化(因为不会直接将三维的图像可视化)。\n\n# 可视化\n下面我们显示中间的slice：\n```python\nplt.subplot(1, 3, 1)\nplt.imshow(img_data[26, :, :])\nplt.subplot(1, 3, 2)\nplt.imshow(img_data[:, 30, :])\nplt.subplot(1, 3, 3)\nplt.imshow(img_data[:, :, 15])\nplt.show()\n```\n\n# 下面的工作\n利用pytorch读取文件，训练神机网络。(可能不会上传到本博客中)\n\n\n\n\n# 参考资料\n[1] http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array","slug":"MRI读取与可视化I","published":1,"updated":"2018-10-18T12:09:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40ms9000d1ouzc6bdq7pz","content":"<p>今天在网上看了一些读取MRI文件的方法，中文的博客并不是很多，另外很多并不适合我的文件格式，本文主要是针对MRI中采用NIFTI(.nii.g其中gz是压缩文件)格式的文件，并进行可视化分析。</p>\n<h1 id=\"NIBabel\"><a href=\"#NIBabel\" class=\"headerlink\" title=\"NIBabel\"></a>NIBabel</h1><p>NIBabel是一个常见的读写神经医学文件的python库，包括ANALYZE, GIFTI, NIfTI2, MINC1, MINC2, MGH和ECAT，还有Philips PAR/REC。<br>下面我们用一张大脑的<a href=\"http://nipy.org/nibabel/_downloads/someones_epi.nii.gz\" target=\"_blank\" rel=\"noopener\">MRI图片</a>，来说这个库的使用，以及MRI文件的格式。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nibabel <span class=\"keyword\">as</span> nib</span><br><span class=\"line\">img = nib.load(<span class=\"string\">'downloads/someones_epi.nii.gz'</span>)</span><br><span class=\"line\">img_header = img.get_header()</span><br><span class=\"line\">print(<span class=\"string\">'Header: '</span>, img_header)</span><br><span class=\"line\">img_data = img.get_fdata()</span><br><span class=\"line\">print(<span class=\"string\">'img_data shape: '</span>, img_data.shape)</span><br></pre></td></tr></table></figure></p>\n<p>一个格式为NIFTI的格式文件，通常包括头文件和相应的图像文件。图像文件时三维的，上面的MRI图片的shape为(53, 61, 33)。下面我们将三个维度的中间slice进行可视化(因为不会直接将三维的图像可视化)。</p>\n<h1 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h1><p>下面我们显示中间的slice：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">plt.imshow(img_data[<span class=\"number\">26</span>, :, :])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">plt.imshow(img_data[:, <span class=\"number\">30</span>, :])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">plt.imshow(img_data[:, :, <span class=\"number\">15</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"下面的工作\"><a href=\"#下面的工作\" class=\"headerlink\" title=\"下面的工作\"></a>下面的工作</h1><p>利用pytorch读取文件，训练神机网络。(可能不会上传到本博客中)</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] <a href=\"http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array\" target=\"_blank\" rel=\"noopener\">http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>今天在网上看了一些读取MRI文件的方法，中文的博客并不是很多，另外很多并不适合我的文件格式，本文主要是针对MRI中采用NIFTI(.nii.g其中gz是压缩文件)格式的文件，并进行可视化分析。</p>\n<h1 id=\"NIBabel\"><a href=\"#NIBabel\" class=\"headerlink\" title=\"NIBabel\"></a>NIBabel</h1><p>NIBabel是一个常见的读写神经医学文件的python库，包括ANALYZE, GIFTI, NIfTI2, MINC1, MINC2, MGH和ECAT，还有Philips PAR/REC。<br>下面我们用一张大脑的<a href=\"http://nipy.org/nibabel/_downloads/someones_epi.nii.gz\" target=\"_blank\" rel=\"noopener\">MRI图片</a>，来说这个库的使用，以及MRI文件的格式。<br><!--�12--></p>\n<p>一个格式为NIFTI的格式文件，通常包括头文件和相应的图像文件。图像文件时三维的，上面的MRI图片的shape为(53, 61, 33)。下面我们将三个维度的中间slice进行可视化(因为不会直接将三维的图像可视化)。</p>\n<h1 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h1><p>下面我们显示中间的slice：<br><!--�13--></p>\n<h1 id=\"下面的工作\"><a href=\"#下面的工作\" class=\"headerlink\" title=\"下面的工作\"></a>下面的工作</h1><p>利用pytorch读取文件，训练神机网络。(可能不会上传到本博客中)</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] <a href=\"http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array\" target=\"_blank\" rel=\"noopener\">http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array</a></p>\n"},{"title":"Pytorch Tutorial","date":"2018-10-12T16:00:00.000Z","_content":"# 写在前面的话\n本文主要是基于Pytorch给出的官方[Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)，然后我按照自己的喜好编辑成Jupyter文档，后转成本博客，用来作为自己的日常参照材料。\n\n# Pytorch\nPytorch给我的感觉是：它是基于更高级的封装，实现深度学习更加简单，比较适合科研型的或者是实现一些想法的入门级选手。Tensorflow更适合工程项目，能够比较高效的运行。但是对于一般选手来说，Pytorch更适合，因为它是动态图，在个人代码水平不是很高的情况下，Pytorch的效率是高于Tensorflow的。\n\n```python\nfrom __future__ import print_function\nimport torch\ndevice = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n```\n\n# Tensors\n\n\n```python\n# Contruct a 2x1 matric, uninitialized:\nx = torch.empty(2, 1, device=device)\nprint(x)\n\n```\n\n    tensor([[0.0000],\n            [0.0000]])\n    \n\n\n```python\n# Construct a randomly initialized matrix:\nx = torch.rand(5, 3, device=device)\nprint(x)\n```\n\n    tensor([[0.2854, 0.5359, 0.7811],\n            [0.1065, 0.0246, 0.3945],\n            [0.8341, 0.6808, 0.4578],\n            [0.4257, 0.7255, 0.3597],\n            [0.3510, 0.3170, 0.1526]])\n    \n\n\n```python\n# Construct a matrix filled zeros and dtype long\nx = torch.zeros(2, 1, dtype=torch.long, device=device)\nprint(x)\n```\n\n    tensor([[0],\n            [0]])\n    \n\n\n```python\n# Construct a tensor directly from data;\nx = torch.tensor([3, 3])\nprint(x)\n```\n\n    tensor([3, 3])\n    \n\n\n```python\nx = x.new_ones(2, 1, dtype=torch.double) # new_* methods take in size\nprint(x)\n\nx = torch.randn_like(x, dtype=torch.float) # override dype and result has same size\nprint(x)\n```\n\n    tensor([[1.],\n            [1.]], dtype=torch.float64)\n    tensor([[1.4535],\n            [0.0968]])\n    \n\n\n```python\n# get its size\nprint(x.size())\n\nprint(x.shape)\n```\n\n    torch.Size([2, 1])\n    torch.Size([2, 1])\n    \n\n# Opertions\n\n\n```python\n# Addition\nx = x.new_ones(3, 2, dtype=torch.float)\ny = torch.rand(3, 2, dtype=torch.float)\nprint(x + y) # syntax 1\nprint(torch.add(x, y)) # syntax 2\nresult = torch.empty(5, 6)\ntorch.add(x, y, out=result) # add x and y to result\nprint(result)\ny.add_(x)\nprint(y) # add x to y \n```\n\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    \n\n注：任何tensor后面带有下划线都会改变tensor的值，比如x.copy_(y), x.t_(x)\n\n\n```python\nx = torch.rand(3, 2)\nprint(x)\nprint(x[:, 1])\n```\n\n    tensor([[0.8368, 0.9204],\n            [0.3797, 0.0908],\n            [0.4454, 0.7684]])\n    tensor([0.9204, 0.0908, 0.7684])\n    \n\n\n```python\n# resizing\nx = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8) # the size -1 is inferred from other dimensions\nprint(x.size(), y.size(), z.size())\n```\n\n    torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n    \n\n\n```python\n# Converting Numpy Array to Torch Tensor\nimport numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)\n```\n\n    [2. 2. 2. 2. 2.]\n    tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n    \n\n\n```python\n# CUDA Tensor\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    y = torch.ones_like(x, device=device)\n    x = x.to(device)\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))\n```\n\n# Define the Network\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n```\n\n本来这个网络应该是LeNet的，输入要求是32x32，我改变了第一个全连接层，将输入变为了20x20。\n所以网络结构可以通过自己的想法进行改变，最重要的是改变全连接层就可以了。\n网络经过卷积之后输入的结果公式为：$$ outputsize = （inputsize - kernelsize + 2 * pad）/stride + 1 $$\n\n\n```python\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 2 * 2, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # if the size is a square you can only specify a single number \n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_feature(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        return x\n    \n    def num_flat_feature(self, x):\n        size = x.size()[1:] # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s \n        return num_features\nnet = Net()\nprint(net)\n```\n\n    Net(\n      (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n      (fc1): Linear(in_features=64, out_features=120, bias=True)\n      (fc2): Linear(in_features=120, out_features=84, bias=True)\n      (fc3): Linear(in_features=84, out_features=10, bias=True)\n    )\n    \n\n\n```python\n# The learnable parameter of a model are returned by net.parameters()\nparams = list(net.parameters())\nprint(len(params))\nprint(params[0].size()) # conv1's .weights\n```\n\n    10\n    torch.Size([6, 1, 5, 5])\n    \n\n\n```python\ninput = torch.randn(1, 1, 20, 20)\nout = net(input)\nprint(out)\n```\n\n    tensor([[0.0432, 0.1072, 0.0000, 0.1096, 0.0378, 0.0000, 0.0000, 0.0000, 0.0202,\n             0.0000]], grad_fn=<ReluBackward>)\n    \n\n## zero the gradients\n\n\n\n```python\nnet.zero_grad()\nout.backward(torch.randn(1, 10))\n```\n\ntorch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\nFor example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\nIf you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.\n\n## Loss Function\n\n\n```python\nout = net(input)\ntarget = torch.randn(10) # a dummy target, for example \ntarget = target.view(1, -1)\ncriterion = nn.MSELoss()\n\nloss = criterion(out, target)\nprint(loss)\n```\n\n    tensor(1.7536, grad_fn=<MseLossBackward>)\n    \n\nforward:\ninput -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n    \n\n\n```python\nprint(loss.grad_fn) # MSELoss\nprint(loss.grad_fn.next_functions[0][0]) # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # relu \n```\n\n    <MseLossBackward object at 0x0000000008619780>\n    <ReluBackward object at 0x0000000008619A58>\n    <ThAddmmBackward object at 0x0000000008619780>\n    \n\n## Backpropagate\n\n\n```python\nnet.zero_grad() # zeros the gradient buffer of all parameters \nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\n# loss.backward() # 为了和下面的产生两次相同的backpropagate，所以将这里注释，下一个单元也是这样。\n\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n```\n\n    conv1.bias.grad before backward\n    tensor([0., 0., 0., 0., 0., 0.])\n    conv1.bias.grad before backward\n    tensor([0., 0., 0., 0., 0., 0.])\n    \n\n\n```python\n## Weights\n# learning_rate = 0.01\n# for f in net.parameters():\n#     f.data.sub_(f.grad.data * learning_rate)  # f = f - learning_rate * gradient\n```\n\n\n```python\nimport torch.optim as optim\n\n# creater your optimizer\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# in your training loop \noptimizer.zero_grad() # zero the gradient buffers\noutput = net(input)\nloss = criterion(out, target)\nloss.backward()\noptimizer.step() # Does the update \n```\n\n# Training A Classifier\n\n\n```python\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n```\n\n\n```python\n# The output of torchvision datasets are PILImage iamges of range [0, 1]. We transform them to Tensor of normalized range [-1, 1]\ntransform = transforms.Compose(\n[transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n                                       download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, \n                                      download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4, \n                                              shuffle=False, num_workers=2)\nclasses = ('plane', 'car', 'bird', 'cat', \n          'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n```\n\n    Files already downloaded and verified\n    Files already downloaded and verified\n    \n\n\n```python\nimport matplotlib.pyplot as plt \nimport numpy as np\n\ndef imshow(img):\n    img = img/2 + 0.5 # unnormalize\n    npimg = img.numpy()\n#     print(npimg.shape)\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n#     print(np.transpose(npimg, (1, 2, 0)).shape)\n    \n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n# print(labels)\n# show images\nimshow(torchvision.utils.make_grid(images)) # 制作图像网格\nplt.show()\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n```\n\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_35_0%20.png)\n\n\n     deer truck plane horse\n    \n\n## Define a Convolution Neural Network\n\n\n```python\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nnet.to(device)\nprint(net)\n```\n\n    Net(\n      (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n      (fc1): Linear(in_features=400, out_features=120, bias=True)\n      (fc2): Linear(in_features=120, out_features=84, bias=True)\n      (fc3): Linear(in_features=84, out_features=10, bias=True)\n    )\n    \n\n## Define a Loss function and opotimizer\n\n\n```python\nimport  torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\n## Train the network \n\n\n```python\nfor epoch in range(2):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs \n        inputs, labels = data \n        inputs, labels = inputs.to(device), labels.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward  + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999: # print every 2000 mini-batches \n            print('[%d, %5d] loss: %.3f' % \n                 (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\nprint('Finished Training')\n```\n\n    [1,  2000] loss: 2.217\n    [1,  4000] loss: 1.855\n    [1,  6000] loss: 1.672\n    [1,  8000] loss: 1.570\n    [1, 10000] loss: 1.506\n    [1, 12000] loss: 1.461\n    [2,  2000] loss: 1.370\n    [2,  4000] loss: 1.369\n    [2,  6000] loss: 1.340\n    [2,  8000] loss: 1.323\n    [2, 10000] loss: 1.276\n    [2, 12000] loss: 1.279\n    Finished Training\n    \n\n\n```python\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images \nimshow(torchvision.utils.make_grid(images))\nplt.show()\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n```\n\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_42_0.png)\n\n\n    GroundTruth:    cat  ship  ship plane\n    \n\n\n```python\noutputs = net(images)\nprint(outputs)\n```\n\n    tensor([[-0.7807, -1.7329,  0.9516,  1.8043, -1.2077,  0.7349,  1.3615, -1.5412,\n              1.0311, -1.7234],\n            [ 5.2413,  6.1315, -1.7400, -3.2287, -5.0497, -5.8038, -4.2375, -4.4465,\n              7.7529,  4.1842],\n            [ 2.7686,  3.8909, -0.7050, -1.7185, -3.2625, -3.2960, -2.2888, -2.6324,\n              3.8761,  2.4697],\n            [ 4.0929,  1.8480,  0.1962, -1.7907, -1.6931, -3.4538, -2.2210, -3.0694,\n              4.5059,  0.7960]], grad_fn=<ThAddmmBackward>)\n    \n\n\n```python\n_, predicted = torch.max(outputs, 1)\nprint(predicted)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n```\n\n    tensor([3, 8, 1, 8])\n    Predicted:    cat  ship   car  ship\n    \n\n\n```python\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n#         print(labels)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))\n```\n\n    Accuracy of the network on the 10000 test images: 54 %\n    \n\n\n```python\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1) # torch.max 可以返回最大值和对应的坐标，np.random.randn只能返回最大值\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))\n```\n\n    Accuracy of plane : 55 %\n    Accuracy of   car : 59 %\n    Accuracy of  bird : 65 %\n    Accuracy of   cat : 29 %\n    Accuracy of  deer : 22 %\n    Accuracy of   dog : 49 %\n    Accuracy of  frog : 71 %\n    Accuracy of horse : 55 %\n    Accuracy of  ship : 75 %\n    Accuracy of truck : 62 %\n    \n","source":"_posts/Pytorch_Tutorial.md","raw":"---\ntitle: Pytorch Tutorial\ndate: 2018-10-13 \ntags: Pytorch\ncategories: 学习\n---\n# 写在前面的话\n本文主要是基于Pytorch给出的官方[Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)，然后我按照自己的喜好编辑成Jupyter文档，后转成本博客，用来作为自己的日常参照材料。\n\n# Pytorch\nPytorch给我的感觉是：它是基于更高级的封装，实现深度学习更加简单，比较适合科研型的或者是实现一些想法的入门级选手。Tensorflow更适合工程项目，能够比较高效的运行。但是对于一般选手来说，Pytorch更适合，因为它是动态图，在个人代码水平不是很高的情况下，Pytorch的效率是高于Tensorflow的。\n\n```python\nfrom __future__ import print_function\nimport torch\ndevice = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n```\n\n# Tensors\n\n\n```python\n# Contruct a 2x1 matric, uninitialized:\nx = torch.empty(2, 1, device=device)\nprint(x)\n\n```\n\n    tensor([[0.0000],\n            [0.0000]])\n    \n\n\n```python\n# Construct a randomly initialized matrix:\nx = torch.rand(5, 3, device=device)\nprint(x)\n```\n\n    tensor([[0.2854, 0.5359, 0.7811],\n            [0.1065, 0.0246, 0.3945],\n            [0.8341, 0.6808, 0.4578],\n            [0.4257, 0.7255, 0.3597],\n            [0.3510, 0.3170, 0.1526]])\n    \n\n\n```python\n# Construct a matrix filled zeros and dtype long\nx = torch.zeros(2, 1, dtype=torch.long, device=device)\nprint(x)\n```\n\n    tensor([[0],\n            [0]])\n    \n\n\n```python\n# Construct a tensor directly from data;\nx = torch.tensor([3, 3])\nprint(x)\n```\n\n    tensor([3, 3])\n    \n\n\n```python\nx = x.new_ones(2, 1, dtype=torch.double) # new_* methods take in size\nprint(x)\n\nx = torch.randn_like(x, dtype=torch.float) # override dype and result has same size\nprint(x)\n```\n\n    tensor([[1.],\n            [1.]], dtype=torch.float64)\n    tensor([[1.4535],\n            [0.0968]])\n    \n\n\n```python\n# get its size\nprint(x.size())\n\nprint(x.shape)\n```\n\n    torch.Size([2, 1])\n    torch.Size([2, 1])\n    \n\n# Opertions\n\n\n```python\n# Addition\nx = x.new_ones(3, 2, dtype=torch.float)\ny = torch.rand(3, 2, dtype=torch.float)\nprint(x + y) # syntax 1\nprint(torch.add(x, y)) # syntax 2\nresult = torch.empty(5, 6)\ntorch.add(x, y, out=result) # add x and y to result\nprint(result)\ny.add_(x)\nprint(y) # add x to y \n```\n\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    tensor([[1.9447, 1.9085],\n            [1.3177, 1.8074],\n            [1.1208, 1.8663]])\n    \n\n注：任何tensor后面带有下划线都会改变tensor的值，比如x.copy_(y), x.t_(x)\n\n\n```python\nx = torch.rand(3, 2)\nprint(x)\nprint(x[:, 1])\n```\n\n    tensor([[0.8368, 0.9204],\n            [0.3797, 0.0908],\n            [0.4454, 0.7684]])\n    tensor([0.9204, 0.0908, 0.7684])\n    \n\n\n```python\n# resizing\nx = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8) # the size -1 is inferred from other dimensions\nprint(x.size(), y.size(), z.size())\n```\n\n    torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n    \n\n\n```python\n# Converting Numpy Array to Torch Tensor\nimport numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)\n```\n\n    [2. 2. 2. 2. 2.]\n    tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n    \n\n\n```python\n# CUDA Tensor\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    y = torch.ones_like(x, device=device)\n    x = x.to(device)\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))\n```\n\n# Define the Network\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n```\n\n本来这个网络应该是LeNet的，输入要求是32x32，我改变了第一个全连接层，将输入变为了20x20。\n所以网络结构可以通过自己的想法进行改变，最重要的是改变全连接层就可以了。\n网络经过卷积之后输入的结果公式为：$$ outputsize = （inputsize - kernelsize + 2 * pad）/stride + 1 $$\n\n\n```python\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 2 * 2, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # if the size is a square you can only specify a single number \n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_feature(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        return x\n    \n    def num_flat_feature(self, x):\n        size = x.size()[1:] # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s \n        return num_features\nnet = Net()\nprint(net)\n```\n\n    Net(\n      (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n      (fc1): Linear(in_features=64, out_features=120, bias=True)\n      (fc2): Linear(in_features=120, out_features=84, bias=True)\n      (fc3): Linear(in_features=84, out_features=10, bias=True)\n    )\n    \n\n\n```python\n# The learnable parameter of a model are returned by net.parameters()\nparams = list(net.parameters())\nprint(len(params))\nprint(params[0].size()) # conv1's .weights\n```\n\n    10\n    torch.Size([6, 1, 5, 5])\n    \n\n\n```python\ninput = torch.randn(1, 1, 20, 20)\nout = net(input)\nprint(out)\n```\n\n    tensor([[0.0432, 0.1072, 0.0000, 0.1096, 0.0378, 0.0000, 0.0000, 0.0000, 0.0202,\n             0.0000]], grad_fn=<ReluBackward>)\n    \n\n## zero the gradients\n\n\n\n```python\nnet.zero_grad()\nout.backward(torch.randn(1, 10))\n```\n\ntorch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\nFor example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\nIf you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.\n\n## Loss Function\n\n\n```python\nout = net(input)\ntarget = torch.randn(10) # a dummy target, for example \ntarget = target.view(1, -1)\ncriterion = nn.MSELoss()\n\nloss = criterion(out, target)\nprint(loss)\n```\n\n    tensor(1.7536, grad_fn=<MseLossBackward>)\n    \n\nforward:\ninput -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n    \n\n\n```python\nprint(loss.grad_fn) # MSELoss\nprint(loss.grad_fn.next_functions[0][0]) # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # relu \n```\n\n    <MseLossBackward object at 0x0000000008619780>\n    <ReluBackward object at 0x0000000008619A58>\n    <ThAddmmBackward object at 0x0000000008619780>\n    \n\n## Backpropagate\n\n\n```python\nnet.zero_grad() # zeros the gradient buffer of all parameters \nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\n# loss.backward() # 为了和下面的产生两次相同的backpropagate，所以将这里注释，下一个单元也是这样。\n\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n```\n\n    conv1.bias.grad before backward\n    tensor([0., 0., 0., 0., 0., 0.])\n    conv1.bias.grad before backward\n    tensor([0., 0., 0., 0., 0., 0.])\n    \n\n\n```python\n## Weights\n# learning_rate = 0.01\n# for f in net.parameters():\n#     f.data.sub_(f.grad.data * learning_rate)  # f = f - learning_rate * gradient\n```\n\n\n```python\nimport torch.optim as optim\n\n# creater your optimizer\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# in your training loop \noptimizer.zero_grad() # zero the gradient buffers\noutput = net(input)\nloss = criterion(out, target)\nloss.backward()\noptimizer.step() # Does the update \n```\n\n# Training A Classifier\n\n\n```python\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n```\n\n\n```python\n# The output of torchvision datasets are PILImage iamges of range [0, 1]. We transform them to Tensor of normalized range [-1, 1]\ntransform = transforms.Compose(\n[transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n                                       download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, \n                                      download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4, \n                                              shuffle=False, num_workers=2)\nclasses = ('plane', 'car', 'bird', 'cat', \n          'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n```\n\n    Files already downloaded and verified\n    Files already downloaded and verified\n    \n\n\n```python\nimport matplotlib.pyplot as plt \nimport numpy as np\n\ndef imshow(img):\n    img = img/2 + 0.5 # unnormalize\n    npimg = img.numpy()\n#     print(npimg.shape)\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n#     print(np.transpose(npimg, (1, 2, 0)).shape)\n    \n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n# print(labels)\n# show images\nimshow(torchvision.utils.make_grid(images)) # 制作图像网格\nplt.show()\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n```\n\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_35_0%20.png)\n\n\n     deer truck plane horse\n    \n\n## Define a Convolution Neural Network\n\n\n```python\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nnet.to(device)\nprint(net)\n```\n\n    Net(\n      (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n      (fc1): Linear(in_features=400, out_features=120, bias=True)\n      (fc2): Linear(in_features=120, out_features=84, bias=True)\n      (fc3): Linear(in_features=84, out_features=10, bias=True)\n    )\n    \n\n## Define a Loss function and opotimizer\n\n\n```python\nimport  torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\n## Train the network \n\n\n```python\nfor epoch in range(2):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs \n        inputs, labels = data \n        inputs, labels = inputs.to(device), labels.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward  + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999: # print every 2000 mini-batches \n            print('[%d, %5d] loss: %.3f' % \n                 (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\nprint('Finished Training')\n```\n\n    [1,  2000] loss: 2.217\n    [1,  4000] loss: 1.855\n    [1,  6000] loss: 1.672\n    [1,  8000] loss: 1.570\n    [1, 10000] loss: 1.506\n    [1, 12000] loss: 1.461\n    [2,  2000] loss: 1.370\n    [2,  4000] loss: 1.369\n    [2,  6000] loss: 1.340\n    [2,  8000] loss: 1.323\n    [2, 10000] loss: 1.276\n    [2, 12000] loss: 1.279\n    Finished Training\n    \n\n\n```python\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images \nimshow(torchvision.utils.make_grid(images))\nplt.show()\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n```\n\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_42_0.png)\n\n\n    GroundTruth:    cat  ship  ship plane\n    \n\n\n```python\noutputs = net(images)\nprint(outputs)\n```\n\n    tensor([[-0.7807, -1.7329,  0.9516,  1.8043, -1.2077,  0.7349,  1.3615, -1.5412,\n              1.0311, -1.7234],\n            [ 5.2413,  6.1315, -1.7400, -3.2287, -5.0497, -5.8038, -4.2375, -4.4465,\n              7.7529,  4.1842],\n            [ 2.7686,  3.8909, -0.7050, -1.7185, -3.2625, -3.2960, -2.2888, -2.6324,\n              3.8761,  2.4697],\n            [ 4.0929,  1.8480,  0.1962, -1.7907, -1.6931, -3.4538, -2.2210, -3.0694,\n              4.5059,  0.7960]], grad_fn=<ThAddmmBackward>)\n    \n\n\n```python\n_, predicted = torch.max(outputs, 1)\nprint(predicted)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n```\n\n    tensor([3, 8, 1, 8])\n    Predicted:    cat  ship   car  ship\n    \n\n\n```python\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n#         print(labels)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))\n```\n\n    Accuracy of the network on the 10000 test images: 54 %\n    \n\n\n```python\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1) # torch.max 可以返回最大值和对应的坐标，np.random.randn只能返回最大值\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))\n```\n\n    Accuracy of plane : 55 %\n    Accuracy of   car : 59 %\n    Accuracy of  bird : 65 %\n    Accuracy of   cat : 29 %\n    Accuracy of  deer : 22 %\n    Accuracy of   dog : 49 %\n    Accuracy of  frog : 71 %\n    Accuracy of horse : 55 %\n    Accuracy of  ship : 75 %\n    Accuracy of truck : 62 %\n    \n","slug":"Pytorch_Tutorial","published":1,"updated":"2018-10-13T03:39:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msa000e1ouztt5nzvlw","content":"<h1 id=\"写在前面的话\"><a href=\"#写在前面的话\" class=\"headerlink\" title=\"写在前面的话\"></a>写在前面的话</h1><p>本文主要是基于Pytorch给出的官方<a href=\"https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\" target=\"_blank\" rel=\"noopener\">Tutorial</a>，然后我按照自己的喜好编辑成Jupyter文档，后转成本博客，用来作为自己的日常参照材料。</p>\n<h1 id=\"Pytorch\"><a href=\"#Pytorch\" class=\"headerlink\" title=\"Pytorch\"></a>Pytorch</h1><p>Pytorch给我的感觉是：它是基于更高级的封装，实现深度学习更加简单，比较适合科研型的或者是实现一些想法的入门级选手。Tensorflow更适合工程项目，能够比较高效的运行。但是对于一般选手来说，Pytorch更适合，因为它是动态图，在个人代码水平不是很高的情况下，Pytorch的效率是高于Tensorflow的。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> print_function</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">device = torch.device( <span class=\"string\">\"cuda\"</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"Tensors\"><a href=\"#Tensors\" class=\"headerlink\" title=\"Tensors\"></a>Tensors</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Contruct a 2x1 matric, uninitialized:</span></span><br><span class=\"line\">x = torch.empty(<span class=\"number\">2</span>, <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">print(x)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[0.0000],\n        [0.0000]])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Construct a randomly initialized matrix:</span></span><br><span class=\"line\">x = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>, device=device)</span><br><span class=\"line\">print(x)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[0.2854, 0.5359, 0.7811],\n        [0.1065, 0.0246, 0.3945],\n        [0.8341, 0.6808, 0.4578],\n        [0.4257, 0.7255, 0.3597],\n        [0.3510, 0.3170, 0.1526]])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Construct a matrix filled zeros and dtype long</span></span><br><span class=\"line\">x = torch.zeros(<span class=\"number\">2</span>, <span class=\"number\">1</span>, dtype=torch.long, device=device)</span><br><span class=\"line\">print(x)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[0],\n        [0]])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Construct a tensor directly from data;</span></span><br><span class=\"line\">x = torch.tensor([<span class=\"number\">3</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">print(x)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([3, 3])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = x.new_ones(<span class=\"number\">2</span>, <span class=\"number\">1</span>, dtype=torch.double) <span class=\"comment\"># new_* methods take in size</span></span><br><span class=\"line\">print(x)</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.randn_like(x, dtype=torch.float) <span class=\"comment\"># override dype and result has same size</span></span><br><span class=\"line\">print(x)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[1.],\n        [1.]], dtype=torch.float64)\ntensor([[1.4535],\n        [0.0968]])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># get its size</span></span><br><span class=\"line\">print(x.size())</span><br><span class=\"line\"></span><br><span class=\"line\">print(x.shape)</span><br></pre></td></tr></table></figure>\n<pre><code>torch.Size([2, 1])\ntorch.Size([2, 1])\n</code></pre><h1 id=\"Opertions\"><a href=\"#Opertions\" class=\"headerlink\" title=\"Opertions\"></a>Opertions</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Addition</span></span><br><span class=\"line\">x = x.new_ones(<span class=\"number\">3</span>, <span class=\"number\">2</span>, dtype=torch.float)</span><br><span class=\"line\">y = torch.rand(<span class=\"number\">3</span>, <span class=\"number\">2</span>, dtype=torch.float)</span><br><span class=\"line\">print(x + y) <span class=\"comment\"># syntax 1</span></span><br><span class=\"line\">print(torch.add(x, y)) <span class=\"comment\"># syntax 2</span></span><br><span class=\"line\">result = torch.empty(<span class=\"number\">5</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\">torch.add(x, y, out=result) <span class=\"comment\"># add x and y to result</span></span><br><span class=\"line\">print(result)</span><br><span class=\"line\">y.add_(x)</span><br><span class=\"line\">print(y) <span class=\"comment\"># add x to y</span></span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\ntensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\ntensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\ntensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\n</code></pre><p>注：任何tensor后面带有下划线都会改变tensor的值，比如x.copy_(y), x.t_(x)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.rand(<span class=\"number\">3</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">print(x)</span><br><span class=\"line\">print(x[:, <span class=\"number\">1</span>])</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[0.8368, 0.9204],\n        [0.3797, 0.0908],\n        [0.4454, 0.7684]])\ntensor([0.9204, 0.0908, 0.7684])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># resizing</span></span><br><span class=\"line\">x = torch.randn(<span class=\"number\">4</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">y = x.view(<span class=\"number\">16</span>)</span><br><span class=\"line\">z = x.view(<span class=\"number\">-1</span>, <span class=\"number\">8</span>) <span class=\"comment\"># the size -1 is inferred from other dimensions</span></span><br><span class=\"line\">print(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure>\n<pre><code>torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Converting Numpy Array to Torch Tensor</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">a = np.ones(<span class=\"number\">5</span>)</span><br><span class=\"line\">b = torch.from_numpy(a)</span><br><span class=\"line\">np.add(a, <span class=\"number\">1</span>, out=a)</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">print(b)</span><br></pre></td></tr></table></figure>\n<pre><code>[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CUDA Tensor</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</span><br><span class=\"line\">    device = torch.device(<span class=\"string\">\"cuda\"</span>)</span><br><span class=\"line\">    y = torch.ones_like(x, device=device)</span><br><span class=\"line\">    x = x.to(device)</span><br><span class=\"line\">    z = x + y</span><br><span class=\"line\">    print(z)</span><br><span class=\"line\">    print(z.to(<span class=\"string\">\"cpu\"</span>, torch.double))</span><br></pre></td></tr></table></figure>\n<h1 id=\"Define-the-Network\"><a href=\"#Define-the-Network\" class=\"headerlink\" title=\"Define the Network\"></a>Define the Network</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br></pre></td></tr></table></figure>\n<p>本来这个网络应该是LeNet的，输入要求是32x32，我改变了第一个全连接层，将输入变为了20x20。<br>所以网络结构可以通过自己的想法进行改变，最重要的是改变全连接层就可以了。<br>网络经过卷积之后输入的结果公式为：$$ outputsize = （inputsize - kernelsize + 2 * pad）/stride + 1 $$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(Net, self).__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class=\"line\">        <span class=\"comment\"># kernel</span></span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">        <span class=\"comment\"># an affine operation: y = Wx + b</span></span><br><span class=\"line\">        self.fc1 = nn.Linear(<span class=\"number\">16</span> * <span class=\"number\">2</span> * <span class=\"number\">2</span>, <span class=\"number\">120</span>)</span><br><span class=\"line\">        self.fc2 = nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>)</span><br><span class=\"line\">        self.fc3 = nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># Max pooling over a (2, 2) window</span></span><br><span class=\"line\">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class=\"number\">2</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\">        <span class=\"comment\"># if the size is a square you can only specify a single number </span></span><br><span class=\"line\">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class=\"number\">2</span>)</span><br><span class=\"line\">        x = x.view(<span class=\"number\">-1</span>, self.num_flat_feature(x))</span><br><span class=\"line\">        x = F.relu(self.fc1(x))</span><br><span class=\"line\">        x = F.relu(self.fc2(x))</span><br><span class=\"line\">        x = F.relu(self.fc3(x))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">num_flat_feature</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">        size = x.size()[<span class=\"number\">1</span>:] <span class=\"comment\"># all dimensions except the batch dimension</span></span><br><span class=\"line\">        num_features = <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> size:</span><br><span class=\"line\">            num_features *= s </span><br><span class=\"line\">        <span class=\"keyword\">return</span> num_features</span><br><span class=\"line\">net = Net()</span><br><span class=\"line\">print(net)</span><br></pre></td></tr></table></figure>\n<pre><code>Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=64, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The learnable parameter of a model are returned by net.parameters()</span></span><br><span class=\"line\">params = list(net.parameters())</span><br><span class=\"line\">print(len(params))</span><br><span class=\"line\">print(params[<span class=\"number\">0</span>].size()) <span class=\"comment\"># conv1's .weights</span></span><br></pre></td></tr></table></figure>\n<pre><code>10\ntorch.Size([6, 1, 5, 5])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">20</span>)</span><br><span class=\"line\">out = net(input)</span><br><span class=\"line\">print(out)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[0.0432, 0.1072, 0.0000, 0.1096, 0.0378, 0.0000, 0.0000, 0.0000, 0.0202,\n         0.0000]], grad_fn=&lt;ReluBackward&gt;)\n</code></pre><h2 id=\"zero-the-gradients\"><a href=\"#zero-the-gradients\" class=\"headerlink\" title=\"zero the gradients\"></a>zero the gradients</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net.zero_grad()</span><br><span class=\"line\">out.backward(torch.randn(<span class=\"number\">1</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<p>torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.<br>For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.<br>If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.</p>\n<h2 id=\"Loss-Function\"><a href=\"#Loss-Function\" class=\"headerlink\" title=\"Loss Function\"></a>Loss Function</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">out = net(input)</span><br><span class=\"line\">target = torch.randn(<span class=\"number\">10</span>) <span class=\"comment\"># a dummy target, for example </span></span><br><span class=\"line\">target = target.view(<span class=\"number\">1</span>, <span class=\"number\">-1</span>)</span><br><span class=\"line\">criterion = nn.MSELoss()</span><br><span class=\"line\"></span><br><span class=\"line\">loss = criterion(out, target)</span><br><span class=\"line\">print(loss)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor(1.7536, grad_fn=&lt;MseLossBackward&gt;)\n</code></pre><p>forward:<br>input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d<br>      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear<br>      -&gt; MSELoss<br>      -&gt; loss</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(loss.grad_fn) <span class=\"comment\"># MSELoss</span></span><br><span class=\"line\">print(loss.grad_fn.next_functions[<span class=\"number\">0</span>][<span class=\"number\">0</span>]) <span class=\"comment\"># Linear</span></span><br><span class=\"line\">print(loss.grad_fn.next_functions[<span class=\"number\">0</span>][<span class=\"number\">0</span>].next_functions[<span class=\"number\">0</span>][<span class=\"number\">0</span>]) <span class=\"comment\"># relu</span></span><br></pre></td></tr></table></figure>\n<pre><code>&lt;MseLossBackward object at 0x0000000008619780&gt;\n&lt;ReluBackward object at 0x0000000008619A58&gt;\n&lt;ThAddmmBackward object at 0x0000000008619780&gt;\n</code></pre><h2 id=\"Backpropagate\"><a href=\"#Backpropagate\" class=\"headerlink\" title=\"Backpropagate\"></a>Backpropagate</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net.zero_grad() <span class=\"comment\"># zeros the gradient buffer of all parameters </span></span><br><span class=\"line\">print(<span class=\"string\">'conv1.bias.grad before backward'</span>)</span><br><span class=\"line\">print(net.conv1.bias.grad)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># loss.backward() # 为了和下面的产生两次相同的backpropagate，所以将这里注释，下一个单元也是这样。</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'conv1.bias.grad before backward'</span>)</span><br><span class=\"line\">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure>\n<pre><code>conv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\nconv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Weights</span></span><br><span class=\"line\"><span class=\"comment\"># learning_rate = 0.01</span></span><br><span class=\"line\"><span class=\"comment\"># for f in net.parameters():</span></span><br><span class=\"line\"><span class=\"comment\">#     f.data.sub_(f.grad.data * learning_rate)  # f = f - learning_rate * gradient</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># creater your optimizer</span></span><br><span class=\"line\">optimizer = optim.SGD(net.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># in your training loop </span></span><br><span class=\"line\">optimizer.zero_grad() <span class=\"comment\"># zero the gradient buffers</span></span><br><span class=\"line\">output = net(input)</span><br><span class=\"line\">loss = criterion(out, target)</span><br><span class=\"line\">loss.backward()</span><br><span class=\"line\">optimizer.step() <span class=\"comment\"># Does the update</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"Training-A-Classifier\"><a href=\"#Training-A-Classifier\" class=\"headerlink\" title=\"Training A Classifier\"></a>Training A Classifier</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> transforms</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The output of torchvision datasets are PILImage iamges of range [0, 1]. We transform them to Tensor of normalized range [-1, 1]</span></span><br><span class=\"line\">transform = transforms.Compose(</span><br><span class=\"line\">[transforms.ToTensor(), transforms.Normalize((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\"></span><br><span class=\"line\">trainset = torchvision.datasets.CIFAR10(root=<span class=\"string\">'./data'</span>, train=<span class=\"keyword\">True</span>, </span><br><span class=\"line\">                                       download=<span class=\"keyword\">True</span>, transform=transform)</span><br><span class=\"line\">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class=\"number\">4</span>, </span><br><span class=\"line\">                                          shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">testset = torchvision.datasets.CIFAR10(root=<span class=\"string\">'./data'</span>, train=<span class=\"keyword\">False</span>, </span><br><span class=\"line\">                                      download=<span class=\"keyword\">True</span>, transform=transform)</span><br><span class=\"line\">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class=\"number\">4</span>, </span><br><span class=\"line\">                                              shuffle=<span class=\"keyword\">False</span>, num_workers=<span class=\"number\">2</span>)</span><br><span class=\"line\">classes = (<span class=\"string\">'plane'</span>, <span class=\"string\">'car'</span>, <span class=\"string\">'bird'</span>, <span class=\"string\">'cat'</span>, </span><br><span class=\"line\">          <span class=\"string\">'deer'</span>, <span class=\"string\">'dog'</span>, <span class=\"string\">'frog'</span>, <span class=\"string\">'horse'</span>, <span class=\"string\">'ship'</span>, <span class=\"string\">'truck'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>Files already downloaded and verified\nFiles already downloaded and verified\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt </span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">imshow</span><span class=\"params\">(img)</span>:</span></span><br><span class=\"line\">    img = img/<span class=\"number\">2</span> + <span class=\"number\">0.5</span> <span class=\"comment\"># unnormalize</span></span><br><span class=\"line\">    npimg = img.numpy()</span><br><span class=\"line\"><span class=\"comment\">#     print(npimg.shape)</span></span><br><span class=\"line\">    plt.imshow(np.transpose(npimg, (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\"><span class=\"comment\">#     print(np.transpose(npimg, (1, 2, 0)).shape)</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># get some random training images</span></span><br><span class=\"line\">dataiter = iter(trainloader)</span><br><span class=\"line\">images, labels = dataiter.next()</span><br><span class=\"line\"><span class=\"comment\"># print(labels)</span></span><br><span class=\"line\"><span class=\"comment\"># show images</span></span><br><span class=\"line\">imshow(torchvision.utils.make_grid(images)) <span class=\"comment\"># 制作图像网格</span></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"><span class=\"comment\"># print labels</span></span><br><span class=\"line\">print(<span class=\"string\">' '</span>.join(<span class=\"string\">'%5s'</span> % classes[labels[j]] <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)))</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_35_0%20.png\" alt></p>\n<pre><code>deer truck plane horse\n</code></pre><h2 id=\"Define-a-Convolution-Neural-Network\"><a href=\"#Define-a-Convolution-Neural-Network\" class=\"headerlink\" title=\"Define a Convolution Neural Network\"></a>Define a Convolution Neural Network</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(Net, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">        self.pool = nn.MaxPool2d(<span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">        self.fc1 = nn.Linear(<span class=\"number\">16</span> * <span class=\"number\">5</span> * <span class=\"number\">5</span>, <span class=\"number\">120</span>)</span><br><span class=\"line\">        self.fc2 = nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>)</span><br><span class=\"line\">        self.fc3 = nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class=\"line\">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">16</span> * <span class=\"number\">5</span> * <span class=\"number\">5</span>)</span><br><span class=\"line\">        x = F.relu(self.fc1(x))</span><br><span class=\"line\">        x = F.relu(self.fc2(x))</span><br><span class=\"line\">        x = self.fc3(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">net = Net()</span><br><span class=\"line\">net.to(device)</span><br><span class=\"line\">print(net)</span><br></pre></td></tr></table></figure>\n<pre><code>Net(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n</code></pre><h2 id=\"Define-a-Loss-function-and-opotimizer\"><a href=\"#Define-a-Loss-function-and-opotimizer\" class=\"headerlink\" title=\"Define a Loss function and opotimizer\"></a>Define a Loss function and opotimizer</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span>  torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss()</span><br><span class=\"line\">optimizer = optim.SGD(net.parameters(), lr=<span class=\"number\">0.001</span>, momentum=<span class=\"number\">0.9</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Train-the-network\"><a href=\"#Train-the-network\" class=\"headerlink\" title=\"Train the network\"></a>Train the network</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>):</span><br><span class=\"line\">    running_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, data <span class=\"keyword\">in</span> enumerate(trainloader, <span class=\"number\">0</span>):</span><br><span class=\"line\">        <span class=\"comment\"># get the inputs </span></span><br><span class=\"line\">        inputs, labels = data </span><br><span class=\"line\">        inputs, labels = inputs.to(device), labels.to(device)</span><br><span class=\"line\">        <span class=\"comment\"># zero the parameter gradients</span></span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># forward  + backward + optimize</span></span><br><span class=\"line\">        outputs = net(inputs)</span><br><span class=\"line\">        loss = criterion(outputs, labels)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># print statistics</span></span><br><span class=\"line\">        running_loss += loss.item()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i % <span class=\"number\">2000</span> == <span class=\"number\">1999</span>: <span class=\"comment\"># print every 2000 mini-batches </span></span><br><span class=\"line\">            print(<span class=\"string\">'[%d, %5d] loss: %.3f'</span> % </span><br><span class=\"line\">                 (epoch + <span class=\"number\">1</span>, i + <span class=\"number\">1</span>, running_loss / <span class=\"number\">2000</span>))</span><br><span class=\"line\">            running_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">print(<span class=\"string\">'Finished Training'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>[1,  2000] loss: 2.217\n[1,  4000] loss: 1.855\n[1,  6000] loss: 1.672\n[1,  8000] loss: 1.570\n[1, 10000] loss: 1.506\n[1, 12000] loss: 1.461\n[2,  2000] loss: 1.370\n[2,  4000] loss: 1.369\n[2,  6000] loss: 1.340\n[2,  8000] loss: 1.323\n[2, 10000] loss: 1.276\n[2, 12000] loss: 1.279\nFinished Training\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataiter = iter(testloader)</span><br><span class=\"line\">images, labels = dataiter.next()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print images </span></span><br><span class=\"line\">imshow(torchvision.utils.make_grid(images))</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\">print(<span class=\"string\">'GroundTruth: '</span>, <span class=\"string\">' '</span>.join(<span class=\"string\">'%5s'</span> % classes[labels[j]] <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)))</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_42_0.png\" alt></p>\n<pre><code>GroundTruth:    cat  ship  ship plane\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">outputs = net(images)</span><br><span class=\"line\">print(outputs)</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([[-0.7807, -1.7329,  0.9516,  1.8043, -1.2077,  0.7349,  1.3615, -1.5412,\n          1.0311, -1.7234],\n        [ 5.2413,  6.1315, -1.7400, -3.2287, -5.0497, -5.8038, -4.2375, -4.4465,\n          7.7529,  4.1842],\n        [ 2.7686,  3.8909, -0.7050, -1.7185, -3.2625, -3.2960, -2.2888, -2.6324,\n          3.8761,  2.4697],\n        [ 4.0929,  1.8480,  0.1962, -1.7907, -1.6931, -3.4538, -2.2210, -3.0694,\n          4.5059,  0.7960]], grad_fn=&lt;ThAddmmBackward&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_, predicted = torch.max(outputs, <span class=\"number\">1</span>)</span><br><span class=\"line\">print(predicted)</span><br><span class=\"line\">print(<span class=\"string\">'Predicted: '</span>, <span class=\"string\">' '</span>.join(<span class=\"string\">'%5s'</span> % classes[predicted[j]] <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)))</span><br></pre></td></tr></table></figure>\n<pre><code>tensor([3, 8, 1, 8])\nPredicted:    cat  ship   car  ship\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">correct = <span class=\"number\">0</span></span><br><span class=\"line\">total = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> testloader:</span><br><span class=\"line\">        images, labels = data</span><br><span class=\"line\"><span class=\"comment\">#         print(labels)</span></span><br><span class=\"line\">        outputs = net(images)</span><br><span class=\"line\">        _, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)</span><br><span class=\"line\">        total += labels.size(<span class=\"number\">0</span>)</span><br><span class=\"line\">        correct += (predicted == labels).sum().item()</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'Accuracy of the network on the 10000 test images: %d %%'</span> % (</span><br><span class=\"line\">    <span class=\"number\">100</span> * correct / total))</span><br></pre></td></tr></table></figure>\n<pre><code>Accuracy of the network on the 10000 test images: 54 %\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class_correct = list(<span class=\"number\">0.</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>))</span><br><span class=\"line\">class_total = list(<span class=\"number\">0.</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>))</span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> testloader:</span><br><span class=\"line\">        images, labels = data</span><br><span class=\"line\">        outputs = net(images)</span><br><span class=\"line\">        _, predicted = torch.max(outputs, <span class=\"number\">1</span>) <span class=\"comment\"># torch.max 可以返回最大值和对应的坐标，np.random.randn只能返回最大值</span></span><br><span class=\"line\">        c = (predicted == labels).squeeze()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>):</span><br><span class=\"line\">            label = labels[i]</span><br><span class=\"line\">            class_correct[label] += c[i].item()</span><br><span class=\"line\">            class_total[label] += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>):</span><br><span class=\"line\">    print(<span class=\"string\">'Accuracy of %5s : %2d %%'</span> % (</span><br><span class=\"line\">        classes[i], <span class=\"number\">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure>\n<pre><code>Accuracy of plane : 55 %\nAccuracy of   car : 59 %\nAccuracy of  bird : 65 %\nAccuracy of   cat : 29 %\nAccuracy of  deer : 22 %\nAccuracy of   dog : 49 %\nAccuracy of  frog : 71 %\nAccuracy of horse : 55 %\nAccuracy of  ship : 75 %\nAccuracy of truck : 62 %\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"写在前面的话\"><a href=\"#写在前面的话\" class=\"headerlink\" title=\"写在前面的话\"></a>写在前面的话</h1><p>本文主要是基于Pytorch给出的官方<a href=\"https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\" target=\"_blank\" rel=\"noopener\">Tutorial</a>，然后我按照自己的喜好编辑成Jupyter文档，后转成本博客，用来作为自己的日常参照材料。</p>\n<h1 id=\"Pytorch\"><a href=\"#Pytorch\" class=\"headerlink\" title=\"Pytorch\"></a>Pytorch</h1><p>Pytorch给我的感觉是：它是基于更高级的封装，实现深度学习更加简单，比较适合科研型的或者是实现一些想法的入门级选手。Tensorflow更适合工程项目，能够比较高效的运行。但是对于一般选手来说，Pytorch更适合，因为它是动态图，在个人代码水平不是很高的情况下，Pytorch的效率是高于Tensorflow的。</p>\n<!--�14-->\n<h1 id=\"Tensors\"><a href=\"#Tensors\" class=\"headerlink\" title=\"Tensors\"></a>Tensors</h1><!--�15-->\n<pre><code>tensor([[0.0000],\n        [0.0000]])\n</code></pre><!--�16-->\n<pre><code>tensor([[0.2854, 0.5359, 0.7811],\n        [0.1065, 0.0246, 0.3945],\n        [0.8341, 0.6808, 0.4578],\n        [0.4257, 0.7255, 0.3597],\n        [0.3510, 0.3170, 0.1526]])\n</code></pre><!--�17-->\n<pre><code>tensor([[0],\n        [0]])\n</code></pre><!--�18-->\n<pre><code>tensor([3, 3])\n</code></pre><!--�19-->\n<pre><code>tensor([[1.],\n        [1.]], dtype=torch.float64)\ntensor([[1.4535],\n        [0.0968]])\n</code></pre><!--�20-->\n<pre><code>torch.Size([2, 1])\ntorch.Size([2, 1])\n</code></pre><h1 id=\"Opertions\"><a href=\"#Opertions\" class=\"headerlink\" title=\"Opertions\"></a>Opertions</h1><!--�21-->\n<pre><code>tensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\ntensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\ntensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\ntensor([[1.9447, 1.9085],\n        [1.3177, 1.8074],\n        [1.1208, 1.8663]])\n</code></pre><p>注：任何tensor后面带有下划线都会改变tensor的值，比如x.copy_(y), x.t_(x)</p>\n<!--�22-->\n<pre><code>tensor([[0.8368, 0.9204],\n        [0.3797, 0.0908],\n        [0.4454, 0.7684]])\ntensor([0.9204, 0.0908, 0.7684])\n</code></pre><!--�23-->\n<pre><code>torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n</code></pre><!--�24-->\n<pre><code>[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n</code></pre><!--�25-->\n<h1 id=\"Define-the-Network\"><a href=\"#Define-the-Network\" class=\"headerlink\" title=\"Define the Network\"></a>Define the Network</h1><!--�26-->\n<p>本来这个网络应该是LeNet的，输入要求是32x32，我改变了第一个全连接层，将输入变为了20x20。<br>所以网络结构可以通过自己的想法进行改变，最重要的是改变全连接层就可以了。<br>网络经过卷积之后输入的结果公式为：$$ outputsize = （inputsize - kernelsize + 2 * pad）/stride + 1 $$</p>\n<!--�27-->\n<pre><code>Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=64, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n</code></pre><!--�28-->\n<pre><code>10\ntorch.Size([6, 1, 5, 5])\n</code></pre><!--�29-->\n<pre><code>tensor([[0.0432, 0.1072, 0.0000, 0.1096, 0.0378, 0.0000, 0.0000, 0.0000, 0.0202,\n         0.0000]], grad_fn=&lt;ReluBackward&gt;)\n</code></pre><h2 id=\"zero-the-gradients\"><a href=\"#zero-the-gradients\" class=\"headerlink\" title=\"zero the gradients\"></a>zero the gradients</h2><!--�30-->\n<p>torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.<br>For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.<br>If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.</p>\n<h2 id=\"Loss-Function\"><a href=\"#Loss-Function\" class=\"headerlink\" title=\"Loss Function\"></a>Loss Function</h2><!--�31-->\n<pre><code>tensor(1.7536, grad_fn=&lt;MseLossBackward&gt;)\n</code></pre><p>forward:<br>input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d<br>      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear<br>      -&gt; MSELoss<br>      -&gt; loss</p>\n<!--�32-->\n<pre><code>&lt;MseLossBackward object at 0x0000000008619780&gt;\n&lt;ReluBackward object at 0x0000000008619A58&gt;\n&lt;ThAddmmBackward object at 0x0000000008619780&gt;\n</code></pre><h2 id=\"Backpropagate\"><a href=\"#Backpropagate\" class=\"headerlink\" title=\"Backpropagate\"></a>Backpropagate</h2><!--�33-->\n<pre><code>conv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\nconv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\n</code></pre><!--�34-->\n<!--�35-->\n<h1 id=\"Training-A-Classifier\"><a href=\"#Training-A-Classifier\" class=\"headerlink\" title=\"Training A Classifier\"></a>Training A Classifier</h1><!--�36-->\n<!--�37-->\n<pre><code>Files already downloaded and verified\nFiles already downloaded and verified\n</code></pre><!--�38-->\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_35_0%20.png\" alt></p>\n<pre><code>deer truck plane horse\n</code></pre><h2 id=\"Define-a-Convolution-Neural-Network\"><a href=\"#Define-a-Convolution-Neural-Network\" class=\"headerlink\" title=\"Define a Convolution Neural Network\"></a>Define a Convolution Neural Network</h2><!--�39-->\n<pre><code>Net(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n</code></pre><h2 id=\"Define-a-Loss-function-and-opotimizer\"><a href=\"#Define-a-Loss-function-and-opotimizer\" class=\"headerlink\" title=\"Define a Loss function and opotimizer\"></a>Define a Loss function and opotimizer</h2><!--�40-->\n<h2 id=\"Train-the-network\"><a href=\"#Train-the-network\" class=\"headerlink\" title=\"Train the network\"></a>Train the network</h2><!--�41-->\n<pre><code>[1,  2000] loss: 2.217\n[1,  4000] loss: 1.855\n[1,  6000] loss: 1.672\n[1,  8000] loss: 1.570\n[1, 10000] loss: 1.506\n[1, 12000] loss: 1.461\n[2,  2000] loss: 1.370\n[2,  4000] loss: 1.369\n[2,  6000] loss: 1.340\n[2,  8000] loss: 1.323\n[2, 10000] loss: 1.276\n[2, 12000] loss: 1.279\nFinished Training\n</code></pre><!--�42-->\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Pytorch_Tutorial_output_42_0.png\" alt></p>\n<pre><code>GroundTruth:    cat  ship  ship plane\n</code></pre><!--�43-->\n<pre><code>tensor([[-0.7807, -1.7329,  0.9516,  1.8043, -1.2077,  0.7349,  1.3615, -1.5412,\n          1.0311, -1.7234],\n        [ 5.2413,  6.1315, -1.7400, -3.2287, -5.0497, -5.8038, -4.2375, -4.4465,\n          7.7529,  4.1842],\n        [ 2.7686,  3.8909, -0.7050, -1.7185, -3.2625, -3.2960, -2.2888, -2.6324,\n          3.8761,  2.4697],\n        [ 4.0929,  1.8480,  0.1962, -1.7907, -1.6931, -3.4538, -2.2210, -3.0694,\n          4.5059,  0.7960]], grad_fn=&lt;ThAddmmBackward&gt;)\n</code></pre><!--�44-->\n<pre><code>tensor([3, 8, 1, 8])\nPredicted:    cat  ship   car  ship\n</code></pre><!--�45-->\n<pre><code>Accuracy of the network on the 10000 test images: 54 %\n</code></pre><!--�46-->\n<pre><code>Accuracy of plane : 55 %\nAccuracy of   car : 59 %\nAccuracy of  bird : 65 %\nAccuracy of   cat : 29 %\nAccuracy of  deer : 22 %\nAccuracy of   dog : 49 %\nAccuracy of  frog : 71 %\nAccuracy of horse : 55 %\nAccuracy of  ship : 75 %\nAccuracy of truck : 62 %\n</code></pre>"},{"title":"Shell学习","date":"2019-07-11T08:24:40.000Z","_content":"# Shell简介\nShell是用户与操作系统之间的壳，同时也是操作系统与用户交互的接口，GUI和CLI都可以算作Shell。Bash是Ubuntu里默认的Shell。\n\n# 运行Shell脚本方法\n1. 作为可运行程序\n```\nchmod +x ./test.sh\n./test.sh\n```\n2. 作为解释器参数\n```/bin/sh test.sh```\n","source":"_posts/Shell学习.md","raw":"---\ntitle: Shell学习\ndate: 2019-07-11 16:24:40\ntags: Shell\ncategories: 学习\n---\n# Shell简介\nShell是用户与操作系统之间的壳，同时也是操作系统与用户交互的接口，GUI和CLI都可以算作Shell。Bash是Ubuntu里默认的Shell。\n\n# 运行Shell脚本方法\n1. 作为可运行程序\n```\nchmod +x ./test.sh\n./test.sh\n```\n2. 作为解释器参数\n```/bin/sh test.sh```\n","slug":"Shell学习","published":1,"updated":"2019-07-11T13:58:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msb000f1ouzsko9iazg","content":"<h1 id=\"Shell简介\"><a href=\"#Shell简介\" class=\"headerlink\" title=\"Shell简介\"></a>Shell简介</h1><p>Shell是用户与操作系统之间的壳，同时也是操作系统与用户交互的接口，GUI和CLI都可以算作Shell。Bash是Ubuntu里默认的Shell。</p>\n<h1 id=\"运行Shell脚本方法\"><a href=\"#运行Shell脚本方法\" class=\"headerlink\" title=\"运行Shell脚本方法\"></a>运行Shell脚本方法</h1><ol>\n<li><p>作为可运行程序</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod +x ./<span class=\"keyword\">test</span>.<span class=\"keyword\">sh</span></span><br><span class=\"line\">./<span class=\"keyword\">test</span>.<span class=\"keyword\">sh</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>作为解释器参数<br><code>/bin/sh test.sh</code></p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Shell简介\"><a href=\"#Shell简介\" class=\"headerlink\" title=\"Shell简介\"></a>Shell简介</h1><p>Shell是用户与操作系统之间的壳，同时也是操作系统与用户交互的接口，GUI和CLI都可以算作Shell。Bash是Ubuntu里默认的Shell。</p>\n<h1 id=\"运行Shell脚本方法\"><a href=\"#运行Shell脚本方法\" class=\"headerlink\" title=\"运行Shell脚本方法\"></a>运行Shell脚本方法</h1><ol>\n<li><p>作为可运行程序</p>\n<!--�47-->\n</li>\n<li><p>作为解释器参数<br><code>/bin/sh test.sh</code></p>\n</li>\n</ol>\n"},{"title":"cs131笔记","date":"2018-07-11T06:31:40.000Z","_content":"* filtering\nForming a new image whose pixel values are transformed from original pixel values.\n\n\n\n\n","source":"_posts/cs131笔记.md","raw":"---\ntitle: cs131笔记\ndate: 2018-07-11 14:31:40\ntags: 概率图模型\ncategories: 学习\n---\n* filtering\nForming a new image whose pixel values are transformed from original pixel values.\n\n\n\n\n","slug":"cs131笔记","published":1,"updated":"2018-10-01T01:56:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msc000g1ouznayrcmv1","content":"<ul>\n<li>filtering<br>Forming a new image whose pixel values are transformed from original pixel values.</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>filtering<br>Forming a new image whose pixel values are transformed from original pixel values.</li>\n</ul>\n"},{"title":"SCI论文绘图方法","date":"2019-06-13T06:24:53.000Z","_content":"小同学，也许你在看论文时也困惑过别人的图为何画的如此的美，如此的精细，不用担心，这里教你SCI级别的论文绘图方法，一看就会，动手就忘（划掉，当然，你可以联系我帮你画，价格好商量）。\n\n# 软件介绍\n我们这里使用的软件叫做gnuplot，这是命令行驱动的绘图工具，可以讲数学函数或数值资料以平面图或者立体图的形式在不同种类的终端机或者是绘图输出装置上。另外，gnuplot是开源的，不必担心版权问题。\n\n## 软件安装\nWindows平台下使用gnuplot非常简单，只要到[gnuplot官网](http://www.gnuplot.info/)上找到windows版本下载安装即可，双击打开安装后的软件，是如下图的界面。\n![gnu_terminal](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/gnu_terminal.png)\n\n# 开始绘图\n我们只需要在`>gnuplot`后面写命令就可以画图了，如果我们想要画一个正弦曲线，我们只需要输入下面的命令即可；\n```\nplot sin(5*x)\n```\n这样我们就得到了一个绘制的正弦曲线，当然我们的目标是为了绘制出SCI论文级的图，当然不能满足于此了。\n下面我们来真正开始看如何绘制一个SCI级别论文图。\n\n# SCI绘图\n下面我们来看一个实际的绘图的情况，下面我用实际训练神经网络的损失函数来举例使用gnuplot绘制的方法。\n首先我们有数据文件，这个数据文件我们命名为 $loss.dat$，保存在`E:\\plot`下，数据的格式如下图所示：\n![data](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/data.png)\n下面我们使用`plot`命令来画我们这个文件的数据，首先我们需要切换到数据文件的保存路径，也就是`E:\\plot`，大家可以使用软件的`CHDir`切换，也可以使用`cd \"E:\\plot\"`切换到数据保存文件的路径。\n使用如下的命令就能绘制出这个文件的图了：\n```\nplot \"loss.dat\" using 1:2 with lines title \"CNN\"\n```\n这行代码表示，我们使用`loss.dat`的第1、2列数据绘制线，并且设置图例为`title`。\n我们会绘制出下图的结果：\n![plot1](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot1.png)\n上面的图是个不完整的图，它没有横纵坐标的描述，也没有图的标题，下面我们来设置这些：\n```\nset xlabel \"Epoch\" \nset ylabel \"Cross Entropy\" \nset title \"Traing Loss\"\nreplot\n```\n将上面的命令以此执行，就能将横坐标设置为\"Epoch\"，纵坐标设置为\"Cross Entropy\"，设置图的标题为\"Traing Loss\"。`replot`将图重新画一遍，这样我们就会把我们增加内容绘制在图当中了。\n![plot2](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot2.png)\n上面的图我们已经基本上画好，图的各种元素已经完备了，但是仍然不好看，所以下面我们来进一步优化我们的图，选一篇我前面在看的文章，Dolz等人设计的HyperDense网络[2]，我们按照他们的绘图风格来进一步优化我们的图。\n对比他们的损失函数的图(文献[2]中的图3，如下图所示)，我们可以看出，我们的图名太小，纵坐标的名字不够清晰，图例没有加框，曲线不够平滑。另外我们绘制的是损失函数的收敛曲线，我们应该让其看起来收敛(虽然实际上选取数据的这段还没有收敛)。\n![hyperdense](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/hyperdense.png)\n首先我们添加网格\n```\nset grid\n```\n然后，将横纵坐标刻度设置为\"Times New Roman\"，10号字，横纵坐标名设置为\"Times New Roman\"，14号字。设置图例为12号字。\n```\nset xtics font 'times.ttf,10'\nset ytics font 'times.ttf,10'\nset xlabel 'Epoch' font 'times.ttf,14'\nset ylabel 'Cross Entropy' font 'times.ttf,14'\nset title 'Traing Loss' font 'times.ttf,14'\nset key font 'times.ttf,12'\n```\n![plot3](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot3.png)\n这时我们再看我们画的图，已经基本具有一般学术论文的样子了。但是，我们仍有可以提高的地方，比如说，我们的线条颜色不好看，我们的收敛曲线看不出收敛的趋势。\n更改线条的颜色，我们改成红色：\n```\nset style line 1 lw 1.5 lc rgb \"#F62217\"\nplot file using 1:2 with lines ls 1 title \"CNN\"\n```\n另外常用的两种线条颜色，一个是蓝色一个是黄色。\n```\nset style line 2 linewidth 2 linecolor rgb \"#D4A017\"\nset style line 3 linewidth 3 linecolor rgb \"#2B60DE\"\n```\n将纵坐标设范围为0.04-0.10，这样我们曲线更加集中，可以更好地看出收敛趋势。\n```\nset yrange [0.04:0.10]\n```\n下面我们为图例加框，设置图例位置，图例框宽度为2，高度为1，文字为左对齐，线段在左文字在右，并且设置图例线段长度为2。\n```\nset key box\nset key center at 42,0.09\nset key width 2\nset key height 1\nset key Left\nset key reverse\nset key samplen 2\n```\n经过上面一顿猛如虎的操作，我们已经基本上绘制出了可以放在论文里面的图了，下面是我们绘制的结果：\n![plot4](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot4.png)\n但是，我们仍能优化这个图，我们希望它能更加的平滑。下面我们使它更加平滑，在gnuplot中的数据平滑命令为smooth，然后常用的算法为$bezier$和esplines$，因为$splines$要额外的平滑权重，这里我们就使用不需要平滑权重的bezier算法。\n```\nplot ”loss.dat“ using 1:2 with lines ls 1 smooth bezier title \"CNN\"\n```\n这就可以得到我们最终需要的曲线图了。\n![result](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/result.png)\n\n# 利用脚本绘图\n聪明的你一定在想，难道我每次都需要一行一行的输入命令吗？其实我们完全可以使用脚本，将前面的命令写进脚本中，然后一次运行就可以得到我们最终的绘图结果了。首先我们需要建立一个文件，文件名为$loss.gnu$，将这个放置在于数据相同的文件夹内，我们这里是`E:\\plot`。\n脚本的内容如下：\n```\nset encoding utf8\nset term wxt enhanced\n\nset xtics font 'times.ttf,10'\nset ytics font 'times.ttf,10'\nset xlabel 'Epoch' font 'times.ttf,14'\nset ylabel 'Cross Entropy' font 'times.ttf,14'\nset title 'Traing Loss' font 'times.ttf,14'\nset key font 'times.ttf,12'\nset key center at 42,0.09\nset key box\nset key reverse\nset key width 2\nset key height 1\nset key Left\nset key samplen 2\nset grid\nset yrange [0.04:0.10]\nset style line 1 lw 1.5 lc rgb \"#F62217\"\n\nfile = \"loss.dat\"\nplot file using 1:2 with lines ls 1 smooth bezier title \"CNN\"\n```\n我们在命令行里面输入`load loss.gnu`运行整个脚本，得到我们最后想要的图片了。\n至此，我们关于使用gnuplot绘制SCI论文图的方法就介绍完毕了，如果大家有需要可以参考文献[1]的内容了解更多。\n\n\n# 参考文献\n[1] http://vision.ouc.edu.cn/zhenghaiyong/courses/tutorials/gnuplot/gnuplot-zh.pdf\n[2] Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.\n\n\n\n\n","source":"_posts/SCI论文绘图方法.md","raw":"---\ntitle: SCI论文绘图方法\ndate: 2019-06-13 14:24:53\ntags: gnuplot\ncategories: 工作\n---\n小同学，也许你在看论文时也困惑过别人的图为何画的如此的美，如此的精细，不用担心，这里教你SCI级别的论文绘图方法，一看就会，动手就忘（划掉，当然，你可以联系我帮你画，价格好商量）。\n\n# 软件介绍\n我们这里使用的软件叫做gnuplot，这是命令行驱动的绘图工具，可以讲数学函数或数值资料以平面图或者立体图的形式在不同种类的终端机或者是绘图输出装置上。另外，gnuplot是开源的，不必担心版权问题。\n\n## 软件安装\nWindows平台下使用gnuplot非常简单，只要到[gnuplot官网](http://www.gnuplot.info/)上找到windows版本下载安装即可，双击打开安装后的软件，是如下图的界面。\n![gnu_terminal](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/gnu_terminal.png)\n\n# 开始绘图\n我们只需要在`>gnuplot`后面写命令就可以画图了，如果我们想要画一个正弦曲线，我们只需要输入下面的命令即可；\n```\nplot sin(5*x)\n```\n这样我们就得到了一个绘制的正弦曲线，当然我们的目标是为了绘制出SCI论文级的图，当然不能满足于此了。\n下面我们来真正开始看如何绘制一个SCI级别论文图。\n\n# SCI绘图\n下面我们来看一个实际的绘图的情况，下面我用实际训练神经网络的损失函数来举例使用gnuplot绘制的方法。\n首先我们有数据文件，这个数据文件我们命名为 $loss.dat$，保存在`E:\\plot`下，数据的格式如下图所示：\n![data](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/data.png)\n下面我们使用`plot`命令来画我们这个文件的数据，首先我们需要切换到数据文件的保存路径，也就是`E:\\plot`，大家可以使用软件的`CHDir`切换，也可以使用`cd \"E:\\plot\"`切换到数据保存文件的路径。\n使用如下的命令就能绘制出这个文件的图了：\n```\nplot \"loss.dat\" using 1:2 with lines title \"CNN\"\n```\n这行代码表示，我们使用`loss.dat`的第1、2列数据绘制线，并且设置图例为`title`。\n我们会绘制出下图的结果：\n![plot1](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot1.png)\n上面的图是个不完整的图，它没有横纵坐标的描述，也没有图的标题，下面我们来设置这些：\n```\nset xlabel \"Epoch\" \nset ylabel \"Cross Entropy\" \nset title \"Traing Loss\"\nreplot\n```\n将上面的命令以此执行，就能将横坐标设置为\"Epoch\"，纵坐标设置为\"Cross Entropy\"，设置图的标题为\"Traing Loss\"。`replot`将图重新画一遍，这样我们就会把我们增加内容绘制在图当中了。\n![plot2](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot2.png)\n上面的图我们已经基本上画好，图的各种元素已经完备了，但是仍然不好看，所以下面我们来进一步优化我们的图，选一篇我前面在看的文章，Dolz等人设计的HyperDense网络[2]，我们按照他们的绘图风格来进一步优化我们的图。\n对比他们的损失函数的图(文献[2]中的图3，如下图所示)，我们可以看出，我们的图名太小，纵坐标的名字不够清晰，图例没有加框，曲线不够平滑。另外我们绘制的是损失函数的收敛曲线，我们应该让其看起来收敛(虽然实际上选取数据的这段还没有收敛)。\n![hyperdense](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/hyperdense.png)\n首先我们添加网格\n```\nset grid\n```\n然后，将横纵坐标刻度设置为\"Times New Roman\"，10号字，横纵坐标名设置为\"Times New Roman\"，14号字。设置图例为12号字。\n```\nset xtics font 'times.ttf,10'\nset ytics font 'times.ttf,10'\nset xlabel 'Epoch' font 'times.ttf,14'\nset ylabel 'Cross Entropy' font 'times.ttf,14'\nset title 'Traing Loss' font 'times.ttf,14'\nset key font 'times.ttf,12'\n```\n![plot3](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot3.png)\n这时我们再看我们画的图，已经基本具有一般学术论文的样子了。但是，我们仍有可以提高的地方，比如说，我们的线条颜色不好看，我们的收敛曲线看不出收敛的趋势。\n更改线条的颜色，我们改成红色：\n```\nset style line 1 lw 1.5 lc rgb \"#F62217\"\nplot file using 1:2 with lines ls 1 title \"CNN\"\n```\n另外常用的两种线条颜色，一个是蓝色一个是黄色。\n```\nset style line 2 linewidth 2 linecolor rgb \"#D4A017\"\nset style line 3 linewidth 3 linecolor rgb \"#2B60DE\"\n```\n将纵坐标设范围为0.04-0.10，这样我们曲线更加集中，可以更好地看出收敛趋势。\n```\nset yrange [0.04:0.10]\n```\n下面我们为图例加框，设置图例位置，图例框宽度为2，高度为1，文字为左对齐，线段在左文字在右，并且设置图例线段长度为2。\n```\nset key box\nset key center at 42,0.09\nset key width 2\nset key height 1\nset key Left\nset key reverse\nset key samplen 2\n```\n经过上面一顿猛如虎的操作，我们已经基本上绘制出了可以放在论文里面的图了，下面是我们绘制的结果：\n![plot4](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot4.png)\n但是，我们仍能优化这个图，我们希望它能更加的平滑。下面我们使它更加平滑，在gnuplot中的数据平滑命令为smooth，然后常用的算法为$bezier$和esplines$，因为$splines$要额外的平滑权重，这里我们就使用不需要平滑权重的bezier算法。\n```\nplot ”loss.dat“ using 1:2 with lines ls 1 smooth bezier title \"CNN\"\n```\n这就可以得到我们最终需要的曲线图了。\n![result](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/result.png)\n\n# 利用脚本绘图\n聪明的你一定在想，难道我每次都需要一行一行的输入命令吗？其实我们完全可以使用脚本，将前面的命令写进脚本中，然后一次运行就可以得到我们最终的绘图结果了。首先我们需要建立一个文件，文件名为$loss.gnu$，将这个放置在于数据相同的文件夹内，我们这里是`E:\\plot`。\n脚本的内容如下：\n```\nset encoding utf8\nset term wxt enhanced\n\nset xtics font 'times.ttf,10'\nset ytics font 'times.ttf,10'\nset xlabel 'Epoch' font 'times.ttf,14'\nset ylabel 'Cross Entropy' font 'times.ttf,14'\nset title 'Traing Loss' font 'times.ttf,14'\nset key font 'times.ttf,12'\nset key center at 42,0.09\nset key box\nset key reverse\nset key width 2\nset key height 1\nset key Left\nset key samplen 2\nset grid\nset yrange [0.04:0.10]\nset style line 1 lw 1.5 lc rgb \"#F62217\"\n\nfile = \"loss.dat\"\nplot file using 1:2 with lines ls 1 smooth bezier title \"CNN\"\n```\n我们在命令行里面输入`load loss.gnu`运行整个脚本，得到我们最后想要的图片了。\n至此，我们关于使用gnuplot绘制SCI论文图的方法就介绍完毕了，如果大家有需要可以参考文献[1]的内容了解更多。\n\n\n# 参考文献\n[1] http://vision.ouc.edu.cn/zhenghaiyong/courses/tutorials/gnuplot/gnuplot-zh.pdf\n[2] Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.\n\n\n\n\n","slug":"SCI论文绘图方法","published":1,"updated":"2019-06-14T07:29:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msd000h1ouzdz8qbxd2","content":"<p>小同学，也许你在看论文时也困惑过别人的图为何画的如此的美，如此的精细，不用担心，这里教你SCI级别的论文绘图方法，一看就会，动手就忘（划掉，当然，你可以联系我帮你画，价格好商量）。</p>\n<h1 id=\"软件介绍\"><a href=\"#软件介绍\" class=\"headerlink\" title=\"软件介绍\"></a>软件介绍</h1><p>我们这里使用的软件叫做gnuplot，这是命令行驱动的绘图工具，可以讲数学函数或数值资料以平面图或者立体图的形式在不同种类的终端机或者是绘图输出装置上。另外，gnuplot是开源的，不必担心版权问题。</p>\n<h2 id=\"软件安装\"><a href=\"#软件安装\" class=\"headerlink\" title=\"软件安装\"></a>软件安装</h2><p>Windows平台下使用gnuplot非常简单，只要到<a href=\"http://www.gnuplot.info/\" target=\"_blank\" rel=\"noopener\">gnuplot官网</a>上找到windows版本下载安装即可，双击打开安装后的软件，是如下图的界面。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/gnu_terminal.png\" alt=\"gnu_terminal\"></p>\n<h1 id=\"开始绘图\"><a href=\"#开始绘图\" class=\"headerlink\" title=\"开始绘图\"></a>开始绘图</h1><p>我们只需要在<code>&gt;gnuplot</code>后面写命令就可以画图了，如果我们想要画一个正弦曲线，我们只需要输入下面的命令即可；<br><figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">plot</span> <span class=\"built_in\">sin</span>(<span class=\"number\">5</span>*x)</span><br></pre></td></tr></table></figure></p>\n<p>这样我们就得到了一个绘制的正弦曲线，当然我们的目标是为了绘制出SCI论文级的图，当然不能满足于此了。<br>下面我们来真正开始看如何绘制一个SCI级别论文图。</p>\n<h1 id=\"SCI绘图\"><a href=\"#SCI绘图\" class=\"headerlink\" title=\"SCI绘图\"></a>SCI绘图</h1><p>下面我们来看一个实际的绘图的情况，下面我用实际训练神经网络的损失函数来举例使用gnuplot绘制的方法。<br>首先我们有数据文件，这个数据文件我们命名为 $loss.dat$，保存在<code>E:\\plot</code>下，数据的格式如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/data.png\" alt=\"data\"><br>下面我们使用<code>plot</code>命令来画我们这个文件的数据，首先我们需要切换到数据文件的保存路径，也就是<code>E:\\plot</code>，大家可以使用软件的<code>CHDir</code>切换，也可以使用<code>cd &quot;E:\\plot&quot;</code>切换到数据保存文件的路径。<br>使用如下的命令就能绘制出这个文件的图了：<br><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plot <span class=\"string\">\"loss.dat\"</span> <span class=\"keyword\">using</span> <span class=\"number\">1</span>:<span class=\"number\">2</span> <span class=\"keyword\">with</span> <span class=\"keyword\">lines</span> title <span class=\"string\">\"CNN\"</span></span><br></pre></td></tr></table></figure></p>\n<p>这行代码表示，我们使用<code>loss.dat</code>的第1、2列数据绘制线，并且设置图例为<code>title</code>。<br>我们会绘制出下图的结果：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot1.png\" alt=\"plot1\"><br>上面的图是个不完整的图，它没有横纵坐标的描述，也没有图的标题，下面我们来设置这些：<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> xlabel <span class=\"comment\">\"Epoch\"</span> </span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">ylabel</span> <span class=\"comment\">\"Cross Entropy\"</span> </span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">title</span> <span class=\"comment\">\"Traing Loss\"</span></span><br><span class=\"line\">replot</span><br></pre></td></tr></table></figure></p>\n<p>将上面的命令以此执行，就能将横坐标设置为”Epoch”，纵坐标设置为”Cross Entropy”，设置图的标题为”Traing Loss”。<code>replot</code>将图重新画一遍，这样我们就会把我们增加内容绘制在图当中了。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot2.png\" alt=\"plot2\"><br>上面的图我们已经基本上画好，图的各种元素已经完备了，但是仍然不好看，所以下面我们来进一步优化我们的图，选一篇我前面在看的文章，Dolz等人设计的HyperDense网络[2]，我们按照他们的绘图风格来进一步优化我们的图。<br>对比他们的损失函数的图(文献[2]中的图3，如下图所示)，我们可以看出，我们的图名太小，纵坐标的名字不够清晰，图例没有加框，曲线不够平滑。另外我们绘制的是损失函数的收敛曲线，我们应该让其看起来收敛(虽然实际上选取数据的这段还没有收敛)。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/hyperdense.png\" alt=\"hyperdense\"><br>首先我们添加网格<br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"builtin-name\">set</span> grid</span><br></pre></td></tr></table></figure></p>\n<p>然后，将横纵坐标刻度设置为”Times New Roman”，10号字，横纵坐标名设置为”Times New Roman”，14号字。设置图例为12号字。<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> xtics <span class=\"comment\">font</span> <span class=\"comment\">'times.ttf,10'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">ytics font</span> <span class=\"comment\">'times.ttf,10'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">xlabel</span> <span class=\"comment\">'Epoch'</span><span class=\"comment\"> font</span> <span class=\"comment\">'times.ttf,14'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">ylabel</span> <span class=\"comment\">'Cross Entropy'</span><span class=\"comment\"> font</span> <span class=\"comment\">'times.ttf,14'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">title</span> <span class=\"comment\">'Traing Loss'</span><span class=\"comment\"> font</span> <span class=\"comment\">'times.ttf,14'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key font</span> <span class=\"comment\">'times.ttf,12'</span></span><br></pre></td></tr></table></figure></p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot3.png\" alt=\"plot3\"><br>这时我们再看我们画的图，已经基本具有一般学术论文的样子了。但是，我们仍有可以提高的地方，比如说，我们的线条颜色不好看，我们的收敛曲线看不出收敛的趋势。<br>更改线条的颜色，我们改成红色：<br><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">set</span> style <span class=\"built_in\">line</span> <span class=\"number\">1</span> lw <span class=\"number\">1.5</span> lc rgb <span class=\"string\">\"#F62217\"</span></span><br><span class=\"line\">plot <span class=\"built_in\">file</span> <span class=\"keyword\">using</span> <span class=\"number\">1</span>:<span class=\"number\">2</span> <span class=\"keyword\">with</span> <span class=\"keyword\">lines</span> ls <span class=\"number\">1</span> title <span class=\"string\">\"CNN\"</span></span><br></pre></td></tr></table></figure></p>\n<p>另外常用的两种线条颜色，一个是蓝色一个是黄色。<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> style <span class=\"comment\">line 2 linewidth 2 linecolor rgb</span> <span class=\"comment\">\"#D4A017\"</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">style line 3 linewidth 3 linecolor rgb</span> <span class=\"comment\">\"#2B60DE\"</span></span><br></pre></td></tr></table></figure></p>\n<p>将纵坐标设范围为0.04-0.10，这样我们曲线更加集中，可以更好地看出收敛趋势。<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> yrange <span class=\"comment\">[0.04:0.10]</span></span><br></pre></td></tr></table></figure></p>\n<p>下面我们为图例加框，设置图例位置，图例框宽度为2，高度为1，文字为左对齐，线段在左文字在右，并且设置图例线段长度为2。<br><figure class=\"highlight processing\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> <span class=\"built_in\">box</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> center at <span class=\"number\">42</span>,<span class=\"number\">0.09</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> <span class=\"built_in\">width</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> <span class=\"built_in\">height</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> Left</span><br><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> <span class=\"built_in\">reverse</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> <span class=\"built_in\">key</span> samplen <span class=\"number\">2</span></span><br></pre></td></tr></table></figure></p>\n<p>经过上面一顿猛如虎的操作，我们已经基本上绘制出了可以放在论文里面的图了，下面是我们绘制的结果：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot4.png\" alt=\"plot4\"><br>但是，我们仍能优化这个图，我们希望它能更加的平滑。下面我们使它更加平滑，在gnuplot中的数据平滑命令为smooth，然后常用的算法为$bezier$和esplines$，因为$splines$要额外的平滑权重，这里我们就使用不需要平滑权重的bezier算法。<br><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plot ”loss.dat“ <span class=\"keyword\">using</span> <span class=\"number\">1</span>:<span class=\"number\">2</span> <span class=\"keyword\">with</span> <span class=\"keyword\">lines</span> ls <span class=\"number\">1</span> smooth bezier title <span class=\"string\">\"CNN\"</span></span><br></pre></td></tr></table></figure></p>\n<p>这就可以得到我们最终需要的曲线图了。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/result.png\" alt=\"result\"></p>\n<h1 id=\"利用脚本绘图\"><a href=\"#利用脚本绘图\" class=\"headerlink\" title=\"利用脚本绘图\"></a>利用脚本绘图</h1><p>聪明的你一定在想，难道我每次都需要一行一行的输入命令吗？其实我们完全可以使用脚本，将前面的命令写进脚本中，然后一次运行就可以得到我们最终的绘图结果了。首先我们需要建立一个文件，文件名为$loss.gnu$，将这个放置在于数据相同的文件夹内，我们这里是<code>E:\\plot</code>。<br>脚本的内容如下：<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> encoding <span class=\"comment\">utf8</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">term wxt enhanced</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">xtics font</span> <span class=\"comment\">'times.ttf,10'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">ytics font</span> <span class=\"comment\">'times.ttf,10'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">xlabel</span> <span class=\"comment\">'Epoch'</span><span class=\"comment\"> font</span> <span class=\"comment\">'times.ttf,14'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">ylabel</span> <span class=\"comment\">'Cross Entropy'</span><span class=\"comment\"> font</span> <span class=\"comment\">'times.ttf,14'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">title</span> <span class=\"comment\">'Traing Loss'</span><span class=\"comment\"> font</span> <span class=\"comment\">'times.ttf,14'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key font</span> <span class=\"comment\">'times.ttf,12'</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key center at 42,0.09</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key box</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key reverse</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key width 2</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key height 1</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key Left</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">key samplen 2</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">grid</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">yrange [0.04:0.10]</span></span><br><span class=\"line\"><span class=\"keyword\">set</span> <span class=\"comment\">style line 1 lw 1.5 lc rgb</span> <span class=\"comment\">\"#F62217\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">file <span class=\"comment\">=</span> <span class=\"comment\">\"loss.dat\"</span></span><br><span class=\"line\">plot <span class=\"comment\">file using 1:2 with lines ls 1 smooth bezier title</span> <span class=\"comment\">\"CNN\"</span></span><br></pre></td></tr></table></figure></p>\n<p>我们在命令行里面输入<code>load loss.gnu</code>运行整个脚本，得到我们最后想要的图片了。<br>至此，我们关于使用gnuplot绘制SCI论文图的方法就介绍完毕了，如果大家有需要可以参考文献[1]的内容了解更多。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://vision.ouc.edu.cn/zhenghaiyong/courses/tutorials/gnuplot/gnuplot-zh.pdf\" target=\"_blank\" rel=\"noopener\">http://vision.ouc.edu.cn/zhenghaiyong/courses/tutorials/gnuplot/gnuplot-zh.pdf</a><br>[2] Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>小同学，也许你在看论文时也困惑过别人的图为何画的如此的美，如此的精细，不用担心，这里教你SCI级别的论文绘图方法，一看就会，动手就忘（划掉，当然，你可以联系我帮你画，价格好商量）。</p>\n<h1 id=\"软件介绍\"><a href=\"#软件介绍\" class=\"headerlink\" title=\"软件介绍\"></a>软件介绍</h1><p>我们这里使用的软件叫做gnuplot，这是命令行驱动的绘图工具，可以讲数学函数或数值资料以平面图或者立体图的形式在不同种类的终端机或者是绘图输出装置上。另外，gnuplot是开源的，不必担心版权问题。</p>\n<h2 id=\"软件安装\"><a href=\"#软件安装\" class=\"headerlink\" title=\"软件安装\"></a>软件安装</h2><p>Windows平台下使用gnuplot非常简单，只要到<a href=\"http://www.gnuplot.info/\" target=\"_blank\" rel=\"noopener\">gnuplot官网</a>上找到windows版本下载安装即可，双击打开安装后的软件，是如下图的界面。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/gnu_terminal.png\" alt=\"gnu_terminal\"></p>\n<h1 id=\"开始绘图\"><a href=\"#开始绘图\" class=\"headerlink\" title=\"开始绘图\"></a>开始绘图</h1><p>我们只需要在<code>&gt;gnuplot</code>后面写命令就可以画图了，如果我们想要画一个正弦曲线，我们只需要输入下面的命令即可；<br><!--�48--></p>\n<p>这样我们就得到了一个绘制的正弦曲线，当然我们的目标是为了绘制出SCI论文级的图，当然不能满足于此了。<br>下面我们来真正开始看如何绘制一个SCI级别论文图。</p>\n<h1 id=\"SCI绘图\"><a href=\"#SCI绘图\" class=\"headerlink\" title=\"SCI绘图\"></a>SCI绘图</h1><p>下面我们来看一个实际的绘图的情况，下面我用实际训练神经网络的损失函数来举例使用gnuplot绘制的方法。<br>首先我们有数据文件，这个数据文件我们命名为 $loss.dat$，保存在<code>E:\\plot</code>下，数据的格式如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/data.png\" alt=\"data\"><br>下面我们使用<code>plot</code>命令来画我们这个文件的数据，首先我们需要切换到数据文件的保存路径，也就是<code>E:\\plot</code>，大家可以使用软件的<code>CHDir</code>切换，也可以使用<code>cd &quot;E:\\plot&quot;</code>切换到数据保存文件的路径。<br>使用如下的命令就能绘制出这个文件的图了：<br><!--�49--></p>\n<p>这行代码表示，我们使用<code>loss.dat</code>的第1、2列数据绘制线，并且设置图例为<code>title</code>。<br>我们会绘制出下图的结果：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot1.png\" alt=\"plot1\"><br>上面的图是个不完整的图，它没有横纵坐标的描述，也没有图的标题，下面我们来设置这些：<br><!--�50--></p>\n<p>将上面的命令以此执行，就能将横坐标设置为”Epoch”，纵坐标设置为”Cross Entropy”，设置图的标题为”Traing Loss”。<code>replot</code>将图重新画一遍，这样我们就会把我们增加内容绘制在图当中了。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot2.png\" alt=\"plot2\"><br>上面的图我们已经基本上画好，图的各种元素已经完备了，但是仍然不好看，所以下面我们来进一步优化我们的图，选一篇我前面在看的文章，Dolz等人设计的HyperDense网络[2]，我们按照他们的绘图风格来进一步优化我们的图。<br>对比他们的损失函数的图(文献[2]中的图3，如下图所示)，我们可以看出，我们的图名太小，纵坐标的名字不够清晰，图例没有加框，曲线不够平滑。另外我们绘制的是损失函数的收敛曲线，我们应该让其看起来收敛(虽然实际上选取数据的这段还没有收敛)。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/hyperdense.png\" alt=\"hyperdense\"><br>首先我们添加网格<br><!--�51--></p>\n<p>然后，将横纵坐标刻度设置为”Times New Roman”，10号字，横纵坐标名设置为”Times New Roman”，14号字。设置图例为12号字。<br><!--�52--></p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot3.png\" alt=\"plot3\"><br>这时我们再看我们画的图，已经基本具有一般学术论文的样子了。但是，我们仍有可以提高的地方，比如说，我们的线条颜色不好看，我们的收敛曲线看不出收敛的趋势。<br>更改线条的颜色，我们改成红色：<br><!--�53--></p>\n<p>另外常用的两种线条颜色，一个是蓝色一个是黄色。<br><!--�54--></p>\n<p>将纵坐标设范围为0.04-0.10，这样我们曲线更加集中，可以更好地看出收敛趋势。<br><!--�55--></p>\n<p>下面我们为图例加框，设置图例位置，图例框宽度为2，高度为1，文字为左对齐，线段在左文字在右，并且设置图例线段长度为2。<br><!--�56--></p>\n<p>经过上面一顿猛如虎的操作，我们已经基本上绘制出了可以放在论文里面的图了，下面是我们绘制的结果：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/plot4.png\" alt=\"plot4\"><br>但是，我们仍能优化这个图，我们希望它能更加的平滑。下面我们使它更加平滑，在gnuplot中的数据平滑命令为smooth，然后常用的算法为$bezier$和esplines$，因为$splines$要额外的平滑权重，这里我们就使用不需要平滑权重的bezier算法。<br><!--�57--></p>\n<p>这就可以得到我们最终需要的曲线图了。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/gnuplot/result.png\" alt=\"result\"></p>\n<h1 id=\"利用脚本绘图\"><a href=\"#利用脚本绘图\" class=\"headerlink\" title=\"利用脚本绘图\"></a>利用脚本绘图</h1><p>聪明的你一定在想，难道我每次都需要一行一行的输入命令吗？其实我们完全可以使用脚本，将前面的命令写进脚本中，然后一次运行就可以得到我们最终的绘图结果了。首先我们需要建立一个文件，文件名为$loss.gnu$，将这个放置在于数据相同的文件夹内，我们这里是<code>E:\\plot</code>。<br>脚本的内容如下：<br><!--�58--></p>\n<p>我们在命令行里面输入<code>load loss.gnu</code>运行整个脚本，得到我们最后想要的图片了。<br>至此，我们关于使用gnuplot绘制SCI论文图的方法就介绍完毕了，如果大家有需要可以参考文献[1]的内容了解更多。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://vision.ouc.edu.cn/zhenghaiyong/courses/tutorials/gnuplot/gnuplot-zh.pdf\" target=\"_blank\" rel=\"noopener\">http://vision.ouc.edu.cn/zhenghaiyong/courses/tutorials/gnuplot/gnuplot-zh.pdf</a><br>[2] Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.</p>\n"},{"title":"多模态机器学习总结与多模态医学图像处理","date":"2018-10-03T09:25:45.000Z","_content":"# 多模态机器学习\n下面是我参考文章[1]总结出来多模态机器学习中存在的挑战，以及目前所使用的方法的思维导图。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif)\n\n# 多模态医学图像数据集\n1. 脑肿瘤分割数据集\n[1] Menze B H, Jakab A, Bauer S, et al. The multimodal brain tumor image segmentation benchmark (BRATS)[J]. IEEE transactions on medical imaging, 2015, 34(10): 1993.\nhttps://www.med.upenn.edu/sbia/brats2018.html\n这个数据集是多模态核磁成像数据集，对肿瘤进行不同尺度的扫描，然后进行多模态分割。\n\n2. 融合数据库\nhttp://www.med.harvard.edu/AANLIB/\nhttp://www.metapix.de/\n\n3. IXI数据库\nhttp://brain-development.org/ixi-dataset/\n这个数据库包含600张MRI图像，可以用于预训练，下面的文章使用了在这个方法。\nSimonovsky M, Gutiérrez-Becker B, Mateus D, et al. A deep metric for multimodal registration[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2016: 10-18.\n\n4. Radiology Objects in COntext\nhttps://github.com/razorx89/roco-dataset\n可以用于训练生成模型生成图片标题，用于分类图片的分类模型，还有基于内容的图像检索。\n\n5. Grand Challenges in Biomedical Image Analysis\nhttps://grand-challenge.org/\n这个网站是对已经发表的论文或者是目前使用的算法提供一个竞赛的平台，里面有很多公开的医学图像数据集，其中包括1， 6， 7中的数据集。\n\n6. Motion Tracking Challenge\nhttp://stacom.cardiacatlas.org/motion-tracking-challenge/\n这个数据库中包含有MRI和3D ultrasound 两个模态的图像。\n\n7. ​Automatic Intervertebral Disc Localization and Segmentation from 3D Multi-modality MR (M3) Images \nhttps://ivdm3seg.weebly.com/data.html\n这个数据集是MRI图像，用于定位和分割。\n\n8. 一些数据集\nhttps://sites.google.com/site/aacruzr/image-datasets\n\n9. Image Registration Evaluation Project\nhttp://www.insight-journal.org/rire/\n用作image registratration效果评价的数据集\n\n10. DICOM image sample sets\n有一些数据供下载，部分是多模态的，数量比较少，只是一些例子，另外，看起来是注册是要收费的样子。\n\n11. https://ida.loni.usc.edu/login.jsp\n一些脑神经科学的医学图像数据库\n\n12. ANDI(阿尔兹海默症)\nhttp://adni.loni.usc.edu/data-samples/access-data/\n\n13. Cancer Imaging Archive\nhttp://www.cancerimagingarchive.net/\n\n# 参考资料\n[1] Baltrušaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.\n\n\n\n","source":"_posts/Multimodal-Machine-Learning.md","raw":"---\ntitle: 多模态机器学习总结与多模态医学图像处理\ndate: 2018-10-03 17:25:45\ntags: 多模态机器学习\ncategories: 学习\n---\n# 多模态机器学习\n下面是我参考文章[1]总结出来多模态机器学习中存在的挑战，以及目前所使用的方法的思维导图。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif)\n\n# 多模态医学图像数据集\n1. 脑肿瘤分割数据集\n[1] Menze B H, Jakab A, Bauer S, et al. The multimodal brain tumor image segmentation benchmark (BRATS)[J]. IEEE transactions on medical imaging, 2015, 34(10): 1993.\nhttps://www.med.upenn.edu/sbia/brats2018.html\n这个数据集是多模态核磁成像数据集，对肿瘤进行不同尺度的扫描，然后进行多模态分割。\n\n2. 融合数据库\nhttp://www.med.harvard.edu/AANLIB/\nhttp://www.metapix.de/\n\n3. IXI数据库\nhttp://brain-development.org/ixi-dataset/\n这个数据库包含600张MRI图像，可以用于预训练，下面的文章使用了在这个方法。\nSimonovsky M, Gutiérrez-Becker B, Mateus D, et al. A deep metric for multimodal registration[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2016: 10-18.\n\n4. Radiology Objects in COntext\nhttps://github.com/razorx89/roco-dataset\n可以用于训练生成模型生成图片标题，用于分类图片的分类模型，还有基于内容的图像检索。\n\n5. Grand Challenges in Biomedical Image Analysis\nhttps://grand-challenge.org/\n这个网站是对已经发表的论文或者是目前使用的算法提供一个竞赛的平台，里面有很多公开的医学图像数据集，其中包括1， 6， 7中的数据集。\n\n6. Motion Tracking Challenge\nhttp://stacom.cardiacatlas.org/motion-tracking-challenge/\n这个数据库中包含有MRI和3D ultrasound 两个模态的图像。\n\n7. ​Automatic Intervertebral Disc Localization and Segmentation from 3D Multi-modality MR (M3) Images \nhttps://ivdm3seg.weebly.com/data.html\n这个数据集是MRI图像，用于定位和分割。\n\n8. 一些数据集\nhttps://sites.google.com/site/aacruzr/image-datasets\n\n9. Image Registration Evaluation Project\nhttp://www.insight-journal.org/rire/\n用作image registratration效果评价的数据集\n\n10. DICOM image sample sets\n有一些数据供下载，部分是多模态的，数量比较少，只是一些例子，另外，看起来是注册是要收费的样子。\n\n11. https://ida.loni.usc.edu/login.jsp\n一些脑神经科学的医学图像数据库\n\n12. ANDI(阿尔兹海默症)\nhttp://adni.loni.usc.edu/data-samples/access-data/\n\n13. Cancer Imaging Archive\nhttp://www.cancerimagingarchive.net/\n\n# 参考资料\n[1] Baltrušaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.\n\n\n\n","slug":"Multimodal-Machine-Learning","published":1,"updated":"2018-10-16T11:55:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mse000i1ouzfgpp0pq1","content":"<h1 id=\"多模态机器学习\"><a href=\"#多模态机器学习\" class=\"headerlink\" title=\"多模态机器学习\"></a>多模态机器学习</h1><p>下面是我参考文章[1]总结出来多模态机器学习中存在的挑战，以及目前所使用的方法的思维导图。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif\" alt></p>\n<h1 id=\"多模态医学图像数据集\"><a href=\"#多模态医学图像数据集\" class=\"headerlink\" title=\"多模态医学图像数据集\"></a>多模态医学图像数据集</h1><ol>\n<li><p>脑肿瘤分割数据集<br>[1] Menze B H, Jakab A, Bauer S, et al. The multimodal brain tumor image segmentation benchmark (BRATS)[J]. IEEE transactions on medical imaging, 2015, 34(10): 1993.<br><a href=\"https://www.med.upenn.edu/sbia/brats2018.html\" target=\"_blank\" rel=\"noopener\">https://www.med.upenn.edu/sbia/brats2018.html</a><br>这个数据集是多模态核磁成像数据集，对肿瘤进行不同尺度的扫描，然后进行多模态分割。</p>\n</li>\n<li><p>融合数据库<br><a href=\"http://www.med.harvard.edu/AANLIB/\" target=\"_blank\" rel=\"noopener\">http://www.med.harvard.edu/AANLIB/</a><br><a href=\"http://www.metapix.de/\" target=\"_blank\" rel=\"noopener\">http://www.metapix.de/</a></p>\n</li>\n<li><p>IXI数据库<br><a href=\"http://brain-development.org/ixi-dataset/\" target=\"_blank\" rel=\"noopener\">http://brain-development.org/ixi-dataset/</a><br>这个数据库包含600张MRI图像，可以用于预训练，下面的文章使用了在这个方法。<br>Simonovsky M, Gutiérrez-Becker B, Mateus D, et al. A deep metric for multimodal registration[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2016: 10-18.</p>\n</li>\n<li><p>Radiology Objects in COntext<br><a href=\"https://github.com/razorx89/roco-dataset\" target=\"_blank\" rel=\"noopener\">https://github.com/razorx89/roco-dataset</a><br>可以用于训练生成模型生成图片标题，用于分类图片的分类模型，还有基于内容的图像检索。</p>\n</li>\n<li><p>Grand Challenges in Biomedical Image Analysis<br><a href=\"https://grand-challenge.org/\" target=\"_blank\" rel=\"noopener\">https://grand-challenge.org/</a><br>这个网站是对已经发表的论文或者是目前使用的算法提供一个竞赛的平台，里面有很多公开的医学图像数据集，其中包括1， 6， 7中的数据集。</p>\n</li>\n<li><p>Motion Tracking Challenge<br><a href=\"http://stacom.cardiacatlas.org/motion-tracking-challenge/\" target=\"_blank\" rel=\"noopener\">http://stacom.cardiacatlas.org/motion-tracking-challenge/</a><br>这个数据库中包含有MRI和3D ultrasound 两个模态的图像。</p>\n</li>\n<li><p>​Automatic Intervertebral Disc Localization and Segmentation from 3D Multi-modality MR (M3) Images<br><a href=\"https://ivdm3seg.weebly.com/data.html\" target=\"_blank\" rel=\"noopener\">https://ivdm3seg.weebly.com/data.html</a><br>这个数据集是MRI图像，用于定位和分割。</p>\n</li>\n<li><p>一些数据集<br><a href=\"https://sites.google.com/site/aacruzr/image-datasets\" target=\"_blank\" rel=\"noopener\">https://sites.google.com/site/aacruzr/image-datasets</a></p>\n</li>\n<li><p>Image Registration Evaluation Project<br><a href=\"http://www.insight-journal.org/rire/\" target=\"_blank\" rel=\"noopener\">http://www.insight-journal.org/rire/</a><br>用作image registratration效果评价的数据集</p>\n</li>\n<li><p>DICOM image sample sets<br>有一些数据供下载，部分是多模态的，数量比较少，只是一些例子，另外，看起来是注册是要收费的样子。</p>\n</li>\n<li><p><a href=\"https://ida.loni.usc.edu/login.jsp\" target=\"_blank\" rel=\"noopener\">https://ida.loni.usc.edu/login.jsp</a><br>一些脑神经科学的医学图像数据库</p>\n</li>\n<li><p>ANDI(阿尔兹海默症)<br><a href=\"http://adni.loni.usc.edu/data-samples/access-data/\" target=\"_blank\" rel=\"noopener\">http://adni.loni.usc.edu/data-samples/access-data/</a></p>\n</li>\n<li><p>Cancer Imaging Archive<br><a href=\"http://www.cancerimagingarchive.net/\" target=\"_blank\" rel=\"noopener\">http://www.cancerimagingarchive.net/</a></p>\n</li>\n</ol>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] Baltrušaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"多模态机器学习\"><a href=\"#多模态机器学习\" class=\"headerlink\" title=\"多模态机器学习\"></a>多模态机器学习</h1><p>下面是我参考文章[1]总结出来多模态机器学习中存在的挑战，以及目前所使用的方法的思维导图。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif\" alt></p>\n<h1 id=\"多模态医学图像数据集\"><a href=\"#多模态医学图像数据集\" class=\"headerlink\" title=\"多模态医学图像数据集\"></a>多模态医学图像数据集</h1><ol>\n<li><p>脑肿瘤分割数据集<br>[1] Menze B H, Jakab A, Bauer S, et al. The multimodal brain tumor image segmentation benchmark (BRATS)[J]. IEEE transactions on medical imaging, 2015, 34(10): 1993.<br><a href=\"https://www.med.upenn.edu/sbia/brats2018.html\" target=\"_blank\" rel=\"noopener\">https://www.med.upenn.edu/sbia/brats2018.html</a><br>这个数据集是多模态核磁成像数据集，对肿瘤进行不同尺度的扫描，然后进行多模态分割。</p>\n</li>\n<li><p>融合数据库<br><a href=\"http://www.med.harvard.edu/AANLIB/\" target=\"_blank\" rel=\"noopener\">http://www.med.harvard.edu/AANLIB/</a><br><a href=\"http://www.metapix.de/\" target=\"_blank\" rel=\"noopener\">http://www.metapix.de/</a></p>\n</li>\n<li><p>IXI数据库<br><a href=\"http://brain-development.org/ixi-dataset/\" target=\"_blank\" rel=\"noopener\">http://brain-development.org/ixi-dataset/</a><br>这个数据库包含600张MRI图像，可以用于预训练，下面的文章使用了在这个方法。<br>Simonovsky M, Gutiérrez-Becker B, Mateus D, et al. A deep metric for multimodal registration[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2016: 10-18.</p>\n</li>\n<li><p>Radiology Objects in COntext<br><a href=\"https://github.com/razorx89/roco-dataset\" target=\"_blank\" rel=\"noopener\">https://github.com/razorx89/roco-dataset</a><br>可以用于训练生成模型生成图片标题，用于分类图片的分类模型，还有基于内容的图像检索。</p>\n</li>\n<li><p>Grand Challenges in Biomedical Image Analysis<br><a href=\"https://grand-challenge.org/\" target=\"_blank\" rel=\"noopener\">https://grand-challenge.org/</a><br>这个网站是对已经发表的论文或者是目前使用的算法提供一个竞赛的平台，里面有很多公开的医学图像数据集，其中包括1， 6， 7中的数据集。</p>\n</li>\n<li><p>Motion Tracking Challenge<br><a href=\"http://stacom.cardiacatlas.org/motion-tracking-challenge/\" target=\"_blank\" rel=\"noopener\">http://stacom.cardiacatlas.org/motion-tracking-challenge/</a><br>这个数据库中包含有MRI和3D ultrasound 两个模态的图像。</p>\n</li>\n<li><p>​Automatic Intervertebral Disc Localization and Segmentation from 3D Multi-modality MR (M3) Images<br><a href=\"https://ivdm3seg.weebly.com/data.html\" target=\"_blank\" rel=\"noopener\">https://ivdm3seg.weebly.com/data.html</a><br>这个数据集是MRI图像，用于定位和分割。</p>\n</li>\n<li><p>一些数据集<br><a href=\"https://sites.google.com/site/aacruzr/image-datasets\" target=\"_blank\" rel=\"noopener\">https://sites.google.com/site/aacruzr/image-datasets</a></p>\n</li>\n<li><p>Image Registration Evaluation Project<br><a href=\"http://www.insight-journal.org/rire/\" target=\"_blank\" rel=\"noopener\">http://www.insight-journal.org/rire/</a><br>用作image registratration效果评价的数据集</p>\n</li>\n<li><p>DICOM image sample sets<br>有一些数据供下载，部分是多模态的，数量比较少，只是一些例子，另外，看起来是注册是要收费的样子。</p>\n</li>\n<li><p><a href=\"https://ida.loni.usc.edu/login.jsp\" target=\"_blank\" rel=\"noopener\">https://ida.loni.usc.edu/login.jsp</a><br>一些脑神经科学的医学图像数据库</p>\n</li>\n<li><p>ANDI(阿尔兹海默症)<br><a href=\"http://adni.loni.usc.edu/data-samples/access-data/\" target=\"_blank\" rel=\"noopener\">http://adni.loni.usc.edu/data-samples/access-data/</a></p>\n</li>\n<li><p>Cancer Imaging Archive<br><a href=\"http://www.cancerimagingarchive.net/\" target=\"_blank\" rel=\"noopener\">http://www.cancerimagingarchive.net/</a></p>\n</li>\n</ol>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] Baltrušaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.</p>\n"},{"title":"VGGNet","date":"2018-08-31T09:43:18.000Z","_content":"# VGGNet模型结构\nVGGNet是牛津大学视觉组(Visual Geometry Group)和Google DeepMind公司研究员共同研究出的深度卷积神经网络。VGGNet使用的比较小的卷积核(3x3)以及2x2的最大池化层，通过增加层数增强非线性性能，同时相较于7x7的卷积核而言，减少了参数。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/vgg16.jpg)\n## VGG16模型处理过程\n以上面图的D为例，下面简要的阐述VGGNet模型的处理过程。\n1. 输入224x224x3的图片，经过64个3x3的卷积核做两次卷积+ReLU，变成224x224x64。\n2. 做MaxPool，池化尺寸为2x2，步长(stride)为2。\n3. 经过128个3x3的卷积核做两次卷积+ReLU，尺寸变为112x112x128。\n4. MaxPool，尺寸变为56x56x128。\n5. 256个3x3的卷积核做三次卷积+ReLU，尺寸变为56x56x256。\n6. MaxPool，尺寸变为28x28x256。\n7. 经512个3x3的卷积核做三次卷积+ReLU，尺寸变为28x28x512。\n8. MaxPool，尺寸变为14x14x512。\n9. 经512个3x3的卷积核做三次卷积+ReLU，尺寸变为14x14x512。\n10. MaxPool，尺寸变为7x7x512。\n11. 与两层1x1x4096，一层1x1x1000进行全连接+ReLU(共三层)。\n12. 通过softmax输出1000个预测结果。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG16%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG%E5%8F%82%E6%95%B0.png)\n\n# 利用VGG19实现火灾分类\n主要参考[1]中的代码，另外我将自己跑出的结果贴在了我的github上，具体地址为[[4]](https://github.com/hjyai94/VGG)。\n\n\n\n# 参考文献\n[1] http://www.cnblogs.com/vipyoumay/p/7884472.html\n[2] https://my.oschina.net/u/876354/blog/1634322\n[3] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.\n[4] https://github.com/hjyai94/VGG\n","source":"_posts/VGG16.md","raw":"---\ntitle: VGGNet\ndate: 2018-08-31 17:43:18\ntags: Deep Learning\ncategories: 学习\n---\n# VGGNet模型结构\nVGGNet是牛津大学视觉组(Visual Geometry Group)和Google DeepMind公司研究员共同研究出的深度卷积神经网络。VGGNet使用的比较小的卷积核(3x3)以及2x2的最大池化层，通过增加层数增强非线性性能，同时相较于7x7的卷积核而言，减少了参数。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/vgg16.jpg)\n## VGG16模型处理过程\n以上面图的D为例，下面简要的阐述VGGNet模型的处理过程。\n1. 输入224x224x3的图片，经过64个3x3的卷积核做两次卷积+ReLU，变成224x224x64。\n2. 做MaxPool，池化尺寸为2x2，步长(stride)为2。\n3. 经过128个3x3的卷积核做两次卷积+ReLU，尺寸变为112x112x128。\n4. MaxPool，尺寸变为56x56x128。\n5. 256个3x3的卷积核做三次卷积+ReLU，尺寸变为56x56x256。\n6. MaxPool，尺寸变为28x28x256。\n7. 经512个3x3的卷积核做三次卷积+ReLU，尺寸变为28x28x512。\n8. MaxPool，尺寸变为14x14x512。\n9. 经512个3x3的卷积核做三次卷积+ReLU，尺寸变为14x14x512。\n10. MaxPool，尺寸变为7x7x512。\n11. 与两层1x1x4096，一层1x1x1000进行全连接+ReLU(共三层)。\n12. 通过softmax输出1000个预测结果。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG16%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png)\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG%E5%8F%82%E6%95%B0.png)\n\n# 利用VGG19实现火灾分类\n主要参考[1]中的代码，另外我将自己跑出的结果贴在了我的github上，具体地址为[[4]](https://github.com/hjyai94/VGG)。\n\n\n\n# 参考文献\n[1] http://www.cnblogs.com/vipyoumay/p/7884472.html\n[2] https://my.oschina.net/u/876354/blog/1634322\n[3] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.\n[4] https://github.com/hjyai94/VGG\n","slug":"VGG16","published":1,"updated":"2018-09-22T06:31:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msf000j1ouz39l6gqbf","content":"<h1 id=\"VGGNet模型结构\"><a href=\"#VGGNet模型结构\" class=\"headerlink\" title=\"VGGNet模型结构\"></a>VGGNet模型结构</h1><p>VGGNet是牛津大学视觉组(Visual Geometry Group)和Google DeepMind公司研究员共同研究出的深度卷积神经网络。VGGNet使用的比较小的卷积核(3x3)以及2x2的最大池化层，通过增加层数增强非线性性能，同时相较于7x7的卷积核而言，减少了参数。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/vgg16.jpg\" alt></p>\n<h2 id=\"VGG16模型处理过程\"><a href=\"#VGG16模型处理过程\" class=\"headerlink\" title=\"VGG16模型处理过程\"></a>VGG16模型处理过程</h2><p>以上面图的D为例，下面简要的阐述VGGNet模型的处理过程。</p>\n<ol>\n<li>输入224x224x3的图片，经过64个3x3的卷积核做两次卷积+ReLU，变成224x224x64。</li>\n<li>做MaxPool，池化尺寸为2x2，步长(stride)为2。</li>\n<li>经过128个3x3的卷积核做两次卷积+ReLU，尺寸变为112x112x128。</li>\n<li>MaxPool，尺寸变为56x56x128。</li>\n<li>256个3x3的卷积核做三次卷积+ReLU，尺寸变为56x56x256。</li>\n<li>MaxPool，尺寸变为28x28x256。</li>\n<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为28x28x512。</li>\n<li>MaxPool，尺寸变为14x14x512。</li>\n<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为14x14x512。</li>\n<li>MaxPool，尺寸变为7x7x512。</li>\n<li>与两层1x1x4096，一层1x1x1000进行全连接+ReLU(共三层)。</li>\n<li>通过softmax输出1000个预测结果。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG16%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png\" alt><br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG%E5%8F%82%E6%95%B0.png\" alt></li>\n</ol>\n<h1 id=\"利用VGG19实现火灾分类\"><a href=\"#利用VGG19实现火灾分类\" class=\"headerlink\" title=\"利用VGG19实现火灾分类\"></a>利用VGG19实现火灾分类</h1><p>主要参考[1]中的代码，另外我将自己跑出的结果贴在了我的github上，具体地址为<a href=\"https://github.com/hjyai94/VGG\" target=\"_blank\" rel=\"noopener\">[4]</a>。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cnblogs.com/vipyoumay/p/7884472.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/vipyoumay/p/7884472.html</a><br>[2] <a href=\"https://my.oschina.net/u/876354/blog/1634322\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/u/876354/blog/1634322</a><br>[3] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.<br>[4] <a href=\"https://github.com/hjyai94/VGG\" target=\"_blank\" rel=\"noopener\">https://github.com/hjyai94/VGG</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"VGGNet模型结构\"><a href=\"#VGGNet模型结构\" class=\"headerlink\" title=\"VGGNet模型结构\"></a>VGGNet模型结构</h1><p>VGGNet是牛津大学视觉组(Visual Geometry Group)和Google DeepMind公司研究员共同研究出的深度卷积神经网络。VGGNet使用的比较小的卷积核(3x3)以及2x2的最大池化层，通过增加层数增强非线性性能，同时相较于7x7的卷积核而言，减少了参数。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/vgg16.jpg\" alt></p>\n<h2 id=\"VGG16模型处理过程\"><a href=\"#VGG16模型处理过程\" class=\"headerlink\" title=\"VGG16模型处理过程\"></a>VGG16模型处理过程</h2><p>以上面图的D为例，下面简要的阐述VGGNet模型的处理过程。</p>\n<ol>\n<li>输入224x224x3的图片，经过64个3x3的卷积核做两次卷积+ReLU，变成224x224x64。</li>\n<li>做MaxPool，池化尺寸为2x2，步长(stride)为2。</li>\n<li>经过128个3x3的卷积核做两次卷积+ReLU，尺寸变为112x112x128。</li>\n<li>MaxPool，尺寸变为56x56x128。</li>\n<li>256个3x3的卷积核做三次卷积+ReLU，尺寸变为56x56x256。</li>\n<li>MaxPool，尺寸变为28x28x256。</li>\n<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为28x28x512。</li>\n<li>MaxPool，尺寸变为14x14x512。</li>\n<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为14x14x512。</li>\n<li>MaxPool，尺寸变为7x7x512。</li>\n<li>与两层1x1x4096，一层1x1x1000进行全连接+ReLU(共三层)。</li>\n<li>通过softmax输出1000个预测结果。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG16%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png\" alt><br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG%E5%8F%82%E6%95%B0.png\" alt></li>\n</ol>\n<h1 id=\"利用VGG19实现火灾分类\"><a href=\"#利用VGG19实现火灾分类\" class=\"headerlink\" title=\"利用VGG19实现火灾分类\"></a>利用VGG19实现火灾分类</h1><p>主要参考[1]中的代码，另外我将自己跑出的结果贴在了我的github上，具体地址为<a href=\"https://github.com/hjyai94/VGG\" target=\"_blank\" rel=\"noopener\">[4]</a>。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cnblogs.com/vipyoumay/p/7884472.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/vipyoumay/p/7884472.html</a><br>[2] <a href=\"https://my.oschina.net/u/876354/blog/1634322\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/u/876354/blog/1634322</a><br>[3] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.<br>[4] <a href=\"https://github.com/hjyai94/VGG\" target=\"_blank\" rel=\"noopener\">https://github.com/hjyai94/VGG</a></p>\n"},{"title":"git使用","date":"2018-02-01T01:20:45.000Z","_content":"创建新的仓库 `git init`\n从服务器上克隆库 `git clone 路径`\n添加和提交\n```\ngit pull origin master\ngit add .\ngit commit -m \"first commit\"\ngit push origin master\n```\n基本可以用来保存文件和从服务器上面下载代码，后面的还没有用到，用到再往这篇博客上面加。\n","source":"_posts/git使用.md","raw":"---\ntitle: git使用\ndate: 2018-02-01 09:20:45\ntags: git\ncategories: 技术\n---\n创建新的仓库 `git init`\n从服务器上克隆库 `git clone 路径`\n添加和提交\n```\ngit pull origin master\ngit add .\ngit commit -m \"first commit\"\ngit push origin master\n```\n基本可以用来保存文件和从服务器上面下载代码，后面的还没有用到，用到再往这篇博客上面加。\n","slug":"git使用","published":1,"updated":"2018-03-28T04:36:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msf000k1ouzxaqx8opt","content":"<p>创建新的仓库 <code>git init</code><br>从服务器上克隆库 <code>git clone 路径</code><br>添加和提交<br><figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git pull origin <span class=\"literal\">master</span></span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m <span class=\"string\">\"first commit\"</span></span><br><span class=\"line\">git push origin <span class=\"literal\">master</span></span><br></pre></td></tr></table></figure></p>\n<p>基本可以用来保存文件和从服务器上面下载代码，后面的还没有用到，用到再往这篇博客上面加。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>创建新的仓库 <code>git init</code><br>从服务器上克隆库 <code>git clone 路径</code><br>添加和提交<br><!--�59--></p>\n<p>基本可以用来保存文件和从服务器上面下载代码，后面的还没有用到，用到再往这篇博客上面加。</p>\n"},{"title":"记录Ubuntu中出现的问题及解决方案","date":"2018-06-13T16:00:00.000Z","_content":"# 执行sudo apt-get update 出错\n出现错误如下：\n`E: Some index files failed to download, they have been ignored, or old ones used instead'\n出现无法更新的情况，可以在`/etc/apt/sources.list.d`中删除对应错误名字的文件。\n","source":"_posts/Ubuntu中出现的问题.md","raw":"---\ntitle: 记录Ubuntu中出现的问题及解决方案\ndate: 2018-06-14\ntags: Ubuntu\ncategories: 技术\n---\n# 执行sudo apt-get update 出错\n出现错误如下：\n`E: Some index files failed to download, they have been ignored, or old ones used instead'\n出现无法更新的情况，可以在`/etc/apt/sources.list.d`中删除对应错误名字的文件。\n","slug":"Ubuntu中出现的问题","published":1,"updated":"2018-09-22T06:31:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msh000l1ouzhsh53eb9","content":"<h1 id=\"执行sudo-apt-get-update-出错\"><a href=\"#执行sudo-apt-get-update-出错\" class=\"headerlink\" title=\"执行sudo apt-get update 出错\"></a>执行sudo apt-get update 出错</h1><p>出现错误如下：<br><code>E: Some index files failed to download, they have been ignored, or old ones used instead&#39;\n出现无法更新的情况，可以在</code>/etc/apt/sources.list.d`中删除对应错误名字的文件。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"执行sudo-apt-get-update-出错\"><a href=\"#执行sudo-apt-get-update-出错\" class=\"headerlink\" title=\"执行sudo apt-get update 出错\"></a>执行sudo apt-get update 出错</h1><p>出现错误如下：<br><code>E: Some index files failed to download, they have been ignored, or old ones used instead&#39;\n出现无法更新的情况，可以在</code>/etc/apt/sources.list.d`中删除对应错误名字的文件。</p>\n"},{"title":"hexo博客使用","date":"2017-11-22T02:51:49.000Z","_content":"# 简单的语句\nhexo clean 清理缓存\nhexo g 或者 hexo generate 产生文件\nhexo d 或者 hexo deploy 发布博客\n\n# 重复输入密码问题\n启动ssh-agent后台 `eval $(ssh-agent)`\n添加密码 `ssh-add`\n这样就可以不必在当前的terminal重复输入密码了。\n","source":"_posts/hexo博客使用.md","raw":"---\ntitle: hexo博客使用\ndate: 2017-11-22 10:51:49\ntags:\n- hexo\ncategories: 技术\n---\n# 简单的语句\nhexo clean 清理缓存\nhexo g 或者 hexo generate 产生文件\nhexo d 或者 hexo deploy 发布博客\n\n# 重复输入密码问题\n启动ssh-agent后台 `eval $(ssh-agent)`\n添加密码 `ssh-add`\n这样就可以不必在当前的terminal重复输入密码了。\n","slug":"hexo博客使用","published":1,"updated":"2018-03-28T04:37:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msi000m1ouzk3b6arc2","content":"<h1 id=\"简单的语句\"><a href=\"#简单的语句\" class=\"headerlink\" title=\"简单的语句\"></a>简单的语句</h1><p>hexo clean 清理缓存<br>hexo g 或者 hexo generate 产生文件<br>hexo d 或者 hexo deploy 发布博客</p>\n<h1 id=\"重复输入密码问题\"><a href=\"#重复输入密码问题\" class=\"headerlink\" title=\"重复输入密码问题\"></a>重复输入密码问题</h1><p>启动ssh-agent后台 <code>eval $(ssh-agent)</code><br>添加密码 <code>ssh-add</code><br>这样就可以不必在当前的terminal重复输入密码了。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"简单的语句\"><a href=\"#简单的语句\" class=\"headerlink\" title=\"简单的语句\"></a>简单的语句</h1><p>hexo clean 清理缓存<br>hexo g 或者 hexo generate 产生文件<br>hexo d 或者 hexo deploy 发布博客</p>\n<h1 id=\"重复输入密码问题\"><a href=\"#重复输入密码问题\" class=\"headerlink\" title=\"重复输入密码问题\"></a>重复输入密码问题</h1><p>启动ssh-agent后台 <code>eval $(ssh-agent)</code><br>添加密码 <code>ssh-add</code><br>这样就可以不必在当前的terminal重复输入密码了。</p>\n"},{"title":"ubuntu16.04下安装atom","date":"2017-11-29T03:43:47.000Z","_content":"# 第一步\n`sudo add-apt-repository    ppa:webupd8team/atom`\n# 第二步\n`sudo apt-get update`\n# 第三步\n`sudo apt-get install atom`\n# 问题\n中间出了点问题，找不到图了，所以就不贴了。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/avatar.jpg)\n","source":"_posts/ubuntu16-04下安装atom.md","raw":"---\ntitle: ubuntu16.04下安装atom\ndate: 2017-11-29 11:43:47\ntags: ubuntu atom\ncategories: 技术\n---\n# 第一步\n`sudo add-apt-repository    ppa:webupd8team/atom`\n# 第二步\n`sudo apt-get update`\n# 第三步\n`sudo apt-get install atom`\n# 问题\n中间出了点问题，找不到图了，所以就不贴了。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/avatar.jpg)\n","slug":"ubuntu16-04下安装atom","published":1,"updated":"2018-09-22T06:31:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msk000n1ouznn2tzm0r","content":"<h1 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步\"></a>第一步</h1><p><code>sudo add-apt-repository    ppa:webupd8team/atom</code></p>\n<h1 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步\"></a>第二步</h1><p><code>sudo apt-get update</code></p>\n<h1 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步\"></a>第三步</h1><p><code>sudo apt-get install atom</code></p>\n<h1 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h1><p>中间出了点问题，找不到图了，所以就不贴了。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/avatar.jpg\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步\"></a>第一步</h1><p><code>sudo add-apt-repository    ppa:webupd8team/atom</code></p>\n<h1 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步\"></a>第二步</h1><p><code>sudo apt-get update</code></p>\n<h1 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步\"></a>第三步</h1><p><code>sudo apt-get install atom</code></p>\n<h1 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h1><p>中间出了点问题，找不到图了，所以就不贴了。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/avatar.jpg\" alt></p>\n"},{"title":"message-passing","date":"2018-04-18T02:52:19.000Z","_content":"# 变量消除的缺点\nelimination algorihthm中会有clique中重复使用的情况，message passing将重复使用的clique保留下来，这样可以减少运算复杂度。\n\n# Elimination on a tree\n将从i开始的变量消除记作$m_{ji}(x_i)$，并且是$x_i$的函数。\n$$m_{ji}(x_i)=\\sum_{x_j}(\\psi(x_j) \\psi(x_i,x_j)\\prod_{k\\in N(j)\\j} m_{kj}(x_j))$$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/elimination%20on%20a%20tree.png)\n$m_{ji}(x_i)$能够表示从$x_j$到$x_i$的置信。\n\n# Two-pass Algorithm\n算法的实施的具体步骤，确定一个根节点，从其他节点中收集信息到这个根节点，然后回到分布的信息。直到某一节点中包含了除却继续传播节点的所有信息，这样就计算信息，然后传播到剩下的节点。\n\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n[2] http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\n注：本文主要参考[1]中第5讲视频以及笔记，参考[2]中第4章。\n","source":"_posts/message-passing.md","raw":"---\ntitle: message-passing\ndate: 2018-04-18 10:52:19\ntags: 概率图模型\ncategories: 学习\n---\n# 变量消除的缺点\nelimination algorihthm中会有clique中重复使用的情况，message passing将重复使用的clique保留下来，这样可以减少运算复杂度。\n\n# Elimination on a tree\n将从i开始的变量消除记作$m_{ji}(x_i)$，并且是$x_i$的函数。\n$$m_{ji}(x_i)=\\sum_{x_j}(\\psi(x_j) \\psi(x_i,x_j)\\prod_{k\\in N(j)\\j} m_{kj}(x_j))$$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/elimination%20on%20a%20tree.png)\n$m_{ji}(x_i)$能够表示从$x_j$到$x_i$的置信。\n\n# Two-pass Algorithm\n算法的实施的具体步骤，确定一个根节点，从其他节点中收集信息到这个根节点，然后回到分布的信息。直到某一节点中包含了除却继续传播节点的所有信息，这样就计算信息，然后传播到剩下的节点。\n\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n[2] http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\n注：本文主要参考[1]中第5讲视频以及笔记，参考[2]中第4章。\n","slug":"message-passing","published":1,"updated":"2018-09-22T06:30:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msl000o1ouzz442iha8","content":"<h1 id=\"变量消除的缺点\"><a href=\"#变量消除的缺点\" class=\"headerlink\" title=\"变量消除的缺点\"></a>变量消除的缺点</h1><p>elimination algorihthm中会有clique中重复使用的情况，message passing将重复使用的clique保留下来，这样可以减少运算复杂度。</p>\n<h1 id=\"Elimination-on-a-tree\"><a href=\"#Elimination-on-a-tree\" class=\"headerlink\" title=\"Elimination on a tree\"></a>Elimination on a tree</h1><p>将从i开始的变量消除记作$m_{ji}(x_i)$，并且是$x_i$的函数。<br>$$m_{ji}(x_i)=\\sum_{x_j}(\\psi(x_j) \\psi(x_i,x_j)\\prod_{k\\in N(j)\\j} m_{kj}(x_j))$$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/elimination%20on%20a%20tree.png\" alt><br>$m_{ji}(x_i)$能够表示从$x_j$到$x_i$的置信。</p>\n<h1 id=\"Two-pass-Algorithm\"><a href=\"#Two-pass-Algorithm\" class=\"headerlink\" title=\"Two-pass Algorithm\"></a>Two-pass Algorithm</h1><p>算法的实施的具体步骤，确定一个根节点，从其他节点中收集信息到这个根节点，然后回到分布的信息。直到某一节点中包含了除却继续传播节点的所有信息，这样就计算信息，然后传播到剩下的节点。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] <a href=\"http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\" target=\"_blank\" rel=\"noopener\">http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A</a><br>注：本文主要参考[1]中第5讲视频以及笔记，参考[2]中第4章。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"变量消除的缺点\"><a href=\"#变量消除的缺点\" class=\"headerlink\" title=\"变量消除的缺点\"></a>变量消除的缺点</h1><p>elimination algorihthm中会有clique中重复使用的情况，message passing将重复使用的clique保留下来，这样可以减少运算复杂度。</p>\n<h1 id=\"Elimination-on-a-tree\"><a href=\"#Elimination-on-a-tree\" class=\"headerlink\" title=\"Elimination on a tree\"></a>Elimination on a tree</h1><p>将从i开始的变量消除记作$m_{ji}(x_i)$，并且是$x_i$的函数。<br>$$m_{ji}(x_i)=\\sum_{x_j}(\\psi(x_j) \\psi(x_i,x_j)\\prod_{k\\in N(j)\\j} m_{kj}(x_j))$$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/elimination%20on%20a%20tree.png\" alt><br>$m_{ji}(x_i)$能够表示从$x_j$到$x_i$的置信。</p>\n<h1 id=\"Two-pass-Algorithm\"><a href=\"#Two-pass-Algorithm\" class=\"headerlink\" title=\"Two-pass Algorithm\"></a>Two-pass Algorithm</h1><p>算法的实施的具体步骤，确定一个根节点，从其他节点中收集信息到这个根节点，然后回到分布的信息。直到某一节点中包含了除却继续传播节点的所有信息，这样就计算信息，然后传播到剩下的节点。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] <a href=\"http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\" target=\"_blank\" rel=\"noopener\">http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A</a><br>注：本文主要参考[1]中第5讲视频以及笔记，参考[2]中第4章。</p>\n"},{"title":"variational inference","date":"2018-07-19T03:15:17.000Z","_content":"# \n","source":"_posts/variational-inference.md","raw":"---\ntitle: variational inference\ndate: 2018-07-19 11:15:17\ntags: 概率图模型\ncategories: 学习\n---\n# \n","slug":"variational-inference","published":1,"updated":"2018-09-22T06:31:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msn000p1ouzhitlyu5m","content":"<p># </p>\n","site":{"data":{}},"excerpt":"","more":"<p># </p>\n"},{"title":"ubuntu下时间同步","date":"2017-12-04T08:26:14.000Z","_content":"`sudo apt-get install nipdate`\n`sudo ntpdate time.nist.gov`\n更新到硬件\n`sudo hwclock --localtime --systohc`\n\n注：方法来自互联网。\n","source":"_posts/ubuntu时间同步.md","raw":"---\ntitle: ubuntu下时间同步\ndate: 2017-12-04 16:26:14\ntags: ubuntu\ncategories: 技术\n---\n`sudo apt-get install nipdate`\n`sudo ntpdate time.nist.gov`\n更新到硬件\n`sudo hwclock --localtime --systohc`\n\n注：方法来自互联网。\n","slug":"ubuntu时间同步","published":1,"updated":"2018-09-22T06:31:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msp000q1ouzawwhzyjp","content":"<p><code>sudo apt-get install nipdate</code><br><code>sudo ntpdate time.nist.gov</code><br>更新到硬件<br><code>sudo hwclock --localtime --systohc</code></p>\n<p>注：方法来自互联网。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><code>sudo apt-get install nipdate</code><br><code>sudo ntpdate time.nist.gov</code><br>更新到硬件<br><code>sudo hwclock --localtime --systohc</code></p>\n<p>注：方法来自互联网。</p>\n"},{"title":"典型相关性(Canonical Correlation Analysis)","date":"2018-09-25T08:50:32.000Z","_content":"# 定义\n给定带有有限距的随机变量的列向量$X = (x_1, ..., x_n)^T$和$Y = (y_1, ..., y_m)^T$，我们可以定义互协方差矩阵$\\Sigma_{XY} = cov(X, Y)$，为$n\\times m$的矩阵，其中$(i, j)$是协方差矩阵$cov(x_i, y_j)$。实际上，我们可以基于$X$和$Y$的采样数据来估计协方差矩阵。\n典型相关性(Canonical Correlation Analysis)是求出向量$a$和$b$使得随机变量$a^T X$和$b^T Y$的相关性$\\rho = corr(a^T X, b^T Y)$最大。随机变量$U = a^T X$和$V = b^T Y$是第一对典型变量。然后寻求一个依然最大化相关但与第一对典型不相关的向量；这样就得到了第二对典型变量。这个步骤会进行$min\\lbrace m, n\\rbrace$。\n\n# 典型相关性\n1. 学习两个线性映射，每个线性映射对应于一组数据，使得两组数据最大相关性。\n\\begin{equation}\\begin{split} (u^{\\star}, v^{\\star}) &= argmax_{u, v} corr(u^T X, v^T Y) \\\\\\\\\n&= argmax_{u, v} \\frac{cov(u^T X, v^T Y)}{\\sqrt{var(u^T X) var(v^T Y)}} \\\\\\\\\n&= argmax_{u, v} \\frac{u^T E(X Y^T)v}{\\sqrt{u^T E(X X^T) u v^T E(Y Y^T) v}} \\\\\\\\\n&= argmax_{u, v} \\frac{u^T \\Sigma_{XY} v}{\\sqrt{u^T \\Sigma_{XX} u v^T \\Sigma_{YY} v}} \\\\\\\\\n\\end{split}\\end{equation}\n\n2. 我们希望获得多个映射矩阵，同时多个线性映射对是相互正交的。\n$$ u_{(i)}^T \\Sigma_{XY} v_{(j)} = u_{(j)}^T \\Sigma_{XY} v_{(i)} = 0\\  \\text {for}\\ i\\neq j$$\n$$ U\\Sigma_{XY}V = tr(U\\Sigma_{XY} V) $$\n其中$U = [u_1, u_2, ..., u_k]$和$V = [v_1, v_2, ..., v_k] $。\n$$(U^{\\star}, V^{\\star}) = argmax_{U, V}\\frac{tr(U^T\\Sigma_{XY} V)}{\\sqrt{U^T\\Sigma_{XX} U} \\sqrt{V^T \\Sigma_{YY} V}}$$\n\n3. 因为上式中分子分布增大相同的倍数，优化目标的结果不变，所以我们采用类似$SVM$中类似的优化方法，固定分母，优化分子，具体转化为[2]：\n\\begin{cases}\nargmax_{U, V} = U^T\\Sigma_{XY} V \\\\\\\\\n\\text{s.t.}\\ U^T \\Sigma_{XX} U = I, V^T \\Sigma_{YY} V= I \\\\\\\\\n\\end{cases}\n这样就变成了有约束的最优化问题，可以使用拉格朗日乘子法，也可以采用$SVD$分解的方法。\n\n* 拉格朗日乘子法\n$$ L = tr(U^T \\Sigma_{XY} V) - \\alpha  (U^T \\Sigma_{XX} U - I)  - \\beta (V^T \\Sigma_{YY} V - I) $$\n对$U$和$V$分别求偏导并令其为0：\n\\begin{cases}\n\\Sigma_{XY} V = 2\\alpha \\Sigma_{XX} U \\\\\\\\\n\\Sigma_{XY}^T U = 2 \\beta \\Sigma_{YY} V \\\\\\\\\n\\end{cases}\n\n对上式分别左乘$U^T$和$V^T$，可以得出$2\\alpha = 2\\beta = U^T \\Sigma_{XY} V $\n将前面的式子再分别左乘$\\Sigma_{XX}^{-1}$和$\\Sigma_{YY}^{-1}$，然后通过分别消除变量可以得出下面的结果：\n$$ \\Sigma_{XX}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma^T_{XY}U = \\lambda U $$\n$$ \\Sigma_{YY}\\Sigma_{XY}\\Sigma_{XX}^{-1}\\Sigma^T_{XY}V = \\lambda V $$\n其中$$\\lambda = 4\\alpha \\beta $$\n只要求出对应特征值最大的特征向量，这样就解出$U$和$V$。\n\n* SVD\n令$ U = \\Sigma_{XX}^{-\\frac{1}{2}} u$，$V = \\Sigma_{YY}^{-\\frac{1}{2}} v $。\n由$U^T \\Sigma_{XX} U = I$和$ V^T \\Sigma_{YY} V= I$，可以得出：$ u^T u = I $ $v^T v = I $\n将原本的最优化问题转化为这样的形式：\n\\begin{cases}\nargmax_{u, v} = u^T\\Sigma_{XX}^{-\\frac{1}{2}} \\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}} v \\\\\\\\\n\\text{s.t.}\\ u^T u = I, v^T v = I  \\\\\\\\\n\\end{cases}\n使用$SVD$就是通过最大化对应的奇异值的特征向量，就是对应的$u$和$v$的结果。\n$$ T = \\Sigma_{XX}^{-\\frac{1}{2}}\\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}}  $$\n$$ (U^{\\star}, V^{\\star}) = (\\Sigma_{XX}^{-\\frac{1}{2}}U_{SVD}, \\Sigma_{YY}^{-\\frac{1}{2}} V_{SVD}) $$\n\n\n# 参考资料\n[1] https://zh.wikipedia.org/wiki/典型相关\n[2] https://blog.csdn.net/Mbx8X9u/article/details/78824216\n","source":"_posts/典型相关性.md","raw":"---\ntitle: 典型相关性(Canonical Correlation Analysis)\ndate: 2018-09-25 16:50:32\ntags: 数据分析\ncategories: 学习\n---\n# 定义\n给定带有有限距的随机变量的列向量$X = (x_1, ..., x_n)^T$和$Y = (y_1, ..., y_m)^T$，我们可以定义互协方差矩阵$\\Sigma_{XY} = cov(X, Y)$，为$n\\times m$的矩阵，其中$(i, j)$是协方差矩阵$cov(x_i, y_j)$。实际上，我们可以基于$X$和$Y$的采样数据来估计协方差矩阵。\n典型相关性(Canonical Correlation Analysis)是求出向量$a$和$b$使得随机变量$a^T X$和$b^T Y$的相关性$\\rho = corr(a^T X, b^T Y)$最大。随机变量$U = a^T X$和$V = b^T Y$是第一对典型变量。然后寻求一个依然最大化相关但与第一对典型不相关的向量；这样就得到了第二对典型变量。这个步骤会进行$min\\lbrace m, n\\rbrace$。\n\n# 典型相关性\n1. 学习两个线性映射，每个线性映射对应于一组数据，使得两组数据最大相关性。\n\\begin{equation}\\begin{split} (u^{\\star}, v^{\\star}) &= argmax_{u, v} corr(u^T X, v^T Y) \\\\\\\\\n&= argmax_{u, v} \\frac{cov(u^T X, v^T Y)}{\\sqrt{var(u^T X) var(v^T Y)}} \\\\\\\\\n&= argmax_{u, v} \\frac{u^T E(X Y^T)v}{\\sqrt{u^T E(X X^T) u v^T E(Y Y^T) v}} \\\\\\\\\n&= argmax_{u, v} \\frac{u^T \\Sigma_{XY} v}{\\sqrt{u^T \\Sigma_{XX} u v^T \\Sigma_{YY} v}} \\\\\\\\\n\\end{split}\\end{equation}\n\n2. 我们希望获得多个映射矩阵，同时多个线性映射对是相互正交的。\n$$ u_{(i)}^T \\Sigma_{XY} v_{(j)} = u_{(j)}^T \\Sigma_{XY} v_{(i)} = 0\\  \\text {for}\\ i\\neq j$$\n$$ U\\Sigma_{XY}V = tr(U\\Sigma_{XY} V) $$\n其中$U = [u_1, u_2, ..., u_k]$和$V = [v_1, v_2, ..., v_k] $。\n$$(U^{\\star}, V^{\\star}) = argmax_{U, V}\\frac{tr(U^T\\Sigma_{XY} V)}{\\sqrt{U^T\\Sigma_{XX} U} \\sqrt{V^T \\Sigma_{YY} V}}$$\n\n3. 因为上式中分子分布增大相同的倍数，优化目标的结果不变，所以我们采用类似$SVM$中类似的优化方法，固定分母，优化分子，具体转化为[2]：\n\\begin{cases}\nargmax_{U, V} = U^T\\Sigma_{XY} V \\\\\\\\\n\\text{s.t.}\\ U^T \\Sigma_{XX} U = I, V^T \\Sigma_{YY} V= I \\\\\\\\\n\\end{cases}\n这样就变成了有约束的最优化问题，可以使用拉格朗日乘子法，也可以采用$SVD$分解的方法。\n\n* 拉格朗日乘子法\n$$ L = tr(U^T \\Sigma_{XY} V) - \\alpha  (U^T \\Sigma_{XX} U - I)  - \\beta (V^T \\Sigma_{YY} V - I) $$\n对$U$和$V$分别求偏导并令其为0：\n\\begin{cases}\n\\Sigma_{XY} V = 2\\alpha \\Sigma_{XX} U \\\\\\\\\n\\Sigma_{XY}^T U = 2 \\beta \\Sigma_{YY} V \\\\\\\\\n\\end{cases}\n\n对上式分别左乘$U^T$和$V^T$，可以得出$2\\alpha = 2\\beta = U^T \\Sigma_{XY} V $\n将前面的式子再分别左乘$\\Sigma_{XX}^{-1}$和$\\Sigma_{YY}^{-1}$，然后通过分别消除变量可以得出下面的结果：\n$$ \\Sigma_{XX}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma^T_{XY}U = \\lambda U $$\n$$ \\Sigma_{YY}\\Sigma_{XY}\\Sigma_{XX}^{-1}\\Sigma^T_{XY}V = \\lambda V $$\n其中$$\\lambda = 4\\alpha \\beta $$\n只要求出对应特征值最大的特征向量，这样就解出$U$和$V$。\n\n* SVD\n令$ U = \\Sigma_{XX}^{-\\frac{1}{2}} u$，$V = \\Sigma_{YY}^{-\\frac{1}{2}} v $。\n由$U^T \\Sigma_{XX} U = I$和$ V^T \\Sigma_{YY} V= I$，可以得出：$ u^T u = I $ $v^T v = I $\n将原本的最优化问题转化为这样的形式：\n\\begin{cases}\nargmax_{u, v} = u^T\\Sigma_{XX}^{-\\frac{1}{2}} \\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}} v \\\\\\\\\n\\text{s.t.}\\ u^T u = I, v^T v = I  \\\\\\\\\n\\end{cases}\n使用$SVD$就是通过最大化对应的奇异值的特征向量，就是对应的$u$和$v$的结果。\n$$ T = \\Sigma_{XX}^{-\\frac{1}{2}}\\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}}  $$\n$$ (U^{\\star}, V^{\\star}) = (\\Sigma_{XX}^{-\\frac{1}{2}}U_{SVD}, \\Sigma_{YY}^{-\\frac{1}{2}} V_{SVD}) $$\n\n\n# 参考资料\n[1] https://zh.wikipedia.org/wiki/典型相关\n[2] https://blog.csdn.net/Mbx8X9u/article/details/78824216\n","slug":"典型相关性","published":1,"updated":"2018-09-26T01:42:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msq000r1ouzmr955nhe","content":"<h1 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h1><p>给定带有有限距的随机变量的列向量$X = (x_1, …, x_n)^T$和$Y = (y_1, …, y_m)^T$，我们可以定义互协方差矩阵$\\Sigma_{XY} = cov(X, Y)$，为$n\\times m$的矩阵，其中$(i, j)$是协方差矩阵$cov(x_i, y_j)$。实际上，我们可以基于$X$和$Y$的采样数据来估计协方差矩阵。<br>典型相关性(Canonical Correlation Analysis)是求出向量$a$和$b$使得随机变量$a^T X$和$b^T Y$的相关性$\\rho = corr(a^T X, b^T Y)$最大。随机变量$U = a^T X$和$V = b^T Y$是第一对典型变量。然后寻求一个依然最大化相关但与第一对典型不相关的向量；这样就得到了第二对典型变量。这个步骤会进行$min\\lbrace m, n\\rbrace$。</p>\n<h1 id=\"典型相关性\"><a href=\"#典型相关性\" class=\"headerlink\" title=\"典型相关性\"></a>典型相关性</h1><ol>\n<li><p>学习两个线性映射，每个线性映射对应于一组数据，使得两组数据最大相关性。<br>\\begin{equation}\\begin{split} (u^{\\star}, v^{\\star}) &amp;= argmax_{u, v} corr(u^T X, v^T Y) \\\\<br>&amp;= argmax_{u, v} \\frac{cov(u^T X, v^T Y)}{\\sqrt{var(u^T X) var(v^T Y)}} \\\\<br>&amp;= argmax_{u, v} \\frac{u^T E(X Y^T)v}{\\sqrt{u^T E(X X^T) u v^T E(Y Y^T) v}} \\\\<br>&amp;= argmax_{u, v} \\frac{u^T \\Sigma_{XY} v}{\\sqrt{u^T \\Sigma_{XX} u v^T \\Sigma_{YY} v}} \\\\<br>\\end{split}\\end{equation}</p>\n</li>\n<li><p>我们希望获得多个映射矩阵，同时多个线性映射对是相互正交的。<br>$$ u_{(i)}^T \\Sigma_{XY} v_{(j)} = u_{(j)}^T \\Sigma_{XY} v_{(i)} = 0\\  \\text {for}\\ i\\neq j$$<br>$$ U\\Sigma_{XY}V = tr(U\\Sigma_{XY} V) $$<br>其中$U = [u_1, u_2, …, u_k]$和$V = [v_1, v_2, …, v_k] $。<br>$$(U^{\\star}, V^{\\star}) = argmax_{U, V}\\frac{tr(U^T\\Sigma_{XY} V)}{\\sqrt{U^T\\Sigma_{XX} U} \\sqrt{V^T \\Sigma_{YY} V}}$$</p>\n</li>\n<li><p>因为上式中分子分布增大相同的倍数，优化目标的结果不变，所以我们采用类似$SVM$中类似的优化方法，固定分母，优化分子，具体转化为[2]：<br>\\begin{cases}<br>argmax_{U, V} = U^T\\Sigma_{XY} V \\\\<br>\\text{s.t.}\\ U^T \\Sigma_{XX} U = I, V^T \\Sigma_{YY} V= I \\\\<br>\\end{cases}<br>这样就变成了有约束的最优化问题，可以使用拉格朗日乘子法，也可以采用$SVD$分解的方法。</p>\n</li>\n</ol>\n<ul>\n<li>拉格朗日乘子法<br>$$ L = tr(U^T \\Sigma_{XY} V) - \\alpha  (U^T \\Sigma_{XX} U - I)  - \\beta (V^T \\Sigma_{YY} V - I) $$<br>对$U$和$V$分别求偏导并令其为0：<br>\\begin{cases}<br>\\Sigma_{XY} V = 2\\alpha \\Sigma_{XX} U \\\\<br>\\Sigma_{XY}^T U = 2 \\beta \\Sigma_{YY} V \\\\<br>\\end{cases}</li>\n</ul>\n<p>对上式分别左乘$U^T$和$V^T$，可以得出$2\\alpha = 2\\beta = U^T \\Sigma_{XY} V $<br>将前面的式子再分别左乘$\\Sigma_{XX}^{-1}$和$\\Sigma_{YY}^{-1}$，然后通过分别消除变量可以得出下面的结果：<br>$$ \\Sigma_{XX}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma^T_{XY}U = \\lambda U $$<br>$$ \\Sigma_{YY}\\Sigma_{XY}\\Sigma_{XX}^{-1}\\Sigma^T_{XY}V = \\lambda V $$<br>其中$$\\lambda = 4\\alpha \\beta $$<br>只要求出对应特征值最大的特征向量，这样就解出$U$和$V$。</p>\n<ul>\n<li>SVD<br>令$ U = \\Sigma_{XX}^{-\\frac{1}{2}} u$，$V = \\Sigma_{YY}^{-\\frac{1}{2}} v $。<br>由$U^T \\Sigma_{XX} U = I$和$ V^T \\Sigma_{YY} V= I$，可以得出：$ u^T u = I $ $v^T v = I $<br>将原本的最优化问题转化为这样的形式：<br>\\begin{cases}<br>argmax_{u, v} = u^T\\Sigma_{XX}^{-\\frac{1}{2}} \\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}} v \\\\<br>\\text{s.t.}\\ u^T u = I, v^T v = I  \\\\<br>\\end{cases}<br>使用$SVD$就是通过最大化对应的奇异值的特征向量，就是对应的$u$和$v$的结果。<br>$$ T = \\Sigma_{XX}^{-\\frac{1}{2}}\\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}}  $$<br>$$ (U^{\\star}, V^{\\star}) = (\\Sigma_{XX}^{-\\frac{1}{2}}U_{SVD}, \\Sigma_{YY}^{-\\frac{1}{2}} V_{SVD}) $$</li>\n</ul>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] <a href=\"https://zh.wikipedia.org/wiki/典型相关\" target=\"_blank\" rel=\"noopener\">https://zh.wikipedia.org/wiki/典型相关</a><br>[2] <a href=\"https://blog.csdn.net/Mbx8X9u/article/details/78824216\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Mbx8X9u/article/details/78824216</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h1><p>给定带有有限距的随机变量的列向量$X = (x_1, …, x_n)^T$和$Y = (y_1, …, y_m)^T$，我们可以定义互协方差矩阵$\\Sigma_{XY} = cov(X, Y)$，为$n\\times m$的矩阵，其中$(i, j)$是协方差矩阵$cov(x_i, y_j)$。实际上，我们可以基于$X$和$Y$的采样数据来估计协方差矩阵。<br>典型相关性(Canonical Correlation Analysis)是求出向量$a$和$b$使得随机变量$a^T X$和$b^T Y$的相关性$\\rho = corr(a^T X, b^T Y)$最大。随机变量$U = a^T X$和$V = b^T Y$是第一对典型变量。然后寻求一个依然最大化相关但与第一对典型不相关的向量；这样就得到了第二对典型变量。这个步骤会进行$min\\lbrace m, n\\rbrace$。</p>\n<h1 id=\"典型相关性\"><a href=\"#典型相关性\" class=\"headerlink\" title=\"典型相关性\"></a>典型相关性</h1><ol>\n<li><p>学习两个线性映射，每个线性映射对应于一组数据，使得两组数据最大相关性。<br>\\begin{equation}\\begin{split} (u^{\\star}, v^{\\star}) &amp;= argmax_{u, v} corr(u^T X, v^T Y) \\\\<br>&amp;= argmax_{u, v} \\frac{cov(u^T X, v^T Y)}{\\sqrt{var(u^T X) var(v^T Y)}} \\\\<br>&amp;= argmax_{u, v} \\frac{u^T E(X Y^T)v}{\\sqrt{u^T E(X X^T) u v^T E(Y Y^T) v}} \\\\<br>&amp;= argmax_{u, v} \\frac{u^T \\Sigma_{XY} v}{\\sqrt{u^T \\Sigma_{XX} u v^T \\Sigma_{YY} v}} \\\\<br>\\end{split}\\end{equation}</p>\n</li>\n<li><p>我们希望获得多个映射矩阵，同时多个线性映射对是相互正交的。<br>$$ u_{(i)}^T \\Sigma_{XY} v_{(j)} = u_{(j)}^T \\Sigma_{XY} v_{(i)} = 0\\  \\text {for}\\ i\\neq j$$<br>$$ U\\Sigma_{XY}V = tr(U\\Sigma_{XY} V) $$<br>其中$U = [u_1, u_2, …, u_k]$和$V = [v_1, v_2, …, v_k] $。<br>$$(U^{\\star}, V^{\\star}) = argmax_{U, V}\\frac{tr(U^T\\Sigma_{XY} V)}{\\sqrt{U^T\\Sigma_{XX} U} \\sqrt{V^T \\Sigma_{YY} V}}$$</p>\n</li>\n<li><p>因为上式中分子分布增大相同的倍数，优化目标的结果不变，所以我们采用类似$SVM$中类似的优化方法，固定分母，优化分子，具体转化为[2]：<br>\\begin{cases}<br>argmax_{U, V} = U^T\\Sigma_{XY} V \\\\<br>\\text{s.t.}\\ U^T \\Sigma_{XX} U = I, V^T \\Sigma_{YY} V= I \\\\<br>\\end{cases}<br>这样就变成了有约束的最优化问题，可以使用拉格朗日乘子法，也可以采用$SVD$分解的方法。</p>\n</li>\n</ol>\n<ul>\n<li>拉格朗日乘子法<br>$$ L = tr(U^T \\Sigma_{XY} V) - \\alpha  (U^T \\Sigma_{XX} U - I)  - \\beta (V^T \\Sigma_{YY} V - I) $$<br>对$U$和$V$分别求偏导并令其为0：<br>\\begin{cases}<br>\\Sigma_{XY} V = 2\\alpha \\Sigma_{XX} U \\\\<br>\\Sigma_{XY}^T U = 2 \\beta \\Sigma_{YY} V \\\\<br>\\end{cases}</li>\n</ul>\n<p>对上式分别左乘$U^T$和$V^T$，可以得出$2\\alpha = 2\\beta = U^T \\Sigma_{XY} V $<br>将前面的式子再分别左乘$\\Sigma_{XX}^{-1}$和$\\Sigma_{YY}^{-1}$，然后通过分别消除变量可以得出下面的结果：<br>$$ \\Sigma_{XX}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma^T_{XY}U = \\lambda U $$<br>$$ \\Sigma_{YY}\\Sigma_{XY}\\Sigma_{XX}^{-1}\\Sigma^T_{XY}V = \\lambda V $$<br>其中$$\\lambda = 4\\alpha \\beta $$<br>只要求出对应特征值最大的特征向量，这样就解出$U$和$V$。</p>\n<ul>\n<li>SVD<br>令$ U = \\Sigma_{XX}^{-\\frac{1}{2}} u$，$V = \\Sigma_{YY}^{-\\frac{1}{2}} v $。<br>由$U^T \\Sigma_{XX} U = I$和$ V^T \\Sigma_{YY} V= I$，可以得出：$ u^T u = I $ $v^T v = I $<br>将原本的最优化问题转化为这样的形式：<br>\\begin{cases}<br>argmax_{u, v} = u^T\\Sigma_{XX}^{-\\frac{1}{2}} \\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}} v \\\\<br>\\text{s.t.}\\ u^T u = I, v^T v = I  \\\\<br>\\end{cases}<br>使用$SVD$就是通过最大化对应的奇异值的特征向量，就是对应的$u$和$v$的结果。<br>$$ T = \\Sigma_{XX}^{-\\frac{1}{2}}\\Sigma_{XY} \\Sigma_{YY}^{-\\frac{1}{2}}  $$<br>$$ (U^{\\star}, V^{\\star}) = (\\Sigma_{XX}^{-\\frac{1}{2}}U_{SVD}, \\Sigma_{YY}^{-\\frac{1}{2}} V_{SVD}) $$</li>\n</ul>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>[1] <a href=\"https://zh.wikipedia.org/wiki/典型相关\" target=\"_blank\" rel=\"noopener\">https://zh.wikipedia.org/wiki/典型相关</a><br>[2] <a href=\"https://blog.csdn.net/Mbx8X9u/article/details/78824216\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Mbx8X9u/article/details/78824216</a></p>\n"},{"title":"写在感冒之后","date":"2017-11-24T14:20:14.000Z","visible":"hide","password":"hjyai94","_content":"# 写在感冒之后\n  今天好像自己感冒了，心情有些低落。明明有很多的事情，可是做事情效率却是极低。满脑子的骚操作，却是没有行动的空想，甚至会想自己会不会就这样抑郁了。我需要更加客观的看待自己，不应该给予自己这么大的压力，总是和别人比较，总觉得自己各方面都很差，可是，这真是对自己的客观判断吗？\n  今天操作博客弄了好久，写系统辨识作业，也许不应该想这么多，就在网上copy一些代码，然后交上去不叫好了吗？自己的编程水平确实有限啊。\n想想本科的学习，从来都是复制和黏贴完成了大部分的作业，保送研究生也是一半的运气，总想着做好一件事，却在这里写博客打发时间，也许我应该早点工作，说不定，那才是适合自己的天地。\n  昨天和老毛同学的谈话十分触动了我，我觉得他的方法论很有道理，可能我应该把心思花在自己的学习上面，我现在是一个非常好的年纪，这个年纪没有爱情，令我十分的遗憾，双鱼座的人感情细腻是真，天天爱幻想也是真，一个并不特别的女生在我的幻想里，也许是个完美的人。放佛现在就是一个非常尴尬的境地，一方面耸的一批，一方面希望自己能有所建树，有所收获。\n  我现在应该抛弃满脑子的完美主义，实事求是，具体问题，具体解决，感冒了吃药，作业没写好，就抄嘛，有什么？都抄了这么多年了。妄想着一步吃成大胖子，却没有踏实的做一点点小事，看文章也是，论文也是，做作业更是如此。\n  今后还是要再踏实一点，不要执着于所谓的完美主义，踏实的完成工作的每一小部分。总想着仰望天空，却不看自己所在何地。想着年薪百万，却连毕业都遥不可及。抛掉这些想法，就当自己从来没有读博，不给自己压力，万一抑郁了就非常有趣了。好了，写完了，准备回宿舍，睡觉，作业没写好，明天再写，今天不想写了。我居然可以写这么多的字，好久没有写了，感觉文笔差的一批，语句都不知道通不通顺。\n","source":"_posts/写在感冒之后.md","raw":"---\ntitle: 写在感冒之后\ndate: 2017-11-24 22:20:14\ntags: 随笔\nvisible: hide\npassword: hjyai94\ncategories: 随笔\n---\n# 写在感冒之后\n  今天好像自己感冒了，心情有些低落。明明有很多的事情，可是做事情效率却是极低。满脑子的骚操作，却是没有行动的空想，甚至会想自己会不会就这样抑郁了。我需要更加客观的看待自己，不应该给予自己这么大的压力，总是和别人比较，总觉得自己各方面都很差，可是，这真是对自己的客观判断吗？\n  今天操作博客弄了好久，写系统辨识作业，也许不应该想这么多，就在网上copy一些代码，然后交上去不叫好了吗？自己的编程水平确实有限啊。\n想想本科的学习，从来都是复制和黏贴完成了大部分的作业，保送研究生也是一半的运气，总想着做好一件事，却在这里写博客打发时间，也许我应该早点工作，说不定，那才是适合自己的天地。\n  昨天和老毛同学的谈话十分触动了我，我觉得他的方法论很有道理，可能我应该把心思花在自己的学习上面，我现在是一个非常好的年纪，这个年纪没有爱情，令我十分的遗憾，双鱼座的人感情细腻是真，天天爱幻想也是真，一个并不特别的女生在我的幻想里，也许是个完美的人。放佛现在就是一个非常尴尬的境地，一方面耸的一批，一方面希望自己能有所建树，有所收获。\n  我现在应该抛弃满脑子的完美主义，实事求是，具体问题，具体解决，感冒了吃药，作业没写好，就抄嘛，有什么？都抄了这么多年了。妄想着一步吃成大胖子，却没有踏实的做一点点小事，看文章也是，论文也是，做作业更是如此。\n  今后还是要再踏实一点，不要执着于所谓的完美主义，踏实的完成工作的每一小部分。总想着仰望天空，却不看自己所在何地。想着年薪百万，却连毕业都遥不可及。抛掉这些想法，就当自己从来没有读博，不给自己压力，万一抑郁了就非常有趣了。好了，写完了，准备回宿舍，睡觉，作业没写好，明天再写，今天不想写了。我居然可以写这么多的字，好久没有写了，感觉文笔差的一批，语句都不知道通不通顺。\n","slug":"写在感冒之后","published":1,"updated":"2019-05-01T13:18:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msr000s1ouzm6lrse4n","content":"<h1 id=\"写在感冒之后\"><a href=\"#写在感冒之后\" class=\"headerlink\" title=\"写在感冒之后\"></a>写在感冒之后</h1><p>  今天好像自己感冒了，心情有些低落。明明有很多的事情，可是做事情效率却是极低。满脑子的骚操作，却是没有行动的空想，甚至会想自己会不会就这样抑郁了。我需要更加客观的看待自己，不应该给予自己这么大的压力，总是和别人比较，总觉得自己各方面都很差，可是，这真是对自己的客观判断吗？<br>  今天操作博客弄了好久，写系统辨识作业，也许不应该想这么多，就在网上copy一些代码，然后交上去不叫好了吗？自己的编程水平确实有限啊。<br>想想本科的学习，从来都是复制和黏贴完成了大部分的作业，保送研究生也是一半的运气，总想着做好一件事，却在这里写博客打发时间，也许我应该早点工作，说不定，那才是适合自己的天地。<br>  昨天和老毛同学的谈话十分触动了我，我觉得他的方法论很有道理，可能我应该把心思花在自己的学习上面，我现在是一个非常好的年纪，这个年纪没有爱情，令我十分的遗憾，双鱼座的人感情细腻是真，天天爱幻想也是真，一个并不特别的女生在我的幻想里，也许是个完美的人。放佛现在就是一个非常尴尬的境地，一方面耸的一批，一方面希望自己能有所建树，有所收获。<br>  我现在应该抛弃满脑子的完美主义，实事求是，具体问题，具体解决，感冒了吃药，作业没写好，就抄嘛，有什么？都抄了这么多年了。妄想着一步吃成大胖子，却没有踏实的做一点点小事，看文章也是，论文也是，做作业更是如此。<br>  今后还是要再踏实一点，不要执着于所谓的完美主义，踏实的完成工作的每一小部分。总想着仰望天空，却不看自己所在何地。想着年薪百万，却连毕业都遥不可及。抛掉这些想法，就当自己从来没有读博，不给自己压力，万一抑郁了就非常有趣了。好了，写完了，准备回宿舍，睡觉，作业没写好，明天再写，今天不想写了。我居然可以写这么多的字，好久没有写了，感觉文笔差的一批，语句都不知道通不通顺。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"写在感冒之后\"><a href=\"#写在感冒之后\" class=\"headerlink\" title=\"写在感冒之后\"></a>写在感冒之后</h1><p>  今天好像自己感冒了，心情有些低落。明明有很多的事情，可是做事情效率却是极低。满脑子的骚操作，却是没有行动的空想，甚至会想自己会不会就这样抑郁了。我需要更加客观的看待自己，不应该给予自己这么大的压力，总是和别人比较，总觉得自己各方面都很差，可是，这真是对自己的客观判断吗？<br>  今天操作博客弄了好久，写系统辨识作业，也许不应该想这么多，就在网上copy一些代码，然后交上去不叫好了吗？自己的编程水平确实有限啊。<br>想想本科的学习，从来都是复制和黏贴完成了大部分的作业，保送研究生也是一半的运气，总想着做好一件事，却在这里写博客打发时间，也许我应该早点工作，说不定，那才是适合自己的天地。<br>  昨天和老毛同学的谈话十分触动了我，我觉得他的方法论很有道理，可能我应该把心思花在自己的学习上面，我现在是一个非常好的年纪，这个年纪没有爱情，令我十分的遗憾，双鱼座的人感情细腻是真，天天爱幻想也是真，一个并不特别的女生在我的幻想里，也许是个完美的人。放佛现在就是一个非常尴尬的境地，一方面耸的一批，一方面希望自己能有所建树，有所收获。<br>  我现在应该抛弃满脑子的完美主义，实事求是，具体问题，具体解决，感冒了吃药，作业没写好，就抄嘛，有什么？都抄了这么多年了。妄想着一步吃成大胖子，却没有踏实的做一点点小事，看文章也是，论文也是，做作业更是如此。<br>  今后还是要再踏实一点，不要执着于所谓的完美主义，踏实的完成工作的每一小部分。总想着仰望天空，却不看自己所在何地。想着年薪百万，却连毕业都遥不可及。抛掉这些想法，就当自己从来没有读博，不给自己压力，万一抑郁了就非常有趣了。好了，写完了，准备回宿舍，睡觉，作业没写好，明天再写，今天不想写了。我居然可以写这么多的字，好久没有写了，感觉文笔差的一批，语句都不知道通不通顺。</p>\n"},{"title":"医学图像处理基础","date":"2019-07-05T08:25:09.000Z","_content":"# 医学图像处理技术\n## 图像二值化以及最优二值化方法\n图像的二值化方法来源于图像的灰度直方图，它是图像灰度级分布的统计，反应图像每种灰度出现的频率。\n所谓的图像的二值化是将确定图像的阈值，将图像分为前景和背景。\n\n## 图像的卷积(Convolution)和相关(Correlation)\n给定输入图片$f(x, y)$，核$w(a, b)$\n* 图像的卷积运算是使目标与目标之间的差距变大。\n卷积运算可以表示为如下的公式：\n$$f*w = \\sum_{(a, b)\\in w, (x-a, y-b)\\in f}f(x-a, y-b)w(a, b)$$\n使用numpy实现简单的二维卷积运算：\n```\ndef conv(image, kernel):\n    \"\"\" An implementation of convolution filter.\n    Args:\n        image: numpy array of shape (Hi, Wi)\n        kernel: numpy array of shape (Hk, Wk)\n\n    Returns:\n        out: numpy array of shape (Hi, Wi)\n    \"\"\"\n    Hi, Wi = image.shape\n    Hk, Wk = kernel.shape\n    out = np.zeros((Hi, Wi))\n    flip_kernel = np.flip(np.flip(kernel, axis=0), axis=1)\n    delta_h = int((Hk-1)/2)\n    delta_w = int((Wk-1)/2)\n    for image_h in range(delta_h, Hi-delta_h):\n        for image_w in range(delta_w, Wi-delta_w):\n            out[image_h][image_w] = np.sum(flip_kernel*image[image_h-delta_h:image_h+delta_h+1, image_w-delta_w:image_w+delta_w+1])\n    return out\n```\n* 图像的相关运算与卷积运算不同之处在于，相关运算不需要将核翻转。\n$$f\\bigotimes w = \\sum_{(a, b)\\in w, (x+a, y+b)\\in f}f(x+a, y+b)w(a, b)$$\n有时候我们利用卷积运算可以得到图像的边缘：Sobel operator mask 和 Prewitt operator masks.\n\n## 图像除噪\n* 高斯滤波\n\n* 中值滤波\n\n# 形态学\n\n* Dilation\n扩张放大图像的前景\n* Erosion\n缩小图像的前景\n* Opening Operation\n先进行Erosion，再做Dilation，可以去除不连续的像素点。\n* Closing Operation\n先做Dilation，后做Erosion，对不连续的像素点进行填埋。\n\n","source":"_posts/医学图像处理基础.md","raw":"---\ntitle: 医学图像处理基础\ndate: 2019-07-05 16:25:09\ntags: 医学图像处理\ncategories: 学习\n---\n# 医学图像处理技术\n## 图像二值化以及最优二值化方法\n图像的二值化方法来源于图像的灰度直方图，它是图像灰度级分布的统计，反应图像每种灰度出现的频率。\n所谓的图像的二值化是将确定图像的阈值，将图像分为前景和背景。\n\n## 图像的卷积(Convolution)和相关(Correlation)\n给定输入图片$f(x, y)$，核$w(a, b)$\n* 图像的卷积运算是使目标与目标之间的差距变大。\n卷积运算可以表示为如下的公式：\n$$f*w = \\sum_{(a, b)\\in w, (x-a, y-b)\\in f}f(x-a, y-b)w(a, b)$$\n使用numpy实现简单的二维卷积运算：\n```\ndef conv(image, kernel):\n    \"\"\" An implementation of convolution filter.\n    Args:\n        image: numpy array of shape (Hi, Wi)\n        kernel: numpy array of shape (Hk, Wk)\n\n    Returns:\n        out: numpy array of shape (Hi, Wi)\n    \"\"\"\n    Hi, Wi = image.shape\n    Hk, Wk = kernel.shape\n    out = np.zeros((Hi, Wi))\n    flip_kernel = np.flip(np.flip(kernel, axis=0), axis=1)\n    delta_h = int((Hk-1)/2)\n    delta_w = int((Wk-1)/2)\n    for image_h in range(delta_h, Hi-delta_h):\n        for image_w in range(delta_w, Wi-delta_w):\n            out[image_h][image_w] = np.sum(flip_kernel*image[image_h-delta_h:image_h+delta_h+1, image_w-delta_w:image_w+delta_w+1])\n    return out\n```\n* 图像的相关运算与卷积运算不同之处在于，相关运算不需要将核翻转。\n$$f\\bigotimes w = \\sum_{(a, b)\\in w, (x+a, y+b)\\in f}f(x+a, y+b)w(a, b)$$\n有时候我们利用卷积运算可以得到图像的边缘：Sobel operator mask 和 Prewitt operator masks.\n\n## 图像除噪\n* 高斯滤波\n\n* 中值滤波\n\n# 形态学\n\n* Dilation\n扩张放大图像的前景\n* Erosion\n缩小图像的前景\n* Opening Operation\n先进行Erosion，再做Dilation，可以去除不连续的像素点。\n* Closing Operation\n先做Dilation，后做Erosion，对不连续的像素点进行填埋。\n\n","slug":"医学图像处理基础","published":1,"updated":"2019-08-10T08:51:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mss000t1ouzoc1w14s7","content":"<h1 id=\"医学图像处理技术\"><a href=\"#医学图像处理技术\" class=\"headerlink\" title=\"医学图像处理技术\"></a>医学图像处理技术</h1><h2 id=\"图像二值化以及最优二值化方法\"><a href=\"#图像二值化以及最优二值化方法\" class=\"headerlink\" title=\"图像二值化以及最优二值化方法\"></a>图像二值化以及最优二值化方法</h2><p>图像的二值化方法来源于图像的灰度直方图，它是图像灰度级分布的统计，反应图像每种灰度出现的频率。<br>所谓的图像的二值化是将确定图像的阈值，将图像分为前景和背景。</p>\n<h2 id=\"图像的卷积-Convolution-和相关-Correlation\"><a href=\"#图像的卷积-Convolution-和相关-Correlation\" class=\"headerlink\" title=\"图像的卷积(Convolution)和相关(Correlation)\"></a>图像的卷积(Convolution)和相关(Correlation)</h2><p>给定输入图片$f(x, y)$，核$w(a, b)$</p>\n<ul>\n<li><p>图像的卷积运算是使目标与目标之间的差距变大。<br>卷积运算可以表示为如下的公式：<br>$$f*w = \\sum_{(a, b)\\in w, (x-a, y-b)\\in f}f(x-a, y-b)w(a, b)$$<br>使用numpy实现简单的二维卷积运算：</p>\n<figure class=\"highlight ceylon\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def conv(image, kernel):</span><br><span class=\"line\">    <span class=\"string\">\"\"\" An implementation of convolution filter.</span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">        image: numpy array of shape (Hi, Wi)</span></span><br><span class=\"line\"><span class=\"string\">        kernel: numpy array of shape (Hk, Wk)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">        out: numpy array of shape (Hi, Wi)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Hi, Wi = image.shape</span><br><span class=\"line\">    Hk, Wk = kernel.shape</span><br><span class=\"line\">    <span class=\"keyword\">out</span> = np.zeros((Hi, Wi))</span><br><span class=\"line\">    flip<span class=\"number\">_k</span>ernel = np.flip(np.flip(kernel, axis=<span class=\"number\">0</span>), axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    delta<span class=\"number\">_</span>h = int((Hk-<span class=\"number\">1</span>)/<span class=\"number\">2</span>)</span><br><span class=\"line\">    delta<span class=\"number\">_</span>w = int((Wk-<span class=\"number\">1</span>)/<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> image<span class=\"number\">_</span>h <span class=\"keyword\">in</span> range(delta<span class=\"number\">_</span>h, Hi-delta<span class=\"number\">_</span>h):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> image<span class=\"number\">_</span>w <span class=\"keyword\">in</span> range(delta<span class=\"number\">_</span>w, Wi-delta<span class=\"number\">_</span>w):</span><br><span class=\"line\">            <span class=\"keyword\">out</span>[image<span class=\"number\">_</span>h][image<span class=\"number\">_</span>w] = np.sum(flip<span class=\"number\">_k</span>ernel*image[image<span class=\"number\">_</span>h-delta<span class=\"number\">_</span>h:image<span class=\"number\">_</span>h+delta<span class=\"number\">_</span>h+<span class=\"number\">1</span>, image<span class=\"number\">_</span>w-delta<span class=\"number\">_</span>w:image<span class=\"number\">_</span>w+delta<span class=\"number\">_</span>w+<span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">out</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>图像的相关运算与卷积运算不同之处在于，相关运算不需要将核翻转。<br>$$f\\bigotimes w = \\sum_{(a, b)\\in w, (x+a, y+b)\\in f}f(x+a, y+b)w(a, b)$$<br>有时候我们利用卷积运算可以得到图像的边缘：Sobel operator mask 和 Prewitt operator masks.</p>\n</li>\n</ul>\n<h2 id=\"图像除噪\"><a href=\"#图像除噪\" class=\"headerlink\" title=\"图像除噪\"></a>图像除噪</h2><ul>\n<li><p>高斯滤波</p>\n</li>\n<li><p>中值滤波</p>\n</li>\n</ul>\n<h1 id=\"形态学\"><a href=\"#形态学\" class=\"headerlink\" title=\"形态学\"></a>形态学</h1><ul>\n<li>Dilation<br>扩张放大图像的前景</li>\n<li>Erosion<br>缩小图像的前景</li>\n<li>Opening Operation<br>先进行Erosion，再做Dilation，可以去除不连续的像素点。</li>\n<li>Closing Operation<br>先做Dilation，后做Erosion，对不连续的像素点进行填埋。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"医学图像处理技术\"><a href=\"#医学图像处理技术\" class=\"headerlink\" title=\"医学图像处理技术\"></a>医学图像处理技术</h1><h2 id=\"图像二值化以及最优二值化方法\"><a href=\"#图像二值化以及最优二值化方法\" class=\"headerlink\" title=\"图像二值化以及最优二值化方法\"></a>图像二值化以及最优二值化方法</h2><p>图像的二值化方法来源于图像的灰度直方图，它是图像灰度级分布的统计，反应图像每种灰度出现的频率。<br>所谓的图像的二值化是将确定图像的阈值，将图像分为前景和背景。</p>\n<h2 id=\"图像的卷积-Convolution-和相关-Correlation\"><a href=\"#图像的卷积-Convolution-和相关-Correlation\" class=\"headerlink\" title=\"图像的卷积(Convolution)和相关(Correlation)\"></a>图像的卷积(Convolution)和相关(Correlation)</h2><p>给定输入图片$f(x, y)$，核$w(a, b)$</p>\n<ul>\n<li><p>图像的卷积运算是使目标与目标之间的差距变大。<br>卷积运算可以表示为如下的公式：<br>$$f*w = \\sum_{(a, b)\\in w, (x-a, y-b)\\in f}f(x-a, y-b)w(a, b)$$<br>使用numpy实现简单的二维卷积运算：</p>\n<!--�60-->\n</li>\n<li><p>图像的相关运算与卷积运算不同之处在于，相关运算不需要将核翻转。<br>$$f\\bigotimes w = \\sum_{(a, b)\\in w, (x+a, y+b)\\in f}f(x+a, y+b)w(a, b)$$<br>有时候我们利用卷积运算可以得到图像的边缘：Sobel operator mask 和 Prewitt operator masks.</p>\n</li>\n</ul>\n<h2 id=\"图像除噪\"><a href=\"#图像除噪\" class=\"headerlink\" title=\"图像除噪\"></a>图像除噪</h2><ul>\n<li><p>高斯滤波</p>\n</li>\n<li><p>中值滤波</p>\n</li>\n</ul>\n<h1 id=\"形态学\"><a href=\"#形态学\" class=\"headerlink\" title=\"形态学\"></a>形态学</h1><ul>\n<li>Dilation<br>扩张放大图像的前景</li>\n<li>Erosion<br>缩小图像的前景</li>\n<li>Opening Operation<br>先进行Erosion，再做Dilation，可以去除不连续的像素点。</li>\n<li>Closing Operation<br>先做Dilation，后做Erosion，对不连续的像素点进行填埋。</li>\n</ul>\n"},{"title":"变量消除","date":"2018-04-03T03:02:58.000Z","_content":"# 精确推断\n精确推断的实质是一种动态规划算法，它利用图模型所描述的条件独立性来削减计算目标所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。\n\n精确推断有以下算法：\n* 变量消除\n* 消息传递\n* 团树\n\n近似推断有一下算法：\n* 随机模拟\n* 马尔可夫链的蒙特卡罗方法\n* 变分算法\n\n本文主要主要是针对精确推断算法中的变量消除算法，计算变量的边际分布或条件分布是一个NP难问题，会随着极大团的增长呈指数增长。近似推断是在较低的时间复杂度下，或者原问题的近似解，这种方法更有一般的实用性。\n\n## 变量消除\n### 有向图\n考虑如下的有向图概率图模型，图中共有五个变量：A,B,C,D,E。如果我们假定每个变量有n个值，那么直接的概率描述就是联合概率密度，那么复杂度为$n^5$。如果我们计算$P(E=e)$，那么我们就要计算：\n$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)$$\n可是这个计算过程需要对另外四个变量求和(边际化)，那么就需要$n^4$的复杂度。\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E7%A4%BA%E4%BE%8B-%E6%97%A0%E5%90%91%E5%9B%BE.png)\n\n我们可以将上面的联合概率密度$P(a,b,c,d,e)$进行因式分解：\n$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$\n假设推断目标是计算边缘概率密度P(e)，那么P(c|b)，P(d|c)，P(e|d)与a无关，将P(a)和P(b|a)的乘积相加。\n$$P(e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$   $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)\\sum_a P(a)P(b\\mid a)$$    $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)P(b)$$\n下面按照b,c,d的顺序进行求和，最后可以得到$P(e)=\\sum_d P(e\\mid d)P(d)$。使用该方法可以一次减少一个变量。每次只需要执行$O(n^2)$操作，最终复杂度为$O(kn^2)$。\n\n### 在HMM上进行变量消除\n参考[4]中笔记对于该例的介绍，主要是利用当前变量相关变量和非相关的变量进行变量消除，每步消除一个变量，最终复杂度为$O(Tn^2)$，其中T表示变量的个数。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png)\n\n### 无向图\n考虑如下的无向图概率图链模型，总共有五个变量A,B,C，D，E，计算联合概率密度P(e)。\n$$ P(e)=\\sum_{a,b,c,d}\\frac{1}{Z}\\phi(a,b)\\phi(b,c)\\phi(c,d)\\phi(d,e)$$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E6%97%A0%E5%90%91%E5%9B%BE.png)\n具体计算方法同有向图相似，超级长的公式，不想打，下面用截图来表示。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png)\n最后通过正则化可以获得最终的概率：\n$$P(e)=\\frac{m_d(e)}{\\sum_e m_d(e)}$$\n\n\n\n\n\n\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n[2] Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.\n[3] 周志华. 机器学习[M]. 清华大学出版社, 2016.\n[4] http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\n注：本文主要参考[1]中第4讲视频以及笔记，参考[2]中第9章，参考[3]中第14章，参考[4]中第3章。\n","source":"_posts/变量消除.md","raw":"---\ntitle: 变量消除\ndate: 2018-04-03 11:02:58\ntags: 概率图模型\ncategories: 学习\n---\n# 精确推断\n精确推断的实质是一种动态规划算法，它利用图模型所描述的条件独立性来削减计算目标所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。\n\n精确推断有以下算法：\n* 变量消除\n* 消息传递\n* 团树\n\n近似推断有一下算法：\n* 随机模拟\n* 马尔可夫链的蒙特卡罗方法\n* 变分算法\n\n本文主要主要是针对精确推断算法中的变量消除算法，计算变量的边际分布或条件分布是一个NP难问题，会随着极大团的增长呈指数增长。近似推断是在较低的时间复杂度下，或者原问题的近似解，这种方法更有一般的实用性。\n\n## 变量消除\n### 有向图\n考虑如下的有向图概率图模型，图中共有五个变量：A,B,C,D,E。如果我们假定每个变量有n个值，那么直接的概率描述就是联合概率密度，那么复杂度为$n^5$。如果我们计算$P(E=e)$，那么我们就要计算：\n$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)$$\n可是这个计算过程需要对另外四个变量求和(边际化)，那么就需要$n^4$的复杂度。\n\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E7%A4%BA%E4%BE%8B-%E6%97%A0%E5%90%91%E5%9B%BE.png)\n\n我们可以将上面的联合概率密度$P(a,b,c,d,e)$进行因式分解：\n$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$\n假设推断目标是计算边缘概率密度P(e)，那么P(c|b)，P(d|c)，P(e|d)与a无关，将P(a)和P(b|a)的乘积相加。\n$$P(e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$   $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)\\sum_a P(a)P(b\\mid a)$$    $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)P(b)$$\n下面按照b,c,d的顺序进行求和，最后可以得到$P(e)=\\sum_d P(e\\mid d)P(d)$。使用该方法可以一次减少一个变量。每次只需要执行$O(n^2)$操作，最终复杂度为$O(kn^2)$。\n\n### 在HMM上进行变量消除\n参考[4]中笔记对于该例的介绍，主要是利用当前变量相关变量和非相关的变量进行变量消除，每步消除一个变量，最终复杂度为$O(Tn^2)$，其中T表示变量的个数。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png)\n\n### 无向图\n考虑如下的无向图概率图链模型，总共有五个变量A,B,C，D，E，计算联合概率密度P(e)。\n$$ P(e)=\\sum_{a,b,c,d}\\frac{1}{Z}\\phi(a,b)\\phi(b,c)\\phi(c,d)\\phi(d,e)$$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E6%97%A0%E5%90%91%E5%9B%BE.png)\n具体计算方法同有向图相似，超级长的公式，不想打，下面用截图来表示。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png)\n最后通过正则化可以获得最终的概率：\n$$P(e)=\\frac{m_d(e)}{\\sum_e m_d(e)}$$\n\n\n\n\n\n\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n[2] Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.\n[3] 周志华. 机器学习[M]. 清华大学出版社, 2016.\n[4] http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\n注：本文主要参考[1]中第4讲视频以及笔记，参考[2]中第9章，参考[3]中第14章，参考[4]中第3章。\n","slug":"变量消除","published":1,"updated":"2018-09-22T06:32:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mst000u1ouzjgbq07ue","content":"<h1 id=\"精确推断\"><a href=\"#精确推断\" class=\"headerlink\" title=\"精确推断\"></a>精确推断</h1><p>精确推断的实质是一种动态规划算法，它利用图模型所描述的条件独立性来削减计算目标所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。</p>\n<p>精确推断有以下算法：</p>\n<ul>\n<li>变量消除</li>\n<li>消息传递</li>\n<li>团树</li>\n</ul>\n<p>近似推断有一下算法：</p>\n<ul>\n<li>随机模拟</li>\n<li>马尔可夫链的蒙特卡罗方法</li>\n<li>变分算法</li>\n</ul>\n<p>本文主要主要是针对精确推断算法中的变量消除算法，计算变量的边际分布或条件分布是一个NP难问题，会随着极大团的增长呈指数增长。近似推断是在较低的时间复杂度下，或者原问题的近似解，这种方法更有一般的实用性。</p>\n<h2 id=\"变量消除\"><a href=\"#变量消除\" class=\"headerlink\" title=\"变量消除\"></a>变量消除</h2><h3 id=\"有向图\"><a href=\"#有向图\" class=\"headerlink\" title=\"有向图\"></a>有向图</h3><p>考虑如下的有向图概率图模型，图中共有五个变量：A,B,C,D,E。如果我们假定每个变量有n个值，那么直接的概率描述就是联合概率密度，那么复杂度为$n^5$。如果我们计算$P(E=e)$，那么我们就要计算：<br>$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)$$<br>可是这个计算过程需要对另外四个变量求和(边际化)，那么就需要$n^4$的复杂度。</p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E7%A4%BA%E4%BE%8B-%E6%97%A0%E5%90%91%E5%9B%BE.png\" alt></p>\n<p>我们可以将上面的联合概率密度$P(a,b,c,d,e)$进行因式分解：<br>$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$<br>假设推断目标是计算边缘概率密度P(e)，那么P(c|b)，P(d|c)，P(e|d)与a无关，将P(a)和P(b|a)的乘积相加。<br>$$P(e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$   $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)\\sum_a P(a)P(b\\mid a)$$    $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)P(b)$$<br>下面按照b,c,d的顺序进行求和，最后可以得到$P(e)=\\sum_d P(e\\mid d)P(d)$。使用该方法可以一次减少一个变量。每次只需要执行$O(n^2)$操作，最终复杂度为$O(kn^2)$。</p>\n<h3 id=\"在HMM上进行变量消除\"><a href=\"#在HMM上进行变量消除\" class=\"headerlink\" title=\"在HMM上进行变量消除\"></a>在HMM上进行变量消除</h3><p>参考[4]中笔记对于该例的介绍，主要是利用当前变量相关变量和非相关的变量进行变量消除，每步消除一个变量，最终复杂度为$O(Tn^2)$，其中T表示变量的个数。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h3 id=\"无向图\"><a href=\"#无向图\" class=\"headerlink\" title=\"无向图\"></a>无向图</h3><p>考虑如下的无向图概率图链模型，总共有五个变量A,B,C，D，E，计算联合概率密度P(e)。<br>$$ P(e)=\\sum_{a,b,c,d}\\frac{1}{Z}\\phi(a,b)\\phi(b,c)\\phi(c,d)\\phi(d,e)$$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E6%97%A0%E5%90%91%E5%9B%BE.png\" alt><br>具体计算方法同有向图相似，超级长的公式，不想打，下面用截图来表示。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png\" alt><br>最后通过正则化可以获得最终的概率：<br>$$P(e)=\\frac{m_d(e)}{\\sum_e m_d(e)}$$</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.<br>[3] 周志华. 机器学习[M]. 清华大学出版社, 2016.<br>[4] <a href=\"http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\" target=\"_blank\" rel=\"noopener\">http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A</a><br>注：本文主要参考[1]中第4讲视频以及笔记，参考[2]中第9章，参考[3]中第14章，参考[4]中第3章。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"精确推断\"><a href=\"#精确推断\" class=\"headerlink\" title=\"精确推断\"></a>精确推断</h1><p>精确推断的实质是一种动态规划算法，它利用图模型所描述的条件独立性来削减计算目标所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。</p>\n<p>精确推断有以下算法：</p>\n<ul>\n<li>变量消除</li>\n<li>消息传递</li>\n<li>团树</li>\n</ul>\n<p>近似推断有一下算法：</p>\n<ul>\n<li>随机模拟</li>\n<li>马尔可夫链的蒙特卡罗方法</li>\n<li>变分算法</li>\n</ul>\n<p>本文主要主要是针对精确推断算法中的变量消除算法，计算变量的边际分布或条件分布是一个NP难问题，会随着极大团的增长呈指数增长。近似推断是在较低的时间复杂度下，或者原问题的近似解，这种方法更有一般的实用性。</p>\n<h2 id=\"变量消除\"><a href=\"#变量消除\" class=\"headerlink\" title=\"变量消除\"></a>变量消除</h2><h3 id=\"有向图\"><a href=\"#有向图\" class=\"headerlink\" title=\"有向图\"></a>有向图</h3><p>考虑如下的有向图概率图模型，图中共有五个变量：A,B,C,D,E。如果我们假定每个变量有n个值，那么直接的概率描述就是联合概率密度，那么复杂度为$n^5$。如果我们计算$P(E=e)$，那么我们就要计算：<br>$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)$$<br>可是这个计算过程需要对另外四个变量求和(边际化)，那么就需要$n^4$的复杂度。</p>\n<p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E7%A4%BA%E4%BE%8B-%E6%97%A0%E5%90%91%E5%9B%BE.png\" alt></p>\n<p>我们可以将上面的联合概率密度$P(a,b,c,d,e)$进行因式分解：<br>$$P(e)=\\sum_{a,b,c,d}P(a,b,c,d,e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$<br>假设推断目标是计算边缘概率密度P(e)，那么P(c|b)，P(d|c)，P(e|d)与a无关，将P(a)和P(b|a)的乘积相加。<br>$$P(e)=\\sum_{a,b,c,d}P(a)P(b\\mid a)P(c\\mid b)P(d\\mid c)P(e\\mid d)$$   $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)\\sum_a P(a)P(b\\mid a)$$    $$=\\sum_{b,c,d}P(c\\mid b)P(d\\mid c)P(e\\mid d)P(b)$$<br>下面按照b,c,d的顺序进行求和，最后可以得到$P(e)=\\sum_d P(e\\mid d)P(d)$。使用该方法可以一次减少一个变量。每次只需要执行$O(n^2)$操作，最终复杂度为$O(kn^2)$。</p>\n<h3 id=\"在HMM上进行变量消除\"><a href=\"#在HMM上进行变量消除\" class=\"headerlink\" title=\"在HMM上进行变量消除\"></a>在HMM上进行变量消除</h3><p>参考[4]中笔记对于该例的介绍，主要是利用当前变量相关变量和非相关的变量进行变量消除，每步消除一个变量，最终复杂度为$O(Tn^2)$，其中T表示变量的个数。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h3 id=\"无向图\"><a href=\"#无向图\" class=\"headerlink\" title=\"无向图\"></a>无向图</h3><p>考虑如下的无向图概率图链模型，总共有五个变量A,B,C，D，E，计算联合概率密度P(e)。<br>$$ P(e)=\\sum_{a,b,c,d}\\frac{1}{Z}\\phi(a,b)\\phi(b,c)\\phi(c,d)\\phi(d,e)$$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E6%97%A0%E5%90%91%E5%9B%BE.png\" alt><br>具体计算方法同有向图相似，超级长的公式，不想打，下面用截图来表示。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png\" alt><br>最后通过正则化可以获得最终的概率：<br>$$P(e)=\\frac{m_d(e)}{\\sum_e m_d(e)}$$</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.<br>[3] 周志华. 机器学习[M]. 清华大学出版社, 2016.<br>[4] <a href=\"http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A\" target=\"_blank\" rel=\"noopener\">http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A</a><br>注：本文主要参考[1]中第4讲视频以及笔记，参考[2]中第9章，参考[3]中第14章，参考[4]中第3章。</p>\n"},{"title":"医学图像分析中的常用评价指标与损失函数","date":"2019-05-23T02:33:37.000Z","_content":"本文将聚焦于FP、TP、TN、FN、准确率和召回率，F-score等指标，并解释这些指标，另外介绍医学图像分割任务中常用的损失函数。\n如下图所示，我们仍然以肿瘤为例，红色圈以内为真值区域(肿瘤的真实位置)，蓝色圈以内为预测结果(预测肿瘤的位置)。其中TP表示预测结果与真值相重叠的一部分，FP也就是常称的假阳性，FN常称为假阴性，TN表示为预测负样本结果与真值负样本结果重叠面积。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/TPandFP.png)\n\n# Dice \nDice 指标是我们在医学图像分割领域中常用的评价指标，它是采用预测结果与真值结果的重叠面积所占比例来表征分割性能的优劣。\n$$ Dice(P, G) = \\frac{2|PG|}{|P|+|G|} = \\frac{2TP}{2TP + FP + FN}$$\nDice 这个指标同时也是F1-score，它是准确率和召回率的调和平均数，也是倒数平均数。准确率和召回率的公式如下：\n$$ precision = \\frac{TP}{TP + FP} $$\n准确率可以看做是预测准确的正样本占所有预测正样本的比例。\n$$ recall = \\frac{TP}{TP + FN} $$\n召回率可以看作是预测准确的正样本占所有真值正样本的比例。\n\n# 损失函数\n下面我们来总结医学图像分割中常用的损失函数，医学图像分割同自然图像分割一样，交叉熵损失函数都是常用的损失函数，交叉熵损失函数","source":"_posts/医学图像分析中的常用评价指标与损失函数.md","raw":"---\ntitle: 医学图像分析中的常用评价指标与损失函数\ndate: 2019-05-23 10:33:37\ntags: 评价指标与损失函数\ncategories: 学习\n---\n本文将聚焦于FP、TP、TN、FN、准确率和召回率，F-score等指标，并解释这些指标，另外介绍医学图像分割任务中常用的损失函数。\n如下图所示，我们仍然以肿瘤为例，红色圈以内为真值区域(肿瘤的真实位置)，蓝色圈以内为预测结果(预测肿瘤的位置)。其中TP表示预测结果与真值相重叠的一部分，FP也就是常称的假阳性，FN常称为假阴性，TN表示为预测负样本结果与真值负样本结果重叠面积。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/TPandFP.png)\n\n# Dice \nDice 指标是我们在医学图像分割领域中常用的评价指标，它是采用预测结果与真值结果的重叠面积所占比例来表征分割性能的优劣。\n$$ Dice(P, G) = \\frac{2|PG|}{|P|+|G|} = \\frac{2TP}{2TP + FP + FN}$$\nDice 这个指标同时也是F1-score，它是准确率和召回率的调和平均数，也是倒数平均数。准确率和召回率的公式如下：\n$$ precision = \\frac{TP}{TP + FP} $$\n准确率可以看做是预测准确的正样本占所有预测正样本的比例。\n$$ recall = \\frac{TP}{TP + FN} $$\n召回率可以看作是预测准确的正样本占所有真值正样本的比例。\n\n# 损失函数\n下面我们来总结医学图像分割中常用的损失函数，医学图像分割同自然图像分割一样，交叉熵损失函数都是常用的损失函数，交叉熵损失函数","slug":"医学图像分析中的常用评价指标与损失函数","published":1,"updated":"2019-05-24T07:22:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mst000v1ouzdd0ysdis","content":"<p>本文将聚焦于FP、TP、TN、FN、准确率和召回率，F-score等指标，并解释这些指标，另外介绍医学图像分割任务中常用的损失函数。<br>如下图所示，我们仍然以肿瘤为例，红色圈以内为真值区域(肿瘤的真实位置)，蓝色圈以内为预测结果(预测肿瘤的位置)。其中TP表示预测结果与真值相重叠的一部分，FP也就是常称的假阳性，FN常称为假阴性，TN表示为预测负样本结果与真值负样本结果重叠面积。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/TPandFP.png\" alt></p>\n<h1 id=\"Dice\"><a href=\"#Dice\" class=\"headerlink\" title=\"Dice\"></a>Dice</h1><p>Dice 指标是我们在医学图像分割领域中常用的评价指标，它是采用预测结果与真值结果的重叠面积所占比例来表征分割性能的优劣。<br>$$ Dice(P, G) = \\frac{2|PG|}{|P|+|G|} = \\frac{2TP}{2TP + FP + FN}$$<br>Dice 这个指标同时也是F1-score，它是准确率和召回率的调和平均数，也是倒数平均数。准确率和召回率的公式如下：<br>$$ precision = \\frac{TP}{TP + FP} $$<br>准确率可以看做是预测准确的正样本占所有预测正样本的比例。<br>$$ recall = \\frac{TP}{TP + FN} $$<br>召回率可以看作是预测准确的正样本占所有真值正样本的比例。</p>\n<h1 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a>损失函数</h1><p>下面我们来总结医学图像分割中常用的损失函数，医学图像分割同自然图像分割一样，交叉熵损失函数都是常用的损失函数，交叉熵损失函数</p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文将聚焦于FP、TP、TN、FN、准确率和召回率，F-score等指标，并解释这些指标，另外介绍医学图像分割任务中常用的损失函数。<br>如下图所示，我们仍然以肿瘤为例，红色圈以内为真值区域(肿瘤的真实位置)，蓝色圈以内为预测结果(预测肿瘤的位置)。其中TP表示预测结果与真值相重叠的一部分，FP也就是常称的假阳性，FN常称为假阴性，TN表示为预测负样本结果与真值负样本结果重叠面积。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/TPandFP.png\" alt></p>\n<h1 id=\"Dice\"><a href=\"#Dice\" class=\"headerlink\" title=\"Dice\"></a>Dice</h1><p>Dice 指标是我们在医学图像分割领域中常用的评价指标，它是采用预测结果与真值结果的重叠面积所占比例来表征分割性能的优劣。<br>$$ Dice(P, G) = \\frac{2|PG|}{|P|+|G|} = \\frac{2TP}{2TP + FP + FN}$$<br>Dice 这个指标同时也是F1-score，它是准确率和召回率的调和平均数，也是倒数平均数。准确率和召回率的公式如下：<br>$$ precision = \\frac{TP}{TP + FP} $$<br>准确率可以看做是预测准确的正样本占所有预测正样本的比例。<br>$$ recall = \\frac{TP}{TP + FN} $$<br>召回率可以看作是预测准确的正样本占所有真值正样本的比例。</p>\n<h1 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a>损失函数</h1><p>下面我们来总结医学图像分割中常用的损失函数，医学图像分割同自然图像分割一样，交叉熵损失函数都是常用的损失函数，交叉熵损失函数</p>\n"},{"title":"医学图像可视化","date":"2019-01-07T07:43:57.000Z","_content":"最近经常使用到之前写的对医学图像进行可视化，下面我将这部分代码和相关内容整理成该博客，分成一下三个部分，第一部分是医学图像的格式，第二部分是医学图像的读取，第三部分是医学图像的可视化。\n\n# 医学图像格式\n医学图像常见的有6种主要格式，分别为DICOM(医学数字成像和通讯)、NIFTI(神经影像信息技术)、PAR/REC(Philips磁共振扫描格式)、ANALYZE(Mayo医学成像)、NRRD(近原始栅格数据)和MNIC。\n目前我就处理过DICOM和NIFTI格式的数据，下面主要对这两种格式进行解释。\n## DICOM\n\n## NIFTI\n\ns","source":"_posts/医学图像可视化.md","raw":"---\ntitle: 医学图像可视化\ndate: 2019-01-07 15:43:57\ntags: 医学图像\ncategories: 学习\n---\n最近经常使用到之前写的对医学图像进行可视化，下面我将这部分代码和相关内容整理成该博客，分成一下三个部分，第一部分是医学图像的格式，第二部分是医学图像的读取，第三部分是医学图像的可视化。\n\n# 医学图像格式\n医学图像常见的有6种主要格式，分别为DICOM(医学数字成像和通讯)、NIFTI(神经影像信息技术)、PAR/REC(Philips磁共振扫描格式)、ANALYZE(Mayo医学成像)、NRRD(近原始栅格数据)和MNIC。\n目前我就处理过DICOM和NIFTI格式的数据，下面主要对这两种格式进行解释。\n## DICOM\n\n## NIFTI\n\ns","slug":"医学图像可视化","published":1,"updated":"2019-01-11T05:50:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msu000w1ouzobcrhf4i","content":"<p>最近经常使用到之前写的对医学图像进行可视化，下面我将这部分代码和相关内容整理成该博客，分成一下三个部分，第一部分是医学图像的格式，第二部分是医学图像的读取，第三部分是医学图像的可视化。</p>\n<h1 id=\"医学图像格式\"><a href=\"#医学图像格式\" class=\"headerlink\" title=\"医学图像格式\"></a>医学图像格式</h1><p>医学图像常见的有6种主要格式，分别为DICOM(医学数字成像和通讯)、NIFTI(神经影像信息技术)、PAR/REC(Philips磁共振扫描格式)、ANALYZE(Mayo医学成像)、NRRD(近原始栅格数据)和MNIC。<br>目前我就处理过DICOM和NIFTI格式的数据，下面主要对这两种格式进行解释。</p>\n<h2 id=\"DICOM\"><a href=\"#DICOM\" class=\"headerlink\" title=\"DICOM\"></a>DICOM</h2><h2 id=\"NIFTI\"><a href=\"#NIFTI\" class=\"headerlink\" title=\"NIFTI\"></a>NIFTI</h2><p>s</p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近经常使用到之前写的对医学图像进行可视化，下面我将这部分代码和相关内容整理成该博客，分成一下三个部分，第一部分是医学图像的格式，第二部分是医学图像的读取，第三部分是医学图像的可视化。</p>\n<h1 id=\"医学图像格式\"><a href=\"#医学图像格式\" class=\"headerlink\" title=\"医学图像格式\"></a>医学图像格式</h1><p>医学图像常见的有6种主要格式，分别为DICOM(医学数字成像和通讯)、NIFTI(神经影像信息技术)、PAR/REC(Philips磁共振扫描格式)、ANALYZE(Mayo医学成像)、NRRD(近原始栅格数据)和MNIC。<br>目前我就处理过DICOM和NIFTI格式的数据，下面主要对这两种格式进行解释。</p>\n<h2 id=\"DICOM\"><a href=\"#DICOM\" class=\"headerlink\" title=\"DICOM\"></a>DICOM</h2><h2 id=\"NIFTI\"><a href=\"#NIFTI\" class=\"headerlink\" title=\"NIFTI\"></a>NIFTI</h2><p>s</p>\n"},{"title":"学期总结","date":"2018-01-29T01:04:04.000Z","_content":"按照培养计划，研一这一学年应该选修45个学分，这个学期选了30个学分，下个学期实际选了18个\n学分的课程。这个学期的主要时间都在上课，课题和论文看的并不是特别的多。主要看了一下吴恩达\n在Coursera上面的机器学习课程，这个课程总共有11周，目前看到了第4周，用Matlab完成前3周和\n第9周推荐系统部分的编程作业。另外看了一下《概率图模型》这本书，看了第1，3章中的基础介\n绍部分。还有就是敲了《笨方法学python》这本书的代码，感觉并没有掌握。\n","source":"_posts/学期总结.md","raw":"---\ntitle: 学期总结\ndate: 2018-01-29 09:04:04\ntags: 总结\ncategories: 工作\n---\n按照培养计划，研一这一学年应该选修45个学分，这个学期选了30个学分，下个学期实际选了18个\n学分的课程。这个学期的主要时间都在上课，课题和论文看的并不是特别的多。主要看了一下吴恩达\n在Coursera上面的机器学习课程，这个课程总共有11周，目前看到了第4周，用Matlab完成前3周和\n第9周推荐系统部分的编程作业。另外看了一下《概率图模型》这本书，看了第1，3章中的基础介\n绍部分。还有就是敲了《笨方法学python》这本书的代码，感觉并没有掌握。\n","slug":"学期总结","published":1,"updated":"2019-05-01T13:20:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msv000x1ouzsmnprsto","content":"<p>按照培养计划，研一这一学年应该选修45个学分，这个学期选了30个学分，下个学期实际选了18个<br>学分的课程。这个学期的主要时间都在上课，课题和论文看的并不是特别的多。主要看了一下吴恩达<br>在Coursera上面的机器学习课程，这个课程总共有11周，目前看到了第4周，用Matlab完成前3周和<br>第9周推荐系统部分的编程作业。另外看了一下《概率图模型》这本书，看了第1，3章中的基础介<br>绍部分。还有就是敲了《笨方法学python》这本书的代码，感觉并没有掌握。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>按照培养计划，研一这一学年应该选修45个学分，这个学期选了30个学分，下个学期实际选了18个<br>学分的课程。这个学期的主要时间都在上课，课题和论文看的并不是特别的多。主要看了一下吴恩达<br>在Coursera上面的机器学习课程，这个课程总共有11周，目前看到了第4周，用Matlab完成前3周和<br>第9周推荐系统部分的编程作业。另外看了一下《概率图模型》这本书，看了第1，3章中的基础介<br>绍部分。还有就是敲了《笨方法学python》这本书的代码，感觉并没有掌握。</p>\n"},{"title":"词汇收集","date":"2017-12-11T14:15:32.000Z","_content":"crucial 重要的  \nindex(indices) 索引\nretain 保留\nfatorize 因子分解\nheuristic 启发式\nexploit 利用\nidiosyncray 特质\nvariation 变种\nredundant 冗余\ncompact 严谨的\nquery 疑问\nconfiguration 组态，格局，配置\nrepetitively 反复地\nprotocol 协议\nsequential 顺序\ninward 向内的\nsynchronous 同步的\narbitrary 随机的\ndepicted = showd\nrecipient 接收者\nin the hospital a patient\nat the hospital\n","source":"_posts/学术词语收集.md","raw":"---\ntitle: 词汇收集\ndate: 2017-12-11 22:15:32\ntags: 词汇收集\ncategories: 学习\n---\ncrucial 重要的  \nindex(indices) 索引\nretain 保留\nfatorize 因子分解\nheuristic 启发式\nexploit 利用\nidiosyncray 特质\nvariation 变种\nredundant 冗余\ncompact 严谨的\nquery 疑问\nconfiguration 组态，格局，配置\nrepetitively 反复地\nprotocol 协议\nsequential 顺序\ninward 向内的\nsynchronous 同步的\narbitrary 随机的\ndepicted = showd\nrecipient 接收者\nin the hospital a patient\nat the hospital\n","slug":"学术词语收集","published":1,"updated":"2018-04-18T10:49:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msv000y1ouzvd8neaik","content":"<p>crucial 重要的<br>index(indices) 索引<br>retain 保留<br>fatorize 因子分解<br>heuristic 启发式<br>exploit 利用<br>idiosyncray 特质<br>variation 变种<br>redundant 冗余<br>compact 严谨的<br>query 疑问<br>configuration 组态，格局，配置<br>repetitively 反复地<br>protocol 协议<br>sequential 顺序<br>inward 向内的<br>synchronous 同步的<br>arbitrary 随机的<br>depicted = showd<br>recipient 接收者<br>in the hospital a patient<br>at the hospital</p>\n","site":{"data":{}},"excerpt":"","more":"<p>crucial 重要的<br>index(indices) 索引<br>retain 保留<br>fatorize 因子分解<br>heuristic 启发式<br>exploit 利用<br>idiosyncray 特质<br>variation 变种<br>redundant 冗余<br>compact 严谨的<br>query 疑问<br>configuration 组态，格局，配置<br>repetitively 反复地<br>protocol 协议<br>sequential 顺序<br>inward 向内的<br>synchronous 同步的<br>arbitrary 随机的<br>depicted = showd<br>recipient 接收者<br>in the hospital a patient<br>at the hospital</p>\n"},{"title":"可观贝叶斯网络中的学习问题","date":"2018-05-12T07:37:27.000Z","_content":"# 完全可观的图模型学习\n图模型学习的目的是在给定独立的样本集的情况下找到合适的的贝叶斯网络，这里的学习（learning）表示对参数的估计或者是从数据学习网络的拓扑结构。\n\n## 最大似然在信息论上的解释\n可以这样理解，将对数似然函数在数据上的和，转变为在变量状态上的和。\n\\begin{equation}\\begin{split} l(\\theta_G,G;D)&=log\\ p(D\\mid \\theta_G,G) (Joint Likelilood)\\\\\\\\\n& = log\\ p\\prod_n(\\prod_i p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}})  (BN Factorization  Rule)\\\\\\\\\n& = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}}))\\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\frac{count(x_i,x_{\\pi_{i(G)}})}{M} log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\\\\\\n\\end{split}\\end{equation}\n\n这里的H表示变量状态，概率分布$p(x_i)$用计数函数取代（count function）。$(x_i,x_{\\pi{i(G)}}$包括了所随机变量的值。\n继续对上面的式子进行推导：\n\\begin{equation}\\begin{split} l(\\theta_G,G;D)&=M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}\\mid \\theta_{i\\mid \\pi_{(G)}})}  {\\hat{p}(x_i, x_{\\pi_{i(G)}})}\\frac{\\hat{p}(x_i)}{\\hat{p}(x_i)})\\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{(G)}})} {\\hat{p}(x_i, x_{\\pi_{i(G)}})\\hat{p}(x_i)}) - M\\ \\Sigma_i\\Sigma_{x_i} - \\hat{p}(x_i)log\\ \\hat{p}(x_i)\\\\\\\\\n& = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i) \\\\\\\\\n\\end{split}\\end{equation}\n这样可以将最大似然估计分成两个部分，第一个部分是所有节点的互信息，第二部分是每个节点的熵。可以得出这样的结论，如果我们确定结构式树结构（每个节点只有一个父节点），那么基于最大似然估计下，我们可以获得一个最优的树。\n\n# Chow-Liu 算法\n目标函数可以写成：\n$$ l(\\theta_G,G;D) = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i)  $$\n将上式后面各个变量的熵去掉，因为变量的熵与树的结构无关，上式化简为：\n\\begin{equation}\\begin{split} C(G) &= M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) \\\\\\\\\n&= M\\ \\Sigma_i\\hat{I}(x_i,x_j) \\\\\\\\\n\\end{split}\\end{equation}\n我们只需要计算经验分布（empirical distribution）和每对节点的互信息（mutual information）就可以了。经验分布可以通过数据直接数出来，下面是计算每对节点$x_i$和$x_j$之间的经验分布和互信息。\n$$ \\hat{p}(X_i, X_j) = \\frac{count(x_i, x_j)}{M} $$\n$$ \\hat{I}(X_i, X_j) = \\Sigma_{x_i, x_j}\\hat{p}(x_i, x_j)log\\ \\frac{\\hat{p}(x_i, x_j)}{\\hat{p}(x_i)\\hat{p}(x_j)} $$\n我们定义一个有节点$x_1, x_2, x_3, ...,x_n$的图，指定图的边$(i, j)$的权值为$\\hat{I}(X_i, X_j)$。Chow-Liu算法可以计算最大权重生成树。挑选任意节点作为根节点，然后使用宽度优先算法（breadth-first-search）来决定方向。\n\n# 对于完全可观的给定结构的参数学习\n假定图结构固定，从N个独立同分布的样本集中进行参数估计$D = \\lbrace x_1, x_2, x_3, ..., x_N\\rbrace$。一般来说，每个训练样本$x_n = x_{n, 1}, x_{n,2}, ..., x_{n,M}$是M维的向量，对应于每个节点。下面介绍几个常见用于参数估计的分布。\n\n## 多项式模型\n对于N个独立同分布的样本，采用unit basis vectors表示，$x_n = (x_{n,1}, x_{n,2}, ..., x_{n,K})$，其中$x_{n,k}=\\lbrace 0, 1 \\rbrace $， $\\Sigma_{k=1}^K x_{n, k} $。这种表示方法将事件抽离出来，不考虑事件本身的意义，关注事件发生与否。数据集$D = \\lbrace x_1, x_2, x_3, ..., x_N\\rbrace$的似然函数为：\n$$ L(\\theta\\mid D) = P(x_1, x_2, ..., x_N\\mid \\theta) = \\prod_{n=1}^N P(x_n\\mid \\theta) = \\prod_k \\theta_k^{n_k} $$\n$$ l(\\theta\\mid D) = log\\ \\prod_k \\theta_k^{n_k}  = \\Sigma_k n_k log\\ \\theta_k $$\n因为存在着等式约束$\\Sigma_{k=1}^K x_{n,k} = 1$，所以需要在$l(\\theta\\mid D)$中加入Lagarange乘子。\n$$ \\hat{l}(\\theta\\mid D) = \\Sigma_k n_k log\\ \\theta_k + \\lambda(1 - \\Sigma_{k=1}^K x_{n,k}) $$\n对$\\theta_k$求偏导并令其为零：\n$$ \\hat{\\theta}_{k,MLE} = \\frac{n_k}{N} $$\n或者$$ \\hat{\\theta}_{k,MLE} = \\frac{1}{N}\\Sigma_n x_{n,k}$$\n此外，$\\bar{n} = {n_1, n_2, ..., n_K}$和$n_k = \\Sigma_n x_{n,k}$是数据集D的充分统计量。\n\n## 贝叶斯参数估计\n贝叶斯参数估计就是通过贝叶斯定理，利用先验概率分布来推测出后验概率分布，所以先验概率分布对于贝叶斯参数估计方法来说非常的重要，下面介绍两种常见的先验。\n\n### 狄利克雷先验(Dirichlet Prior)\nDirichlet Prior由一组超参数$\\alpha_1, \\alpha_2, ...,\\alpha_N$来定义。Dirichlet分布如下：\n$$ P(\\theta) = \\frac{\\Gamma(\\Sigma_k \\alpha_k)}{\\prod_k \\Gamma(\\Sigma_k \\alpha_k)} \\prod_k \\theta_k^{\\alpha_k-1} = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k-1} $$\n其中$C(\\alpha)$是正则化参数，后验概率可以写成如下形式：\n$$ P(\\theta\\mid x_1, x_2, ..., x_N) = \\frac{P(x_1, x_2,..., x_N\\mid \\theta)P(\\theta)}{P(x_1, x_2, ..., x_N)} \\propto \\prod_k \\theta_k^{\\alpha_k + n_k -1} $$\n因为后验概率与先验概率形式相同，所以被叫做共轭先验。也就是说，只要先验是Dirichlet分布，那么后验就必定是Dirichlet分布。\n基于这一特性，就有了序列贝叶斯更新算法。由Dirichlet先验分布$P(\\vec{\\theta}\\mid \\vec{\\alpha}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha})$，后验更新为$P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n'}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n'})$，之后通过$N'$个样本，可以获得充分统计量$\\vec{n'}$，后验变成：\n$$ P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n'}, \\vec{n''}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n'}, \\vec{n''}) $$\n观测另外$N''$数据有充分统计量$\\vec{n''}$。这样序列化的处理数据方式和批处理是等价的。Dirichlet主要的缺点是一维的分布，不能处理多维的分布，对于多维有对数正态先验。\n\n### 对数正态先验\n对数正态先验相比于Dirichlet拥有更加丰富的分布性质。下面是对数先验的定义：\n$$ \\theta \\sim LN_K(\\mu, \\Sigma) $$ $$ \\gamma \\sim N_{K-1}(\\mu, \\Sigma)\\ \\ \\  \\gamma_K = 0 $$  $$\\theta_i \\sim \\lbrace \\gamma_i - log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $$\n对数配分函数 $ C(\\gamma) = log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $\n对数正态先验可以获得更好的协方差结构的性质，但是它不是共轭先验。\n\n### 多元正态分布的参数估计\n高斯分布的概率密度函数为：\n$$p(X; \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$\n可以对$\\mu$和$\\Sigma$进行最大似然估计：\n$$ \\mu_{MLE} = \\frac{1}{N}\\Sigma_n x_n $$\n$$ \\Sigma_{MLE} = \\frac{1}{N}\\Sigma_n (x_n - \\mu_{MLE})(x_n - \\mu_{MLE})^T $$\n我们需要主要到当$\\Sigma$不是满秩的时候，其也不是可逆的。贝叶斯估计的优势在于贝叶斯估计具有先验知识，或者是先验是共轭的，这样就可以进行序列化的处理，类似于批处理的方式。\n特别的，当$\\mu$未知，$\\sigma$已知时：\n$$ p(\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace $$\n联合概率分布为：\n$$ P(x,\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace * (2\\pi\\sigma^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\sigma^2}\\Sigma_{n=1}^N (x_n - \\mu)^2 \\rbrace $$\n后验概率即为：\n$$ P(\\mu\\mid X) = (2\\pi\\tilde{\\sigma}^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\tilde{\\sigma}^2} (\\mu - \\tilde{\\mu})^2 \\rbrace $$\n其中$\\mu = \\frac{N/\\sigma^2}{N/\\sigma^2 + 1/\\tau} \\bar{x} + \\frac{1/\\tau}{N/\\sigma^2 + 1/\\tau}\\mu_0 $和$ \\tilde{\\sigma}^2 = (\\frac{N}{\\sigma^2} + \\frac{1}{\\tau^2})^{-1} $\n后验均值是先验和极大似然估计的凸组合，权值与噪声水平成正比。\n后验$1/\\tilde{\\sigma}^2$是先验$1/\\tau^2$与每个观测数据对于$1/\\sigma^2$的影响。\n\n## 最大似然估计用于一般的贝叶斯网络\n如果我们假定每个条件概率密度参数是全局独立的，所有的节点是可观的，那么对数似然函数可以分解为如下的形式：\n$$ l(\\theta; D) = log\\ p(D\\mid \\theta) = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i} \\mid x_{n,\\pi_i}, \\theta_i)) $$\n对于独立同分布的数据似然函数为：\n$$ p(D\\mid \\theta) = \\prod_n p(x_n\\mid \\theta) $$\n\n### 最大似然估计用于离散形式的贝叶斯网络\n假定每个条件概率分布都可以用一个表格来表示，其中$\\theta_{ijk} = P(X_i = j\\mid x_{\\pi_i} = k)$，然后充分统计量就是所有可能的状态的和$ n_{ijk} = \\Sigma_n x_{n,i}^j x_{n,{\\pi_i}}^k $，对数似然函数写成：\n$$ l(\\theta; \\mid D) = log\\prod_{i,j,k}\\theta_{ijk}^{n_{ijk}} = \\Sigma_{i,j,k}n_{i,j,k} log\\ \\theta_{i,j,k} $$\n其中$\\Sigma_j \\theta_{ijk} = 1$，使用拉格朗日乘数法可以得出结果：\n$$ \\theta_{ijk}^{ML} = \\frac{n_{ijk}}{\\Sigma_{j'} n_{ij'k}} $$\n\n## 贝叶斯参数估计\n* 全局独立性 $p(\\theta_m\\mid G) = \\prod_{i=1}^M p(\\theta_i \\mid G)$\n* 局部独立性 $p(\\theta_i\\mid G) = \\prod_{j=1}^{q_i} p(\\theta_{x_i^k\\mid x_{\\pi_i^j}} \\mid G)$\n全局参数独立性指的是每个节点间的参数是独立的，局部参数独立性指的是节点的参数在其父节点不同的情况下独立。\n\n* 离散的有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Multi(\\theta)$，同时Dirichlet先验为$p(\\theta) = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k - 1}$。\n* 高斯有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Normal(\\mu,\\Sigma)$，正态Wishart先验为：\n$$ p(\\mu\\mid v,\\alpha_{\\mu},W) = Normal(v,(\\alpha_{\\mu}W)^{-1}) $$\n$$ p(W\\mid \\alpha_w,T) = c(n, \\alpha_w)|T|^{\\alpha_w /2}|W|^{(\\alpha_w -n-1)/2} exp \\lbrace\\frac{1}{2}tr\\lbrace TW \\rbrace\\rbrace $$\n其中$W = \\Sigma^{-1}$。\n\n##　马尔科夫链转移矩阵\n考虑一个时不变的一阶马尔科夫链，初始状态概率向量为$\\pi_k = P(X_1^K = 1)$，状态转移矩阵$A_{ij} = P(X_t^j = 1\\mid x_{t-1}^i = 1)$。联合概率为：\n$$ P(X_{1:T\\mid \\theta}) = P(x_1\\mid \\pi)\\prod_{t=2}^T P(X_t\\mid X_{t-1})$$\n对数似然函数为：\n$$ l(\\theta;D) = \\Sigma_n log\\ p(x_{n,1}\\mid \\pi) + \\Sigma_n\\Sigma_{t=2}^T log\\ P(x_{n,t}\\mid x_{n,t-1,A}) $$\nA是随机矩阵并且$\\Sigma_j A_{ij}$，所以$A_{ij}$的最大似然估计是从$i$到$j$转移的分式：\n$$ A_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)}{\\Psi(i\\rightarrow \\star)} = \\frac{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i x_{n,t}^j}{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i} $$\n\n上面的方法有一个稀疏的问题，当$i\\rightarrow j$没有出现时，$A_{ij}=0$，那么即将出现的单词对$i\\rightarrow j$概率为零。可以使用下面的方法进行解决：\n$$ \\tilde{A}_{i\\rightarrow \\star} = \\lambda\\eta_t + (1 - \\lambda) A_{i\\rightarrow \\star}^{ML} $$\n\n## 隐马尔科夫模型\n* 两个状态之间转移的可能性$P(y_t^j = 1\\mid y_{t-1}^i = 1) = a_{i,j}$或者$P(y_t\\mid y_{t-1} = 1)\\sim Multinomial(a_{i,1}, a_{i,2}, ..., a_{i,M})$。\n* 开始概率$P(y_1) \\sim Multinomial(\\pi_1, \\pi_2,..., \\pi_M)$。\n* 每个y向x的传播概率$P(x_t\\mid y_t^i = 1)\\sim Multinomial(b_{i,1}, b_{i,2}, ..., b_{i,K})$。\n\n给定$x=x_1,...,x_N$对实际的状态路径已知，定义如下：\n$A_{ij} = \\Psi$状态转移在y上从$i\\rightarrow j$\n$B_{ik} = \\Psi $状态i在y中影响在x中的k\n$\\theta$的最大似然估计：\n$$a_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)} {\\Psi(i\\rightarrow \\star)} = \\frac{A_{ij}}{\\Sigma_j A_{ij}}$$\n$$ b_{ik}^{ML} = \\frac{\\Psi(i\\rightarrow \\star)}{\\Psi(i\\rightarrow \\star)} = \\frac{B_{ij}}{\\Sigma_k B_{ik}} $$\n\n对于样本较小的情况下，采用伪计数。\n$A_{ij} = \\Psi$状态转移在$y+R_{ij$}$上从$i\\rightarrow j$\n$B_{ik} = \\Psi$状态i在$y$中影响在$x+S_{ik}$中的k\n$R_{ij}$，$S_{ij}$是伪计数，体现了我们对先验信息的信任。\n\n# 总结\n对于完全可观的贝叶斯网络，可以进行分解，所以学习问题可以进行分解。\n* 结构学习\n + Chow Liu 算法\n + 近邻选择\n* 在概率图的单个节点上进行学习-密度估计：指数族分布\n + 一般的离散分布\n + 一般的连续分布\n + 共轭先验\n* 两个节点进行学习：广义线性模型\n + 条件概率密度估计\n + 分类\n* 更多的节点\n + 利用局部的性质\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n注：本文主要参考[1]中第7讲视频以及笔记。\n","source":"_posts/可观贝叶斯网络中的学习问题.md","raw":"---\ntitle: 可观贝叶斯网络中的学习问题\ndate: 2018-05-12 15:37:27\ntags:\n- 概率图模型\n- 贝叶斯网络学习\ncategories: 学习\n---\n# 完全可观的图模型学习\n图模型学习的目的是在给定独立的样本集的情况下找到合适的的贝叶斯网络，这里的学习（learning）表示对参数的估计或者是从数据学习网络的拓扑结构。\n\n## 最大似然在信息论上的解释\n可以这样理解，将对数似然函数在数据上的和，转变为在变量状态上的和。\n\\begin{equation}\\begin{split} l(\\theta_G,G;D)&=log\\ p(D\\mid \\theta_G,G) (Joint Likelilood)\\\\\\\\\n& = log\\ p\\prod_n(\\prod_i p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}})  (BN Factorization  Rule)\\\\\\\\\n& = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}}))\\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\frac{count(x_i,x_{\\pi_{i(G)}})}{M} log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\\\\\\n\\end{split}\\end{equation}\n\n这里的H表示变量状态，概率分布$p(x_i)$用计数函数取代（count function）。$(x_i,x_{\\pi{i(G)}}$包括了所随机变量的值。\n继续对上面的式子进行推导：\n\\begin{equation}\\begin{split} l(\\theta_G,G;D)&=M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}\\mid \\theta_{i\\mid \\pi_{(G)}})}  {\\hat{p}(x_i, x_{\\pi_{i(G)}})}\\frac{\\hat{p}(x_i)}{\\hat{p}(x_i)})\\\\\\\\\n& = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{(G)}})} {\\hat{p}(x_i, x_{\\pi_{i(G)}})\\hat{p}(x_i)}) - M\\ \\Sigma_i\\Sigma_{x_i} - \\hat{p}(x_i)log\\ \\hat{p}(x_i)\\\\\\\\\n& = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i) \\\\\\\\\n\\end{split}\\end{equation}\n这样可以将最大似然估计分成两个部分，第一个部分是所有节点的互信息，第二部分是每个节点的熵。可以得出这样的结论，如果我们确定结构式树结构（每个节点只有一个父节点），那么基于最大似然估计下，我们可以获得一个最优的树。\n\n# Chow-Liu 算法\n目标函数可以写成：\n$$ l(\\theta_G,G;D) = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i)  $$\n将上式后面各个变量的熵去掉，因为变量的熵与树的结构无关，上式化简为：\n\\begin{equation}\\begin{split} C(G) &= M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) \\\\\\\\\n&= M\\ \\Sigma_i\\hat{I}(x_i,x_j) \\\\\\\\\n\\end{split}\\end{equation}\n我们只需要计算经验分布（empirical distribution）和每对节点的互信息（mutual information）就可以了。经验分布可以通过数据直接数出来，下面是计算每对节点$x_i$和$x_j$之间的经验分布和互信息。\n$$ \\hat{p}(X_i, X_j) = \\frac{count(x_i, x_j)}{M} $$\n$$ \\hat{I}(X_i, X_j) = \\Sigma_{x_i, x_j}\\hat{p}(x_i, x_j)log\\ \\frac{\\hat{p}(x_i, x_j)}{\\hat{p}(x_i)\\hat{p}(x_j)} $$\n我们定义一个有节点$x_1, x_2, x_3, ...,x_n$的图，指定图的边$(i, j)$的权值为$\\hat{I}(X_i, X_j)$。Chow-Liu算法可以计算最大权重生成树。挑选任意节点作为根节点，然后使用宽度优先算法（breadth-first-search）来决定方向。\n\n# 对于完全可观的给定结构的参数学习\n假定图结构固定，从N个独立同分布的样本集中进行参数估计$D = \\lbrace x_1, x_2, x_3, ..., x_N\\rbrace$。一般来说，每个训练样本$x_n = x_{n, 1}, x_{n,2}, ..., x_{n,M}$是M维的向量，对应于每个节点。下面介绍几个常见用于参数估计的分布。\n\n## 多项式模型\n对于N个独立同分布的样本，采用unit basis vectors表示，$x_n = (x_{n,1}, x_{n,2}, ..., x_{n,K})$，其中$x_{n,k}=\\lbrace 0, 1 \\rbrace $， $\\Sigma_{k=1}^K x_{n, k} $。这种表示方法将事件抽离出来，不考虑事件本身的意义，关注事件发生与否。数据集$D = \\lbrace x_1, x_2, x_3, ..., x_N\\rbrace$的似然函数为：\n$$ L(\\theta\\mid D) = P(x_1, x_2, ..., x_N\\mid \\theta) = \\prod_{n=1}^N P(x_n\\mid \\theta) = \\prod_k \\theta_k^{n_k} $$\n$$ l(\\theta\\mid D) = log\\ \\prod_k \\theta_k^{n_k}  = \\Sigma_k n_k log\\ \\theta_k $$\n因为存在着等式约束$\\Sigma_{k=1}^K x_{n,k} = 1$，所以需要在$l(\\theta\\mid D)$中加入Lagarange乘子。\n$$ \\hat{l}(\\theta\\mid D) = \\Sigma_k n_k log\\ \\theta_k + \\lambda(1 - \\Sigma_{k=1}^K x_{n,k}) $$\n对$\\theta_k$求偏导并令其为零：\n$$ \\hat{\\theta}_{k,MLE} = \\frac{n_k}{N} $$\n或者$$ \\hat{\\theta}_{k,MLE} = \\frac{1}{N}\\Sigma_n x_{n,k}$$\n此外，$\\bar{n} = {n_1, n_2, ..., n_K}$和$n_k = \\Sigma_n x_{n,k}$是数据集D的充分统计量。\n\n## 贝叶斯参数估计\n贝叶斯参数估计就是通过贝叶斯定理，利用先验概率分布来推测出后验概率分布，所以先验概率分布对于贝叶斯参数估计方法来说非常的重要，下面介绍两种常见的先验。\n\n### 狄利克雷先验(Dirichlet Prior)\nDirichlet Prior由一组超参数$\\alpha_1, \\alpha_2, ...,\\alpha_N$来定义。Dirichlet分布如下：\n$$ P(\\theta) = \\frac{\\Gamma(\\Sigma_k \\alpha_k)}{\\prod_k \\Gamma(\\Sigma_k \\alpha_k)} \\prod_k \\theta_k^{\\alpha_k-1} = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k-1} $$\n其中$C(\\alpha)$是正则化参数，后验概率可以写成如下形式：\n$$ P(\\theta\\mid x_1, x_2, ..., x_N) = \\frac{P(x_1, x_2,..., x_N\\mid \\theta)P(\\theta)}{P(x_1, x_2, ..., x_N)} \\propto \\prod_k \\theta_k^{\\alpha_k + n_k -1} $$\n因为后验概率与先验概率形式相同，所以被叫做共轭先验。也就是说，只要先验是Dirichlet分布，那么后验就必定是Dirichlet分布。\n基于这一特性，就有了序列贝叶斯更新算法。由Dirichlet先验分布$P(\\vec{\\theta}\\mid \\vec{\\alpha}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha})$，后验更新为$P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n'}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n'})$，之后通过$N'$个样本，可以获得充分统计量$\\vec{n'}$，后验变成：\n$$ P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n'}, \\vec{n''}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n'}, \\vec{n''}) $$\n观测另外$N''$数据有充分统计量$\\vec{n''}$。这样序列化的处理数据方式和批处理是等价的。Dirichlet主要的缺点是一维的分布，不能处理多维的分布，对于多维有对数正态先验。\n\n### 对数正态先验\n对数正态先验相比于Dirichlet拥有更加丰富的分布性质。下面是对数先验的定义：\n$$ \\theta \\sim LN_K(\\mu, \\Sigma) $$ $$ \\gamma \\sim N_{K-1}(\\mu, \\Sigma)\\ \\ \\  \\gamma_K = 0 $$  $$\\theta_i \\sim \\lbrace \\gamma_i - log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $$\n对数配分函数 $ C(\\gamma) = log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $\n对数正态先验可以获得更好的协方差结构的性质，但是它不是共轭先验。\n\n### 多元正态分布的参数估计\n高斯分布的概率密度函数为：\n$$p(X; \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$\n可以对$\\mu$和$\\Sigma$进行最大似然估计：\n$$ \\mu_{MLE} = \\frac{1}{N}\\Sigma_n x_n $$\n$$ \\Sigma_{MLE} = \\frac{1}{N}\\Sigma_n (x_n - \\mu_{MLE})(x_n - \\mu_{MLE})^T $$\n我们需要主要到当$\\Sigma$不是满秩的时候，其也不是可逆的。贝叶斯估计的优势在于贝叶斯估计具有先验知识，或者是先验是共轭的，这样就可以进行序列化的处理，类似于批处理的方式。\n特别的，当$\\mu$未知，$\\sigma$已知时：\n$$ p(\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace $$\n联合概率分布为：\n$$ P(x,\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace * (2\\pi\\sigma^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\sigma^2}\\Sigma_{n=1}^N (x_n - \\mu)^2 \\rbrace $$\n后验概率即为：\n$$ P(\\mu\\mid X) = (2\\pi\\tilde{\\sigma}^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\tilde{\\sigma}^2} (\\mu - \\tilde{\\mu})^2 \\rbrace $$\n其中$\\mu = \\frac{N/\\sigma^2}{N/\\sigma^2 + 1/\\tau} \\bar{x} + \\frac{1/\\tau}{N/\\sigma^2 + 1/\\tau}\\mu_0 $和$ \\tilde{\\sigma}^2 = (\\frac{N}{\\sigma^2} + \\frac{1}{\\tau^2})^{-1} $\n后验均值是先验和极大似然估计的凸组合，权值与噪声水平成正比。\n后验$1/\\tilde{\\sigma}^2$是先验$1/\\tau^2$与每个观测数据对于$1/\\sigma^2$的影响。\n\n## 最大似然估计用于一般的贝叶斯网络\n如果我们假定每个条件概率密度参数是全局独立的，所有的节点是可观的，那么对数似然函数可以分解为如下的形式：\n$$ l(\\theta; D) = log\\ p(D\\mid \\theta) = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i} \\mid x_{n,\\pi_i}, \\theta_i)) $$\n对于独立同分布的数据似然函数为：\n$$ p(D\\mid \\theta) = \\prod_n p(x_n\\mid \\theta) $$\n\n### 最大似然估计用于离散形式的贝叶斯网络\n假定每个条件概率分布都可以用一个表格来表示，其中$\\theta_{ijk} = P(X_i = j\\mid x_{\\pi_i} = k)$，然后充分统计量就是所有可能的状态的和$ n_{ijk} = \\Sigma_n x_{n,i}^j x_{n,{\\pi_i}}^k $，对数似然函数写成：\n$$ l(\\theta; \\mid D) = log\\prod_{i,j,k}\\theta_{ijk}^{n_{ijk}} = \\Sigma_{i,j,k}n_{i,j,k} log\\ \\theta_{i,j,k} $$\n其中$\\Sigma_j \\theta_{ijk} = 1$，使用拉格朗日乘数法可以得出结果：\n$$ \\theta_{ijk}^{ML} = \\frac{n_{ijk}}{\\Sigma_{j'} n_{ij'k}} $$\n\n## 贝叶斯参数估计\n* 全局独立性 $p(\\theta_m\\mid G) = \\prod_{i=1}^M p(\\theta_i \\mid G)$\n* 局部独立性 $p(\\theta_i\\mid G) = \\prod_{j=1}^{q_i} p(\\theta_{x_i^k\\mid x_{\\pi_i^j}} \\mid G)$\n全局参数独立性指的是每个节点间的参数是独立的，局部参数独立性指的是节点的参数在其父节点不同的情况下独立。\n\n* 离散的有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Multi(\\theta)$，同时Dirichlet先验为$p(\\theta) = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k - 1}$。\n* 高斯有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Normal(\\mu,\\Sigma)$，正态Wishart先验为：\n$$ p(\\mu\\mid v,\\alpha_{\\mu},W) = Normal(v,(\\alpha_{\\mu}W)^{-1}) $$\n$$ p(W\\mid \\alpha_w,T) = c(n, \\alpha_w)|T|^{\\alpha_w /2}|W|^{(\\alpha_w -n-1)/2} exp \\lbrace\\frac{1}{2}tr\\lbrace TW \\rbrace\\rbrace $$\n其中$W = \\Sigma^{-1}$。\n\n##　马尔科夫链转移矩阵\n考虑一个时不变的一阶马尔科夫链，初始状态概率向量为$\\pi_k = P(X_1^K = 1)$，状态转移矩阵$A_{ij} = P(X_t^j = 1\\mid x_{t-1}^i = 1)$。联合概率为：\n$$ P(X_{1:T\\mid \\theta}) = P(x_1\\mid \\pi)\\prod_{t=2}^T P(X_t\\mid X_{t-1})$$\n对数似然函数为：\n$$ l(\\theta;D) = \\Sigma_n log\\ p(x_{n,1}\\mid \\pi) + \\Sigma_n\\Sigma_{t=2}^T log\\ P(x_{n,t}\\mid x_{n,t-1,A}) $$\nA是随机矩阵并且$\\Sigma_j A_{ij}$，所以$A_{ij}$的最大似然估计是从$i$到$j$转移的分式：\n$$ A_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)}{\\Psi(i\\rightarrow \\star)} = \\frac{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i x_{n,t}^j}{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i} $$\n\n上面的方法有一个稀疏的问题，当$i\\rightarrow j$没有出现时，$A_{ij}=0$，那么即将出现的单词对$i\\rightarrow j$概率为零。可以使用下面的方法进行解决：\n$$ \\tilde{A}_{i\\rightarrow \\star} = \\lambda\\eta_t + (1 - \\lambda) A_{i\\rightarrow \\star}^{ML} $$\n\n## 隐马尔科夫模型\n* 两个状态之间转移的可能性$P(y_t^j = 1\\mid y_{t-1}^i = 1) = a_{i,j}$或者$P(y_t\\mid y_{t-1} = 1)\\sim Multinomial(a_{i,1}, a_{i,2}, ..., a_{i,M})$。\n* 开始概率$P(y_1) \\sim Multinomial(\\pi_1, \\pi_2,..., \\pi_M)$。\n* 每个y向x的传播概率$P(x_t\\mid y_t^i = 1)\\sim Multinomial(b_{i,1}, b_{i,2}, ..., b_{i,K})$。\n\n给定$x=x_1,...,x_N$对实际的状态路径已知，定义如下：\n$A_{ij} = \\Psi$状态转移在y上从$i\\rightarrow j$\n$B_{ik} = \\Psi $状态i在y中影响在x中的k\n$\\theta$的最大似然估计：\n$$a_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)} {\\Psi(i\\rightarrow \\star)} = \\frac{A_{ij}}{\\Sigma_j A_{ij}}$$\n$$ b_{ik}^{ML} = \\frac{\\Psi(i\\rightarrow \\star)}{\\Psi(i\\rightarrow \\star)} = \\frac{B_{ij}}{\\Sigma_k B_{ik}} $$\n\n对于样本较小的情况下，采用伪计数。\n$A_{ij} = \\Psi$状态转移在$y+R_{ij$}$上从$i\\rightarrow j$\n$B_{ik} = \\Psi$状态i在$y$中影响在$x+S_{ik}$中的k\n$R_{ij}$，$S_{ij}$是伪计数，体现了我们对先验信息的信任。\n\n# 总结\n对于完全可观的贝叶斯网络，可以进行分解，所以学习问题可以进行分解。\n* 结构学习\n + Chow Liu 算法\n + 近邻选择\n* 在概率图的单个节点上进行学习-密度估计：指数族分布\n + 一般的离散分布\n + 一般的连续分布\n + 共轭先验\n* 两个节点进行学习：广义线性模型\n + 条件概率密度估计\n + 分类\n* 更多的节点\n + 利用局部的性质\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n注：本文主要参考[1]中第7讲视频以及笔记。\n","slug":"可观贝叶斯网络中的学习问题","published":1,"updated":"2018-09-22T06:33:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msw000z1ouzjj06n113","content":"<h1 id=\"完全可观的图模型学习\"><a href=\"#完全可观的图模型学习\" class=\"headerlink\" title=\"完全可观的图模型学习\"></a>完全可观的图模型学习</h1><p>图模型学习的目的是在给定独立的样本集的情况下找到合适的的贝叶斯网络，这里的学习（learning）表示对参数的估计或者是从数据学习网络的拓扑结构。</p>\n<h2 id=\"最大似然在信息论上的解释\"><a href=\"#最大似然在信息论上的解释\" class=\"headerlink\" title=\"最大似然在信息论上的解释\"></a>最大似然在信息论上的解释</h2><p>可以这样理解，将对数似然函数在数据上的和，转变为在变量状态上的和。<br>\\begin{equation}\\begin{split} l(\\theta_G,G;D)&amp;=log\\ p(D\\mid \\theta_G,G) (Joint Likelilood)\\\\<br>&amp; = log\\ p\\prod_n(\\prod_i p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}})  (BN Factorization  Rule)\\\\<br>&amp; = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}}))\\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\frac{count(x_i,x_{\\pi_{i(G)}})}{M} log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\<br>\\end{split}\\end{equation}</p>\n<p>这里的H表示变量状态，概率分布$p(x_i)$用计数函数取代（count function）。$(x_i,x_{\\pi{i(G)}}$包括了所随机变量的值。<br>继续对上面的式子进行推导：<br>\\begin{equation}\\begin{split} l(\\theta_G,G;D)&amp;=M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}\\mid \\theta_{i\\mid \\pi_{(G)}})}  {\\hat{p}(x_i, x_{\\pi_{i(G)}})}\\frac{\\hat{p}(x_i)}{\\hat{p}(x_i)})\\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{(G)}})} {\\hat{p}(x_i, x_{\\pi_{i(G)}})\\hat{p}(x_i)}) - M\\ \\Sigma_i\\Sigma_{x_i} - \\hat{p}(x_i)log\\ \\hat{p}(x_i)\\\\<br>&amp; = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i) \\\\<br>\\end{split}\\end{equation}<br>这样可以将最大似然估计分成两个部分，第一个部分是所有节点的互信息，第二部分是每个节点的熵。可以得出这样的结论，如果我们确定结构式树结构（每个节点只有一个父节点），那么基于最大似然估计下，我们可以获得一个最优的树。</p>\n<h1 id=\"Chow-Liu-算法\"><a href=\"#Chow-Liu-算法\" class=\"headerlink\" title=\"Chow-Liu 算法\"></a>Chow-Liu 算法</h1><p>目标函数可以写成：<br>$$ l(\\theta_G,G;D) = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i)  $$<br>将上式后面各个变量的熵去掉，因为变量的熵与树的结构无关，上式化简为：<br>\\begin{equation}\\begin{split} C(G) &amp;= M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) \\\\<br>&amp;= M\\ \\Sigma_i\\hat{I}(x_i,x_j) \\\\<br>\\end{split}\\end{equation}<br>我们只需要计算经验分布（empirical distribution）和每对节点的互信息（mutual information）就可以了。经验分布可以通过数据直接数出来，下面是计算每对节点$x_i$和$x_j$之间的经验分布和互信息。<br>$$ \\hat{p}(X_i, X_j) = \\frac{count(x_i, x_j)}{M} $$<br>$$ \\hat{I}(X_i, X_j) = \\Sigma_{x_i, x_j}\\hat{p}(x_i, x_j)log\\ \\frac{\\hat{p}(x_i, x_j)}{\\hat{p}(x_i)\\hat{p}(x_j)} $$<br>我们定义一个有节点$x_1, x_2, x_3, …,x_n$的图，指定图的边$(i, j)$的权值为$\\hat{I}(X_i, X_j)$。Chow-Liu算法可以计算最大权重生成树。挑选任意节点作为根节点，然后使用宽度优先算法（breadth-first-search）来决定方向。</p>\n<h1 id=\"对于完全可观的给定结构的参数学习\"><a href=\"#对于完全可观的给定结构的参数学习\" class=\"headerlink\" title=\"对于完全可观的给定结构的参数学习\"></a>对于完全可观的给定结构的参数学习</h1><p>假定图结构固定，从N个独立同分布的样本集中进行参数估计$D = \\lbrace x_1, x_2, x_3, …, x_N\\rbrace$。一般来说，每个训练样本$x_n = x_{n, 1}, x_{n,2}, …, x_{n,M}$是M维的向量，对应于每个节点。下面介绍几个常见用于参数估计的分布。</p>\n<h2 id=\"多项式模型\"><a href=\"#多项式模型\" class=\"headerlink\" title=\"多项式模型\"></a>多项式模型</h2><p>对于N个独立同分布的样本，采用unit basis vectors表示，$x_n = (x_{n,1}, x_{n,2}, …, x_{n,K})$，其中$x_{n,k}=\\lbrace 0, 1 \\rbrace $， $\\Sigma_{k=1}^K x_{n, k} $。这种表示方法将事件抽离出来，不考虑事件本身的意义，关注事件发生与否。数据集$D = \\lbrace x_1, x_2, x_3, …, x_N\\rbrace$的似然函数为：<br>$$ L(\\theta\\mid D) = P(x_1, x_2, …, x_N\\mid \\theta) = \\prod_{n=1}^N P(x_n\\mid \\theta) = \\prod_k \\theta_k^{n_k} $$<br>$$ l(\\theta\\mid D) = log\\ \\prod_k \\theta_k^{n_k}  = \\Sigma_k n_k log\\ \\theta_k $$<br>因为存在着等式约束$\\Sigma_{k=1}^K x_{n,k} = 1$，所以需要在$l(\\theta\\mid D)$中加入Lagarange乘子。<br>$$ \\hat{l}(\\theta\\mid D) = \\Sigma_k n_k log\\ \\theta_k + \\lambda(1 - \\Sigma_{k=1}^K x_{n,k}) $$<br>对$\\theta_k$求偏导并令其为零：<br>$$ \\hat{\\theta}_{k,MLE} = \\frac{n_k}{N} $$<br>或者$$ \\hat{\\theta}_{k,MLE} = \\frac{1}{N}\\Sigma_n x_{n,k}$$<br>此外，$\\bar{n} = {n_1, n_2, …, n_K}$和$n_k = \\Sigma_n x_{n,k}$是数据集D的充分统计量。</p>\n<h2 id=\"贝叶斯参数估计\"><a href=\"#贝叶斯参数估计\" class=\"headerlink\" title=\"贝叶斯参数估计\"></a>贝叶斯参数估计</h2><p>贝叶斯参数估计就是通过贝叶斯定理，利用先验概率分布来推测出后验概率分布，所以先验概率分布对于贝叶斯参数估计方法来说非常的重要，下面介绍两种常见的先验。</p>\n<h3 id=\"狄利克雷先验-Dirichlet-Prior\"><a href=\"#狄利克雷先验-Dirichlet-Prior\" class=\"headerlink\" title=\"狄利克雷先验(Dirichlet Prior)\"></a>狄利克雷先验(Dirichlet Prior)</h3><p>Dirichlet Prior由一组超参数$\\alpha_1, \\alpha_2, …,\\alpha_N$来定义。Dirichlet分布如下：<br>$$ P(\\theta) = \\frac{\\Gamma(\\Sigma_k \\alpha_k)}{\\prod_k \\Gamma(\\Sigma_k \\alpha_k)} \\prod_k \\theta_k^{\\alpha_k-1} = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k-1} $$<br>其中$C(\\alpha)$是正则化参数，后验概率可以写成如下形式：<br>$$ P(\\theta\\mid x_1, x_2, …, x_N) = \\frac{P(x_1, x_2,…, x_N\\mid \\theta)P(\\theta)}{P(x_1, x_2, …, x_N)} \\propto \\prod_k \\theta_k^{\\alpha_k + n_k -1} $$<br>因为后验概率与先验概率形式相同，所以被叫做共轭先验。也就是说，只要先验是Dirichlet分布，那么后验就必定是Dirichlet分布。<br>基于这一特性，就有了序列贝叶斯更新算法。由Dirichlet先验分布$P(\\vec{\\theta}\\mid \\vec{\\alpha}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha})$，后验更新为$P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n’}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n’})$，之后通过$N’$个样本，可以获得充分统计量$\\vec{n’}$，后验变成：<br>$$ P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n’}, \\vec{n’’}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n’}, \\vec{n’’}) $$<br>观测另外$N’’$数据有充分统计量$\\vec{n’’}$。这样序列化的处理数据方式和批处理是等价的。Dirichlet主要的缺点是一维的分布，不能处理多维的分布，对于多维有对数正态先验。</p>\n<h3 id=\"对数正态先验\"><a href=\"#对数正态先验\" class=\"headerlink\" title=\"对数正态先验\"></a>对数正态先验</h3><p>对数正态先验相比于Dirichlet拥有更加丰富的分布性质。下面是对数先验的定义：<br>$$ \\theta \\sim LN_K(\\mu, \\Sigma) $$ $$ \\gamma \\sim N_{K-1}(\\mu, \\Sigma)\\ \\ \\  \\gamma_K = 0 $$  $$\\theta_i \\sim \\lbrace \\gamma_i - log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $$<br>对数配分函数 $ C(\\gamma) = log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $<br>对数正态先验可以获得更好的协方差结构的性质，但是它不是共轭先验。</p>\n<h3 id=\"多元正态分布的参数估计\"><a href=\"#多元正态分布的参数估计\" class=\"headerlink\" title=\"多元正态分布的参数估计\"></a>多元正态分布的参数估计</h3><p>高斯分布的概率密度函数为：<br>$$p(X; \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$<br>可以对$\\mu$和$\\Sigma$进行最大似然估计：<br>$$ \\mu_{MLE} = \\frac{1}{N}\\Sigma_n x_n $$<br>$$ \\Sigma_{MLE} = \\frac{1}{N}\\Sigma_n (x_n - \\mu_{MLE})(x_n - \\mu_{MLE})^T $$<br>我们需要主要到当$\\Sigma$不是满秩的时候，其也不是可逆的。贝叶斯估计的优势在于贝叶斯估计具有先验知识，或者是先验是共轭的，这样就可以进行序列化的处理，类似于批处理的方式。<br>特别的，当$\\mu$未知，$\\sigma$已知时：<br>$$ p(\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace $$<br>联合概率分布为：<br>$$ P(x,\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace * (2\\pi\\sigma^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\sigma^2}\\Sigma_{n=1}^N (x_n - \\mu)^2 \\rbrace $$<br>后验概率即为：<br>$$ P(\\mu\\mid X) = (2\\pi\\tilde{\\sigma}^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\tilde{\\sigma}^2} (\\mu - \\tilde{\\mu})^2 \\rbrace $$<br>其中$\\mu = \\frac{N/\\sigma^2}{N/\\sigma^2 + 1/\\tau} \\bar{x} + \\frac{1/\\tau}{N/\\sigma^2 + 1/\\tau}\\mu_0 $和$ \\tilde{\\sigma}^2 = (\\frac{N}{\\sigma^2} + \\frac{1}{\\tau^2})^{-1} $<br>后验均值是先验和极大似然估计的凸组合，权值与噪声水平成正比。<br>后验$1/\\tilde{\\sigma}^2$是先验$1/\\tau^2$与每个观测数据对于$1/\\sigma^2$的影响。</p>\n<h2 id=\"最大似然估计用于一般的贝叶斯网络\"><a href=\"#最大似然估计用于一般的贝叶斯网络\" class=\"headerlink\" title=\"最大似然估计用于一般的贝叶斯网络\"></a>最大似然估计用于一般的贝叶斯网络</h2><p>如果我们假定每个条件概率密度参数是全局独立的，所有的节点是可观的，那么对数似然函数可以分解为如下的形式：<br>$$ l(\\theta; D) = log\\ p(D\\mid \\theta) = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i} \\mid x_{n,\\pi_i}, \\theta_i)) $$<br>对于独立同分布的数据似然函数为：<br>$$ p(D\\mid \\theta) = \\prod_n p(x_n\\mid \\theta) $$</p>\n<h3 id=\"最大似然估计用于离散形式的贝叶斯网络\"><a href=\"#最大似然估计用于离散形式的贝叶斯网络\" class=\"headerlink\" title=\"最大似然估计用于离散形式的贝叶斯网络\"></a>最大似然估计用于离散形式的贝叶斯网络</h3><p>假定每个条件概率分布都可以用一个表格来表示，其中$\\theta_{ijk} = P(X_i = j\\mid x_{\\pi_i} = k)$，然后充分统计量就是所有可能的状态的和$ n_{ijk} = \\Sigma_n x_{n,i}^j x_{n,{\\pi_i}}^k $，对数似然函数写成：<br>$$ l(\\theta; \\mid D) = log\\prod_{i,j,k}\\theta_{ijk}^{n_{ijk}} = \\Sigma_{i,j,k}n_{i,j,k} log\\ \\theta_{i,j,k} $$<br>其中$\\Sigma_j \\theta_{ijk} = 1$，使用拉格朗日乘数法可以得出结果：<br>$$ \\theta_{ijk}^{ML} = \\frac{n_{ijk}}{\\Sigma_{j’} n_{ij’k}} $$</p>\n<h2 id=\"贝叶斯参数估计-1\"><a href=\"#贝叶斯参数估计-1\" class=\"headerlink\" title=\"贝叶斯参数估计\"></a>贝叶斯参数估计</h2><ul>\n<li>全局独立性 $p(\\theta_m\\mid G) = \\prod_{i=1}^M p(\\theta_i \\mid G)$</li>\n<li><p>局部独立性 $p(\\theta_i\\mid G) = \\prod_{j=1}^{q_i} p(\\theta_{x_i^k\\mid x_{\\pi_i^j}} \\mid G)$<br>全局参数独立性指的是每个节点间的参数是独立的，局部参数独立性指的是节点的参数在其父节点不同的情况下独立。</p>\n</li>\n<li><p>离散的有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Multi(\\theta)$，同时Dirichlet先验为$p(\\theta) = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k - 1}$。</p>\n</li>\n<li>高斯有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Normal(\\mu,\\Sigma)$，正态Wishart先验为：<br>$$ p(\\mu\\mid v,\\alpha_{\\mu},W) = Normal(v,(\\alpha_{\\mu}W)^{-1}) $$<br>$$ p(W\\mid \\alpha_w,T) = c(n, \\alpha_w)|T|^{\\alpha_w /2}|W|^{(\\alpha_w -n-1)/2} exp \\lbrace\\frac{1}{2}tr\\lbrace TW \\rbrace\\rbrace $$<br>其中$W = \\Sigma^{-1}$。</li>\n</ul>\n<p>##　马尔科夫链转移矩阵<br>考虑一个时不变的一阶马尔科夫链，初始状态概率向量为$\\pi_k = P(X_1^K = 1)$，状态转移矩阵$A_{ij} = P(X_t^j = 1\\mid x_{t-1}^i = 1)$。联合概率为：<br>$$ P(X_{1:T\\mid \\theta}) = P(x_1\\mid \\pi)\\prod_{t=2}^T P(X_t\\mid X_{t-1})$$<br>对数似然函数为：<br>$$ l(\\theta;D) = \\Sigma_n log\\ p(x_{n,1}\\mid \\pi) + \\Sigma_n\\Sigma_{t=2}^T log\\ P(x_{n,t}\\mid x_{n,t-1,A}) $$<br>A是随机矩阵并且$\\Sigma_j A_{ij}$，所以$A_{ij}$的最大似然估计是从$i$到$j$转移的分式：<br>$$ A_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)}{\\Psi(i\\rightarrow \\star)} = \\frac{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i x_{n,t}^j}{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i} $$</p>\n<p>上面的方法有一个稀疏的问题，当$i\\rightarrow j$没有出现时，$A_{ij}=0$，那么即将出现的单词对$i\\rightarrow j$概率为零。可以使用下面的方法进行解决：<br>$$ \\tilde{A}_{i\\rightarrow \\star} = \\lambda\\eta_t + (1 - \\lambda) A_{i\\rightarrow \\star}^{ML} $$</p>\n<h2 id=\"隐马尔科夫模型\"><a href=\"#隐马尔科夫模型\" class=\"headerlink\" title=\"隐马尔科夫模型\"></a>隐马尔科夫模型</h2><ul>\n<li>两个状态之间转移的可能性$P(y_t^j = 1\\mid y_{t-1}^i = 1) = a_{i,j}$或者$P(y_t\\mid y_{t-1} = 1)\\sim Multinomial(a_{i,1}, a_{i,2}, …, a_{i,M})$。</li>\n<li>开始概率$P(y_1) \\sim Multinomial(\\pi_1, \\pi_2,…, \\pi_M)$。</li>\n<li>每个y向x的传播概率$P(x_t\\mid y_t^i = 1)\\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K})$。</li>\n</ul>\n<p>给定$x=x_1,…,x_N$对实际的状态路径已知，定义如下：<br>$A_{ij} = \\Psi$状态转移在y上从$i\\rightarrow j$<br>$B_{ik} = \\Psi $状态i在y中影响在x中的k<br>$\\theta$的最大似然估计：<br>$$a_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)} {\\Psi(i\\rightarrow \\star)} = \\frac{A_{ij}}{\\Sigma_j A_{ij}}$$<br>$$ b_{ik}^{ML} = \\frac{\\Psi(i\\rightarrow \\star)}{\\Psi(i\\rightarrow \\star)} = \\frac{B_{ij}}{\\Sigma_k B_{ik}} $$</p>\n<p>对于样本较小的情况下，采用伪计数。<br>$A_{ij} = \\Psi$状态转移在$y+R_{ij$}$上从$i\\rightarrow j$<br>$B_{ik} = \\Psi$状态i在$y$中影响在$x+S_{ik}$中的k<br>$R_{ij}$，$S_{ij}$是伪计数，体现了我们对先验信息的信任。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>对于完全可观的贝叶斯网络，可以进行分解，所以学习问题可以进行分解。</p>\n<ul>\n<li>结构学习<ul>\n<li>Chow Liu 算法</li>\n<li>近邻选择</li>\n</ul>\n</li>\n<li>在概率图的单个节点上进行学习-密度估计：指数族分布<ul>\n<li>一般的离散分布</li>\n<li>一般的连续分布</li>\n<li>共轭先验</li>\n</ul>\n</li>\n<li>两个节点进行学习：广义线性模型<ul>\n<li>条件概率密度估计</li>\n<li>分类</li>\n</ul>\n</li>\n<li>更多的节点<ul>\n<li>利用局部的性质</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第7讲视频以及笔记。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"完全可观的图模型学习\"><a href=\"#完全可观的图模型学习\" class=\"headerlink\" title=\"完全可观的图模型学习\"></a>完全可观的图模型学习</h1><p>图模型学习的目的是在给定独立的样本集的情况下找到合适的的贝叶斯网络，这里的学习（learning）表示对参数的估计或者是从数据学习网络的拓扑结构。</p>\n<h2 id=\"最大似然在信息论上的解释\"><a href=\"#最大似然在信息论上的解释\" class=\"headerlink\" title=\"最大似然在信息论上的解释\"></a>最大似然在信息论上的解释</h2><p>可以这样理解，将对数似然函数在数据上的和，转变为在变量状态上的和。<br>\\begin{equation}\\begin{split} l(\\theta_G,G;D)&amp;=log\\ p(D\\mid \\theta_G,G) (Joint Likelilood)\\\\<br>&amp; = log\\ p\\prod_n(\\prod_i p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}})  (BN Factorization  Rule)\\\\<br>&amp; = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i}\\mid x_{n,\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{i(G)}}))\\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\frac{count(x_i,x_{\\pi_{i(G)}})}{M} log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\<br>\\end{split}\\end{equation}</p>\n<p>这里的H表示变量状态，概率分布$p(x_i)$用计数函数取代（count function）。$(x_i,x_{\\pi{i(G)}}$包括了所随机变量的值。<br>继续对上面的式子进行推导：<br>\\begin{equation}\\begin{split} l(\\theta_G,G;D)&amp;=M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ p(x_i\\mid x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi(G)}))  \\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}\\mid \\theta_{i\\mid \\pi_{(G)}})}  {\\hat{p}(x_i, x_{\\pi_{i(G)}})}\\frac{\\hat{p}(x_i)}{\\hat{p}(x_i)})\\\\<br>&amp; = M\\ \\Sigma_i(\\Sigma_{x_i,x_{\\pi_{i(G)}}} \\hat{p}(x_i, x_{\\pi_{i(G)}}) log\\ \\frac{p(x_i, x_{\\pi_{i(G)}}, \\theta_{i\\mid \\pi_{(G)}})} {\\hat{p}(x_i, x_{\\pi_{i(G)}})\\hat{p}(x_i)}) - M\\ \\Sigma_i\\Sigma_{x_i} - \\hat{p}(x_i)log\\ \\hat{p}(x_i)\\\\<br>&amp; = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i) \\\\<br>\\end{split}\\end{equation}<br>这样可以将最大似然估计分成两个部分，第一个部分是所有节点的互信息，第二部分是每个节点的熵。可以得出这样的结论，如果我们确定结构式树结构（每个节点只有一个父节点），那么基于最大似然估计下，我们可以获得一个最优的树。</p>\n<h1 id=\"Chow-Liu-算法\"><a href=\"#Chow-Liu-算法\" class=\"headerlink\" title=\"Chow-Liu 算法\"></a>Chow-Liu 算法</h1><p>目标函数可以写成：<br>$$ l(\\theta_G,G;D) = M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) - M\\ \\Sigma_i\\hat{H}(x_i)  $$<br>将上式后面各个变量的熵去掉，因为变量的熵与树的结构无关，上式化简为：<br>\\begin{equation}\\begin{split} C(G) &amp;= M\\ \\Sigma_i\\hat{I}(x_i,x_{\\pi_{i(G)}}) \\\\<br>&amp;= M\\ \\Sigma_i\\hat{I}(x_i,x_j) \\\\<br>\\end{split}\\end{equation}<br>我们只需要计算经验分布（empirical distribution）和每对节点的互信息（mutual information）就可以了。经验分布可以通过数据直接数出来，下面是计算每对节点$x_i$和$x_j$之间的经验分布和互信息。<br>$$ \\hat{p}(X_i, X_j) = \\frac{count(x_i, x_j)}{M} $$<br>$$ \\hat{I}(X_i, X_j) = \\Sigma_{x_i, x_j}\\hat{p}(x_i, x_j)log\\ \\frac{\\hat{p}(x_i, x_j)}{\\hat{p}(x_i)\\hat{p}(x_j)} $$<br>我们定义一个有节点$x_1, x_2, x_3, …,x_n$的图，指定图的边$(i, j)$的权值为$\\hat{I}(X_i, X_j)$。Chow-Liu算法可以计算最大权重生成树。挑选任意节点作为根节点，然后使用宽度优先算法（breadth-first-search）来决定方向。</p>\n<h1 id=\"对于完全可观的给定结构的参数学习\"><a href=\"#对于完全可观的给定结构的参数学习\" class=\"headerlink\" title=\"对于完全可观的给定结构的参数学习\"></a>对于完全可观的给定结构的参数学习</h1><p>假定图结构固定，从N个独立同分布的样本集中进行参数估计$D = \\lbrace x_1, x_2, x_3, …, x_N\\rbrace$。一般来说，每个训练样本$x_n = x_{n, 1}, x_{n,2}, …, x_{n,M}$是M维的向量，对应于每个节点。下面介绍几个常见用于参数估计的分布。</p>\n<h2 id=\"多项式模型\"><a href=\"#多项式模型\" class=\"headerlink\" title=\"多项式模型\"></a>多项式模型</h2><p>对于N个独立同分布的样本，采用unit basis vectors表示，$x_n = (x_{n,1}, x_{n,2}, …, x_{n,K})$，其中$x_{n,k}=\\lbrace 0, 1 \\rbrace $， $\\Sigma_{k=1}^K x_{n, k} $。这种表示方法将事件抽离出来，不考虑事件本身的意义，关注事件发生与否。数据集$D = \\lbrace x_1, x_2, x_3, …, x_N\\rbrace$的似然函数为：<br>$$ L(\\theta\\mid D) = P(x_1, x_2, …, x_N\\mid \\theta) = \\prod_{n=1}^N P(x_n\\mid \\theta) = \\prod_k \\theta_k^{n_k} $$<br>$$ l(\\theta\\mid D) = log\\ \\prod_k \\theta_k^{n_k}  = \\Sigma_k n_k log\\ \\theta_k $$<br>因为存在着等式约束$\\Sigma_{k=1}^K x_{n,k} = 1$，所以需要在$l(\\theta\\mid D)$中加入Lagarange乘子。<br>$$ \\hat{l}(\\theta\\mid D) = \\Sigma_k n_k log\\ \\theta_k + \\lambda(1 - \\Sigma_{k=1}^K x_{n,k}) $$<br>对$\\theta_k$求偏导并令其为零：<br>$$ \\hat{\\theta}_{k,MLE} = \\frac{n_k}{N} $$<br>或者$$ \\hat{\\theta}_{k,MLE} = \\frac{1}{N}\\Sigma_n x_{n,k}$$<br>此外，$\\bar{n} = {n_1, n_2, …, n_K}$和$n_k = \\Sigma_n x_{n,k}$是数据集D的充分统计量。</p>\n<h2 id=\"贝叶斯参数估计\"><a href=\"#贝叶斯参数估计\" class=\"headerlink\" title=\"贝叶斯参数估计\"></a>贝叶斯参数估计</h2><p>贝叶斯参数估计就是通过贝叶斯定理，利用先验概率分布来推测出后验概率分布，所以先验概率分布对于贝叶斯参数估计方法来说非常的重要，下面介绍两种常见的先验。</p>\n<h3 id=\"狄利克雷先验-Dirichlet-Prior\"><a href=\"#狄利克雷先验-Dirichlet-Prior\" class=\"headerlink\" title=\"狄利克雷先验(Dirichlet Prior)\"></a>狄利克雷先验(Dirichlet Prior)</h3><p>Dirichlet Prior由一组超参数$\\alpha_1, \\alpha_2, …,\\alpha_N$来定义。Dirichlet分布如下：<br>$$ P(\\theta) = \\frac{\\Gamma(\\Sigma_k \\alpha_k)}{\\prod_k \\Gamma(\\Sigma_k \\alpha_k)} \\prod_k \\theta_k^{\\alpha_k-1} = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k-1} $$<br>其中$C(\\alpha)$是正则化参数，后验概率可以写成如下形式：<br>$$ P(\\theta\\mid x_1, x_2, …, x_N) = \\frac{P(x_1, x_2,…, x_N\\mid \\theta)P(\\theta)}{P(x_1, x_2, …, x_N)} \\propto \\prod_k \\theta_k^{\\alpha_k + n_k -1} $$<br>因为后验概率与先验概率形式相同，所以被叫做共轭先验。也就是说，只要先验是Dirichlet分布，那么后验就必定是Dirichlet分布。<br>基于这一特性，就有了序列贝叶斯更新算法。由Dirichlet先验分布$P(\\vec{\\theta}\\mid \\vec{\\alpha}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha})$，后验更新为$P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n’}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n’})$，之后通过$N’$个样本，可以获得充分统计量$\\vec{n’}$，后验变成：<br>$$ P(\\vec{\\theta}\\mid \\vec{\\alpha},\\vec{n’}, \\vec{n’’}) = Dir(\\vec{\\theta}\\mid \\vec{\\alpha}, \\vec{n’}, \\vec{n’’}) $$<br>观测另外$N’’$数据有充分统计量$\\vec{n’’}$。这样序列化的处理数据方式和批处理是等价的。Dirichlet主要的缺点是一维的分布，不能处理多维的分布，对于多维有对数正态先验。</p>\n<h3 id=\"对数正态先验\"><a href=\"#对数正态先验\" class=\"headerlink\" title=\"对数正态先验\"></a>对数正态先验</h3><p>对数正态先验相比于Dirichlet拥有更加丰富的分布性质。下面是对数先验的定义：<br>$$ \\theta \\sim LN_K(\\mu, \\Sigma) $$ $$ \\gamma \\sim N_{K-1}(\\mu, \\Sigma)\\ \\ \\  \\gamma_K = 0 $$  $$\\theta_i \\sim \\lbrace \\gamma_i - log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $$<br>对数配分函数 $ C(\\gamma) = log(1 + \\Sigma_{i=1}^{K-1} e^{\\gamma_i}) $<br>对数正态先验可以获得更好的协方差结构的性质，但是它不是共轭先验。</p>\n<h3 id=\"多元正态分布的参数估计\"><a href=\"#多元正态分布的参数估计\" class=\"headerlink\" title=\"多元正态分布的参数估计\"></a>多元正态分布的参数估计</h3><p>高斯分布的概率密度函数为：<br>$$p(X; \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$<br>可以对$\\mu$和$\\Sigma$进行最大似然估计：<br>$$ \\mu_{MLE} = \\frac{1}{N}\\Sigma_n x_n $$<br>$$ \\Sigma_{MLE} = \\frac{1}{N}\\Sigma_n (x_n - \\mu_{MLE})(x_n - \\mu_{MLE})^T $$<br>我们需要主要到当$\\Sigma$不是满秩的时候，其也不是可逆的。贝叶斯估计的优势在于贝叶斯估计具有先验知识，或者是先验是共轭的，这样就可以进行序列化的处理，类似于批处理的方式。<br>特别的，当$\\mu$未知，$\\sigma$已知时：<br>$$ p(\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace $$<br>联合概率分布为：<br>$$ P(x,\\mu) = (2\\pi\\tau^2)^{-1/2} exp\\lbrace -(\\mu - \\mu_0)^2 /2\\tau^2 \\rbrace * (2\\pi\\sigma^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\sigma^2}\\Sigma_{n=1}^N (x_n - \\mu)^2 \\rbrace $$<br>后验概率即为：<br>$$ P(\\mu\\mid X) = (2\\pi\\tilde{\\sigma}^2)^{-N/2} exp\\lbrace -\\frac{1}{2\\tilde{\\sigma}^2} (\\mu - \\tilde{\\mu})^2 \\rbrace $$<br>其中$\\mu = \\frac{N/\\sigma^2}{N/\\sigma^2 + 1/\\tau} \\bar{x} + \\frac{1/\\tau}{N/\\sigma^2 + 1/\\tau}\\mu_0 $和$ \\tilde{\\sigma}^2 = (\\frac{N}{\\sigma^2} + \\frac{1}{\\tau^2})^{-1} $<br>后验均值是先验和极大似然估计的凸组合，权值与噪声水平成正比。<br>后验$1/\\tilde{\\sigma}^2$是先验$1/\\tau^2$与每个观测数据对于$1/\\sigma^2$的影响。</p>\n<h2 id=\"最大似然估计用于一般的贝叶斯网络\"><a href=\"#最大似然估计用于一般的贝叶斯网络\" class=\"headerlink\" title=\"最大似然估计用于一般的贝叶斯网络\"></a>最大似然估计用于一般的贝叶斯网络</h2><p>如果我们假定每个条件概率密度参数是全局独立的，所有的节点是可观的，那么对数似然函数可以分解为如下的形式：<br>$$ l(\\theta; D) = log\\ p(D\\mid \\theta) = \\Sigma_i(\\Sigma_n log\\ p(x_{n,i} \\mid x_{n,\\pi_i}, \\theta_i)) $$<br>对于独立同分布的数据似然函数为：<br>$$ p(D\\mid \\theta) = \\prod_n p(x_n\\mid \\theta) $$</p>\n<h3 id=\"最大似然估计用于离散形式的贝叶斯网络\"><a href=\"#最大似然估计用于离散形式的贝叶斯网络\" class=\"headerlink\" title=\"最大似然估计用于离散形式的贝叶斯网络\"></a>最大似然估计用于离散形式的贝叶斯网络</h3><p>假定每个条件概率分布都可以用一个表格来表示，其中$\\theta_{ijk} = P(X_i = j\\mid x_{\\pi_i} = k)$，然后充分统计量就是所有可能的状态的和$ n_{ijk} = \\Sigma_n x_{n,i}^j x_{n,{\\pi_i}}^k $，对数似然函数写成：<br>$$ l(\\theta; \\mid D) = log\\prod_{i,j,k}\\theta_{ijk}^{n_{ijk}} = \\Sigma_{i,j,k}n_{i,j,k} log\\ \\theta_{i,j,k} $$<br>其中$\\Sigma_j \\theta_{ijk} = 1$，使用拉格朗日乘数法可以得出结果：<br>$$ \\theta_{ijk}^{ML} = \\frac{n_{ijk}}{\\Sigma_{j’} n_{ij’k}} $$</p>\n<h2 id=\"贝叶斯参数估计-1\"><a href=\"#贝叶斯参数估计-1\" class=\"headerlink\" title=\"贝叶斯参数估计\"></a>贝叶斯参数估计</h2><ul>\n<li>全局独立性 $p(\\theta_m\\mid G) = \\prod_{i=1}^M p(\\theta_i \\mid G)$</li>\n<li><p>局部独立性 $p(\\theta_i\\mid G) = \\prod_{j=1}^{q_i} p(\\theta_{x_i^k\\mid x_{\\pi_i^j}} \\mid G)$<br>全局参数独立性指的是每个节点间的参数是独立的，局部参数独立性指的是节点的参数在其父节点不同的情况下独立。</p>\n</li>\n<li><p>离散的有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Multi(\\theta)$，同时Dirichlet先验为$p(\\theta) = C(\\alpha)\\prod_k \\theta_k^{\\alpha_k - 1}$。</p>\n</li>\n<li>高斯有向无环图模型满足$x_i\\mid x_{\\pi_i}^j \\sim Normal(\\mu,\\Sigma)$，正态Wishart先验为：<br>$$ p(\\mu\\mid v,\\alpha_{\\mu},W) = Normal(v,(\\alpha_{\\mu}W)^{-1}) $$<br>$$ p(W\\mid \\alpha_w,T) = c(n, \\alpha_w)|T|^{\\alpha_w /2}|W|^{(\\alpha_w -n-1)/2} exp \\lbrace\\frac{1}{2}tr\\lbrace TW \\rbrace\\rbrace $$<br>其中$W = \\Sigma^{-1}$。</li>\n</ul>\n<p>##　马尔科夫链转移矩阵<br>考虑一个时不变的一阶马尔科夫链，初始状态概率向量为$\\pi_k = P(X_1^K = 1)$，状态转移矩阵$A_{ij} = P(X_t^j = 1\\mid x_{t-1}^i = 1)$。联合概率为：<br>$$ P(X_{1:T\\mid \\theta}) = P(x_1\\mid \\pi)\\prod_{t=2}^T P(X_t\\mid X_{t-1})$$<br>对数似然函数为：<br>$$ l(\\theta;D) = \\Sigma_n log\\ p(x_{n,1}\\mid \\pi) + \\Sigma_n\\Sigma_{t=2}^T log\\ P(x_{n,t}\\mid x_{n,t-1,A}) $$<br>A是随机矩阵并且$\\Sigma_j A_{ij}$，所以$A_{ij}$的最大似然估计是从$i$到$j$转移的分式：<br>$$ A_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)}{\\Psi(i\\rightarrow \\star)} = \\frac{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i x_{n,t}^j}{\\Sigma_n\\Sigma_{t=2}^T x_{n,t-1}^i} $$</p>\n<p>上面的方法有一个稀疏的问题，当$i\\rightarrow j$没有出现时，$A_{ij}=0$，那么即将出现的单词对$i\\rightarrow j$概率为零。可以使用下面的方法进行解决：<br>$$ \\tilde{A}_{i\\rightarrow \\star} = \\lambda\\eta_t + (1 - \\lambda) A_{i\\rightarrow \\star}^{ML} $$</p>\n<h2 id=\"隐马尔科夫模型\"><a href=\"#隐马尔科夫模型\" class=\"headerlink\" title=\"隐马尔科夫模型\"></a>隐马尔科夫模型</h2><ul>\n<li>两个状态之间转移的可能性$P(y_t^j = 1\\mid y_{t-1}^i = 1) = a_{i,j}$或者$P(y_t\\mid y_{t-1} = 1)\\sim Multinomial(a_{i,1}, a_{i,2}, …, a_{i,M})$。</li>\n<li>开始概率$P(y_1) \\sim Multinomial(\\pi_1, \\pi_2,…, \\pi_M)$。</li>\n<li>每个y向x的传播概率$P(x_t\\mid y_t^i = 1)\\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K})$。</li>\n</ul>\n<p>给定$x=x_1,…,x_N$对实际的状态路径已知，定义如下：<br>$A_{ij} = \\Psi$状态转移在y上从$i\\rightarrow j$<br>$B_{ik} = \\Psi $状态i在y中影响在x中的k<br>$\\theta$的最大似然估计：<br>$$a_{ij}^{ML} = \\frac{\\Psi(i\\rightarrow j)} {\\Psi(i\\rightarrow \\star)} = \\frac{A_{ij}}{\\Sigma_j A_{ij}}$$<br>$$ b_{ik}^{ML} = \\frac{\\Psi(i\\rightarrow \\star)}{\\Psi(i\\rightarrow \\star)} = \\frac{B_{ij}}{\\Sigma_k B_{ik}} $$</p>\n<p>对于样本较小的情况下，采用伪计数。<br>$A_{ij} = \\Psi$状态转移在$y+R_{ij$}$上从$i\\rightarrow j$<br>$B_{ik} = \\Psi$状态i在$y$中影响在$x+S_{ik}$中的k<br>$R_{ij}$，$S_{ij}$是伪计数，体现了我们对先验信息的信任。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>对于完全可观的贝叶斯网络，可以进行分解，所以学习问题可以进行分解。</p>\n<ul>\n<li>结构学习<ul>\n<li>Chow Liu 算法</li>\n<li>近邻选择</li>\n</ul>\n</li>\n<li>在概率图的单个节点上进行学习-密度估计：指数族分布<ul>\n<li>一般的离散分布</li>\n<li>一般的连续分布</li>\n<li>共轭先验</li>\n</ul>\n</li>\n<li>两个节点进行学习：广义线性模型<ul>\n<li>条件概率密度估计</li>\n<li>分类</li>\n</ul>\n</li>\n<li>更多的节点<ul>\n<li>利用局部的性质</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第7讲视频以及笔记。</p>\n"},{"title":"可观无向图模型中的学习问题","date":"2018-05-17T02:58:53.000Z","_content":"# 最大似然结构学习\n\n## 连续型马尔科夫随机场\n给定高斯图模型，我们可以用一个伊辛模型来呈现。\n$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$\n下面令$\\mu=0$和$Q=\\Sigma_{-1}$，高斯模型可以写成：\n$$p(x\\mid \\mu,Q)=\\frac{|Q|^{1/2}} {(2\\pi)^{k/2}}exp \\lbrace  -\\frac{1}{2}()\\Sigma_i q_{ii} (x_i)^2 - \\Sigma_{i<j} q_{ij} x_i x_j) \\rbrace$$\n我们将上式指数中的第一部分看做是定义在节点上的势函数，第二部分是定义在比边上的势函数，也就是说等同于一个伊辛模型。\n$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$\n\n## 稀疏图模型\n协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精确矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。\n如果出现$p \\gg n$时，得不到最大似然估计，这是我们使用近邻选择得方法，增加惩罚函数来学习稀疏的图模型。\n近邻选择可以看做是伊辛模型。\n$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$\n\n# 最大似然估计\n\n## 似然条件\n有向图中，对数似然可以分解为一组和的形式，每个对应于一个子节点对应其父节点。无向图中，对数似然并不能分解，因为Z是包含了所有的参数的函数。\n$$ p(x) = \\frac{1}{Z} \\prod_{c\\in C} \\psi_c{x_c}, Z = \\Sigma_x \\prod_{c\\in C} \\psi_c(x_c) $$\n我们需要通过推测来学习参数。我们获得了输入数据的充分统计量，计数。\n$$total\\ count:m(x) = \\Sigma_n \\delta(x, x_n)$$  $$cliqu\\ count:m(x_c) = \\Sigma_{x_{V\\setminus c}} m(x)$$\n似然函数为：\n$$p(D\\mid \\theta) = \\prod_n \\prod_x p(x\\mid \\theta)^{\\delta(x,x_n)}$$\n\n\\begin{equation}\\begin{split} log\\ p(D\\mid \\theta)&=\\Sigma_n \\Sigma_x \\delta(x,x_n)log\\ p(x\\mid \\theta\\\\\\\\\nl & = \\Sigma_x m(x)log(\\frac{1}{Z}\\prod_c \\pi_c(x_c))\\\\\\\\\n& = \\Sigma_c \\Sigma_{x_c}m(x_c)log\\ \\psi_c(x_c) - N log\\ Z \\\\\\\\\n\\end{split}\\end{equation}\n上式的两个部分对$\\psi_c(x_c)$求导：\n第一项：\n$$ \\frac{\\partial l_1}{\\partial \\psi_c(x_c)} = m(x_c)/\\psi_c(x_c) $$\n第二项：\n\\begin{equation}\\begin{split} \\frac{\\partial log\\ Z}{\\partial \\psi_c(x_c)} & = \\frac{1}{Z} \\frac{\\partial}{\\partial\\psi_c(x_c)}(\\Sigma_{\\tilde{x} } \\prod_{d} \\psi_d(\\tilde x_d))\\\\\\\\\n& = \\frac{1}{Z} \\Sigma_{\\tilde{x}}\\delta(\\tilde x_c, x_c)\\frac{\\partial}{\\partial \\psi_c(x_c)}(\\prod_{d} \\psi_d(\\tilde x_d) \\\\\\\\\n& =  \\Sigma_{\\tilde x}\\delta(\\tilde x_c, x_c) \\frac{1}{\\psi_c(\\tilde x_c)} \\frac{1}{Z} \\prod_d \\psi_d(\\tilde x_d)\\\\\\\\\n& = \\frac{1}{\\psi_c (x_c)}\\Sigma_{\\tilde x} \\delta(\\tilde x_c, x_c) p(\\tilde x)  \\\\\\\\\n& = \\frac{x_c}{\\psi_c (x_c)}\n\\end{split}\\end{equation}\n\n令导数为零，有：$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$，从结果可以看出，模型的边缘概率密度等于观测的边缘概率密度。\n$$ p_{MLE}^{\\star} (x_c) = \\frac{m(x_c)}{N} = \\tilde p(x_c) $$\n但是结果并没有给出似然参数的估计方法，只是给出了必须满足的条件。\n\n## 可分解模型\n对于可分解的模型，势函数可以定义于最大团上，团势函数的最大似然等价于经验边际。因此最大似然可以通过检查得到。基于势函数的表示似然$p(x)=\\frac{\\prod_c \\psi_c(x_c)}{\\prod_s \\psi_s(x_s)}$，其中c是最大团，s是最大团分离的因子。为了计算团势，将他们等同于经验边际。分离因子必须分解为几个邻居，那么$Z=1$。\n\n### 例一\n考虑链$X_1-X_2-X_3$，有团$(x_1, x_2),(x_2, x_3)$，分离因子$x_2$。\n$$ \\tilde p_{MLE}(x_1, x_2, x_3) = \\frac{\\tilde p(x_1, x_2)\\tilde p(x_2, x_3)}{\\tilde p(x_2)} $$\n$$ \\tilde{\\psi}_{12}^{MLE}(x_1, x_2) = \\tilde p(x_1, x_2) $$\n$$ \\tilde{\\psi}_{23}^{MLE}(x_2, x_3) = \\frac{\\tilde p(x_2, x_3)}{\\tilde p(x_2)}= \\tilde p(x_2\\mid x_3) $$\n\n### 例二\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png)\n团$(x_1, x_2, x_3),(x_2, x_3, x_4)$，分离因子$x_2,x_3$\n$$ \\tilde p_{MLE}(x_1, x_2, x_3, x_4) = \\frac{\\tilde p(x_1, x_2, x_3)\\tilde p(x_2, x_3, x_4)}{\\tilde p(x_2, x_3)} $$\n$$ \\tilde{\\psi}_{123}^{MLE}(x_1, x_2,x_3) = \\frac{\\tilde p(x_1, x_2, x_3)}{\\tilde p(x_2, x_33)}= \\tilde p(x_1\\mid x_2, x_3) $$\n$$ \\tilde{\\psi}_{234}^{MLE}(x_2, x_3, x_4) =  \\tilde p(x_2, x_3, x_4) $$\n\n## 不可分离模型-IPF和GIS\n如果一个图是不可分离的，也就是说势函数不能以最大团定义，我们不能将经验边际等价于势函数的似然。\n\n### Tabular Cique Potentials-IPF\n如果团势函数是表格形式或者可以使用简介的参数模型表示，那么我们可以使用IPF来求最大似然估计。\n从上面的似然函数导数：\n$$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$$\n我们可以得到：\n$$ \\frac{\\tilde p(x_c)}{\\psi_c(x_c)} = \\frac{p(x_c)}{\\psi_c(x_c)} $$\n因为$\\psi_c$隐性的出现了模型边际$p(x_c)$中，所以在点$\\psi_c$上存在等式关系，所以直接解出$\\psi_c$是非常困难的，因为其出现在了等式两边。\n我们将$\\psi_c$在右边固定，然后在左边解出，循环所有的团，进行下面的迭代：\n$$ \\psi_c^{(t+1)}(x_c) = \\psi_c^{(t)}(x_c)\\frac{\\tilde p(x_c)}{p^{(t)}(x_c)} $$\n上面的算法可以看做是坐标上升算法，其中的坐标就是势团的参数。因此在每一步中，似然函数的值会增加，这样就可以收敛到全局极大值。这个算法童谣可以被看做是最小化观测数据的分布与模型分布的KL散度(交叉熵),只有当模型是可分解的。\n$$ max\\ l \\Leftrightarrow KL(\\tilde p(x)\\mid \\mid p(x\\mid\\theta))=\\Sigma_x \\tilde p(x)log\\frac{\\tilde p(x)}{p(x\\mid \\theta)} $$\n\n\\begin{equation}\\begin{split} KL(q(x_a, x_b)\\mid \\mid p(x_a, x_b)) &= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)q(x_b\\mid x_a)}{p(x_a)p(x_b\\mid x_a)}\\\\\\\\\n&= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)}{p(x_a)} + \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_b\\mid x_a)}{p(x_b\\mid x_a)}\\\\\\\\\n&= KL(1(x_aq)\\mid\\mid p(x_a)) + \\Sigma_x q(x_a)KL(q(x_b\\mid x_a)\\mid\\mid p(x_b\\mid x_a))\\\\\\\\\n\\end{split}\\end{equation}\n将上面两个式子合并：\n$$ KL(\\tilde p(x)\\mid\\mid p(x\\theta)) = KL(\\tilde p(x_c)\\mid \\mid p(x_c\\theta)) + \\Sigma_{x_a}\\tilde p(x_c)KL(\\tilde p(x_{-c})\\mid\\mid p(x_{-c}\\mid x_c)) $$\n从上面的式子可以看出，改变团势$\\psi$并不会改变条件分布，所以对上式中第二项不会产生影响。\n为了最小化第一项，和IPF的方法一样，我们将边际分布逼近观测分布。\n可以将IPF解释为：保存原有的条件分布$p^{(t)}(x_{-c}\\mid x_c)$，用观测数据分布取代原有的边际分布。\n\n### Feature-based Clique Potentials\n当团势不能用表格表达时，或者更加一般的来说，获得团势是指数级的推测难度，必须要从有限的数据中学习指数个参数。我们可以将团变小，但是这样需要更多的独立性假设，并且改变了图模型结构。另外一种方法是不改变模型结构，使用更加一般的团势的参数。这被叫做基于特征的方法。\n特征是对于一般的设定为空，对于少数特别的设定会有高低之分。每个特征函数都能变成小团势，然后将小团势乘起来就可以得到团势了。\n例如，一个团势$\\psi(x_1, x_2, x_3)$：\n$$ \\psi_c(x_a, x_2, x_3) = e^{\\theta_{ing}f_{ing}}\\times e^{\\theta_{?ed}f_{?ed}} \\times ... = exp\\lbrace \\Sigma_{k=1}^T \\theta_k f_k(c_1, c_2, c_3)\\rbrace $$\n每个特征都有一个权重$\\theta_k$，它可以用增加或者减少团势的概率。\n团上的边际分布就是一个广义指数族：\n$$ p(c_1, c_2, c_3) \\propto exp(\\theta_{ing}f_{ing}(x_1, x_2, x_3) + \\theta_{?ed}f_{?ed}(x_1, x_2, x_3) + ...) $$\n一般来说，特征可能是重叠的，没有限制的显示因子或者任意团变量的子集：\n$$ \\psi_c(x_c) = exp\\lbrace \\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$\n我们可以将团势向前面一样乘起来：\n$$ p(x) = \\frac{1}{Z(\\theta)}\\psi_c (x_c) = \\frac{1}{Z(\\theta)}exp\\lbrace \\Sigma_c\\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$\n可以简化为：\n$$ p(x) = \\frac{1}{Z(\\theta)}exp(\\Sigma_i \\theta_i f_i(x_{c_i})) $$\n这就是指数族模型，特征值就是充分统计量。\n\n## Gerneralized Iterative Scaling - GIS\n基于之前的概率函数，我们想通过一个算法求最大概率，然后有了GIS。\n我们首先不是考虑直接优化目标，而是处理目标函数的下界。\n\\begin{equation}\\begin{split} \\tilde l(\\theta;D) &= l(\\theta;D)/N \\\\\\\\\n&= \\frac{1}{N}\\Sigma_n log\\ p(x_n\\mid \\theta) \\\\\\\\\n&= \\Sigma_x \\tilde p(x)log\\ p(x\\mid \\theta) \\\\\\\\\n&= \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - log\\ Z(\\theta) \\\\\\\\\n&\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\\\\\\n\\end{split}\\end{equation}\n\n因为对数函数有一个线性上界：$log\\ Z(\\theta)\\leqslant \\mu Z(\\theta) - log\\ \\mu - 1$\n定义：$\\Delta\\theta_i^{(t)} = \\theta_i-\\theta_i^{(t)} $\n\\begin{equation}\\begin{split}\\tilde l(\\theta;D) &\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\\\\\\n&= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\frac{1}{Z(\\theta^{(t)})}\\Sigma_x exp(\\Sigma_i \\theta_i^{(t)} f_i(x))exp(\\Sigma_i \\Delta\\theta_i^{(t)}f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\\\\\\n&= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})exp(\\Sigma_i \\Delta\\theta_i^{(t)} f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\\\\\\n\\end{split}\\end{equation}\n\n假定$f_i(x) \\geqslant,\\Sigma_i f_i(x) = 1$，使用杰西不等式，$exp(\\Sigma_i \\pi_i x_i)\\leqslant \\Sigma_i \\pi_i exp(x_i)$有：\n$$ \\tilde l(\\theta;D) \\geqslant \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})\\Sigma_i f_i(x)exp(\\Delta\\theta_i^{(t)}) - log\\ Z(\\theta^{(t)}) + 1 $$\n令上面式子的右边等于$\\Delta(\\theta)$。\n求偏导令其为零：\n$$ \\frac{\\partial \\Lambda}{\\partial \\theta_i} = \\Sigma_x \\tilde p(x)f_i(x) - exp(\\Delta\\theta_i^{(t)})\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x) = 0$$\n$$ e^{\\Delta\\theta_i^{(t)}} = \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x)}= \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}) $$\n更新准则：\n$$ \\theta_i^{(t+1)} = \\theta_i^{(t)} + \\Delta\\theta_i^{(t)} \\Rightarrow p^{(t+1)}(x)=p^{(t)}(x)\\prod_i e^{\\Delta\\theta_i^{(t)}} $$\n\\begin{equation}\\begin{split} p^{(t+1)}(x) &= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}))^{f_i(x)} \\\\\\\\\n&= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)}(Z(\\theta^{(t)}))^{\\Sigma_i f_i(x)} \\\\\\\\\n&= p^{(t)}(x)\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)} \\\\\\\\\n\\end{split}\\end{equation}\n\n# 总结\n## IPF\nIPF是无向图模型求最大似然的一般方法。\n* 对$\\psi_c$在每个团上一个固定的等式，坐标上升。\n* 在最大团边际空间上进行I-projection\n* 需要势函数完全的参数化\n* 必须要以最大团描述\n* 对于完全可分的模型，变成一次算法\n\n## GIS\n* 要以基于特征的势函数描述\n* GIS是IPF的特殊形式，GIS的团势是建立在特征值配置上的。\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n注：本文主要参考[1]中第8讲视频以及笔记。\n","source":"_posts/可观无向图模型中的学习问题.md","raw":"---\ntitle: 可观无向图模型中的学习问题\ndate: 2018-05-17 10:58:53\ntags:\n- 概率图模型\n- 无向图学习\ncategories: 学习\n---\n# 最大似然结构学习\n\n## 连续型马尔科夫随机场\n给定高斯图模型，我们可以用一个伊辛模型来呈现。\n$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$\n下面令$\\mu=0$和$Q=\\Sigma_{-1}$，高斯模型可以写成：\n$$p(x\\mid \\mu,Q)=\\frac{|Q|^{1/2}} {(2\\pi)^{k/2}}exp \\lbrace  -\\frac{1}{2}()\\Sigma_i q_{ii} (x_i)^2 - \\Sigma_{i<j} q_{ij} x_i x_j) \\rbrace$$\n我们将上式指数中的第一部分看做是定义在节点上的势函数，第二部分是定义在比边上的势函数，也就是说等同于一个伊辛模型。\n$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$\n\n## 稀疏图模型\n协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精确矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。\n如果出现$p \\gg n$时，得不到最大似然估计，这是我们使用近邻选择得方法，增加惩罚函数来学习稀疏的图模型。\n近邻选择可以看做是伊辛模型。\n$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$\n\n# 最大似然估计\n\n## 似然条件\n有向图中，对数似然可以分解为一组和的形式，每个对应于一个子节点对应其父节点。无向图中，对数似然并不能分解，因为Z是包含了所有的参数的函数。\n$$ p(x) = \\frac{1}{Z} \\prod_{c\\in C} \\psi_c{x_c}, Z = \\Sigma_x \\prod_{c\\in C} \\psi_c(x_c) $$\n我们需要通过推测来学习参数。我们获得了输入数据的充分统计量，计数。\n$$total\\ count:m(x) = \\Sigma_n \\delta(x, x_n)$$  $$cliqu\\ count:m(x_c) = \\Sigma_{x_{V\\setminus c}} m(x)$$\n似然函数为：\n$$p(D\\mid \\theta) = \\prod_n \\prod_x p(x\\mid \\theta)^{\\delta(x,x_n)}$$\n\n\\begin{equation}\\begin{split} log\\ p(D\\mid \\theta)&=\\Sigma_n \\Sigma_x \\delta(x,x_n)log\\ p(x\\mid \\theta\\\\\\\\\nl & = \\Sigma_x m(x)log(\\frac{1}{Z}\\prod_c \\pi_c(x_c))\\\\\\\\\n& = \\Sigma_c \\Sigma_{x_c}m(x_c)log\\ \\psi_c(x_c) - N log\\ Z \\\\\\\\\n\\end{split}\\end{equation}\n上式的两个部分对$\\psi_c(x_c)$求导：\n第一项：\n$$ \\frac{\\partial l_1}{\\partial \\psi_c(x_c)} = m(x_c)/\\psi_c(x_c) $$\n第二项：\n\\begin{equation}\\begin{split} \\frac{\\partial log\\ Z}{\\partial \\psi_c(x_c)} & = \\frac{1}{Z} \\frac{\\partial}{\\partial\\psi_c(x_c)}(\\Sigma_{\\tilde{x} } \\prod_{d} \\psi_d(\\tilde x_d))\\\\\\\\\n& = \\frac{1}{Z} \\Sigma_{\\tilde{x}}\\delta(\\tilde x_c, x_c)\\frac{\\partial}{\\partial \\psi_c(x_c)}(\\prod_{d} \\psi_d(\\tilde x_d) \\\\\\\\\n& =  \\Sigma_{\\tilde x}\\delta(\\tilde x_c, x_c) \\frac{1}{\\psi_c(\\tilde x_c)} \\frac{1}{Z} \\prod_d \\psi_d(\\tilde x_d)\\\\\\\\\n& = \\frac{1}{\\psi_c (x_c)}\\Sigma_{\\tilde x} \\delta(\\tilde x_c, x_c) p(\\tilde x)  \\\\\\\\\n& = \\frac{x_c}{\\psi_c (x_c)}\n\\end{split}\\end{equation}\n\n令导数为零，有：$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$，从结果可以看出，模型的边缘概率密度等于观测的边缘概率密度。\n$$ p_{MLE}^{\\star} (x_c) = \\frac{m(x_c)}{N} = \\tilde p(x_c) $$\n但是结果并没有给出似然参数的估计方法，只是给出了必须满足的条件。\n\n## 可分解模型\n对于可分解的模型，势函数可以定义于最大团上，团势函数的最大似然等价于经验边际。因此最大似然可以通过检查得到。基于势函数的表示似然$p(x)=\\frac{\\prod_c \\psi_c(x_c)}{\\prod_s \\psi_s(x_s)}$，其中c是最大团，s是最大团分离的因子。为了计算团势，将他们等同于经验边际。分离因子必须分解为几个邻居，那么$Z=1$。\n\n### 例一\n考虑链$X_1-X_2-X_3$，有团$(x_1, x_2),(x_2, x_3)$，分离因子$x_2$。\n$$ \\tilde p_{MLE}(x_1, x_2, x_3) = \\frac{\\tilde p(x_1, x_2)\\tilde p(x_2, x_3)}{\\tilde p(x_2)} $$\n$$ \\tilde{\\psi}_{12}^{MLE}(x_1, x_2) = \\tilde p(x_1, x_2) $$\n$$ \\tilde{\\psi}_{23}^{MLE}(x_2, x_3) = \\frac{\\tilde p(x_2, x_3)}{\\tilde p(x_2)}= \\tilde p(x_2\\mid x_3) $$\n\n### 例二\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png)\n团$(x_1, x_2, x_3),(x_2, x_3, x_4)$，分离因子$x_2,x_3$\n$$ \\tilde p_{MLE}(x_1, x_2, x_3, x_4) = \\frac{\\tilde p(x_1, x_2, x_3)\\tilde p(x_2, x_3, x_4)}{\\tilde p(x_2, x_3)} $$\n$$ \\tilde{\\psi}_{123}^{MLE}(x_1, x_2,x_3) = \\frac{\\tilde p(x_1, x_2, x_3)}{\\tilde p(x_2, x_33)}= \\tilde p(x_1\\mid x_2, x_3) $$\n$$ \\tilde{\\psi}_{234}^{MLE}(x_2, x_3, x_4) =  \\tilde p(x_2, x_3, x_4) $$\n\n## 不可分离模型-IPF和GIS\n如果一个图是不可分离的，也就是说势函数不能以最大团定义，我们不能将经验边际等价于势函数的似然。\n\n### Tabular Cique Potentials-IPF\n如果团势函数是表格形式或者可以使用简介的参数模型表示，那么我们可以使用IPF来求最大似然估计。\n从上面的似然函数导数：\n$$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$$\n我们可以得到：\n$$ \\frac{\\tilde p(x_c)}{\\psi_c(x_c)} = \\frac{p(x_c)}{\\psi_c(x_c)} $$\n因为$\\psi_c$隐性的出现了模型边际$p(x_c)$中，所以在点$\\psi_c$上存在等式关系，所以直接解出$\\psi_c$是非常困难的，因为其出现在了等式两边。\n我们将$\\psi_c$在右边固定，然后在左边解出，循环所有的团，进行下面的迭代：\n$$ \\psi_c^{(t+1)}(x_c) = \\psi_c^{(t)}(x_c)\\frac{\\tilde p(x_c)}{p^{(t)}(x_c)} $$\n上面的算法可以看做是坐标上升算法，其中的坐标就是势团的参数。因此在每一步中，似然函数的值会增加，这样就可以收敛到全局极大值。这个算法童谣可以被看做是最小化观测数据的分布与模型分布的KL散度(交叉熵),只有当模型是可分解的。\n$$ max\\ l \\Leftrightarrow KL(\\tilde p(x)\\mid \\mid p(x\\mid\\theta))=\\Sigma_x \\tilde p(x)log\\frac{\\tilde p(x)}{p(x\\mid \\theta)} $$\n\n\\begin{equation}\\begin{split} KL(q(x_a, x_b)\\mid \\mid p(x_a, x_b)) &= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)q(x_b\\mid x_a)}{p(x_a)p(x_b\\mid x_a)}\\\\\\\\\n&= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)}{p(x_a)} + \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_b\\mid x_a)}{p(x_b\\mid x_a)}\\\\\\\\\n&= KL(1(x_aq)\\mid\\mid p(x_a)) + \\Sigma_x q(x_a)KL(q(x_b\\mid x_a)\\mid\\mid p(x_b\\mid x_a))\\\\\\\\\n\\end{split}\\end{equation}\n将上面两个式子合并：\n$$ KL(\\tilde p(x)\\mid\\mid p(x\\theta)) = KL(\\tilde p(x_c)\\mid \\mid p(x_c\\theta)) + \\Sigma_{x_a}\\tilde p(x_c)KL(\\tilde p(x_{-c})\\mid\\mid p(x_{-c}\\mid x_c)) $$\n从上面的式子可以看出，改变团势$\\psi$并不会改变条件分布，所以对上式中第二项不会产生影响。\n为了最小化第一项，和IPF的方法一样，我们将边际分布逼近观测分布。\n可以将IPF解释为：保存原有的条件分布$p^{(t)}(x_{-c}\\mid x_c)$，用观测数据分布取代原有的边际分布。\n\n### Feature-based Clique Potentials\n当团势不能用表格表达时，或者更加一般的来说，获得团势是指数级的推测难度，必须要从有限的数据中学习指数个参数。我们可以将团变小，但是这样需要更多的独立性假设，并且改变了图模型结构。另外一种方法是不改变模型结构，使用更加一般的团势的参数。这被叫做基于特征的方法。\n特征是对于一般的设定为空，对于少数特别的设定会有高低之分。每个特征函数都能变成小团势，然后将小团势乘起来就可以得到团势了。\n例如，一个团势$\\psi(x_1, x_2, x_3)$：\n$$ \\psi_c(x_a, x_2, x_3) = e^{\\theta_{ing}f_{ing}}\\times e^{\\theta_{?ed}f_{?ed}} \\times ... = exp\\lbrace \\Sigma_{k=1}^T \\theta_k f_k(c_1, c_2, c_3)\\rbrace $$\n每个特征都有一个权重$\\theta_k$，它可以用增加或者减少团势的概率。\n团上的边际分布就是一个广义指数族：\n$$ p(c_1, c_2, c_3) \\propto exp(\\theta_{ing}f_{ing}(x_1, x_2, x_3) + \\theta_{?ed}f_{?ed}(x_1, x_2, x_3) + ...) $$\n一般来说，特征可能是重叠的，没有限制的显示因子或者任意团变量的子集：\n$$ \\psi_c(x_c) = exp\\lbrace \\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$\n我们可以将团势向前面一样乘起来：\n$$ p(x) = \\frac{1}{Z(\\theta)}\\psi_c (x_c) = \\frac{1}{Z(\\theta)}exp\\lbrace \\Sigma_c\\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$\n可以简化为：\n$$ p(x) = \\frac{1}{Z(\\theta)}exp(\\Sigma_i \\theta_i f_i(x_{c_i})) $$\n这就是指数族模型，特征值就是充分统计量。\n\n## Gerneralized Iterative Scaling - GIS\n基于之前的概率函数，我们想通过一个算法求最大概率，然后有了GIS。\n我们首先不是考虑直接优化目标，而是处理目标函数的下界。\n\\begin{equation}\\begin{split} \\tilde l(\\theta;D) &= l(\\theta;D)/N \\\\\\\\\n&= \\frac{1}{N}\\Sigma_n log\\ p(x_n\\mid \\theta) \\\\\\\\\n&= \\Sigma_x \\tilde p(x)log\\ p(x\\mid \\theta) \\\\\\\\\n&= \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - log\\ Z(\\theta) \\\\\\\\\n&\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\\\\\\n\\end{split}\\end{equation}\n\n因为对数函数有一个线性上界：$log\\ Z(\\theta)\\leqslant \\mu Z(\\theta) - log\\ \\mu - 1$\n定义：$\\Delta\\theta_i^{(t)} = \\theta_i-\\theta_i^{(t)} $\n\\begin{equation}\\begin{split}\\tilde l(\\theta;D) &\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\\\\\\n&= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\frac{1}{Z(\\theta^{(t)})}\\Sigma_x exp(\\Sigma_i \\theta_i^{(t)} f_i(x))exp(\\Sigma_i \\Delta\\theta_i^{(t)}f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\\\\\\n&= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})exp(\\Sigma_i \\Delta\\theta_i^{(t)} f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\\\\\\n\\end{split}\\end{equation}\n\n假定$f_i(x) \\geqslant,\\Sigma_i f_i(x) = 1$，使用杰西不等式，$exp(\\Sigma_i \\pi_i x_i)\\leqslant \\Sigma_i \\pi_i exp(x_i)$有：\n$$ \\tilde l(\\theta;D) \\geqslant \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})\\Sigma_i f_i(x)exp(\\Delta\\theta_i^{(t)}) - log\\ Z(\\theta^{(t)}) + 1 $$\n令上面式子的右边等于$\\Delta(\\theta)$。\n求偏导令其为零：\n$$ \\frac{\\partial \\Lambda}{\\partial \\theta_i} = \\Sigma_x \\tilde p(x)f_i(x) - exp(\\Delta\\theta_i^{(t)})\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x) = 0$$\n$$ e^{\\Delta\\theta_i^{(t)}} = \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x)}= \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}) $$\n更新准则：\n$$ \\theta_i^{(t+1)} = \\theta_i^{(t)} + \\Delta\\theta_i^{(t)} \\Rightarrow p^{(t+1)}(x)=p^{(t)}(x)\\prod_i e^{\\Delta\\theta_i^{(t)}} $$\n\\begin{equation}\\begin{split} p^{(t+1)}(x) &= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}))^{f_i(x)} \\\\\\\\\n&= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)}(Z(\\theta^{(t)}))^{\\Sigma_i f_i(x)} \\\\\\\\\n&= p^{(t)}(x)\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)} \\\\\\\\\n\\end{split}\\end{equation}\n\n# 总结\n## IPF\nIPF是无向图模型求最大似然的一般方法。\n* 对$\\psi_c$在每个团上一个固定的等式，坐标上升。\n* 在最大团边际空间上进行I-projection\n* 需要势函数完全的参数化\n* 必须要以最大团描述\n* 对于完全可分的模型，变成一次算法\n\n## GIS\n* 要以基于特征的势函数描述\n* GIS是IPF的特殊形式，GIS的团势是建立在特征值配置上的。\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n注：本文主要参考[1]中第8讲视频以及笔记。\n","slug":"可观无向图模型中的学习问题","published":1,"updated":"2018-09-22T06:33:36.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msx00101ouz0tjg13k4","content":"<h1 id=\"最大似然结构学习\"><a href=\"#最大似然结构学习\" class=\"headerlink\" title=\"最大似然结构学习\"></a>最大似然结构学习</h1><h2 id=\"连续型马尔科夫随机场\"><a href=\"#连续型马尔科夫随机场\" class=\"headerlink\" title=\"连续型马尔科夫随机场\"></a>连续型马尔科夫随机场</h2><p>给定高斯图模型，我们可以用一个伊辛模型来呈现。<br>$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$<br>下面令$\\mu=0$和$Q=\\Sigma_{-1}$，高斯模型可以写成：<br>$$p(x\\mid \\mu,Q)=\\frac{|Q|^{1/2}} {(2\\pi)^{k/2}}exp \\lbrace  -\\frac{1}{2}()\\Sigma_i q_{ii} (x_i)^2 - \\Sigma_{i&lt;j} q_{ij} x_i x_j) \\rbrace$$<br>我们将上式指数中的第一部分看做是定义在节点上的势函数，第二部分是定义在比边上的势函数，也就是说等同于一个伊辛模型。<br>$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$</p>\n<h2 id=\"稀疏图模型\"><a href=\"#稀疏图模型\" class=\"headerlink\" title=\"稀疏图模型\"></a>稀疏图模型</h2><p>协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精确矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。<br>如果出现$p \\gg n$时，得不到最大似然估计，这是我们使用近邻选择得方法，增加惩罚函数来学习稀疏的图模型。<br>近邻选择可以看做是伊辛模型。<br>$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$</p>\n<h1 id=\"最大似然估计\"><a href=\"#最大似然估计\" class=\"headerlink\" title=\"最大似然估计\"></a>最大似然估计</h1><h2 id=\"似然条件\"><a href=\"#似然条件\" class=\"headerlink\" title=\"似然条件\"></a>似然条件</h2><p>有向图中，对数似然可以分解为一组和的形式，每个对应于一个子节点对应其父节点。无向图中，对数似然并不能分解，因为Z是包含了所有的参数的函数。<br>$$ p(x) = \\frac{1}{Z} \\prod_{c\\in C} \\psi_c{x_c}, Z = \\Sigma_x \\prod_{c\\in C} \\psi_c(x_c) $$<br>我们需要通过推测来学习参数。我们获得了输入数据的充分统计量，计数。<br>$$total\\ count:m(x) = \\Sigma_n \\delta(x, x_n)$$  $$cliqu\\ count:m(x_c) = \\Sigma_{x_{V\\setminus c}} m(x)$$<br>似然函数为：<br>$$p(D\\mid \\theta) = \\prod_n \\prod_x p(x\\mid \\theta)^{\\delta(x,x_n)}$$</p>\n<p>\\begin{equation}\\begin{split} log\\ p(D\\mid \\theta)&amp;=\\Sigma_n \\Sigma_x \\delta(x,x_n)log\\ p(x\\mid \\theta\\\\<br>l &amp; = \\Sigma_x m(x)log(\\frac{1}{Z}\\prod_c \\pi_c(x_c))\\\\<br>&amp; = \\Sigma_c \\Sigma_{x_c}m(x_c)log\\ \\psi_c(x_c) - N log\\ Z \\\\<br>\\end{split}\\end{equation}<br>上式的两个部分对$\\psi_c(x_c)$求导：<br>第一项：<br>$$ \\frac{\\partial l_1}{\\partial \\psi_c(x_c)} = m(x_c)/\\psi_c(x_c) $$<br>第二项：<br>\\begin{equation}\\begin{split} \\frac{\\partial log\\ Z}{\\partial \\psi_c(x_c)} &amp; = \\frac{1}{Z} \\frac{\\partial}{\\partial\\psi_c(x_c)}(\\Sigma_{\\tilde{x} } \\prod_{d} \\psi_d(\\tilde x_d))\\\\<br>&amp; = \\frac{1}{Z} \\Sigma_{\\tilde{x}}\\delta(\\tilde x_c, x_c)\\frac{\\partial}{\\partial \\psi_c(x_c)}(\\prod_{d} \\psi_d(\\tilde x_d) \\\\<br>&amp; =  \\Sigma_{\\tilde x}\\delta(\\tilde x_c, x_c) \\frac{1}{\\psi_c(\\tilde x_c)} \\frac{1}{Z} \\prod_d \\psi_d(\\tilde x_d)\\\\<br>&amp; = \\frac{1}{\\psi_c (x_c)}\\Sigma_{\\tilde x} \\delta(\\tilde x_c, x_c) p(\\tilde x)  \\\\<br>&amp; = \\frac{x_c}{\\psi_c (x_c)}<br>\\end{split}\\end{equation}</p>\n<p>令导数为零，有：$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$，从结果可以看出，模型的边缘概率密度等于观测的边缘概率密度。<br>$$ p_{MLE}^{\\star} (x_c) = \\frac{m(x_c)}{N} = \\tilde p(x_c) $$<br>但是结果并没有给出似然参数的估计方法，只是给出了必须满足的条件。</p>\n<h2 id=\"可分解模型\"><a href=\"#可分解模型\" class=\"headerlink\" title=\"可分解模型\"></a>可分解模型</h2><p>对于可分解的模型，势函数可以定义于最大团上，团势函数的最大似然等价于经验边际。因此最大似然可以通过检查得到。基于势函数的表示似然$p(x)=\\frac{\\prod_c \\psi_c(x_c)}{\\prod_s \\psi_s(x_s)}$，其中c是最大团，s是最大团分离的因子。为了计算团势，将他们等同于经验边际。分离因子必须分解为几个邻居，那么$Z=1$。</p>\n<h3 id=\"例一\"><a href=\"#例一\" class=\"headerlink\" title=\"例一\"></a>例一</h3><p>考虑链$X_1-X_2-X_3$，有团$(x_1, x_2),(x_2, x_3)$，分离因子$x_2$。<br>$$ \\tilde p_{MLE}(x_1, x_2, x_3) = \\frac{\\tilde p(x_1, x_2)\\tilde p(x_2, x_3)}{\\tilde p(x_2)} $$<br>$$ \\tilde{\\psi}_{12}^{MLE}(x_1, x_2) = \\tilde p(x_1, x_2) $$<br>$$ \\tilde{\\psi}_{23}^{MLE}(x_2, x_3) = \\frac{\\tilde p(x_2, x_3)}{\\tilde p(x_2)}= \\tilde p(x_2\\mid x_3) $$</p>\n<h3 id=\"例二\"><a href=\"#例二\" class=\"headerlink\" title=\"例二\"></a>例二</h3><p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png\" alt><br>团$(x_1, x_2, x_3),(x_2, x_3, x_4)$，分离因子$x_2,x_3$<br>$$ \\tilde p_{MLE}(x_1, x_2, x_3, x_4) = \\frac{\\tilde p(x_1, x_2, x_3)\\tilde p(x_2, x_3, x_4)}{\\tilde p(x_2, x_3)} $$<br>$$ \\tilde{\\psi}_{123}^{MLE}(x_1, x_2,x_3) = \\frac{\\tilde p(x_1, x_2, x_3)}{\\tilde p(x_2, x_33)}= \\tilde p(x_1\\mid x_2, x_3) $$<br>$$ \\tilde{\\psi}_{234}^{MLE}(x_2, x_3, x_4) =  \\tilde p(x_2, x_3, x_4) $$</p>\n<h2 id=\"不可分离模型-IPF和GIS\"><a href=\"#不可分离模型-IPF和GIS\" class=\"headerlink\" title=\"不可分离模型-IPF和GIS\"></a>不可分离模型-IPF和GIS</h2><p>如果一个图是不可分离的，也就是说势函数不能以最大团定义，我们不能将经验边际等价于势函数的似然。</p>\n<h3 id=\"Tabular-Cique-Potentials-IPF\"><a href=\"#Tabular-Cique-Potentials-IPF\" class=\"headerlink\" title=\"Tabular Cique Potentials-IPF\"></a>Tabular Cique Potentials-IPF</h3><p>如果团势函数是表格形式或者可以使用简介的参数模型表示，那么我们可以使用IPF来求最大似然估计。<br>从上面的似然函数导数：<br>$$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$$<br>我们可以得到：<br>$$ \\frac{\\tilde p(x_c)}{\\psi_c(x_c)} = \\frac{p(x_c)}{\\psi_c(x_c)} $$<br>因为$\\psi_c$隐性的出现了模型边际$p(x_c)$中，所以在点$\\psi_c$上存在等式关系，所以直接解出$\\psi_c$是非常困难的，因为其出现在了等式两边。<br>我们将$\\psi_c$在右边固定，然后在左边解出，循环所有的团，进行下面的迭代：<br>$$ \\psi_c^{(t+1)}(x_c) = \\psi_c^{(t)}(x_c)\\frac{\\tilde p(x_c)}{p^{(t)}(x_c)} $$<br>上面的算法可以看做是坐标上升算法，其中的坐标就是势团的参数。因此在每一步中，似然函数的值会增加，这样就可以收敛到全局极大值。这个算法童谣可以被看做是最小化观测数据的分布与模型分布的KL散度(交叉熵),只有当模型是可分解的。<br>$$ max\\ l \\Leftrightarrow KL(\\tilde p(x)\\mid \\mid p(x\\mid\\theta))=\\Sigma_x \\tilde p(x)log\\frac{\\tilde p(x)}{p(x\\mid \\theta)} $$</p>\n<p>\\begin{equation}\\begin{split} KL(q(x_a, x_b)\\mid \\mid p(x_a, x_b)) &amp;= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)q(x_b\\mid x_a)}{p(x_a)p(x_b\\mid x_a)}\\\\<br>&amp;= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)}{p(x_a)} + \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_b\\mid x_a)}{p(x_b\\mid x_a)}\\\\<br>&amp;= KL(1(x_aq)\\mid\\mid p(x_a)) + \\Sigma_x q(x_a)KL(q(x_b\\mid x_a)\\mid\\mid p(x_b\\mid x_a))\\\\<br>\\end{split}\\end{equation}<br>将上面两个式子合并：<br>$$ KL(\\tilde p(x)\\mid\\mid p(x\\theta)) = KL(\\tilde p(x_c)\\mid \\mid p(x_c\\theta)) + \\Sigma_{x_a}\\tilde p(x_c)KL(\\tilde p(x_{-c})\\mid\\mid p(x_{-c}\\mid x_c)) $$<br>从上面的式子可以看出，改变团势$\\psi$并不会改变条件分布，所以对上式中第二项不会产生影响。<br>为了最小化第一项，和IPF的方法一样，我们将边际分布逼近观测分布。<br>可以将IPF解释为：保存原有的条件分布$p^{(t)}(x_{-c}\\mid x_c)$，用观测数据分布取代原有的边际分布。</p>\n<h3 id=\"Feature-based-Clique-Potentials\"><a href=\"#Feature-based-Clique-Potentials\" class=\"headerlink\" title=\"Feature-based Clique Potentials\"></a>Feature-based Clique Potentials</h3><p>当团势不能用表格表达时，或者更加一般的来说，获得团势是指数级的推测难度，必须要从有限的数据中学习指数个参数。我们可以将团变小，但是这样需要更多的独立性假设，并且改变了图模型结构。另外一种方法是不改变模型结构，使用更加一般的团势的参数。这被叫做基于特征的方法。<br>特征是对于一般的设定为空，对于少数特别的设定会有高低之分。每个特征函数都能变成小团势，然后将小团势乘起来就可以得到团势了。<br>例如，一个团势$\\psi(x_1, x_2, x_3)$：<br>$$ \\psi_c(x_a, x_2, x_3) = e^{\\theta_{ing}f_{ing}}\\times e^{\\theta_{?ed}f_{?ed}} \\times … = exp\\lbrace \\Sigma_{k=1}^T \\theta_k f_k(c_1, c_2, c_3)\\rbrace $$<br>每个特征都有一个权重$\\theta_k$，它可以用增加或者减少团势的概率。<br>团上的边际分布就是一个广义指数族：<br>$$ p(c_1, c_2, c_3) \\propto exp(\\theta_{ing}f_{ing}(x_1, x_2, x_3) + \\theta_{?ed}f_{?ed}(x_1, x_2, x_3) + …) $$<br>一般来说，特征可能是重叠的，没有限制的显示因子或者任意团变量的子集：<br>$$ \\psi_c(x_c) = exp\\lbrace \\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$<br>我们可以将团势向前面一样乘起来：<br>$$ p(x) = \\frac{1}{Z(\\theta)}\\psi_c (x_c) = \\frac{1}{Z(\\theta)}exp\\lbrace \\Sigma_c\\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$<br>可以简化为：<br>$$ p(x) = \\frac{1}{Z(\\theta)}exp(\\Sigma_i \\theta_i f_i(x_{c_i})) $$<br>这就是指数族模型，特征值就是充分统计量。</p>\n<h2 id=\"Gerneralized-Iterative-Scaling-GIS\"><a href=\"#Gerneralized-Iterative-Scaling-GIS\" class=\"headerlink\" title=\"Gerneralized Iterative Scaling - GIS\"></a>Gerneralized Iterative Scaling - GIS</h2><p>基于之前的概率函数，我们想通过一个算法求最大概率，然后有了GIS。<br>我们首先不是考虑直接优化目标，而是处理目标函数的下界。<br>\\begin{equation}\\begin{split} \\tilde l(\\theta;D) &amp;= l(\\theta;D)/N \\\\<br>&amp;= \\frac{1}{N}\\Sigma_n log\\ p(x_n\\mid \\theta) \\\\<br>&amp;= \\Sigma_x \\tilde p(x)log\\ p(x\\mid \\theta) \\\\<br>&amp;= \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - log\\ Z(\\theta) \\\\<br>&amp;\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\<br>\\end{split}\\end{equation}</p>\n<p>因为对数函数有一个线性上界：$log\\ Z(\\theta)\\leqslant \\mu Z(\\theta) - log\\ \\mu - 1$<br>定义：$\\Delta\\theta_i^{(t)} = \\theta_i-\\theta_i^{(t)} $<br>\\begin{equation}\\begin{split}\\tilde l(\\theta;D) &amp;\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\<br>&amp;= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\frac{1}{Z(\\theta^{(t)})}\\Sigma_x exp(\\Sigma_i \\theta_i^{(t)} f_i(x))exp(\\Sigma_i \\Delta\\theta_i^{(t)}f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\<br>&amp;= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})exp(\\Sigma_i \\Delta\\theta_i^{(t)} f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\<br>\\end{split}\\end{equation}</p>\n<p>假定$f_i(x) \\geqslant,\\Sigma_i f_i(x) = 1$，使用杰西不等式，$exp(\\Sigma_i \\pi_i x_i)\\leqslant \\Sigma_i \\pi_i exp(x_i)$有：<br>$$ \\tilde l(\\theta;D) \\geqslant \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})\\Sigma_i f_i(x)exp(\\Delta\\theta_i^{(t)}) - log\\ Z(\\theta^{(t)}) + 1 $$<br>令上面式子的右边等于$\\Delta(\\theta)$。<br>求偏导令其为零：<br>$$ \\frac{\\partial \\Lambda}{\\partial \\theta_i} = \\Sigma_x \\tilde p(x)f_i(x) - exp(\\Delta\\theta_i^{(t)})\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x) = 0$$<br>$$ e^{\\Delta\\theta_i^{(t)}} = \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x)}= \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}) $$<br>更新准则：<br>$$ \\theta_i^{(t+1)} = \\theta_i^{(t)} + \\Delta\\theta_i^{(t)} \\Rightarrow p^{(t+1)}(x)=p^{(t)}(x)\\prod_i e^{\\Delta\\theta_i^{(t)}} $$<br>\\begin{equation}\\begin{split} p^{(t+1)}(x) &amp;= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}))^{f_i(x)} \\\\<br>&amp;= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)}(Z(\\theta^{(t)}))^{\\Sigma_i f_i(x)} \\\\<br>&amp;= p^{(t)}(x)\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)} \\\\<br>\\end{split}\\end{equation}</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><h2 id=\"IPF\"><a href=\"#IPF\" class=\"headerlink\" title=\"IPF\"></a>IPF</h2><p>IPF是无向图模型求最大似然的一般方法。</p>\n<ul>\n<li>对$\\psi_c$在每个团上一个固定的等式，坐标上升。</li>\n<li>在最大团边际空间上进行I-projection</li>\n<li>需要势函数完全的参数化</li>\n<li>必须要以最大团描述</li>\n<li>对于完全可分的模型，变成一次算法</li>\n</ul>\n<h2 id=\"GIS\"><a href=\"#GIS\" class=\"headerlink\" title=\"GIS\"></a>GIS</h2><ul>\n<li>要以基于特征的势函数描述</li>\n<li>GIS是IPF的特殊形式，GIS的团势是建立在特征值配置上的。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第8讲视频以及笔记。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"最大似然结构学习\"><a href=\"#最大似然结构学习\" class=\"headerlink\" title=\"最大似然结构学习\"></a>最大似然结构学习</h1><h2 id=\"连续型马尔科夫随机场\"><a href=\"#连续型马尔科夫随机场\" class=\"headerlink\" title=\"连续型马尔科夫随机场\"></a>连续型马尔科夫随机场</h2><p>给定高斯图模型，我们可以用一个伊辛模型来呈现。<br>$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$<br>下面令$\\mu=0$和$Q=\\Sigma_{-1}$，高斯模型可以写成：<br>$$p(x\\mid \\mu,Q)=\\frac{|Q|^{1/2}} {(2\\pi)^{k/2}}exp \\lbrace  -\\frac{1}{2}()\\Sigma_i q_{ii} (x_i)^2 - \\Sigma_{i&lt;j} q_{ij} x_i x_j) \\rbrace$$<br>我们将上式指数中的第一部分看做是定义在节点上的势函数，第二部分是定义在比边上的势函数，也就是说等同于一个伊辛模型。<br>$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$</p>\n<h2 id=\"稀疏图模型\"><a href=\"#稀疏图模型\" class=\"headerlink\" title=\"稀疏图模型\"></a>稀疏图模型</h2><p>协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精确矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。<br>如果出现$p \\gg n$时，得不到最大似然估计，这是我们使用近邻选择得方法，增加惩罚函数来学习稀疏的图模型。<br>近邻选择可以看做是伊辛模型。<br>$$ P(x\\mid \\Theta) = exp\\ (\\Sigma_{i\\in V} \\theta_{ii}^t x_{d,j} + \\Sigma_{(i,j)\\in E} x_{d,i}x_{d,j} - A(\\Theta)) $$</p>\n<h1 id=\"最大似然估计\"><a href=\"#最大似然估计\" class=\"headerlink\" title=\"最大似然估计\"></a>最大似然估计</h1><h2 id=\"似然条件\"><a href=\"#似然条件\" class=\"headerlink\" title=\"似然条件\"></a>似然条件</h2><p>有向图中，对数似然可以分解为一组和的形式，每个对应于一个子节点对应其父节点。无向图中，对数似然并不能分解，因为Z是包含了所有的参数的函数。<br>$$ p(x) = \\frac{1}{Z} \\prod_{c\\in C} \\psi_c{x_c}, Z = \\Sigma_x \\prod_{c\\in C} \\psi_c(x_c) $$<br>我们需要通过推测来学习参数。我们获得了输入数据的充分统计量，计数。<br>$$total\\ count:m(x) = \\Sigma_n \\delta(x, x_n)$$  $$cliqu\\ count:m(x_c) = \\Sigma_{x_{V\\setminus c}} m(x)$$<br>似然函数为：<br>$$p(D\\mid \\theta) = \\prod_n \\prod_x p(x\\mid \\theta)^{\\delta(x,x_n)}$$</p>\n<p>\\begin{equation}\\begin{split} log\\ p(D\\mid \\theta)&amp;=\\Sigma_n \\Sigma_x \\delta(x,x_n)log\\ p(x\\mid \\theta\\\\<br>l &amp; = \\Sigma_x m(x)log(\\frac{1}{Z}\\prod_c \\pi_c(x_c))\\\\<br>&amp; = \\Sigma_c \\Sigma_{x_c}m(x_c)log\\ \\psi_c(x_c) - N log\\ Z \\\\<br>\\end{split}\\end{equation}<br>上式的两个部分对$\\psi_c(x_c)$求导：<br>第一项：<br>$$ \\frac{\\partial l_1}{\\partial \\psi_c(x_c)} = m(x_c)/\\psi_c(x_c) $$<br>第二项：<br>\\begin{equation}\\begin{split} \\frac{\\partial log\\ Z}{\\partial \\psi_c(x_c)} &amp; = \\frac{1}{Z} \\frac{\\partial}{\\partial\\psi_c(x_c)}(\\Sigma_{\\tilde{x} } \\prod_{d} \\psi_d(\\tilde x_d))\\\\<br>&amp; = \\frac{1}{Z} \\Sigma_{\\tilde{x}}\\delta(\\tilde x_c, x_c)\\frac{\\partial}{\\partial \\psi_c(x_c)}(\\prod_{d} \\psi_d(\\tilde x_d) \\\\<br>&amp; =  \\Sigma_{\\tilde x}\\delta(\\tilde x_c, x_c) \\frac{1}{\\psi_c(\\tilde x_c)} \\frac{1}{Z} \\prod_d \\psi_d(\\tilde x_d)\\\\<br>&amp; = \\frac{1}{\\psi_c (x_c)}\\Sigma_{\\tilde x} \\delta(\\tilde x_c, x_c) p(\\tilde x)  \\\\<br>&amp; = \\frac{x_c}{\\psi_c (x_c)}<br>\\end{split}\\end{equation}</p>\n<p>令导数为零，有：$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$，从结果可以看出，模型的边缘概率密度等于观测的边缘概率密度。<br>$$ p_{MLE}^{\\star} (x_c) = \\frac{m(x_c)}{N} = \\tilde p(x_c) $$<br>但是结果并没有给出似然参数的估计方法，只是给出了必须满足的条件。</p>\n<h2 id=\"可分解模型\"><a href=\"#可分解模型\" class=\"headerlink\" title=\"可分解模型\"></a>可分解模型</h2><p>对于可分解的模型，势函数可以定义于最大团上，团势函数的最大似然等价于经验边际。因此最大似然可以通过检查得到。基于势函数的表示似然$p(x)=\\frac{\\prod_c \\psi_c(x_c)}{\\prod_s \\psi_s(x_s)}$，其中c是最大团，s是最大团分离的因子。为了计算团势，将他们等同于经验边际。分离因子必须分解为几个邻居，那么$Z=1$。</p>\n<h3 id=\"例一\"><a href=\"#例一\" class=\"headerlink\" title=\"例一\"></a>例一</h3><p>考虑链$X_1-X_2-X_3$，有团$(x_1, x_2),(x_2, x_3)$，分离因子$x_2$。<br>$$ \\tilde p_{MLE}(x_1, x_2, x_3) = \\frac{\\tilde p(x_1, x_2)\\tilde p(x_2, x_3)}{\\tilde p(x_2)} $$<br>$$ \\tilde{\\psi}_{12}^{MLE}(x_1, x_2) = \\tilde p(x_1, x_2) $$<br>$$ \\tilde{\\psi}_{23}^{MLE}(x_2, x_3) = \\frac{\\tilde p(x_2, x_3)}{\\tilde p(x_2)}= \\tilde p(x_2\\mid x_3) $$</p>\n<h3 id=\"例二\"><a href=\"#例二\" class=\"headerlink\" title=\"例二\"></a>例二</h3><p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png\" alt><br>团$(x_1, x_2, x_3),(x_2, x_3, x_4)$，分离因子$x_2,x_3$<br>$$ \\tilde p_{MLE}(x_1, x_2, x_3, x_4) = \\frac{\\tilde p(x_1, x_2, x_3)\\tilde p(x_2, x_3, x_4)}{\\tilde p(x_2, x_3)} $$<br>$$ \\tilde{\\psi}_{123}^{MLE}(x_1, x_2,x_3) = \\frac{\\tilde p(x_1, x_2, x_3)}{\\tilde p(x_2, x_33)}= \\tilde p(x_1\\mid x_2, x_3) $$<br>$$ \\tilde{\\psi}_{234}^{MLE}(x_2, x_3, x_4) =  \\tilde p(x_2, x_3, x_4) $$</p>\n<h2 id=\"不可分离模型-IPF和GIS\"><a href=\"#不可分离模型-IPF和GIS\" class=\"headerlink\" title=\"不可分离模型-IPF和GIS\"></a>不可分离模型-IPF和GIS</h2><p>如果一个图是不可分离的，也就是说势函数不能以最大团定义，我们不能将经验边际等价于势函数的似然。</p>\n<h3 id=\"Tabular-Cique-Potentials-IPF\"><a href=\"#Tabular-Cique-Potentials-IPF\" class=\"headerlink\" title=\"Tabular Cique Potentials-IPF\"></a>Tabular Cique Potentials-IPF</h3><p>如果团势函数是表格形式或者可以使用简介的参数模型表示，那么我们可以使用IPF来求最大似然估计。<br>从上面的似然函数导数：<br>$$\\frac{\\partial l}{\\partial \\psi_c(x_c)} = \\frac{m(x_c)}{\\psi_c(x_c)} - N\\frac{p(x_c)}{\\psi_c(x_c)} = 0$$<br>我们可以得到：<br>$$ \\frac{\\tilde p(x_c)}{\\psi_c(x_c)} = \\frac{p(x_c)}{\\psi_c(x_c)} $$<br>因为$\\psi_c$隐性的出现了模型边际$p(x_c)$中，所以在点$\\psi_c$上存在等式关系，所以直接解出$\\psi_c$是非常困难的，因为其出现在了等式两边。<br>我们将$\\psi_c$在右边固定，然后在左边解出，循环所有的团，进行下面的迭代：<br>$$ \\psi_c^{(t+1)}(x_c) = \\psi_c^{(t)}(x_c)\\frac{\\tilde p(x_c)}{p^{(t)}(x_c)} $$<br>上面的算法可以看做是坐标上升算法，其中的坐标就是势团的参数。因此在每一步中，似然函数的值会增加，这样就可以收敛到全局极大值。这个算法童谣可以被看做是最小化观测数据的分布与模型分布的KL散度(交叉熵),只有当模型是可分解的。<br>$$ max\\ l \\Leftrightarrow KL(\\tilde p(x)\\mid \\mid p(x\\mid\\theta))=\\Sigma_x \\tilde p(x)log\\frac{\\tilde p(x)}{p(x\\mid \\theta)} $$</p>\n<p>\\begin{equation}\\begin{split} KL(q(x_a, x_b)\\mid \\mid p(x_a, x_b)) &amp;= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)q(x_b\\mid x_a)}{p(x_a)p(x_b\\mid x_a)}\\\\<br>&amp;= \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_a)}{p(x_a)} + \\Sigma_{x_a, x_b}q(x_a)q(x_b\\mid x_a)log\\frac{q(x_b\\mid x_a)}{p(x_b\\mid x_a)}\\\\<br>&amp;= KL(1(x_aq)\\mid\\mid p(x_a)) + \\Sigma_x q(x_a)KL(q(x_b\\mid x_a)\\mid\\mid p(x_b\\mid x_a))\\\\<br>\\end{split}\\end{equation}<br>将上面两个式子合并：<br>$$ KL(\\tilde p(x)\\mid\\mid p(x\\theta)) = KL(\\tilde p(x_c)\\mid \\mid p(x_c\\theta)) + \\Sigma_{x_a}\\tilde p(x_c)KL(\\tilde p(x_{-c})\\mid\\mid p(x_{-c}\\mid x_c)) $$<br>从上面的式子可以看出，改变团势$\\psi$并不会改变条件分布，所以对上式中第二项不会产生影响。<br>为了最小化第一项，和IPF的方法一样，我们将边际分布逼近观测分布。<br>可以将IPF解释为：保存原有的条件分布$p^{(t)}(x_{-c}\\mid x_c)$，用观测数据分布取代原有的边际分布。</p>\n<h3 id=\"Feature-based-Clique-Potentials\"><a href=\"#Feature-based-Clique-Potentials\" class=\"headerlink\" title=\"Feature-based Clique Potentials\"></a>Feature-based Clique Potentials</h3><p>当团势不能用表格表达时，或者更加一般的来说，获得团势是指数级的推测难度，必须要从有限的数据中学习指数个参数。我们可以将团变小，但是这样需要更多的独立性假设，并且改变了图模型结构。另外一种方法是不改变模型结构，使用更加一般的团势的参数。这被叫做基于特征的方法。<br>特征是对于一般的设定为空，对于少数特别的设定会有高低之分。每个特征函数都能变成小团势，然后将小团势乘起来就可以得到团势了。<br>例如，一个团势$\\psi(x_1, x_2, x_3)$：<br>$$ \\psi_c(x_a, x_2, x_3) = e^{\\theta_{ing}f_{ing}}\\times e^{\\theta_{?ed}f_{?ed}} \\times … = exp\\lbrace \\Sigma_{k=1}^T \\theta_k f_k(c_1, c_2, c_3)\\rbrace $$<br>每个特征都有一个权重$\\theta_k$，它可以用增加或者减少团势的概率。<br>团上的边际分布就是一个广义指数族：<br>$$ p(c_1, c_2, c_3) \\propto exp(\\theta_{ing}f_{ing}(x_1, x_2, x_3) + \\theta_{?ed}f_{?ed}(x_1, x_2, x_3) + …) $$<br>一般来说，特征可能是重叠的，没有限制的显示因子或者任意团变量的子集：<br>$$ \\psi_c(x_c) = exp\\lbrace \\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$<br>我们可以将团势向前面一样乘起来：<br>$$ p(x) = \\frac{1}{Z(\\theta)}\\psi_c (x_c) = \\frac{1}{Z(\\theta)}exp\\lbrace \\Sigma_c\\Sigma_{i\\in I_c} \\theta_k f_k(x_{c_i})\\rbrace $$<br>可以简化为：<br>$$ p(x) = \\frac{1}{Z(\\theta)}exp(\\Sigma_i \\theta_i f_i(x_{c_i})) $$<br>这就是指数族模型，特征值就是充分统计量。</p>\n<h2 id=\"Gerneralized-Iterative-Scaling-GIS\"><a href=\"#Gerneralized-Iterative-Scaling-GIS\" class=\"headerlink\" title=\"Gerneralized Iterative Scaling - GIS\"></a>Gerneralized Iterative Scaling - GIS</h2><p>基于之前的概率函数，我们想通过一个算法求最大概率，然后有了GIS。<br>我们首先不是考虑直接优化目标，而是处理目标函数的下界。<br>\\begin{equation}\\begin{split} \\tilde l(\\theta;D) &amp;= l(\\theta;D)/N \\\\<br>&amp;= \\frac{1}{N}\\Sigma_n log\\ p(x_n\\mid \\theta) \\\\<br>&amp;= \\Sigma_x \\tilde p(x)log\\ p(x\\mid \\theta) \\\\<br>&amp;= \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - log\\ Z(\\theta) \\\\<br>&amp;\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\<br>\\end{split}\\end{equation}</p>\n<p>因为对数函数有一个线性上界：$log\\ Z(\\theta)\\leqslant \\mu Z(\\theta) - log\\ \\mu - 1$<br>定义：$\\Delta\\theta_i^{(t)} = \\theta_i-\\theta_i^{(t)} $<br>\\begin{equation}\\begin{split}\\tilde l(\\theta;D) &amp;\\geqslant \\Sigma_x \\tilde p(x)\\Sigma_i \\theta_i f_i(x) - \\frac{Z(\\theta)}{Z(\\theta^{(t)})} - log Z(\\theta^{(t)}) + 1 \\\\<br>&amp;= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\frac{1}{Z(\\theta^{(t)})}\\Sigma_x exp(\\Sigma_i \\theta_i^{(t)} f_i(x))exp(\\Sigma_i \\Delta\\theta_i^{(t)}f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\<br>&amp;= \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})exp(\\Sigma_i \\Delta\\theta_i^{(t)} f_i(x)) - log\\ Z(\\theta^{(t)}) + 1\\\\<br>\\end{split}\\end{equation}</p>\n<p>假定$f_i(x) \\geqslant,\\Sigma_i f_i(x) = 1$，使用杰西不等式，$exp(\\Sigma_i \\pi_i x_i)\\leqslant \\Sigma_i \\pi_i exp(x_i)$有：<br>$$ \\tilde l(\\theta;D) \\geqslant \\Sigma_i \\theta_i \\Sigma_x \\tilde p(x)f_i(x) - \\Sigma_x p(x\\mid \\theta^{(x)})\\Sigma_i f_i(x)exp(\\Delta\\theta_i^{(t)}) - log\\ Z(\\theta^{(t)}) + 1 $$<br>令上面式子的右边等于$\\Delta(\\theta)$。<br>求偏导令其为零：<br>$$ \\frac{\\partial \\Lambda}{\\partial \\theta_i} = \\Sigma_x \\tilde p(x)f_i(x) - exp(\\Delta\\theta_i^{(t)})\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x) = 0$$<br>$$ e^{\\Delta\\theta_i^{(t)}} = \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p(x\\mid \\theta^{(t)})f_i(x)}= \\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}) $$<br>更新准则：<br>$$ \\theta_i^{(t+1)} = \\theta_i^{(t)} + \\Delta\\theta_i^{(t)} \\Rightarrow p^{(t+1)}(x)=p^{(t)}(x)\\prod_i e^{\\Delta\\theta_i^{(t)}} $$<br>\\begin{equation}\\begin{split} p^{(t+1)}(x) &amp;= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)}Z(\\theta^{(t)}))^{f_i(x)} \\\\<br>&amp;= \\frac{p^{(t)}(x)}{Z(\\theta^{(t)})}\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)}(Z(\\theta^{(t)}))^{\\Sigma_i f_i(x)} \\\\<br>&amp;= p^{(t)}(x)\\prod_i (\\frac{\\Sigma_x \\tilde p(x)f_i)(x)}{\\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)} \\\\<br>\\end{split}\\end{equation}</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><h2 id=\"IPF\"><a href=\"#IPF\" class=\"headerlink\" title=\"IPF\"></a>IPF</h2><p>IPF是无向图模型求最大似然的一般方法。</p>\n<ul>\n<li>对$\\psi_c$在每个团上一个固定的等式，坐标上升。</li>\n<li>在最大团边际空间上进行I-projection</li>\n<li>需要势函数完全的参数化</li>\n<li>必须要以最大团描述</li>\n<li>对于完全可分的模型，变成一次算法</li>\n</ul>\n<h2 id=\"GIS\"><a href=\"#GIS\" class=\"headerlink\" title=\"GIS\"></a>GIS</h2><ul>\n<li>要以基于特征的势函数描述</li>\n<li>GIS是IPF的特殊形式，GIS的团势是建立在特征值配置上的。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第8讲视频以及笔记。</p>\n"},{"title":"建博初衷","date":"2017-11-22T02:46:08.000Z","_content":"主要是无聊，其次是玩耍。\n人的一生有太多的事情需要忙碌，有些事情，很快忘记，希望文字可以表达我当时的心情。\n记录一些随笔，一些笔记，还有一些心情。\n","source":"_posts/建博初衷.md","raw":"---\ntitle: 建博初衷\ndate: 2017-11-22 10:46:08\ncategories: 随笔\n---\n主要是无聊，其次是玩耍。\n人的一生有太多的事情需要忙碌，有些事情，很快忘记，希望文字可以表达我当时的心情。\n记录一些随笔，一些笔记，还有一些心情。\n","slug":"建博初衷","published":1,"updated":"2019-05-01T13:19:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msx00111ouzz840z3qn","content":"<p>主要是无聊，其次是玩耍。<br>人的一生有太多的事情需要忙碌，有些事情，很快忘记，希望文字可以表达我当时的心情。<br>记录一些随笔，一些笔记，还有一些心情。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>主要是无聊，其次是玩耍。<br>人的一生有太多的事情需要忙碌，有些事情，很快忘记，希望文字可以表达我当时的心情。<br>记录一些随笔，一些笔记，还有一些心情。</p>\n"},{"title":"文献整理","date":"2019-04-07T08:24:07.000Z","_content":"本文整理了最近看的论文，主要方向是脑肿瘤分割，由论文链接，论文出发点，以及论文的创新点构成。\n# Densely Connected Convolutional Networks\n\n[Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.](https://arxiv.org/pdf/1608.06993.pdf)\n\n## Standpoint\nRecent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output.\n\n## Innovation\nDesign densely connected convolutional networks with shorter connections.\n\n\n# DRINet for Medical Image Segmenation\n\n[Chen L, Bentley P, Mori K, et al. DRINet for medical image segmentation[J]. IEEE transactions on medical imaging, 2018, 37(11): 2453-2462.](https://ieeexplore.ieee.org/abstract/document/8357580)\n\n## Standpoint\nThese convolution layers learn representative features of input images and construct segmentation based on the features. However, the features learned by standard convolution layers are not distinctive when the differences among different categoriesare subtle in terms of intensity, location,shape, and size.\n\n## Innovation\nA novel combination of the dense connections with the inception structure to address segmentation problems. The use of dense connection blocks, residual inception blocks, and the unpooling blocks achieve high performance while maintaining computational efficiency;\n\n# Autofocus Layer for Semantic Segmentation\n\n[Qin Y, Kamnitsas K, Ancha S, et al. Autofocus layer for semantic segmentation[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018: 603-611.](https://arxiv.org/pdf/1805.08403.pdf)\n\n## Standpoint \nFor high performance, segmentation algorithms are required to use multi-scale context [6], while still aiming for pixel-level accuracy. Multi-scale processing provides detailed cues, such as texture information of a structure, combined with contextual information, such as a structure's surroundings, which can facilitate decisions that are ambiguous when based only on local context.\n\n## Innovation \nThey propose the autofocus convolutional layer for semantic segmentation with the objective of enhancing the capabilities of neural networks for multi-scale processing. Autofocus layers adaptively change the size of the e_ective receptive field based on the processed context to generate more powerful features. This is achieved by parallelising mul-tiple convolutional layers with di_erent dilation rates, combined by an attention mechanism that learns to focus on the optimal scales driven by context.\n\n# Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks\n\n[Razzak I, Imran M, Xu G. Efficient brain tumor segmentation with multiscale two-pathway-group conventional neural networks[J]. IEEE journal of biomedical and health informatics, 2018.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481481)\n\n## Standpoint\n1. Manual segmentation of the brain tumors for cancerdiagnosis from MRI images is a difficult, tedious and timeconsuming task. The accuracy and the robustness of brain tumor segmentation, therefore, are crucial for the diagnosis, treatment planning, and treatment outcome evaluation.\n\n2. Traditional methods of Deep learning such as Convolutional Neural Networks require a large amount of annotated data to learn from, which is often difficult to obtain in the medical domain.\n\n## Innovation \nThey describe a new model Two-Pathway-Group CNN architecture for brain tumor segmentation, which exploits local features and global contextual features simultaneously.\n\n# Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation\n[Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.](\nhttps://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841516X00084/1-s2.0-S1361841516301839/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFoaCXVzLWVhc3QtMSJHMEUCIQCsuiUnmXyD1We5Tahtd1Ldmgji9yslyjwGHfhjWGrTiQIgZI2%2BSICLI%2BYwirHiDv%2FTGDXrqzMMTAnO5VipOujh940q2gMIIxACGgwwNTkwMDM1NDY4NjUiDOhYw6AGmMFoYimUsiq3A%2FnJoakde5OPvuBW9NTk4RD1uQJfiKzq5%2FdL8VVSGt0uujA4qFZjyFNLFImg8WtHa8N72KURPf%2F%2FlECf7quq6thriQ0IWcKRggEmnVyrb5S75twqjs9lMB8wJAS42NwKBogUAnv7a%2FKHlyI8bYvJvCYZfvrlvFkwfoqPN0pvd9qRc22UwUp0osCTlucrynSxWlDakHV20ZOyw985%2FS8ERhfyMNmK%2B3poagUKTzXbwy1oA8CJ8njLfuV7uNiL2GXJrWnv4XD%2FrS7R%2BedMGzNCK%2Fel7pAff6%2B5Q6Mzd4%2FmtnA9UYvyGCJiY4qOlxib%2FG8oFexAZohS20ZIqgpWg4BUz%2FG5%2BqWxHxPB6htlq503UBMvXYqp86NIZ7%2B2tbZ7bKWr7Lj27885H0t6YEQjB4Bec0wVQLnEfpo4vI2b0zxlItdgpALLT9XuYog9rBvCa6G943RX4qA5wO0MtkZl3mcTqgDpImX7qsYnhY9cZWWgOqxYiNX0ksUDoggLES6QI9s1XVaKh4fd0bTQ%2BF9kBw8s%2BJ%2FaVU1TwFWWLJDHmMPwL6ZUV6bvMdmjPcG6aFz3lru8gPARpK0YlmQwu6Ol5QU6tAFf7vS%2B1BXojpfdrukDGETT2BJQlXwWYhY%2F4SH2PnmzSW%2BOWqFiVeuSGtpzWetonvYspUAAt9zO24zb0Ap2SSIzKn8Zd6qnzjEZzI8rLe3i9CmoZ%2BlfC41rZvNeYEqxWapay%2F8ygSZUDYTvHj93Vj4eFdu1uHVL5Tm2vFs8ukNDDlS6hdp3Zk3UaM1QfDkLksa8fEjCwFldyOdIcfhoykJHNM8%2FpdBmA%2Ffqz%2FBk7HaV8kgtL9Y%3D&AWSAccessKeyId=ASIAQ3PHCVTYQ3ZV253X&Expires=1554601073&Signature=OeSwkuAFTu2MZ2agSyHzQz7OZww%3D&hash=0185f4d47582fa2a2ee2c35cf986b0fd9e15d14bd40721c8e67816d7851da17e&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841516301839&tid=spdf-b5e3157c-b347-43ad-bbd6-0d660c93b8f7&sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&type=client)\n## Standpoint \n The heterogeneous appearance of lesions including the large variability in location, size, shape and frequency make it difficult to devise effective segmentation rules. It is thus highly non-trivial to delineate contu- sions, oedema and haemorrhages in TBI, or sub-components of brain tumours such as proliferating cells and necrotic core.\n\n## Innovation \n They  propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. \n\n# HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation\n\n[Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8515234)\n\n## Standpoint\nDense connections have attracted substantial attention in computer vision because they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet, which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances in natural image classification tasks.\n\n## Innovation \nThey propose HyperDenseNet, a 3D fully convolutional neural network that extends the definition of dense connectivity to multi-modal segmentation problems. Each imaging modality has a path, and dense connections occur not only between the pairs of layers within the same path, but also between those across different paths.\n\n\n# A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation\n\n[Zhao X, Wu Y, Song G, et al. A deep learning model integrating FCNNs and CRFs for brain tumor segmentation[J]. Medical image analysis, 2018, 43: 98-111](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841517X0008X/1-s2.0-S136184151730141X/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFsaCXVzLWVhc3QtMSJHMEUCIQCmFiL2ekwH7KF8z%2Fc0vWR0Ac9yL8K5oGv5DOeBI7VJhQIgfy%2FpbMeHw7IWu30Pc%2FGwfPGxvuI5Calk%2Bgjx2fm5U8wq2gMIJBACGgwwNTkwMDM1NDY4NjUiDIGTbcyCi60TQJ8PRyq3A1%2Fzz%2B3VHHOekK%2FJw6MU%2FZqrd9oySC4b6nKbDevYilRhqIjYFRKlF1Ij0YgzO2xl2qPCJA1Luoh3fIm4CfQomsuNh0vwUU4VcwwTOdRKW4Biycm5IxXEePAh2xuIUSBB%2B%2BRbOIwmmHKraKf8UaAlFLz%2FxDHEPqk%2Ft8WllncOm3fus26FVvSt6tBpAiUmIlWi%2B8a%2BiJ6GF61aZBjlsGbZhDHS%2BtsTXMdRysCnSdGTClkKbVshva2YJUU7dM%2BqzxrrGCTCDCFYq%2Fo%2FCszl%2BTV%2BperpIIltFrMZdVk1g%2FnAmD35O%2Bsgk1V4iQiYrdXAvCcNO1Vt7gmaTg8k4lZjXacSw52vrDW76YcU%2FOWq7BYkFB8v3CTeIH0pPvvDmLRbSOYt7HmYWMuSTR5AS5DgrJvY2al3UczqOK8rYSN4qcu5GdgNa7fzvQaouXF2SHQ%2FVj9sH8agALf0MbOzTOH43EadU5ATM8X3JYwWEh9bP7mPor3cQm1VHvDz0Eq9NtduHt2r9EYQ0nqR22AmBAfSYbaf1yz55k6bwUtqukP5IJm6BCeeaVbaz9zB0rVbAHdUCh3tgnqsds%2Fvlf4wy7%2Bl5QU6tAFpdYJnVeDFfg8QKDDpZ9fcsFs5bdMoGPRaU8hY495aNV4QleUmufJAirYtZvSZAQbZGelsALa1gT7OwuMDACZ76e3FyfsRjc9sgQIWXy73%2FvnbUIiSAH%2F0BUiE0Sfq%2FXB2gzShepFEjd1nIf9nrzmKl8TLiMxWQm%2F7txg8Y4ndrsBnq1YWoYn9nkg6MF4a5Hy6M4W2hBk%2FOq1MpN1%2Bh20l%2FhkH%2BUDkInb5ni4zsRTuPDTvgi0%3D&AWSAccessKeyId=ASIAQ3PHCVTYRA73P2UO&Expires=1554605840&Signature=mupLWqHKaKQuDReHsSReahixCgc%3D&hash=d7e362b71f1842d8657ac4a022fe9b558190b5ecd29082efd89e41cda056cd25&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S136184151730141X&tid=spdf-ff9d6147-ba0b-4dfc-b397-32911281b48b&sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&type=client)\n\n## Standpoint \nAccurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation.\n\n## Innovation \nBuild upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency.\n\n# U-Net: Convolutional Networks for Biomedical Image Segmentation\n\n[Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.](\nhttps://arxiv.org/pdf/1505.04597.pdf)\n\n## Standpoint\nThere is large consent that successful training of deep networks requires many thousand annotated training samples.\n\n## Innovation \nIn this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently.\n\n## Review \nThis architecture is very useful in many medical image segmentation task, so is it the best architecture?\n\nThe novel architecture is not emphasized in this paper, but this paper propose U-Net that has been a popular network architecture.\n\n\n","source":"_posts/文献整理.md","raw":"---\ntitle: 文献整理\ndate: 2019-04-07 16:24:07\ntags: Brain tumor segmentation\ncategories: 工作\n---\n本文整理了最近看的论文，主要方向是脑肿瘤分割，由论文链接，论文出发点，以及论文的创新点构成。\n# Densely Connected Convolutional Networks\n\n[Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.](https://arxiv.org/pdf/1608.06993.pdf)\n\n## Standpoint\nRecent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output.\n\n## Innovation\nDesign densely connected convolutional networks with shorter connections.\n\n\n# DRINet for Medical Image Segmenation\n\n[Chen L, Bentley P, Mori K, et al. DRINet for medical image segmentation[J]. IEEE transactions on medical imaging, 2018, 37(11): 2453-2462.](https://ieeexplore.ieee.org/abstract/document/8357580)\n\n## Standpoint\nThese convolution layers learn representative features of input images and construct segmentation based on the features. However, the features learned by standard convolution layers are not distinctive when the differences among different categoriesare subtle in terms of intensity, location,shape, and size.\n\n## Innovation\nA novel combination of the dense connections with the inception structure to address segmentation problems. The use of dense connection blocks, residual inception blocks, and the unpooling blocks achieve high performance while maintaining computational efficiency;\n\n# Autofocus Layer for Semantic Segmentation\n\n[Qin Y, Kamnitsas K, Ancha S, et al. Autofocus layer for semantic segmentation[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018: 603-611.](https://arxiv.org/pdf/1805.08403.pdf)\n\n## Standpoint \nFor high performance, segmentation algorithms are required to use multi-scale context [6], while still aiming for pixel-level accuracy. Multi-scale processing provides detailed cues, such as texture information of a structure, combined with contextual information, such as a structure's surroundings, which can facilitate decisions that are ambiguous when based only on local context.\n\n## Innovation \nThey propose the autofocus convolutional layer for semantic segmentation with the objective of enhancing the capabilities of neural networks for multi-scale processing. Autofocus layers adaptively change the size of the e_ective receptive field based on the processed context to generate more powerful features. This is achieved by parallelising mul-tiple convolutional layers with di_erent dilation rates, combined by an attention mechanism that learns to focus on the optimal scales driven by context.\n\n# Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks\n\n[Razzak I, Imran M, Xu G. Efficient brain tumor segmentation with multiscale two-pathway-group conventional neural networks[J]. IEEE journal of biomedical and health informatics, 2018.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481481)\n\n## Standpoint\n1. Manual segmentation of the brain tumors for cancerdiagnosis from MRI images is a difficult, tedious and timeconsuming task. The accuracy and the robustness of brain tumor segmentation, therefore, are crucial for the diagnosis, treatment planning, and treatment outcome evaluation.\n\n2. Traditional methods of Deep learning such as Convolutional Neural Networks require a large amount of annotated data to learn from, which is often difficult to obtain in the medical domain.\n\n## Innovation \nThey describe a new model Two-Pathway-Group CNN architecture for brain tumor segmentation, which exploits local features and global contextual features simultaneously.\n\n# Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation\n[Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.](\nhttps://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841516X00084/1-s2.0-S1361841516301839/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFoaCXVzLWVhc3QtMSJHMEUCIQCsuiUnmXyD1We5Tahtd1Ldmgji9yslyjwGHfhjWGrTiQIgZI2%2BSICLI%2BYwirHiDv%2FTGDXrqzMMTAnO5VipOujh940q2gMIIxACGgwwNTkwMDM1NDY4NjUiDOhYw6AGmMFoYimUsiq3A%2FnJoakde5OPvuBW9NTk4RD1uQJfiKzq5%2FdL8VVSGt0uujA4qFZjyFNLFImg8WtHa8N72KURPf%2F%2FlECf7quq6thriQ0IWcKRggEmnVyrb5S75twqjs9lMB8wJAS42NwKBogUAnv7a%2FKHlyI8bYvJvCYZfvrlvFkwfoqPN0pvd9qRc22UwUp0osCTlucrynSxWlDakHV20ZOyw985%2FS8ERhfyMNmK%2B3poagUKTzXbwy1oA8CJ8njLfuV7uNiL2GXJrWnv4XD%2FrS7R%2BedMGzNCK%2Fel7pAff6%2B5Q6Mzd4%2FmtnA9UYvyGCJiY4qOlxib%2FG8oFexAZohS20ZIqgpWg4BUz%2FG5%2BqWxHxPB6htlq503UBMvXYqp86NIZ7%2B2tbZ7bKWr7Lj27885H0t6YEQjB4Bec0wVQLnEfpo4vI2b0zxlItdgpALLT9XuYog9rBvCa6G943RX4qA5wO0MtkZl3mcTqgDpImX7qsYnhY9cZWWgOqxYiNX0ksUDoggLES6QI9s1XVaKh4fd0bTQ%2BF9kBw8s%2BJ%2FaVU1TwFWWLJDHmMPwL6ZUV6bvMdmjPcG6aFz3lru8gPARpK0YlmQwu6Ol5QU6tAFf7vS%2B1BXojpfdrukDGETT2BJQlXwWYhY%2F4SH2PnmzSW%2BOWqFiVeuSGtpzWetonvYspUAAt9zO24zb0Ap2SSIzKn8Zd6qnzjEZzI8rLe3i9CmoZ%2BlfC41rZvNeYEqxWapay%2F8ygSZUDYTvHj93Vj4eFdu1uHVL5Tm2vFs8ukNDDlS6hdp3Zk3UaM1QfDkLksa8fEjCwFldyOdIcfhoykJHNM8%2FpdBmA%2Ffqz%2FBk7HaV8kgtL9Y%3D&AWSAccessKeyId=ASIAQ3PHCVTYQ3ZV253X&Expires=1554601073&Signature=OeSwkuAFTu2MZ2agSyHzQz7OZww%3D&hash=0185f4d47582fa2a2ee2c35cf986b0fd9e15d14bd40721c8e67816d7851da17e&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841516301839&tid=spdf-b5e3157c-b347-43ad-bbd6-0d660c93b8f7&sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&type=client)\n## Standpoint \n The heterogeneous appearance of lesions including the large variability in location, size, shape and frequency make it difficult to devise effective segmentation rules. It is thus highly non-trivial to delineate contu- sions, oedema and haemorrhages in TBI, or sub-components of brain tumours such as proliferating cells and necrotic core.\n\n## Innovation \n They  propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. \n\n# HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation\n\n[Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8515234)\n\n## Standpoint\nDense connections have attracted substantial attention in computer vision because they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet, which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances in natural image classification tasks.\n\n## Innovation \nThey propose HyperDenseNet, a 3D fully convolutional neural network that extends the definition of dense connectivity to multi-modal segmentation problems. Each imaging modality has a path, and dense connections occur not only between the pairs of layers within the same path, but also between those across different paths.\n\n\n# A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation\n\n[Zhao X, Wu Y, Song G, et al. A deep learning model integrating FCNNs and CRFs for brain tumor segmentation[J]. Medical image analysis, 2018, 43: 98-111](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841517X0008X/1-s2.0-S136184151730141X/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFsaCXVzLWVhc3QtMSJHMEUCIQCmFiL2ekwH7KF8z%2Fc0vWR0Ac9yL8K5oGv5DOeBI7VJhQIgfy%2FpbMeHw7IWu30Pc%2FGwfPGxvuI5Calk%2Bgjx2fm5U8wq2gMIJBACGgwwNTkwMDM1NDY4NjUiDIGTbcyCi60TQJ8PRyq3A1%2Fzz%2B3VHHOekK%2FJw6MU%2FZqrd9oySC4b6nKbDevYilRhqIjYFRKlF1Ij0YgzO2xl2qPCJA1Luoh3fIm4CfQomsuNh0vwUU4VcwwTOdRKW4Biycm5IxXEePAh2xuIUSBB%2B%2BRbOIwmmHKraKf8UaAlFLz%2FxDHEPqk%2Ft8WllncOm3fus26FVvSt6tBpAiUmIlWi%2B8a%2BiJ6GF61aZBjlsGbZhDHS%2BtsTXMdRysCnSdGTClkKbVshva2YJUU7dM%2BqzxrrGCTCDCFYq%2Fo%2FCszl%2BTV%2BperpIIltFrMZdVk1g%2FnAmD35O%2Bsgk1V4iQiYrdXAvCcNO1Vt7gmaTg8k4lZjXacSw52vrDW76YcU%2FOWq7BYkFB8v3CTeIH0pPvvDmLRbSOYt7HmYWMuSTR5AS5DgrJvY2al3UczqOK8rYSN4qcu5GdgNa7fzvQaouXF2SHQ%2FVj9sH8agALf0MbOzTOH43EadU5ATM8X3JYwWEh9bP7mPor3cQm1VHvDz0Eq9NtduHt2r9EYQ0nqR22AmBAfSYbaf1yz55k6bwUtqukP5IJm6BCeeaVbaz9zB0rVbAHdUCh3tgnqsds%2Fvlf4wy7%2Bl5QU6tAFpdYJnVeDFfg8QKDDpZ9fcsFs5bdMoGPRaU8hY495aNV4QleUmufJAirYtZvSZAQbZGelsALa1gT7OwuMDACZ76e3FyfsRjc9sgQIWXy73%2FvnbUIiSAH%2F0BUiE0Sfq%2FXB2gzShepFEjd1nIf9nrzmKl8TLiMxWQm%2F7txg8Y4ndrsBnq1YWoYn9nkg6MF4a5Hy6M4W2hBk%2FOq1MpN1%2Bh20l%2FhkH%2BUDkInb5ni4zsRTuPDTvgi0%3D&AWSAccessKeyId=ASIAQ3PHCVTYRA73P2UO&Expires=1554605840&Signature=mupLWqHKaKQuDReHsSReahixCgc%3D&hash=d7e362b71f1842d8657ac4a022fe9b558190b5ecd29082efd89e41cda056cd25&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S136184151730141X&tid=spdf-ff9d6147-ba0b-4dfc-b397-32911281b48b&sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&type=client)\n\n## Standpoint \nAccurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation.\n\n## Innovation \nBuild upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency.\n\n# U-Net: Convolutional Networks for Biomedical Image Segmentation\n\n[Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.](\nhttps://arxiv.org/pdf/1505.04597.pdf)\n\n## Standpoint\nThere is large consent that successful training of deep networks requires many thousand annotated training samples.\n\n## Innovation \nIn this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently.\n\n## Review \nThis architecture is very useful in many medical image segmentation task, so is it the best architecture?\n\nThe novel architecture is not emphasized in this paper, but this paper propose U-Net that has been a popular network architecture.\n\n\n","slug":"文献整理","published":1,"updated":"2019-04-07T11:29:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msy00121ouzo1824npv","content":"<p>本文整理了最近看的论文，主要方向是脑肿瘤分割，由论文链接，论文出发点，以及论文的创新点构成。</p>\n<h1 id=\"Densely-Connected-Convolutional-Networks\"><a href=\"#Densely-Connected-Convolutional-Networks\" class=\"headerlink\" title=\"Densely Connected Convolutional Networks\"></a>Densely Connected Convolutional Networks</h1><p><a href=\"https://arxiv.org/pdf/1608.06993.pdf\" target=\"_blank\" rel=\"noopener\">Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</a></p>\n<h2 id=\"Standpoint\"><a href=\"#Standpoint\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output.</p>\n<h2 id=\"Innovation\"><a href=\"#Innovation\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>Design densely connected convolutional networks with shorter connections.</p>\n<h1 id=\"DRINet-for-Medical-Image-Segmenation\"><a href=\"#DRINet-for-Medical-Image-Segmenation\" class=\"headerlink\" title=\"DRINet for Medical Image Segmenation\"></a>DRINet for Medical Image Segmenation</h1><p><a href=\"https://ieeexplore.ieee.org/abstract/document/8357580\" target=\"_blank\" rel=\"noopener\">Chen L, Bentley P, Mori K, et al. DRINet for medical image segmentation[J]. IEEE transactions on medical imaging, 2018, 37(11): 2453-2462.</a></p>\n<h2 id=\"Standpoint-1\"><a href=\"#Standpoint-1\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>These convolution layers learn representative features of input images and construct segmentation based on the features. However, the features learned by standard convolution layers are not distinctive when the differences among different categoriesare subtle in terms of intensity, location,shape, and size.</p>\n<h2 id=\"Innovation-1\"><a href=\"#Innovation-1\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>A novel combination of the dense connections with the inception structure to address segmentation problems. The use of dense connection blocks, residual inception blocks, and the unpooling blocks achieve high performance while maintaining computational efficiency;</p>\n<h1 id=\"Autofocus-Layer-for-Semantic-Segmentation\"><a href=\"#Autofocus-Layer-for-Semantic-Segmentation\" class=\"headerlink\" title=\"Autofocus Layer for Semantic Segmentation\"></a>Autofocus Layer for Semantic Segmentation</h1><p><a href=\"https://arxiv.org/pdf/1805.08403.pdf\" target=\"_blank\" rel=\"noopener\">Qin Y, Kamnitsas K, Ancha S, et al. Autofocus layer for semantic segmentation[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018: 603-611.</a></p>\n<h2 id=\"Standpoint-2\"><a href=\"#Standpoint-2\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>For high performance, segmentation algorithms are required to use multi-scale context [6], while still aiming for pixel-level accuracy. Multi-scale processing provides detailed cues, such as texture information of a structure, combined with contextual information, such as a structure’s surroundings, which can facilitate decisions that are ambiguous when based only on local context.</p>\n<h2 id=\"Innovation-2\"><a href=\"#Innovation-2\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>They propose the autofocus convolutional layer for semantic segmentation with the objective of enhancing the capabilities of neural networks for multi-scale processing. Autofocus layers adaptively change the size of the e_ective receptive field based on the processed context to generate more powerful features. This is achieved by parallelising mul-tiple convolutional layers with di_erent dilation rates, combined by an attention mechanism that learns to focus on the optimal scales driven by context.</p>\n<h1 id=\"Efficient-Brain-Tumor-Segmentation-with-Multiscale-Two-Pathway-Group-Conventional-Neural-Networks\"><a href=\"#Efficient-Brain-Tumor-Segmentation-with-Multiscale-Two-Pathway-Group-Conventional-Neural-Networks\" class=\"headerlink\" title=\"Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks\"></a>Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks</h1><p><a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481481\" target=\"_blank\" rel=\"noopener\">Razzak I, Imran M, Xu G. Efficient brain tumor segmentation with multiscale two-pathway-group conventional neural networks[J]. IEEE journal of biomedical and health informatics, 2018.</a></p>\n<h2 id=\"Standpoint-3\"><a href=\"#Standpoint-3\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><ol>\n<li><p>Manual segmentation of the brain tumors for cancerdiagnosis from MRI images is a difficult, tedious and timeconsuming task. The accuracy and the robustness of brain tumor segmentation, therefore, are crucial for the diagnosis, treatment planning, and treatment outcome evaluation.</p>\n</li>\n<li><p>Traditional methods of Deep learning such as Convolutional Neural Networks require a large amount of annotated data to learn from, which is often difficult to obtain in the medical domain.</p>\n</li>\n</ol>\n<h2 id=\"Innovation-3\"><a href=\"#Innovation-3\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>They describe a new model Two-Pathway-Group CNN architecture for brain tumor segmentation, which exploits local features and global contextual features simultaneously.</p>\n<h1 id=\"Efficient-Multi-scale-3D-CNN-with-Fully-Connected-CRF-for-Accurate-Brain-lesion-Segmentation\"><a href=\"#Efficient-Multi-scale-3D-CNN-with-Fully-Connected-CRF-for-Accurate-Brain-lesion-Segmentation\" class=\"headerlink\" title=\"Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation\"></a>Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation</h1><p><a href=\"https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841516X00084/1-s2.0-S1361841516301839/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFoaCXVzLWVhc3QtMSJHMEUCIQCsuiUnmXyD1We5Tahtd1Ldmgji9yslyjwGHfhjWGrTiQIgZI2%2BSICLI%2BYwirHiDv%2FTGDXrqzMMTAnO5VipOujh940q2gMIIxACGgwwNTkwMDM1NDY4NjUiDOhYw6AGmMFoYimUsiq3A%2FnJoakde5OPvuBW9NTk4RD1uQJfiKzq5%2FdL8VVSGt0uujA4qFZjyFNLFImg8WtHa8N72KURPf%2F%2FlECf7quq6thriQ0IWcKRggEmnVyrb5S75twqjs9lMB8wJAS42NwKBogUAnv7a%2FKHlyI8bYvJvCYZfvrlvFkwfoqPN0pvd9qRc22UwUp0osCTlucrynSxWlDakHV20ZOyw985%2FS8ERhfyMNmK%2B3poagUKTzXbwy1oA8CJ8njLfuV7uNiL2GXJrWnv4XD%2FrS7R%2BedMGzNCK%2Fel7pAff6%2B5Q6Mzd4%2FmtnA9UYvyGCJiY4qOlxib%2FG8oFexAZohS20ZIqgpWg4BUz%2FG5%2BqWxHxPB6htlq503UBMvXYqp86NIZ7%2B2tbZ7bKWr7Lj27885H0t6YEQjB4Bec0wVQLnEfpo4vI2b0zxlItdgpALLT9XuYog9rBvCa6G943RX4qA5wO0MtkZl3mcTqgDpImX7qsYnhY9cZWWgOqxYiNX0ksUDoggLES6QI9s1XVaKh4fd0bTQ%2BF9kBw8s%2BJ%2FaVU1TwFWWLJDHmMPwL6ZUV6bvMdmjPcG6aFz3lru8gPARpK0YlmQwu6Ol5QU6tAFf7vS%2B1BXojpfdrukDGETT2BJQlXwWYhY%2F4SH2PnmzSW%2BOWqFiVeuSGtpzWetonvYspUAAt9zO24zb0Ap2SSIzKn8Zd6qnzjEZzI8rLe3i9CmoZ%2BlfC41rZvNeYEqxWapay%2F8ygSZUDYTvHj93Vj4eFdu1uHVL5Tm2vFs8ukNDDlS6hdp3Zk3UaM1QfDkLksa8fEjCwFldyOdIcfhoykJHNM8%2FpdBmA%2Ffqz%2FBk7HaV8kgtL9Y%3D&amp;AWSAccessKeyId=ASIAQ3PHCVTYQ3ZV253X&amp;Expires=1554601073&amp;Signature=OeSwkuAFTu2MZ2agSyHzQz7OZww%3D&amp;hash=0185f4d47582fa2a2ee2c35cf986b0fd9e15d14bd40721c8e67816d7851da17e&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1361841516301839&amp;tid=spdf-b5e3157c-b347-43ad-bbd6-0d660c93b8f7&amp;sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&amp;type=client\" target=\"_blank\" rel=\"noopener\">Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.</a></p>\n<h2 id=\"Standpoint-4\"><a href=\"#Standpoint-4\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p> The heterogeneous appearance of lesions including the large variability in location, size, shape and frequency make it difficult to devise effective segmentation rules. It is thus highly non-trivial to delineate contu- sions, oedema and haemorrhages in TBI, or sub-components of brain tumours such as proliferating cells and necrotic core.</p>\n<h2 id=\"Innovation-4\"><a href=\"#Innovation-4\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p> They  propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. </p>\n<h1 id=\"HyperDense-Net-A-Hyper-densely-Connected-CNN-for-Multi-modal-Image-Segmentation\"><a href=\"#HyperDense-Net-A-Hyper-densely-Connected-CNN-for-Multi-modal-Image-Segmentation\" class=\"headerlink\" title=\"HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation\"></a>HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation</h1><p><a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8515234\" target=\"_blank\" rel=\"noopener\">Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.</a></p>\n<h2 id=\"Standpoint-5\"><a href=\"#Standpoint-5\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>Dense connections have attracted substantial attention in computer vision because they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet, which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances in natural image classification tasks.</p>\n<h2 id=\"Innovation-5\"><a href=\"#Innovation-5\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>They propose HyperDenseNet, a 3D fully convolutional neural network that extends the definition of dense connectivity to multi-modal segmentation problems. Each imaging modality has a path, and dense connections occur not only between the pairs of layers within the same path, but also between those across different paths.</p>\n<h1 id=\"A-Deep-Learning-model-integrating-FCNNs-and-CRFs-for-brain-tumor-segmentation\"><a href=\"#A-Deep-Learning-model-integrating-FCNNs-and-CRFs-for-brain-tumor-segmentation\" class=\"headerlink\" title=\"A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation\"></a>A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation</h1><p><a href=\"https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841517X0008X/1-s2.0-S136184151730141X/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFsaCXVzLWVhc3QtMSJHMEUCIQCmFiL2ekwH7KF8z%2Fc0vWR0Ac9yL8K5oGv5DOeBI7VJhQIgfy%2FpbMeHw7IWu30Pc%2FGwfPGxvuI5Calk%2Bgjx2fm5U8wq2gMIJBACGgwwNTkwMDM1NDY4NjUiDIGTbcyCi60TQJ8PRyq3A1%2Fzz%2B3VHHOekK%2FJw6MU%2FZqrd9oySC4b6nKbDevYilRhqIjYFRKlF1Ij0YgzO2xl2qPCJA1Luoh3fIm4CfQomsuNh0vwUU4VcwwTOdRKW4Biycm5IxXEePAh2xuIUSBB%2B%2BRbOIwmmHKraKf8UaAlFLz%2FxDHEPqk%2Ft8WllncOm3fus26FVvSt6tBpAiUmIlWi%2B8a%2BiJ6GF61aZBjlsGbZhDHS%2BtsTXMdRysCnSdGTClkKbVshva2YJUU7dM%2BqzxrrGCTCDCFYq%2Fo%2FCszl%2BTV%2BperpIIltFrMZdVk1g%2FnAmD35O%2Bsgk1V4iQiYrdXAvCcNO1Vt7gmaTg8k4lZjXacSw52vrDW76YcU%2FOWq7BYkFB8v3CTeIH0pPvvDmLRbSOYt7HmYWMuSTR5AS5DgrJvY2al3UczqOK8rYSN4qcu5GdgNa7fzvQaouXF2SHQ%2FVj9sH8agALf0MbOzTOH43EadU5ATM8X3JYwWEh9bP7mPor3cQm1VHvDz0Eq9NtduHt2r9EYQ0nqR22AmBAfSYbaf1yz55k6bwUtqukP5IJm6BCeeaVbaz9zB0rVbAHdUCh3tgnqsds%2Fvlf4wy7%2Bl5QU6tAFpdYJnVeDFfg8QKDDpZ9fcsFs5bdMoGPRaU8hY495aNV4QleUmufJAirYtZvSZAQbZGelsALa1gT7OwuMDACZ76e3FyfsRjc9sgQIWXy73%2FvnbUIiSAH%2F0BUiE0Sfq%2FXB2gzShepFEjd1nIf9nrzmKl8TLiMxWQm%2F7txg8Y4ndrsBnq1YWoYn9nkg6MF4a5Hy6M4W2hBk%2FOq1MpN1%2Bh20l%2FhkH%2BUDkInb5ni4zsRTuPDTvgi0%3D&amp;AWSAccessKeyId=ASIAQ3PHCVTYRA73P2UO&amp;Expires=1554605840&amp;Signature=mupLWqHKaKQuDReHsSReahixCgc%3D&amp;hash=d7e362b71f1842d8657ac4a022fe9b558190b5ecd29082efd89e41cda056cd25&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S136184151730141X&amp;tid=spdf-ff9d6147-ba0b-4dfc-b397-32911281b48b&amp;sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&amp;type=client\" target=\"_blank\" rel=\"noopener\">Zhao X, Wu Y, Song G, et al. A deep learning model integrating FCNNs and CRFs for brain tumor segmentation[J]. Medical image analysis, 2018, 43: 98-111</a></p>\n<h2 id=\"Standpoint-6\"><a href=\"#Standpoint-6\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation.</p>\n<h2 id=\"Innovation-6\"><a href=\"#Innovation-6\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>Build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency.</p>\n<h1 id=\"U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation\"><a href=\"#U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation\" class=\"headerlink\" title=\"U-Net: Convolutional Networks for Biomedical Image Segmentation\"></a>U-Net: Convolutional Networks for Biomedical Image Segmentation</h1><p><a href=\"https://arxiv.org/pdf/1505.04597.pdf\" target=\"_blank\" rel=\"noopener\">Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.</a></p>\n<h2 id=\"Standpoint-7\"><a href=\"#Standpoint-7\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>There is large consent that successful training of deep networks requires many thousand annotated training samples.</p>\n<h2 id=\"Innovation-7\"><a href=\"#Innovation-7\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently.</p>\n<h2 id=\"Review\"><a href=\"#Review\" class=\"headerlink\" title=\"Review\"></a>Review</h2><p>This architecture is very useful in many medical image segmentation task, so is it the best architecture?</p>\n<p>The novel architecture is not emphasized in this paper, but this paper propose U-Net that has been a popular network architecture.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文整理了最近看的论文，主要方向是脑肿瘤分割，由论文链接，论文出发点，以及论文的创新点构成。</p>\n<h1 id=\"Densely-Connected-Convolutional-Networks\"><a href=\"#Densely-Connected-Convolutional-Networks\" class=\"headerlink\" title=\"Densely Connected Convolutional Networks\"></a>Densely Connected Convolutional Networks</h1><p><a href=\"https://arxiv.org/pdf/1608.06993.pdf\" target=\"_blank\" rel=\"noopener\">Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</a></p>\n<h2 id=\"Standpoint\"><a href=\"#Standpoint\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output.</p>\n<h2 id=\"Innovation\"><a href=\"#Innovation\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>Design densely connected convolutional networks with shorter connections.</p>\n<h1 id=\"DRINet-for-Medical-Image-Segmenation\"><a href=\"#DRINet-for-Medical-Image-Segmenation\" class=\"headerlink\" title=\"DRINet for Medical Image Segmenation\"></a>DRINet for Medical Image Segmenation</h1><p><a href=\"https://ieeexplore.ieee.org/abstract/document/8357580\" target=\"_blank\" rel=\"noopener\">Chen L, Bentley P, Mori K, et al. DRINet for medical image segmentation[J]. IEEE transactions on medical imaging, 2018, 37(11): 2453-2462.</a></p>\n<h2 id=\"Standpoint-1\"><a href=\"#Standpoint-1\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>These convolution layers learn representative features of input images and construct segmentation based on the features. However, the features learned by standard convolution layers are not distinctive when the differences among different categoriesare subtle in terms of intensity, location,shape, and size.</p>\n<h2 id=\"Innovation-1\"><a href=\"#Innovation-1\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>A novel combination of the dense connections with the inception structure to address segmentation problems. The use of dense connection blocks, residual inception blocks, and the unpooling blocks achieve high performance while maintaining computational efficiency;</p>\n<h1 id=\"Autofocus-Layer-for-Semantic-Segmentation\"><a href=\"#Autofocus-Layer-for-Semantic-Segmentation\" class=\"headerlink\" title=\"Autofocus Layer for Semantic Segmentation\"></a>Autofocus Layer for Semantic Segmentation</h1><p><a href=\"https://arxiv.org/pdf/1805.08403.pdf\" target=\"_blank\" rel=\"noopener\">Qin Y, Kamnitsas K, Ancha S, et al. Autofocus layer for semantic segmentation[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018: 603-611.</a></p>\n<h2 id=\"Standpoint-2\"><a href=\"#Standpoint-2\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>For high performance, segmentation algorithms are required to use multi-scale context [6], while still aiming for pixel-level accuracy. Multi-scale processing provides detailed cues, such as texture information of a structure, combined with contextual information, such as a structure’s surroundings, which can facilitate decisions that are ambiguous when based only on local context.</p>\n<h2 id=\"Innovation-2\"><a href=\"#Innovation-2\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>They propose the autofocus convolutional layer for semantic segmentation with the objective of enhancing the capabilities of neural networks for multi-scale processing. Autofocus layers adaptively change the size of the e_ective receptive field based on the processed context to generate more powerful features. This is achieved by parallelising mul-tiple convolutional layers with di_erent dilation rates, combined by an attention mechanism that learns to focus on the optimal scales driven by context.</p>\n<h1 id=\"Efficient-Brain-Tumor-Segmentation-with-Multiscale-Two-Pathway-Group-Conventional-Neural-Networks\"><a href=\"#Efficient-Brain-Tumor-Segmentation-with-Multiscale-Two-Pathway-Group-Conventional-Neural-Networks\" class=\"headerlink\" title=\"Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks\"></a>Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks</h1><p><a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481481\" target=\"_blank\" rel=\"noopener\">Razzak I, Imran M, Xu G. Efficient brain tumor segmentation with multiscale two-pathway-group conventional neural networks[J]. IEEE journal of biomedical and health informatics, 2018.</a></p>\n<h2 id=\"Standpoint-3\"><a href=\"#Standpoint-3\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><ol>\n<li><p>Manual segmentation of the brain tumors for cancerdiagnosis from MRI images is a difficult, tedious and timeconsuming task. The accuracy and the robustness of brain tumor segmentation, therefore, are crucial for the diagnosis, treatment planning, and treatment outcome evaluation.</p>\n</li>\n<li><p>Traditional methods of Deep learning such as Convolutional Neural Networks require a large amount of annotated data to learn from, which is often difficult to obtain in the medical domain.</p>\n</li>\n</ol>\n<h2 id=\"Innovation-3\"><a href=\"#Innovation-3\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>They describe a new model Two-Pathway-Group CNN architecture for brain tumor segmentation, which exploits local features and global contextual features simultaneously.</p>\n<h1 id=\"Efficient-Multi-scale-3D-CNN-with-Fully-Connected-CRF-for-Accurate-Brain-lesion-Segmentation\"><a href=\"#Efficient-Multi-scale-3D-CNN-with-Fully-Connected-CRF-for-Accurate-Brain-lesion-Segmentation\" class=\"headerlink\" title=\"Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation\"></a>Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation</h1><p><a href=\"https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841516X00084/1-s2.0-S1361841516301839/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFoaCXVzLWVhc3QtMSJHMEUCIQCsuiUnmXyD1We5Tahtd1Ldmgji9yslyjwGHfhjWGrTiQIgZI2%2BSICLI%2BYwirHiDv%2FTGDXrqzMMTAnO5VipOujh940q2gMIIxACGgwwNTkwMDM1NDY4NjUiDOhYw6AGmMFoYimUsiq3A%2FnJoakde5OPvuBW9NTk4RD1uQJfiKzq5%2FdL8VVSGt0uujA4qFZjyFNLFImg8WtHa8N72KURPf%2F%2FlECf7quq6thriQ0IWcKRggEmnVyrb5S75twqjs9lMB8wJAS42NwKBogUAnv7a%2FKHlyI8bYvJvCYZfvrlvFkwfoqPN0pvd9qRc22UwUp0osCTlucrynSxWlDakHV20ZOyw985%2FS8ERhfyMNmK%2B3poagUKTzXbwy1oA8CJ8njLfuV7uNiL2GXJrWnv4XD%2FrS7R%2BedMGzNCK%2Fel7pAff6%2B5Q6Mzd4%2FmtnA9UYvyGCJiY4qOlxib%2FG8oFexAZohS20ZIqgpWg4BUz%2FG5%2BqWxHxPB6htlq503UBMvXYqp86NIZ7%2B2tbZ7bKWr7Lj27885H0t6YEQjB4Bec0wVQLnEfpo4vI2b0zxlItdgpALLT9XuYog9rBvCa6G943RX4qA5wO0MtkZl3mcTqgDpImX7qsYnhY9cZWWgOqxYiNX0ksUDoggLES6QI9s1XVaKh4fd0bTQ%2BF9kBw8s%2BJ%2FaVU1TwFWWLJDHmMPwL6ZUV6bvMdmjPcG6aFz3lru8gPARpK0YlmQwu6Ol5QU6tAFf7vS%2B1BXojpfdrukDGETT2BJQlXwWYhY%2F4SH2PnmzSW%2BOWqFiVeuSGtpzWetonvYspUAAt9zO24zb0Ap2SSIzKn8Zd6qnzjEZzI8rLe3i9CmoZ%2BlfC41rZvNeYEqxWapay%2F8ygSZUDYTvHj93Vj4eFdu1uHVL5Tm2vFs8ukNDDlS6hdp3Zk3UaM1QfDkLksa8fEjCwFldyOdIcfhoykJHNM8%2FpdBmA%2Ffqz%2FBk7HaV8kgtL9Y%3D&amp;AWSAccessKeyId=ASIAQ3PHCVTYQ3ZV253X&amp;Expires=1554601073&amp;Signature=OeSwkuAFTu2MZ2agSyHzQz7OZww%3D&amp;hash=0185f4d47582fa2a2ee2c35cf986b0fd9e15d14bd40721c8e67816d7851da17e&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1361841516301839&amp;tid=spdf-b5e3157c-b347-43ad-bbd6-0d660c93b8f7&amp;sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&amp;type=client\" target=\"_blank\" rel=\"noopener\">Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.</a></p>\n<h2 id=\"Standpoint-4\"><a href=\"#Standpoint-4\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p> The heterogeneous appearance of lesions including the large variability in location, size, shape and frequency make it difficult to devise effective segmentation rules. It is thus highly non-trivial to delineate contu- sions, oedema and haemorrhages in TBI, or sub-components of brain tumours such as proliferating cells and necrotic core.</p>\n<h2 id=\"Innovation-4\"><a href=\"#Innovation-4\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p> They  propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. </p>\n<h1 id=\"HyperDense-Net-A-Hyper-densely-Connected-CNN-for-Multi-modal-Image-Segmentation\"><a href=\"#HyperDense-Net-A-Hyper-densely-Connected-CNN-for-Multi-modal-Image-Segmentation\" class=\"headerlink\" title=\"HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation\"></a>HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation</h1><p><a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8515234\" target=\"_blank\" rel=\"noopener\">Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.</a></p>\n<h2 id=\"Standpoint-5\"><a href=\"#Standpoint-5\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>Dense connections have attracted substantial attention in computer vision because they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet, which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances in natural image classification tasks.</p>\n<h2 id=\"Innovation-5\"><a href=\"#Innovation-5\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>They propose HyperDenseNet, a 3D fully convolutional neural network that extends the definition of dense connectivity to multi-modal segmentation problems. Each imaging modality has a path, and dense connections occur not only between the pairs of layers within the same path, but also between those across different paths.</p>\n<h1 id=\"A-Deep-Learning-model-integrating-FCNNs-and-CRFs-for-brain-tumor-segmentation\"><a href=\"#A-Deep-Learning-model-integrating-FCNNs-and-CRFs-for-brain-tumor-segmentation\" class=\"headerlink\" title=\"A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation\"></a>A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation</h1><p><a href=\"https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841517X0008X/1-s2.0-S136184151730141X/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFsaCXVzLWVhc3QtMSJHMEUCIQCmFiL2ekwH7KF8z%2Fc0vWR0Ac9yL8K5oGv5DOeBI7VJhQIgfy%2FpbMeHw7IWu30Pc%2FGwfPGxvuI5Calk%2Bgjx2fm5U8wq2gMIJBACGgwwNTkwMDM1NDY4NjUiDIGTbcyCi60TQJ8PRyq3A1%2Fzz%2B3VHHOekK%2FJw6MU%2FZqrd9oySC4b6nKbDevYilRhqIjYFRKlF1Ij0YgzO2xl2qPCJA1Luoh3fIm4CfQomsuNh0vwUU4VcwwTOdRKW4Biycm5IxXEePAh2xuIUSBB%2B%2BRbOIwmmHKraKf8UaAlFLz%2FxDHEPqk%2Ft8WllncOm3fus26FVvSt6tBpAiUmIlWi%2B8a%2BiJ6GF61aZBjlsGbZhDHS%2BtsTXMdRysCnSdGTClkKbVshva2YJUU7dM%2BqzxrrGCTCDCFYq%2Fo%2FCszl%2BTV%2BperpIIltFrMZdVk1g%2FnAmD35O%2Bsgk1V4iQiYrdXAvCcNO1Vt7gmaTg8k4lZjXacSw52vrDW76YcU%2FOWq7BYkFB8v3CTeIH0pPvvDmLRbSOYt7HmYWMuSTR5AS5DgrJvY2al3UczqOK8rYSN4qcu5GdgNa7fzvQaouXF2SHQ%2FVj9sH8agALf0MbOzTOH43EadU5ATM8X3JYwWEh9bP7mPor3cQm1VHvDz0Eq9NtduHt2r9EYQ0nqR22AmBAfSYbaf1yz55k6bwUtqukP5IJm6BCeeaVbaz9zB0rVbAHdUCh3tgnqsds%2Fvlf4wy7%2Bl5QU6tAFpdYJnVeDFfg8QKDDpZ9fcsFs5bdMoGPRaU8hY495aNV4QleUmufJAirYtZvSZAQbZGelsALa1gT7OwuMDACZ76e3FyfsRjc9sgQIWXy73%2FvnbUIiSAH%2F0BUiE0Sfq%2FXB2gzShepFEjd1nIf9nrzmKl8TLiMxWQm%2F7txg8Y4ndrsBnq1YWoYn9nkg6MF4a5Hy6M4W2hBk%2FOq1MpN1%2Bh20l%2FhkH%2BUDkInb5ni4zsRTuPDTvgi0%3D&amp;AWSAccessKeyId=ASIAQ3PHCVTYRA73P2UO&amp;Expires=1554605840&amp;Signature=mupLWqHKaKQuDReHsSReahixCgc%3D&amp;hash=d7e362b71f1842d8657ac4a022fe9b558190b5ecd29082efd89e41cda056cd25&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S136184151730141X&amp;tid=spdf-ff9d6147-ba0b-4dfc-b397-32911281b48b&amp;sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&amp;type=client\" target=\"_blank\" rel=\"noopener\">Zhao X, Wu Y, Song G, et al. A deep learning model integrating FCNNs and CRFs for brain tumor segmentation[J]. Medical image analysis, 2018, 43: 98-111</a></p>\n<h2 id=\"Standpoint-6\"><a href=\"#Standpoint-6\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation.</p>\n<h2 id=\"Innovation-6\"><a href=\"#Innovation-6\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>Build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency.</p>\n<h1 id=\"U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation\"><a href=\"#U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation\" class=\"headerlink\" title=\"U-Net: Convolutional Networks for Biomedical Image Segmentation\"></a>U-Net: Convolutional Networks for Biomedical Image Segmentation</h1><p><a href=\"https://arxiv.org/pdf/1505.04597.pdf\" target=\"_blank\" rel=\"noopener\">Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.</a></p>\n<h2 id=\"Standpoint-7\"><a href=\"#Standpoint-7\" class=\"headerlink\" title=\"Standpoint\"></a>Standpoint</h2><p>There is large consent that successful training of deep networks requires many thousand annotated training samples.</p>\n<h2 id=\"Innovation-7\"><a href=\"#Innovation-7\" class=\"headerlink\" title=\"Innovation\"></a>Innovation</h2><p>In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently.</p>\n<h2 id=\"Review\"><a href=\"#Review\" class=\"headerlink\" title=\"Review\"></a>Review</h2><p>This architecture is very useful in many medical image segmentation task, so is it the best architecture?</p>\n<p>The novel architecture is not emphasized in this paper, but this paper propose U-Net that has been a popular network architecture.</p>\n"},{"title":"概率图模型","date":"2018-03-23T08:35:46.000Z","_content":"# 贝叶斯网络 Bayesian Network\n贝叶斯网络是概率图模型的一种结构，通过有向无环图来表示模型中的关联性。在特定的图结构中，节点表示随机变量，有向边表示相连的变量之间的因果关系。\n\n## 贝叶斯网的链式法则\n$$ P(X_1, X_2, ..., X_n) = \\Pi_{i=1:n}P(X_i \\mid Parents(X_i)) $$\n\n## I-Map和P-Map\n令P为X上的分布，$I(P)$是满足$(X&perp; Y\\mid Z)$的独立性断言的集合。I(G)表示图G上独立性关系的集合，如果$ I(G) \\subseteq  I(P) $，则可成G为P的I-Map。\n显然只要某个图的独立性关机集合是I(P)的子集，其对应的图就是I-Map，所以I-Map有很多个，只有当I(G)=I(P)时，对应的图可以等价的表示这个概率分布，G就叫做P的P-Map(Perfect-Map)。\n\n## 独立性\n\n### 局部马尔科夫独立性\n记$ Pa_{x_i} $是图G中$ X_i $的父节点，将图G中不是$X_i$后代的子节点变量记为$ NonDescendants_{X_i} $。G满足如下的条件独立性论断$I_l(G)$：$ X_i &perp; NonDescendants_{X_i}\\mid Pa_{x_i}:\\forall i$，也就是说在\n\n给定父节点的情况下，子节点间相互独立。\n\n### 全局马尔科夫独立性\n全局的马尔科夫独立性与d-分离有关，如果在给定Z的情况下，节点X和Y独立，则X和Y是D-separation。\n\n迹是三个变量相连的路径，比如X，Y，Z。迹有三种形式：\n- Causal Trail $ X \\to Z \\to Y $: 有效当且仅当Z不可观。\n+ Evidential Trail $X \\leftarrow Z \\leftarrow Y$: 有效当且仅当Z不可观。\n* Common Cause $X \\leftarrow Z \\to Y$：有效当且仅当Z不可观。\n- Common Effect $ X \\to Z \\leftarrow Y $：有效当且仅当Z（或者是其他后代）可观。\n\n与d-分离想对应的独立性的集合用I(G)表示：\n$$I(G)=\\lbrace(X &perp; Y\\mid Z):d-sep_G(X;Y\\mid Z)\\rbrace $$\n上面的集合也叫做全局马尔科夫的独立性。\n\n## 可靠性与完备性\n* d-分离的可靠性与贝叶斯网络因子分离定理有关,如果分布P根据G因子分解，那么，$I(G)\\subseteq I(P)$。\n* 对于任意的分布P根据G因子分解，如果$ (X &perp; Y|Z) \\in I(P)$，那么就有$dsep_G(X; Y\\mid Z)\\in I(P)$\n* G是一个贝叶斯网络结构的图，如果给定Z时X和Y不是在图G中d-分离的，那么X和Y在某些图G上的因子分解分布P中相互依赖。\n* 对于几乎所有的在G上的因子分解的分布P，$I(P)=I(G)$。几乎所有指的是对于参数化条件概率空间中除了测度为0的分布。\n\n# 马尔科夫网络 Markov Network\n上面是有向图模型，又叫做贝叶斯网络，下面我们来看一下无向图模型，也被叫做马尔科夫网。\n如下的式子必须使用马尔科夫网：\n$$A \\perp C\\mid \\lbrace B, D \\rbrace, B \\perp D\\mid \\lbrace A, B\\rbrace$$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%97%A0%E5%90%91%E5%9B%BE.jpg)\nclique就是指的强连通的团，通常翻译为团，每个团会定义一个势函数(potential function)。\n无向图模型可以通过一个给定的无向图来表示概率分布$P(X_1,...X_n)$，每一个在图H中的团$c\\in C$代表一组正势函数$\\psi_c$，比如：\n$$P(X_1, ..., X_n)=\\frac{1}{Z}\\prod_{c\\in C}\\psi_c(X_c)$$\n\n其中Z是配分函数(partition function)，是一个归一化的常数：\n$$Z=\\sum_{X_1, ..., X_n}\\prod_{c\\in C}\\psi_c(X_c)$$\n\n\n\n## 全局马尔科夫独立性\n如果在给定节点集B时，任意两个节点A和C中的节点之间没有路径，那么则称B在图H中分离A和B。\n如果对于任意不连接的A，B，C，比如B分离A和C，也就说在给定C的情况下，A和C独立，那么该概率分布满足全局马尔科夫独立性。\n$$I(H)=\\lbrace A \\perp C\\mid B:sep_H(A;C\\mid B)\\rbrace$$\n\n### 完备性\nH是一个马尔科夫网结构，如果在给定Z时，X与Y在图H中不可分离，则在给定Z时，X与Y在因子分解的分布中存在依赖关系。\n\n### 可靠性\n* P为X上的正分布，而H为X上的一个马尔科夫网结构。如果P是在图H上的吉布斯分布，那么H是P的I-Map。\n* P为X上的分布，而H为X上的一个马尔科夫网结构。如果H是P的一个I-Map，则P是可以再H上分解的一个吉布斯分布。\n\n## 局部马尔科夫独立性\nH=(V,E)是一个马尔科夫网，与H相关的成对独立性定义如下：\n$$I_P(H)=\\lbrace (X \\perp Y \\mid V-\\lbrace X, Y\\rbrace):X-Y\\notin H\\rbrace$$\n对于给定的图H=(V,E),X在H中的马尔科夫毯$$MB_H(X)$$定义为X在H中的近邻。与H相关的局部独立性定义如下：\n$$I_l(H)=\\lbrace(X \\perp V-\\lbrace X\\rbrace -MB_{H}(X)\\mid MB_{H}(X)):X\\in V\\rbrace$$\n\n## 局部马尔科夫性与全局马尔科夫性的联系\n$$P\\models I_l(H)\\Rightarrow P\\models I_P(H)$$  $$P=I(H)\\Rightarrow P\\models I_l(H)$$  $$P>0\\  and\\  P\\models I_p(H) \\Rightarrow P\\models I(H)$$\n推论：对于一个正分布P，全局、局部和成对独立性是等价的。\n\n## 团(cliques)\n团是一个完全子图(complete graph)，最大团是最大可能的完全子图。最大的团记作max-clique，不是最大的团记作sub-cliques。\n\n## 对数线性模型\n$$P(X_1,...,X_n)=\\frac{1}{Z} exp[-\\sum_{i=1}^k \\omega_c(X_c)]$$\n## Perfect Maps\n只要分布的分离特性与独立特性一致，马尔科夫网就可以是分布的一个P-Map。然而，就像是贝叶斯网，不是所有的分布都能用无向图来表示。实际上，无向图和有向图不恩能够完全的表达分布的空间。\n\n## 模型实例　\n### 波尔兹曼机\n波尔兹曼机的连接方式如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/波尔兹曼机示意图.png)\n波尔兹曼机是一个全连接的图，每条无向边表示一对依赖关系，节点是二值变量。\n上图的联合概率分布如下：\n$$\nP(x_1, x_2, x_3, x_4)=\\frac{1}{Z}exp\\lbrace \\sum_{i,j}\\phi_{ij}(x_i, x_j)\\rbrace\n=\\frac{1}{Z}exp\\lbrace\\sum_{i,j}\\theta_{ij}x_ix_j+\\sum_i\\alpha_i x_i + C \\rbrace\n=\\frac{1}{Z}exp\\lbrace(x-\\mu)^T\\Theta(x-\\mu)\\rbrace\n$$\n\n### 受限波尔兹曼机\n受限波尔兹曼机通常有很多层构成，每个层中有两个子层，一个隐藏层，另一个是可见层。RBM的概率分布函数：\n$$P(x,h\\mid \\theta)=exp\\lbrace\\sum_i\\theta_i\\phi_i(x_i)+\\sum_j\\theta_j\\phi_j(h_j)+\\sum_{i,j}\\theta_{i,j}\\phi_{i,j}(x_i,h_j)-A(\\theta)\\rbrace$$\nRBM的因子是边际相关的，在给定可观的节点的情况下因子是条件独立的。可以进行迭代吉布斯采样。\n\n### 条件随机场\n条件随机场是一种判别式的无向图模型，通过观测序列得到标记序列。CRF并没有假定各个特征值之间的独立性，概率分布如下：\n$$P_\\theta(y\\mid x)=\\frac{1}{Z}exp\\lbrace \\sum_{e\\in E,k}\\lambda_k f_k(e,y\\mid_e,s)+\\sum_{v\\in V,k}\\mu_k g_k(v,y\\mid_v,x)\\rbrace$$\n其中，x是观测序列(数据序列)，y是标记序列，v是标记随机变量集V的顶点，e是来自边集E的边。k是特证序号，$f_k$是固定的二值特征函数，$g_k$是给定的二值顶点特征。$\\theta=(\\lambda_1, ..., \\lambda_n;\\mu_1, ..., \\mu_n)$是需要估计的参数$y\\mid_e$是由e定义的y的集合，$y\\mid_v$是由v定义的y的集合。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%9C%BA.png)\n\n## 总结\n* 无向图模型表明了变量间的相互关系（relatedness），而不是因果关系（causality）。\n* 无向图可以定义联合或者独立分布。\n\n\n\n# 参考文献\nhttp://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\nKoller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.\n周志华. 机器学习[M]. 清华大学出版社, 2016.\n","source":"_posts/概率图模型.md","raw":"---\ntitle: 概率图模型\ndate: 2018-03-23 16:35:46\ntags: 概率图模型\ncategories: 学习\n---\n# 贝叶斯网络 Bayesian Network\n贝叶斯网络是概率图模型的一种结构，通过有向无环图来表示模型中的关联性。在特定的图结构中，节点表示随机变量，有向边表示相连的变量之间的因果关系。\n\n## 贝叶斯网的链式法则\n$$ P(X_1, X_2, ..., X_n) = \\Pi_{i=1:n}P(X_i \\mid Parents(X_i)) $$\n\n## I-Map和P-Map\n令P为X上的分布，$I(P)$是满足$(X&perp; Y\\mid Z)$的独立性断言的集合。I(G)表示图G上独立性关系的集合，如果$ I(G) \\subseteq  I(P) $，则可成G为P的I-Map。\n显然只要某个图的独立性关机集合是I(P)的子集，其对应的图就是I-Map，所以I-Map有很多个，只有当I(G)=I(P)时，对应的图可以等价的表示这个概率分布，G就叫做P的P-Map(Perfect-Map)。\n\n## 独立性\n\n### 局部马尔科夫独立性\n记$ Pa_{x_i} $是图G中$ X_i $的父节点，将图G中不是$X_i$后代的子节点变量记为$ NonDescendants_{X_i} $。G满足如下的条件独立性论断$I_l(G)$：$ X_i &perp; NonDescendants_{X_i}\\mid Pa_{x_i}:\\forall i$，也就是说在\n\n给定父节点的情况下，子节点间相互独立。\n\n### 全局马尔科夫独立性\n全局的马尔科夫独立性与d-分离有关，如果在给定Z的情况下，节点X和Y独立，则X和Y是D-separation。\n\n迹是三个变量相连的路径，比如X，Y，Z。迹有三种形式：\n- Causal Trail $ X \\to Z \\to Y $: 有效当且仅当Z不可观。\n+ Evidential Trail $X \\leftarrow Z \\leftarrow Y$: 有效当且仅当Z不可观。\n* Common Cause $X \\leftarrow Z \\to Y$：有效当且仅当Z不可观。\n- Common Effect $ X \\to Z \\leftarrow Y $：有效当且仅当Z（或者是其他后代）可观。\n\n与d-分离想对应的独立性的集合用I(G)表示：\n$$I(G)=\\lbrace(X &perp; Y\\mid Z):d-sep_G(X;Y\\mid Z)\\rbrace $$\n上面的集合也叫做全局马尔科夫的独立性。\n\n## 可靠性与完备性\n* d-分离的可靠性与贝叶斯网络因子分离定理有关,如果分布P根据G因子分解，那么，$I(G)\\subseteq I(P)$。\n* 对于任意的分布P根据G因子分解，如果$ (X &perp; Y|Z) \\in I(P)$，那么就有$dsep_G(X; Y\\mid Z)\\in I(P)$\n* G是一个贝叶斯网络结构的图，如果给定Z时X和Y不是在图G中d-分离的，那么X和Y在某些图G上的因子分解分布P中相互依赖。\n* 对于几乎所有的在G上的因子分解的分布P，$I(P)=I(G)$。几乎所有指的是对于参数化条件概率空间中除了测度为0的分布。\n\n# 马尔科夫网络 Markov Network\n上面是有向图模型，又叫做贝叶斯网络，下面我们来看一下无向图模型，也被叫做马尔科夫网。\n如下的式子必须使用马尔科夫网：\n$$A \\perp C\\mid \\lbrace B, D \\rbrace, B \\perp D\\mid \\lbrace A, B\\rbrace$$\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%97%A0%E5%90%91%E5%9B%BE.jpg)\nclique就是指的强连通的团，通常翻译为团，每个团会定义一个势函数(potential function)。\n无向图模型可以通过一个给定的无向图来表示概率分布$P(X_1,...X_n)$，每一个在图H中的团$c\\in C$代表一组正势函数$\\psi_c$，比如：\n$$P(X_1, ..., X_n)=\\frac{1}{Z}\\prod_{c\\in C}\\psi_c(X_c)$$\n\n其中Z是配分函数(partition function)，是一个归一化的常数：\n$$Z=\\sum_{X_1, ..., X_n}\\prod_{c\\in C}\\psi_c(X_c)$$\n\n\n\n## 全局马尔科夫独立性\n如果在给定节点集B时，任意两个节点A和C中的节点之间没有路径，那么则称B在图H中分离A和B。\n如果对于任意不连接的A，B，C，比如B分离A和C，也就说在给定C的情况下，A和C独立，那么该概率分布满足全局马尔科夫独立性。\n$$I(H)=\\lbrace A \\perp C\\mid B:sep_H(A;C\\mid B)\\rbrace$$\n\n### 完备性\nH是一个马尔科夫网结构，如果在给定Z时，X与Y在图H中不可分离，则在给定Z时，X与Y在因子分解的分布中存在依赖关系。\n\n### 可靠性\n* P为X上的正分布，而H为X上的一个马尔科夫网结构。如果P是在图H上的吉布斯分布，那么H是P的I-Map。\n* P为X上的分布，而H为X上的一个马尔科夫网结构。如果H是P的一个I-Map，则P是可以再H上分解的一个吉布斯分布。\n\n## 局部马尔科夫独立性\nH=(V,E)是一个马尔科夫网，与H相关的成对独立性定义如下：\n$$I_P(H)=\\lbrace (X \\perp Y \\mid V-\\lbrace X, Y\\rbrace):X-Y\\notin H\\rbrace$$\n对于给定的图H=(V,E),X在H中的马尔科夫毯$$MB_H(X)$$定义为X在H中的近邻。与H相关的局部独立性定义如下：\n$$I_l(H)=\\lbrace(X \\perp V-\\lbrace X\\rbrace -MB_{H}(X)\\mid MB_{H}(X)):X\\in V\\rbrace$$\n\n## 局部马尔科夫性与全局马尔科夫性的联系\n$$P\\models I_l(H)\\Rightarrow P\\models I_P(H)$$  $$P=I(H)\\Rightarrow P\\models I_l(H)$$  $$P>0\\  and\\  P\\models I_p(H) \\Rightarrow P\\models I(H)$$\n推论：对于一个正分布P，全局、局部和成对独立性是等价的。\n\n## 团(cliques)\n团是一个完全子图(complete graph)，最大团是最大可能的完全子图。最大的团记作max-clique，不是最大的团记作sub-cliques。\n\n## 对数线性模型\n$$P(X_1,...,X_n)=\\frac{1}{Z} exp[-\\sum_{i=1}^k \\omega_c(X_c)]$$\n## Perfect Maps\n只要分布的分离特性与独立特性一致，马尔科夫网就可以是分布的一个P-Map。然而，就像是贝叶斯网，不是所有的分布都能用无向图来表示。实际上，无向图和有向图不恩能够完全的表达分布的空间。\n\n## 模型实例　\n### 波尔兹曼机\n波尔兹曼机的连接方式如下图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/波尔兹曼机示意图.png)\n波尔兹曼机是一个全连接的图，每条无向边表示一对依赖关系，节点是二值变量。\n上图的联合概率分布如下：\n$$\nP(x_1, x_2, x_3, x_4)=\\frac{1}{Z}exp\\lbrace \\sum_{i,j}\\phi_{ij}(x_i, x_j)\\rbrace\n=\\frac{1}{Z}exp\\lbrace\\sum_{i,j}\\theta_{ij}x_ix_j+\\sum_i\\alpha_i x_i + C \\rbrace\n=\\frac{1}{Z}exp\\lbrace(x-\\mu)^T\\Theta(x-\\mu)\\rbrace\n$$\n\n### 受限波尔兹曼机\n受限波尔兹曼机通常有很多层构成，每个层中有两个子层，一个隐藏层，另一个是可见层。RBM的概率分布函数：\n$$P(x,h\\mid \\theta)=exp\\lbrace\\sum_i\\theta_i\\phi_i(x_i)+\\sum_j\\theta_j\\phi_j(h_j)+\\sum_{i,j}\\theta_{i,j}\\phi_{i,j}(x_i,h_j)-A(\\theta)\\rbrace$$\nRBM的因子是边际相关的，在给定可观的节点的情况下因子是条件独立的。可以进行迭代吉布斯采样。\n\n### 条件随机场\n条件随机场是一种判别式的无向图模型，通过观测序列得到标记序列。CRF并没有假定各个特征值之间的独立性，概率分布如下：\n$$P_\\theta(y\\mid x)=\\frac{1}{Z}exp\\lbrace \\sum_{e\\in E,k}\\lambda_k f_k(e,y\\mid_e,s)+\\sum_{v\\in V,k}\\mu_k g_k(v,y\\mid_v,x)\\rbrace$$\n其中，x是观测序列(数据序列)，y是标记序列，v是标记随机变量集V的顶点，e是来自边集E的边。k是特证序号，$f_k$是固定的二值特征函数，$g_k$是给定的二值顶点特征。$\\theta=(\\lambda_1, ..., \\lambda_n;\\mu_1, ..., \\mu_n)$是需要估计的参数$y\\mid_e$是由e定义的y的集合，$y\\mid_v$是由v定义的y的集合。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%9C%BA.png)\n\n## 总结\n* 无向图模型表明了变量间的相互关系（relatedness），而不是因果关系（causality）。\n* 无向图可以定义联合或者独立分布。\n\n\n\n# 参考文献\nhttp://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\nKoller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.\n周志华. 机器学习[M]. 清华大学出版社, 2016.\n","slug":"概率图模型","published":1,"updated":"2018-09-22T06:32:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msz00131ouzo7w82ov6","content":"<h1 id=\"贝叶斯网络-Bayesian-Network\"><a href=\"#贝叶斯网络-Bayesian-Network\" class=\"headerlink\" title=\"贝叶斯网络 Bayesian Network\"></a>贝叶斯网络 Bayesian Network</h1><p>贝叶斯网络是概率图模型的一种结构，通过有向无环图来表示模型中的关联性。在特定的图结构中，节点表示随机变量，有向边表示相连的变量之间的因果关系。</p>\n<h2 id=\"贝叶斯网的链式法则\"><a href=\"#贝叶斯网的链式法则\" class=\"headerlink\" title=\"贝叶斯网的链式法则\"></a>贝叶斯网的链式法则</h2><p>$$ P(X_1, X_2, …, X_n) = \\Pi_{i=1:n}P(X_i \\mid Parents(X_i)) $$</p>\n<h2 id=\"I-Map和P-Map\"><a href=\"#I-Map和P-Map\" class=\"headerlink\" title=\"I-Map和P-Map\"></a>I-Map和P-Map</h2><p>令P为X上的分布，$I(P)$是满足$(X&perp; Y\\mid Z)$的独立性断言的集合。I(G)表示图G上独立性关系的集合，如果$ I(G) \\subseteq  I(P) $，则可成G为P的I-Map。<br>显然只要某个图的独立性关机集合是I(P)的子集，其对应的图就是I-Map，所以I-Map有很多个，只有当I(G)=I(P)时，对应的图可以等价的表示这个概率分布，G就叫做P的P-Map(Perfect-Map)。</p>\n<h2 id=\"独立性\"><a href=\"#独立性\" class=\"headerlink\" title=\"独立性\"></a>独立性</h2><h3 id=\"局部马尔科夫独立性\"><a href=\"#局部马尔科夫独立性\" class=\"headerlink\" title=\"局部马尔科夫独立性\"></a>局部马尔科夫独立性</h3><p>记$ Pa_{x_i} $是图G中$ X_i $的父节点，将图G中不是$X_i$后代的子节点变量记为$ NonDescendants_{X_i} $。G满足如下的条件独立性论断$I_l(G)$：$ X_i &perp; NonDescendants_{X_i}\\mid Pa_{x_i}:\\forall i$，也就是说在</p>\n<p>给定父节点的情况下，子节点间相互独立。</p>\n<h3 id=\"全局马尔科夫独立性\"><a href=\"#全局马尔科夫独立性\" class=\"headerlink\" title=\"全局马尔科夫独立性\"></a>全局马尔科夫独立性</h3><p>全局的马尔科夫独立性与d-分离有关，如果在给定Z的情况下，节点X和Y独立，则X和Y是D-separation。</p>\n<p>迹是三个变量相连的路径，比如X，Y，Z。迹有三种形式：</p>\n<ul>\n<li>Causal Trail $ X \\to Z \\to Y $: 有效当且仅当Z不可观。</li>\n</ul>\n<ul>\n<li>Evidential Trail $X \\leftarrow Z \\leftarrow Y$: 有效当且仅当Z不可观。</li>\n</ul>\n<ul>\n<li>Common Cause $X \\leftarrow Z \\to Y$：有效当且仅当Z不可观。</li>\n</ul>\n<ul>\n<li>Common Effect $ X \\to Z \\leftarrow Y $：有效当且仅当Z（或者是其他后代）可观。</li>\n</ul>\n<p>与d-分离想对应的独立性的集合用I(G)表示：<br>$$I(G)=\\lbrace(X &perp; Y\\mid Z):d-sep_G(X;Y\\mid Z)\\rbrace $$<br>上面的集合也叫做全局马尔科夫的独立性。</p>\n<h2 id=\"可靠性与完备性\"><a href=\"#可靠性与完备性\" class=\"headerlink\" title=\"可靠性与完备性\"></a>可靠性与完备性</h2><ul>\n<li>d-分离的可靠性与贝叶斯网络因子分离定理有关,如果分布P根据G因子分解，那么，$I(G)\\subseteq I(P)$。</li>\n<li>对于任意的分布P根据G因子分解，如果$ (X &perp; Y|Z) \\in I(P)$，那么就有$dsep_G(X; Y\\mid Z)\\in I(P)$</li>\n<li>G是一个贝叶斯网络结构的图，如果给定Z时X和Y不是在图G中d-分离的，那么X和Y在某些图G上的因子分解分布P中相互依赖。</li>\n<li>对于几乎所有的在G上的因子分解的分布P，$I(P)=I(G)$。几乎所有指的是对于参数化条件概率空间中除了测度为0的分布。</li>\n</ul>\n<h1 id=\"马尔科夫网络-Markov-Network\"><a href=\"#马尔科夫网络-Markov-Network\" class=\"headerlink\" title=\"马尔科夫网络 Markov Network\"></a>马尔科夫网络 Markov Network</h1><p>上面是有向图模型，又叫做贝叶斯网络，下面我们来看一下无向图模型，也被叫做马尔科夫网。<br>如下的式子必须使用马尔科夫网：<br>$$A \\perp C\\mid \\lbrace B, D \\rbrace, B \\perp D\\mid \\lbrace A, B\\rbrace$$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%97%A0%E5%90%91%E5%9B%BE.jpg\" alt><br>clique就是指的强连通的团，通常翻译为团，每个团会定义一个势函数(potential function)。<br>无向图模型可以通过一个给定的无向图来表示概率分布$P(X_1,…X_n)$，每一个在图H中的团$c\\in C$代表一组正势函数$\\psi_c$，比如：<br>$$P(X_1, …, X_n)=\\frac{1}{Z}\\prod_{c\\in C}\\psi_c(X_c)$$</p>\n<p>其中Z是配分函数(partition function)，是一个归一化的常数：<br>$$Z=\\sum_{X_1, …, X_n}\\prod_{c\\in C}\\psi_c(X_c)$$</p>\n<h2 id=\"全局马尔科夫独立性-1\"><a href=\"#全局马尔科夫独立性-1\" class=\"headerlink\" title=\"全局马尔科夫独立性\"></a>全局马尔科夫独立性</h2><p>如果在给定节点集B时，任意两个节点A和C中的节点之间没有路径，那么则称B在图H中分离A和B。<br>如果对于任意不连接的A，B，C，比如B分离A和C，也就说在给定C的情况下，A和C独立，那么该概率分布满足全局马尔科夫独立性。<br>$$I(H)=\\lbrace A \\perp C\\mid B:sep_H(A;C\\mid B)\\rbrace$$</p>\n<h3 id=\"完备性\"><a href=\"#完备性\" class=\"headerlink\" title=\"完备性\"></a>完备性</h3><p>H是一个马尔科夫网结构，如果在给定Z时，X与Y在图H中不可分离，则在给定Z时，X与Y在因子分解的分布中存在依赖关系。</p>\n<h3 id=\"可靠性\"><a href=\"#可靠性\" class=\"headerlink\" title=\"可靠性\"></a>可靠性</h3><ul>\n<li>P为X上的正分布，而H为X上的一个马尔科夫网结构。如果P是在图H上的吉布斯分布，那么H是P的I-Map。</li>\n<li>P为X上的分布，而H为X上的一个马尔科夫网结构。如果H是P的一个I-Map，则P是可以再H上分解的一个吉布斯分布。</li>\n</ul>\n<h2 id=\"局部马尔科夫独立性-1\"><a href=\"#局部马尔科夫独立性-1\" class=\"headerlink\" title=\"局部马尔科夫独立性\"></a>局部马尔科夫独立性</h2><p>H=(V,E)是一个马尔科夫网，与H相关的成对独立性定义如下：<br>$$I_P(H)=\\lbrace (X \\perp Y \\mid V-\\lbrace X, Y\\rbrace):X-Y\\notin H\\rbrace$$<br>对于给定的图H=(V,E),X在H中的马尔科夫毯$$MB_H(X)$$定义为X在H中的近邻。与H相关的局部独立性定义如下：<br>$$I_l(H)=\\lbrace(X \\perp V-\\lbrace X\\rbrace -MB_{H}(X)\\mid MB_{H}(X)):X\\in V\\rbrace$$</p>\n<h2 id=\"局部马尔科夫性与全局马尔科夫性的联系\"><a href=\"#局部马尔科夫性与全局马尔科夫性的联系\" class=\"headerlink\" title=\"局部马尔科夫性与全局马尔科夫性的联系\"></a>局部马尔科夫性与全局马尔科夫性的联系</h2><p>$$P\\models I_l(H)\\Rightarrow P\\models I_P(H)$$  $$P=I(H)\\Rightarrow P\\models I_l(H)$$  $$P&gt;0\\  and\\  P\\models I_p(H) \\Rightarrow P\\models I(H)$$<br>推论：对于一个正分布P，全局、局部和成对独立性是等价的。</p>\n<h2 id=\"团-cliques\"><a href=\"#团-cliques\" class=\"headerlink\" title=\"团(cliques)\"></a>团(cliques)</h2><p>团是一个完全子图(complete graph)，最大团是最大可能的完全子图。最大的团记作max-clique，不是最大的团记作sub-cliques。</p>\n<h2 id=\"对数线性模型\"><a href=\"#对数线性模型\" class=\"headerlink\" title=\"对数线性模型\"></a>对数线性模型</h2><p>$$P(X_1,…,X_n)=\\frac{1}{Z} exp[-\\sum_{i=1}^k \\omega_c(X_c)]$$</p>\n<h2 id=\"Perfect-Maps\"><a href=\"#Perfect-Maps\" class=\"headerlink\" title=\"Perfect Maps\"></a>Perfect Maps</h2><p>只要分布的分离特性与独立特性一致，马尔科夫网就可以是分布的一个P-Map。然而，就像是贝叶斯网，不是所有的分布都能用无向图来表示。实际上，无向图和有向图不恩能够完全的表达分布的空间。</p>\n<h2 id=\"模型实例\"><a href=\"#模型实例\" class=\"headerlink\" title=\"模型实例　\"></a>模型实例　</h2><h3 id=\"波尔兹曼机\"><a href=\"#波尔兹曼机\" class=\"headerlink\" title=\"波尔兹曼机\"></a>波尔兹曼机</h3><p>波尔兹曼机的连接方式如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/波尔兹曼机示意图.png\" alt><br>波尔兹曼机是一个全连接的图，每条无向边表示一对依赖关系，节点是二值变量。<br>上图的联合概率分布如下：<br>$$<br>P(x_1, x_2, x_3, x_4)=\\frac{1}{Z}exp\\lbrace \\sum_{i,j}\\phi_{ij}(x_i, x_j)\\rbrace<br>=\\frac{1}{Z}exp\\lbrace\\sum_{i,j}\\theta_{ij}x_ix_j+\\sum_i\\alpha_i x_i + C \\rbrace<br>=\\frac{1}{Z}exp\\lbrace(x-\\mu)^T\\Theta(x-\\mu)\\rbrace<br>$$</p>\n<h3 id=\"受限波尔兹曼机\"><a href=\"#受限波尔兹曼机\" class=\"headerlink\" title=\"受限波尔兹曼机\"></a>受限波尔兹曼机</h3><p>受限波尔兹曼机通常有很多层构成，每个层中有两个子层，一个隐藏层，另一个是可见层。RBM的概率分布函数：<br>$$P(x,h\\mid \\theta)=exp\\lbrace\\sum_i\\theta_i\\phi_i(x_i)+\\sum_j\\theta_j\\phi_j(h_j)+\\sum_{i,j}\\theta_{i,j}\\phi_{i,j}(x_i,h_j)-A(\\theta)\\rbrace$$<br>RBM的因子是边际相关的，在给定可观的节点的情况下因子是条件独立的。可以进行迭代吉布斯采样。</p>\n<h3 id=\"条件随机场\"><a href=\"#条件随机场\" class=\"headerlink\" title=\"条件随机场\"></a>条件随机场</h3><p>条件随机场是一种判别式的无向图模型，通过观测序列得到标记序列。CRF并没有假定各个特征值之间的独立性，概率分布如下：<br>$$P_\\theta(y\\mid x)=\\frac{1}{Z}exp\\lbrace \\sum_{e\\in E,k}\\lambda_k f_k(e,y\\mid_e,s)+\\sum_{v\\in V,k}\\mu_k g_k(v,y\\mid_v,x)\\rbrace$$<br>其中，x是观测序列(数据序列)，y是标记序列，v是标记随机变量集V的顶点，e是来自边集E的边。k是特证序号，$f_k$是固定的二值特征函数，$g_k$是给定的二值顶点特征。$\\theta=(\\lambda_1, …, \\lambda_n;\\mu_1, …, \\mu_n)$是需要估计的参数$y\\mid_e$是由e定义的y的集合，$y\\mid_v$是由v定义的y的集合。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%9C%BA.png\" alt></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>无向图模型表明了变量间的相互关系（relatedness），而不是因果关系（causality）。</li>\n<li>无向图可以定义联合或者独立分布。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p><a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.<br>周志华. 机器学习[M]. 清华大学出版社, 2016.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"贝叶斯网络-Bayesian-Network\"><a href=\"#贝叶斯网络-Bayesian-Network\" class=\"headerlink\" title=\"贝叶斯网络 Bayesian Network\"></a>贝叶斯网络 Bayesian Network</h1><p>贝叶斯网络是概率图模型的一种结构，通过有向无环图来表示模型中的关联性。在特定的图结构中，节点表示随机变量，有向边表示相连的变量之间的因果关系。</p>\n<h2 id=\"贝叶斯网的链式法则\"><a href=\"#贝叶斯网的链式法则\" class=\"headerlink\" title=\"贝叶斯网的链式法则\"></a>贝叶斯网的链式法则</h2><p>$$ P(X_1, X_2, …, X_n) = \\Pi_{i=1:n}P(X_i \\mid Parents(X_i)) $$</p>\n<h2 id=\"I-Map和P-Map\"><a href=\"#I-Map和P-Map\" class=\"headerlink\" title=\"I-Map和P-Map\"></a>I-Map和P-Map</h2><p>令P为X上的分布，$I(P)$是满足$(X&perp; Y\\mid Z)$的独立性断言的集合。I(G)表示图G上独立性关系的集合，如果$ I(G) \\subseteq  I(P) $，则可成G为P的I-Map。<br>显然只要某个图的独立性关机集合是I(P)的子集，其对应的图就是I-Map，所以I-Map有很多个，只有当I(G)=I(P)时，对应的图可以等价的表示这个概率分布，G就叫做P的P-Map(Perfect-Map)。</p>\n<h2 id=\"独立性\"><a href=\"#独立性\" class=\"headerlink\" title=\"独立性\"></a>独立性</h2><h3 id=\"局部马尔科夫独立性\"><a href=\"#局部马尔科夫独立性\" class=\"headerlink\" title=\"局部马尔科夫独立性\"></a>局部马尔科夫独立性</h3><p>记$ Pa_{x_i} $是图G中$ X_i $的父节点，将图G中不是$X_i$后代的子节点变量记为$ NonDescendants_{X_i} $。G满足如下的条件独立性论断$I_l(G)$：$ X_i &perp; NonDescendants_{X_i}\\mid Pa_{x_i}:\\forall i$，也就是说在</p>\n<p>给定父节点的情况下，子节点间相互独立。</p>\n<h3 id=\"全局马尔科夫独立性\"><a href=\"#全局马尔科夫独立性\" class=\"headerlink\" title=\"全局马尔科夫独立性\"></a>全局马尔科夫独立性</h3><p>全局的马尔科夫独立性与d-分离有关，如果在给定Z的情况下，节点X和Y独立，则X和Y是D-separation。</p>\n<p>迹是三个变量相连的路径，比如X，Y，Z。迹有三种形式：</p>\n<ul>\n<li>Causal Trail $ X \\to Z \\to Y $: 有效当且仅当Z不可观。</li>\n</ul>\n<ul>\n<li>Evidential Trail $X \\leftarrow Z \\leftarrow Y$: 有效当且仅当Z不可观。</li>\n</ul>\n<ul>\n<li>Common Cause $X \\leftarrow Z \\to Y$：有效当且仅当Z不可观。</li>\n</ul>\n<ul>\n<li>Common Effect $ X \\to Z \\leftarrow Y $：有效当且仅当Z（或者是其他后代）可观。</li>\n</ul>\n<p>与d-分离想对应的独立性的集合用I(G)表示：<br>$$I(G)=\\lbrace(X &perp; Y\\mid Z):d-sep_G(X;Y\\mid Z)\\rbrace $$<br>上面的集合也叫做全局马尔科夫的独立性。</p>\n<h2 id=\"可靠性与完备性\"><a href=\"#可靠性与完备性\" class=\"headerlink\" title=\"可靠性与完备性\"></a>可靠性与完备性</h2><ul>\n<li>d-分离的可靠性与贝叶斯网络因子分离定理有关,如果分布P根据G因子分解，那么，$I(G)\\subseteq I(P)$。</li>\n<li>对于任意的分布P根据G因子分解，如果$ (X &perp; Y|Z) \\in I(P)$，那么就有$dsep_G(X; Y\\mid Z)\\in I(P)$</li>\n<li>G是一个贝叶斯网络结构的图，如果给定Z时X和Y不是在图G中d-分离的，那么X和Y在某些图G上的因子分解分布P中相互依赖。</li>\n<li>对于几乎所有的在G上的因子分解的分布P，$I(P)=I(G)$。几乎所有指的是对于参数化条件概率空间中除了测度为0的分布。</li>\n</ul>\n<h1 id=\"马尔科夫网络-Markov-Network\"><a href=\"#马尔科夫网络-Markov-Network\" class=\"headerlink\" title=\"马尔科夫网络 Markov Network\"></a>马尔科夫网络 Markov Network</h1><p>上面是有向图模型，又叫做贝叶斯网络，下面我们来看一下无向图模型，也被叫做马尔科夫网。<br>如下的式子必须使用马尔科夫网：<br>$$A \\perp C\\mid \\lbrace B, D \\rbrace, B \\perp D\\mid \\lbrace A, B\\rbrace$$<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%97%A0%E5%90%91%E5%9B%BE.jpg\" alt><br>clique就是指的强连通的团，通常翻译为团，每个团会定义一个势函数(potential function)。<br>无向图模型可以通过一个给定的无向图来表示概率分布$P(X_1,…X_n)$，每一个在图H中的团$c\\in C$代表一组正势函数$\\psi_c$，比如：<br>$$P(X_1, …, X_n)=\\frac{1}{Z}\\prod_{c\\in C}\\psi_c(X_c)$$</p>\n<p>其中Z是配分函数(partition function)，是一个归一化的常数：<br>$$Z=\\sum_{X_1, …, X_n}\\prod_{c\\in C}\\psi_c(X_c)$$</p>\n<h2 id=\"全局马尔科夫独立性-1\"><a href=\"#全局马尔科夫独立性-1\" class=\"headerlink\" title=\"全局马尔科夫独立性\"></a>全局马尔科夫独立性</h2><p>如果在给定节点集B时，任意两个节点A和C中的节点之间没有路径，那么则称B在图H中分离A和B。<br>如果对于任意不连接的A，B，C，比如B分离A和C，也就说在给定C的情况下，A和C独立，那么该概率分布满足全局马尔科夫独立性。<br>$$I(H)=\\lbrace A \\perp C\\mid B:sep_H(A;C\\mid B)\\rbrace$$</p>\n<h3 id=\"完备性\"><a href=\"#完备性\" class=\"headerlink\" title=\"完备性\"></a>完备性</h3><p>H是一个马尔科夫网结构，如果在给定Z时，X与Y在图H中不可分离，则在给定Z时，X与Y在因子分解的分布中存在依赖关系。</p>\n<h3 id=\"可靠性\"><a href=\"#可靠性\" class=\"headerlink\" title=\"可靠性\"></a>可靠性</h3><ul>\n<li>P为X上的正分布，而H为X上的一个马尔科夫网结构。如果P是在图H上的吉布斯分布，那么H是P的I-Map。</li>\n<li>P为X上的分布，而H为X上的一个马尔科夫网结构。如果H是P的一个I-Map，则P是可以再H上分解的一个吉布斯分布。</li>\n</ul>\n<h2 id=\"局部马尔科夫独立性-1\"><a href=\"#局部马尔科夫独立性-1\" class=\"headerlink\" title=\"局部马尔科夫独立性\"></a>局部马尔科夫独立性</h2><p>H=(V,E)是一个马尔科夫网，与H相关的成对独立性定义如下：<br>$$I_P(H)=\\lbrace (X \\perp Y \\mid V-\\lbrace X, Y\\rbrace):X-Y\\notin H\\rbrace$$<br>对于给定的图H=(V,E),X在H中的马尔科夫毯$$MB_H(X)$$定义为X在H中的近邻。与H相关的局部独立性定义如下：<br>$$I_l(H)=\\lbrace(X \\perp V-\\lbrace X\\rbrace -MB_{H}(X)\\mid MB_{H}(X)):X\\in V\\rbrace$$</p>\n<h2 id=\"局部马尔科夫性与全局马尔科夫性的联系\"><a href=\"#局部马尔科夫性与全局马尔科夫性的联系\" class=\"headerlink\" title=\"局部马尔科夫性与全局马尔科夫性的联系\"></a>局部马尔科夫性与全局马尔科夫性的联系</h2><p>$$P\\models I_l(H)\\Rightarrow P\\models I_P(H)$$  $$P=I(H)\\Rightarrow P\\models I_l(H)$$  $$P&gt;0\\  and\\  P\\models I_p(H) \\Rightarrow P\\models I(H)$$<br>推论：对于一个正分布P，全局、局部和成对独立性是等价的。</p>\n<h2 id=\"团-cliques\"><a href=\"#团-cliques\" class=\"headerlink\" title=\"团(cliques)\"></a>团(cliques)</h2><p>团是一个完全子图(complete graph)，最大团是最大可能的完全子图。最大的团记作max-clique，不是最大的团记作sub-cliques。</p>\n<h2 id=\"对数线性模型\"><a href=\"#对数线性模型\" class=\"headerlink\" title=\"对数线性模型\"></a>对数线性模型</h2><p>$$P(X_1,…,X_n)=\\frac{1}{Z} exp[-\\sum_{i=1}^k \\omega_c(X_c)]$$</p>\n<h2 id=\"Perfect-Maps\"><a href=\"#Perfect-Maps\" class=\"headerlink\" title=\"Perfect Maps\"></a>Perfect Maps</h2><p>只要分布的分离特性与独立特性一致，马尔科夫网就可以是分布的一个P-Map。然而，就像是贝叶斯网，不是所有的分布都能用无向图来表示。实际上，无向图和有向图不恩能够完全的表达分布的空间。</p>\n<h2 id=\"模型实例\"><a href=\"#模型实例\" class=\"headerlink\" title=\"模型实例　\"></a>模型实例　</h2><h3 id=\"波尔兹曼机\"><a href=\"#波尔兹曼机\" class=\"headerlink\" title=\"波尔兹曼机\"></a>波尔兹曼机</h3><p>波尔兹曼机的连接方式如下图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/波尔兹曼机示意图.png\" alt><br>波尔兹曼机是一个全连接的图，每条无向边表示一对依赖关系，节点是二值变量。<br>上图的联合概率分布如下：<br>$$<br>P(x_1, x_2, x_3, x_4)=\\frac{1}{Z}exp\\lbrace \\sum_{i,j}\\phi_{ij}(x_i, x_j)\\rbrace<br>=\\frac{1}{Z}exp\\lbrace\\sum_{i,j}\\theta_{ij}x_ix_j+\\sum_i\\alpha_i x_i + C \\rbrace<br>=\\frac{1}{Z}exp\\lbrace(x-\\mu)^T\\Theta(x-\\mu)\\rbrace<br>$$</p>\n<h3 id=\"受限波尔兹曼机\"><a href=\"#受限波尔兹曼机\" class=\"headerlink\" title=\"受限波尔兹曼机\"></a>受限波尔兹曼机</h3><p>受限波尔兹曼机通常有很多层构成，每个层中有两个子层，一个隐藏层，另一个是可见层。RBM的概率分布函数：<br>$$P(x,h\\mid \\theta)=exp\\lbrace\\sum_i\\theta_i\\phi_i(x_i)+\\sum_j\\theta_j\\phi_j(h_j)+\\sum_{i,j}\\theta_{i,j}\\phi_{i,j}(x_i,h_j)-A(\\theta)\\rbrace$$<br>RBM的因子是边际相关的，在给定可观的节点的情况下因子是条件独立的。可以进行迭代吉布斯采样。</p>\n<h3 id=\"条件随机场\"><a href=\"#条件随机场\" class=\"headerlink\" title=\"条件随机场\"></a>条件随机场</h3><p>条件随机场是一种判别式的无向图模型，通过观测序列得到标记序列。CRF并没有假定各个特征值之间的独立性，概率分布如下：<br>$$P_\\theta(y\\mid x)=\\frac{1}{Z}exp\\lbrace \\sum_{e\\in E,k}\\lambda_k f_k(e,y\\mid_e,s)+\\sum_{v\\in V,k}\\mu_k g_k(v,y\\mid_v,x)\\rbrace$$<br>其中，x是观测序列(数据序列)，y是标记序列，v是标记随机变量集V的顶点，e是来自边集E的边。k是特证序号，$f_k$是固定的二值特征函数，$g_k$是给定的二值顶点特征。$\\theta=(\\lambda_1, …, \\lambda_n;\\mu_1, …, \\mu_n)$是需要估计的参数$y\\mid_e$是由e定义的y的集合，$y\\mid_v$是由v定义的y的集合。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%9C%BA.png\" alt></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>无向图模型表明了变量间的相互关系（relatedness），而不是因果关系（causality）。</li>\n<li>无向图可以定义联合或者独立分布。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p><a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.<br>周志华. 机器学习[M]. 清华大学出版社, 2016.</p>\n"},{"title":"概率论知识点","date":"2018-04-25T02:11:46.000Z","_content":"# 频率学派和贝叶斯学派\n频率学派：观测数据是随机变量，参数是未知但确定的；\n贝叶斯学派：观测数据是已知的，参数是随机变量。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png)\n","source":"_posts/概率论知识点.md","raw":"---\ntitle: 概率论知识点\ndate: 2018-04-25 10:11:46\ntags: 概率论\ncategories: 学习\n---\n# 频率学派和贝叶斯学派\n频率学派：观测数据是随机变量，参数是未知但确定的；\n贝叶斯学派：观测数据是已知的，参数是随机变量。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png)\n","slug":"概率论知识点","published":1,"updated":"2018-09-22T06:32:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40msz00141ouzypkmgxo7","content":"<h1 id=\"频率学派和贝叶斯学派\"><a href=\"#频率学派和贝叶斯学派\" class=\"headerlink\" title=\"频率学派和贝叶斯学派\"></a>频率学派和贝叶斯学派</h1><p>频率学派：观测数据是随机变量，参数是未知但确定的；<br>贝叶斯学派：观测数据是已知的，参数是随机变量。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"频率学派和贝叶斯学派\"><a href=\"#频率学派和贝叶斯学派\" class=\"headerlink\" title=\"频率学派和贝叶斯学派\"></a>频率学派和贝叶斯学派</h1><p>频率学派：观测数据是随机变量，参数是未知但确定的；<br>贝叶斯学派：观测数据是已知的，参数是随机变量。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png\" alt></p>\n"},{"title":"指数族与广义线性模型","date":"2018-05-09T02:30:15.000Z","_content":"# 指数族\n将随机变量X写成指数族的形式：\n$$p(X=x;\\eta)=h(x)exp(\\eta^T T(x)-A(\\eta))$$\n其中：$\\eta$是自然参数向量（natural paramater），T(x)是充分统计量（sufficient statistic），$A(\\eta)$是对数判分函数（log partition function）。\n\n## 例子\n指数族可以包括许多的例子，比如高斯分布，伯努利分布，多项式分布等。\n\n### 多元正态分布\n令向量$X\\in R^k$\n$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$\n$$=\\frac{1}{(2\\pi)^{k/2}} exp\\lbrace -\\frac{1}{2} tr(\\Sigma^{-1}x x^T) + \\mu^T \\Sigma^{-1}x^T- \\frac{1}{2}\\mu^T \\Sigma^{-1}\\mu - log|\\Sigma|\\rbrace$$\n对应的指数族表示：\n$$\\eta = [\\Sigma^{-1}\\mu; -\\frac{1}{2}vec(\\Sigma^{-1})]$$  $$ T(x)=[x;vec(xx^T)]$$  $$ A(\\eta)=\\frac{1}{2} \\mu^T \\Sigma^{-1} \\mu + log|\\Sigma| $$  $$ h(x)= \\frac{1} { {2\\pi}^{k/2} } $$\n\n### 伯努利分布\n$$ p(x;\\phi) $$  $$ = \\phi^x(1-\\phi)^{1-x} $$  $$ = exp(log(\\phi^x(1-\\phi)^{1-x}) $$  $$ = exp(log(\\phi^x)+log((1-\\phi)^{1-x})) $$  $$ = exp(xlog(\\phi) + (1-x)log(1-\\phi)) $$  $$ = exp(xlog(\\frac{\\phi}{1-\\phi})+log(1-\\phi))$$\n对应于指数族：\n$$ \\eta = log(\\frac{\\phi}{1-\\phi}) $$  $$ T(x) = x $$  $$ A(\\eta) = -log(1-\\phi) $$  $$ h(x) = 1 $$\n\n###  其他\n很多的分布可以看做是指数族：单变量高斯分布（the univariate Gaussian)，泊松分布（Poisson）， 多项分布（multinomial），线性回归（linear regression），伊辛模型（Ising model），受限波尔兹曼机机（restricted Boltzmann machines），还有条件随机场（contional random field，CRFs）。\n\n#### 条件随机场\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png)\n条件随机场是基于上面图的无向图模型，势函数是定义在成对输出上面的。\n$$ p_\\theta(y\\mid x)=\\frac{1}{Z(x)}exp(\\Sigma_{e\\in E,k} \\lambda_k f_k(e,y\\mid_e, x) + \\Sigma_{v\\in V,k} \\mu_k g_k(v,y\\mid_v, x))$$\n其中$f_k$和$g_k$是固定的，$g_k$是波尔顶点特征，$f_k$是波尔边特征。\n\n## 指数族特性\n指数族具有如下的特性：\n1. 对数配分函数的第d阶导数，是充分统计量的第d阶中心距。\n比如：对数配分函数的一阶导数是T(X)的均值，其二阶导是T(X)的方差。\n2. 因为对数配分函数的二阶导是正的，所以对数配分函数是凸的，因此方差总是非负的。\n3. 我们可以将对数配分函数的一阶导看成自然参数的函数，然后令其为零，反过来利用距参数就可以解决自然参数，记作：$\\eta = \\psi(\\mu)$ 。\n4. 在指数族上进行最大似然估计与矩匹配是一致的。\n  * 写出一般指数族的对数似然函数:\n  $$ const + \\eta^T (\\Sigma_{i=1}^n T(x_i)) - nA(\\eta) $$\n  * 求似然函数的梯度：\n  $$ \\Sigma_{i=1}^n T(x_i)) - n\\Delta_\\eta A(\\eta) $$\n  * 令$\\Delta_\\eta A$为零：\n  $$ \\Delta_\\eta A = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow \\mu = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow 矩估计=样本距 $$\n\n### 充分统计量\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png)\n从贝叶斯的观点出发：如果T具备了我们预测参数$\\theta$的所有信息（即T是充分统计量），那么$\\theta \\perp X \\mid T \\Rightarrow P(\\theta \\mid X, T)=P(\\theta\\mid T)$。\n从频率学派的角度出发：如果T已知的用来产生数据的参数，那么$ X \\perp \\theta \\mid T \\Rightarrow P(X\\mid T;\\theta) = P(X\\mid T) $\n从马尔科夫随机场的角度进行考虑：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%85%85%E5%88%86%E7%BB%9F%E8%AE%A1%E9%87%8F.png)\n\n## 贝叶斯\n重新从贝叶斯的角度出发，写出给定自然参数的似然函数，我们选择了一个自然参数先验，然后计算出自然参数的后验概率。\n比如：\n$$ p(x\\mid \\eta) \\propto exp(\\eta^ T T(x) - A(\\eta))$$\n$$ p(\\eta) \\propto exp(\\xi^T T(\\eta) - A(\\xi)) $$\n$$ p(\\eta\\mid x, \\xi) \\propto exp(\\eta^T T(x) + \\xi^T T(\\eta) + A(\\eta) + A(\\xi)) $$\n如果$\\eta = T(\\eta)$ ，那么后验概率变为：\n$$ p(\\eta\\mid x, \\xi) \\propto exp(T(\\eta)(T(x) + \\xi)+ A(\\eta) + A(\\xi)) $$\n当$ \\eta = T(\\eta)$ ，我们指定$\\eta ~exponentialFamily$，这是先验就是共轭先验。\n\n# 广义线性模型\n广义线性模型可以将分类和回归问题进行统一，使用相同的统计框架。\n假定：\n$$ Y \\sim exponentialFamily $$\n$$ \\eta = \\psi(\\mu=f(\\xi = \\theta^T x)) $$\n其中Y是响应，x是固定输入，$\\theta$是需要学习的参数，$f$（响应函数，response function），$\\psi$增加了一定的灵活性，f经常被设定为$\\psi^{-1}$（canonical response function）。\n\n# 广义线性模型的批学习\n考虑通过求导的方法来解决最小二乘问题，就是使代价函数达到极小：\n$$ J(\\theta) = \\frac{1}{2} \\Sigma_{i=1}^n (x_i^T\\theta - y_i)^2 = \\frac{1}{2} (X\\theta-y) $$\n$x_i$表示第i个输入样本，$y_i$表示第i个输出样本。\n对$J(\\theta)$求一阶导并令其为零，可以得到取得极小值时的$\\theta$。\n$$ \\triangledown J(\\theta) = X^T X\\theta - X^T y = 0 \\Rightarrow \\theta^* = (X^T X)^{-1} X^T y $$\n使用牛顿法进行迭代寻找最优解，牛顿法更新参数更新准则：\n$$ \\theta^{t+1} = \\theta^t - H^{-1}\\triangledown J(\\theta) $$\n\n对数似然函数$l = \\Sigma_n logh(y_n) + \\Sigma_n(\\theta^T x_n y_n - A(\\eta))$\n下面获得Hessian阵：\n\\begin{equation}\\begin{split} H&=\\frac{d^2 l}{d\\theta d\\theta^T}\\\\\\\\\n& = \\frac{d}{d\\theta^T}\\Sigma_n(y_n-\\mu_n)x_n\\\\\\\\\n& = \\Sigma_n x_n \\frac{d\\mu_n}{d\\theta^T}\\\\\\\\\n& = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} \\frac{d\\eta_n}{d\\theta^T}\\\\\\\\\n& = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} x_n^T \\\\   因为\\eta_n = \\theta^T x_n\\\\\\\\\n& = -X^T W X\n\\end{split}\\end{equation}\n其中$X = [x_n^T]$，$W = diag[\\frac{d\\mu_1}{d\\eta_1},...,\\frac{d\\mu_N}{d\\eta_N}]$。W可以同过计算$A(\\eta)$的二阶导来计算。\n代换上式中的$\\triangledown J(\\theta)$和H，可以得到：\n$$ \\theta^{t+1} = (X^T W^t X)^{-1} X^T W^t z^t $$\n其中$z^t = X\\theta^ t + (W^t)^{-1}(y - \\mu^t)$。因为W是对角阵，所有该式子具有解耦的作用。\n\n### 对数几率回归\n条件概率分布如下（伯努利分布）：\n$$ p(y \\mid x) = \\mu(x)^y (1-\\mu(x))^{1-y} $$\n其中$\\mu$是logistic函数\n$$ \\mu(x) = \\frac{1}{1 + e^{-\\eta(x)}} $$\n\n由于$p(y\\mid x)$是指数族，\n均值：\n$$ E[y\\mid x] = \\mu = \\frac{1}{1 + e^{-\\eta(x)}} $$\ncanonical response  function:\n$$ \\eta = \\xi = \\theta^T x $$\n利用上面的方法广义线性模型中的方法求W：\n$$ \\frac{d\\mu}{d\\eta} = \\mu (1 - \\mu) $$\n$$ W =\n\\begin{pmatrix}\n\\mu_1 (1 - \\mu_1)\\\\\\\\\n&\\ddots \\\\\\\\\n& & \\mu_N (1-\\mu_N) \\\\\\\\\n\\end{pmatrix}\n$$\n其中N是训练样本的数量，d是输入样本的维度。上面的方法每代复杂度为$O(Nd^3)$。可以利用拟牛顿法来近似计算Hessian阵来减小运算成本。\n共轭梯度每代的复杂度为$O(N d)$，在实际中使用效果更好。dang样本数量较大时，也可以采用随机梯度下降。\n\n### 线性回归\n条件概率分布为：\n$$p(y\\mid x,\\theta,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  \\frac{1}{2}(y-\\mu)^T\\Sigma^{-1}(y - \\mu) \\rbrace$$\n从上面多元正态分布中，可以写成指数族的形式。\n利用上面的方法广义线性模型中的方法求W：\n$$ \\frac{d\\mu}{d\\eta} = 1 $$\n$$ W = 1 $$\n更新规则如下：\n$$ \\theta^{t+1} = \\theta^t + (X^T X)^{-1} X^T(y - \\mu^t) $$\n\n# 总结\n* 对于指数族分布，最大似然估计等价于矩估计。\n* 广义线性模型是图模型的实际应用中的重要组成部分。\n* 要选择合适的独立性以及合适的先验。\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n注：本文主要参考[1]中第6讲视频以及笔记。\n","source":"_posts/指数族与广义线性模型.md","raw":"---\ntitle: 指数族与广义线性模型\ndate: 2018-05-09 10:30:15\ntags: 概率图模型\ncategories: 学习\n---\n# 指数族\n将随机变量X写成指数族的形式：\n$$p(X=x;\\eta)=h(x)exp(\\eta^T T(x)-A(\\eta))$$\n其中：$\\eta$是自然参数向量（natural paramater），T(x)是充分统计量（sufficient statistic），$A(\\eta)$是对数判分函数（log partition function）。\n\n## 例子\n指数族可以包括许多的例子，比如高斯分布，伯努利分布，多项式分布等。\n\n### 多元正态分布\n令向量$X\\in R^k$\n$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$\n$$=\\frac{1}{(2\\pi)^{k/2}} exp\\lbrace -\\frac{1}{2} tr(\\Sigma^{-1}x x^T) + \\mu^T \\Sigma^{-1}x^T- \\frac{1}{2}\\mu^T \\Sigma^{-1}\\mu - log|\\Sigma|\\rbrace$$\n对应的指数族表示：\n$$\\eta = [\\Sigma^{-1}\\mu; -\\frac{1}{2}vec(\\Sigma^{-1})]$$  $$ T(x)=[x;vec(xx^T)]$$  $$ A(\\eta)=\\frac{1}{2} \\mu^T \\Sigma^{-1} \\mu + log|\\Sigma| $$  $$ h(x)= \\frac{1} { {2\\pi}^{k/2} } $$\n\n### 伯努利分布\n$$ p(x;\\phi) $$  $$ = \\phi^x(1-\\phi)^{1-x} $$  $$ = exp(log(\\phi^x(1-\\phi)^{1-x}) $$  $$ = exp(log(\\phi^x)+log((1-\\phi)^{1-x})) $$  $$ = exp(xlog(\\phi) + (1-x)log(1-\\phi)) $$  $$ = exp(xlog(\\frac{\\phi}{1-\\phi})+log(1-\\phi))$$\n对应于指数族：\n$$ \\eta = log(\\frac{\\phi}{1-\\phi}) $$  $$ T(x) = x $$  $$ A(\\eta) = -log(1-\\phi) $$  $$ h(x) = 1 $$\n\n###  其他\n很多的分布可以看做是指数族：单变量高斯分布（the univariate Gaussian)，泊松分布（Poisson）， 多项分布（multinomial），线性回归（linear regression），伊辛模型（Ising model），受限波尔兹曼机机（restricted Boltzmann machines），还有条件随机场（contional random field，CRFs）。\n\n#### 条件随机场\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png)\n条件随机场是基于上面图的无向图模型，势函数是定义在成对输出上面的。\n$$ p_\\theta(y\\mid x)=\\frac{1}{Z(x)}exp(\\Sigma_{e\\in E,k} \\lambda_k f_k(e,y\\mid_e, x) + \\Sigma_{v\\in V,k} \\mu_k g_k(v,y\\mid_v, x))$$\n其中$f_k$和$g_k$是固定的，$g_k$是波尔顶点特征，$f_k$是波尔边特征。\n\n## 指数族特性\n指数族具有如下的特性：\n1. 对数配分函数的第d阶导数，是充分统计量的第d阶中心距。\n比如：对数配分函数的一阶导数是T(X)的均值，其二阶导是T(X)的方差。\n2. 因为对数配分函数的二阶导是正的，所以对数配分函数是凸的，因此方差总是非负的。\n3. 我们可以将对数配分函数的一阶导看成自然参数的函数，然后令其为零，反过来利用距参数就可以解决自然参数，记作：$\\eta = \\psi(\\mu)$ 。\n4. 在指数族上进行最大似然估计与矩匹配是一致的。\n  * 写出一般指数族的对数似然函数:\n  $$ const + \\eta^T (\\Sigma_{i=1}^n T(x_i)) - nA(\\eta) $$\n  * 求似然函数的梯度：\n  $$ \\Sigma_{i=1}^n T(x_i)) - n\\Delta_\\eta A(\\eta) $$\n  * 令$\\Delta_\\eta A$为零：\n  $$ \\Delta_\\eta A = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow \\mu = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow 矩估计=样本距 $$\n\n### 充分统计量\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png)\n从贝叶斯的观点出发：如果T具备了我们预测参数$\\theta$的所有信息（即T是充分统计量），那么$\\theta \\perp X \\mid T \\Rightarrow P(\\theta \\mid X, T)=P(\\theta\\mid T)$。\n从频率学派的角度出发：如果T已知的用来产生数据的参数，那么$ X \\perp \\theta \\mid T \\Rightarrow P(X\\mid T;\\theta) = P(X\\mid T) $\n从马尔科夫随机场的角度进行考虑：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%85%85%E5%88%86%E7%BB%9F%E8%AE%A1%E9%87%8F.png)\n\n## 贝叶斯\n重新从贝叶斯的角度出发，写出给定自然参数的似然函数，我们选择了一个自然参数先验，然后计算出自然参数的后验概率。\n比如：\n$$ p(x\\mid \\eta) \\propto exp(\\eta^ T T(x) - A(\\eta))$$\n$$ p(\\eta) \\propto exp(\\xi^T T(\\eta) - A(\\xi)) $$\n$$ p(\\eta\\mid x, \\xi) \\propto exp(\\eta^T T(x) + \\xi^T T(\\eta) + A(\\eta) + A(\\xi)) $$\n如果$\\eta = T(\\eta)$ ，那么后验概率变为：\n$$ p(\\eta\\mid x, \\xi) \\propto exp(T(\\eta)(T(x) + \\xi)+ A(\\eta) + A(\\xi)) $$\n当$ \\eta = T(\\eta)$ ，我们指定$\\eta ~exponentialFamily$，这是先验就是共轭先验。\n\n# 广义线性模型\n广义线性模型可以将分类和回归问题进行统一，使用相同的统计框架。\n假定：\n$$ Y \\sim exponentialFamily $$\n$$ \\eta = \\psi(\\mu=f(\\xi = \\theta^T x)) $$\n其中Y是响应，x是固定输入，$\\theta$是需要学习的参数，$f$（响应函数，response function），$\\psi$增加了一定的灵活性，f经常被设定为$\\psi^{-1}$（canonical response function）。\n\n# 广义线性模型的批学习\n考虑通过求导的方法来解决最小二乘问题，就是使代价函数达到极小：\n$$ J(\\theta) = \\frac{1}{2} \\Sigma_{i=1}^n (x_i^T\\theta - y_i)^2 = \\frac{1}{2} (X\\theta-y) $$\n$x_i$表示第i个输入样本，$y_i$表示第i个输出样本。\n对$J(\\theta)$求一阶导并令其为零，可以得到取得极小值时的$\\theta$。\n$$ \\triangledown J(\\theta) = X^T X\\theta - X^T y = 0 \\Rightarrow \\theta^* = (X^T X)^{-1} X^T y $$\n使用牛顿法进行迭代寻找最优解，牛顿法更新参数更新准则：\n$$ \\theta^{t+1} = \\theta^t - H^{-1}\\triangledown J(\\theta) $$\n\n对数似然函数$l = \\Sigma_n logh(y_n) + \\Sigma_n(\\theta^T x_n y_n - A(\\eta))$\n下面获得Hessian阵：\n\\begin{equation}\\begin{split} H&=\\frac{d^2 l}{d\\theta d\\theta^T}\\\\\\\\\n& = \\frac{d}{d\\theta^T}\\Sigma_n(y_n-\\mu_n)x_n\\\\\\\\\n& = \\Sigma_n x_n \\frac{d\\mu_n}{d\\theta^T}\\\\\\\\\n& = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} \\frac{d\\eta_n}{d\\theta^T}\\\\\\\\\n& = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} x_n^T \\\\   因为\\eta_n = \\theta^T x_n\\\\\\\\\n& = -X^T W X\n\\end{split}\\end{equation}\n其中$X = [x_n^T]$，$W = diag[\\frac{d\\mu_1}{d\\eta_1},...,\\frac{d\\mu_N}{d\\eta_N}]$。W可以同过计算$A(\\eta)$的二阶导来计算。\n代换上式中的$\\triangledown J(\\theta)$和H，可以得到：\n$$ \\theta^{t+1} = (X^T W^t X)^{-1} X^T W^t z^t $$\n其中$z^t = X\\theta^ t + (W^t)^{-1}(y - \\mu^t)$。因为W是对角阵，所有该式子具有解耦的作用。\n\n### 对数几率回归\n条件概率分布如下（伯努利分布）：\n$$ p(y \\mid x) = \\mu(x)^y (1-\\mu(x))^{1-y} $$\n其中$\\mu$是logistic函数\n$$ \\mu(x) = \\frac{1}{1 + e^{-\\eta(x)}} $$\n\n由于$p(y\\mid x)$是指数族，\n均值：\n$$ E[y\\mid x] = \\mu = \\frac{1}{1 + e^{-\\eta(x)}} $$\ncanonical response  function:\n$$ \\eta = \\xi = \\theta^T x $$\n利用上面的方法广义线性模型中的方法求W：\n$$ \\frac{d\\mu}{d\\eta} = \\mu (1 - \\mu) $$\n$$ W =\n\\begin{pmatrix}\n\\mu_1 (1 - \\mu_1)\\\\\\\\\n&\\ddots \\\\\\\\\n& & \\mu_N (1-\\mu_N) \\\\\\\\\n\\end{pmatrix}\n$$\n其中N是训练样本的数量，d是输入样本的维度。上面的方法每代复杂度为$O(Nd^3)$。可以利用拟牛顿法来近似计算Hessian阵来减小运算成本。\n共轭梯度每代的复杂度为$O(N d)$，在实际中使用效果更好。dang样本数量较大时，也可以采用随机梯度下降。\n\n### 线性回归\n条件概率分布为：\n$$p(y\\mid x,\\theta,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  \\frac{1}{2}(y-\\mu)^T\\Sigma^{-1}(y - \\mu) \\rbrace$$\n从上面多元正态分布中，可以写成指数族的形式。\n利用上面的方法广义线性模型中的方法求W：\n$$ \\frac{d\\mu}{d\\eta} = 1 $$\n$$ W = 1 $$\n更新规则如下：\n$$ \\theta^{t+1} = \\theta^t + (X^T X)^{-1} X^T(y - \\mu^t) $$\n\n# 总结\n* 对于指数族分布，最大似然估计等价于矩估计。\n* 广义线性模型是图模型的实际应用中的重要组成部分。\n* 要选择合适的独立性以及合适的先验。\n\n# 参考文献\n[1] http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\n注：本文主要参考[1]中第6讲视频以及笔记。\n","slug":"指数族与广义线性模型","published":1,"updated":"2018-09-22T06:33:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt000151ouz8tid2lmp","content":"<h1 id=\"指数族\"><a href=\"#指数族\" class=\"headerlink\" title=\"指数族\"></a>指数族</h1><p>将随机变量X写成指数族的形式：<br>$$p(X=x;\\eta)=h(x)exp(\\eta^T T(x)-A(\\eta))$$<br>其中：$\\eta$是自然参数向量（natural paramater），T(x)是充分统计量（sufficient statistic），$A(\\eta)$是对数判分函数（log partition function）。</p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><p>指数族可以包括许多的例子，比如高斯分布，伯努利分布，多项式分布等。</p>\n<h3 id=\"多元正态分布\"><a href=\"#多元正态分布\" class=\"headerlink\" title=\"多元正态分布\"></a>多元正态分布</h3><p>令向量$X\\in R^k$<br>$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$<br>$$=\\frac{1}{(2\\pi)^{k/2}} exp\\lbrace -\\frac{1}{2} tr(\\Sigma^{-1}x x^T) + \\mu^T \\Sigma^{-1}x^T- \\frac{1}{2}\\mu^T \\Sigma^{-1}\\mu - log|\\Sigma|\\rbrace$$<br>对应的指数族表示：<br>$$\\eta = [\\Sigma^{-1}\\mu; -\\frac{1}{2}vec(\\Sigma^{-1})]$$  $$ T(x)=[x;vec(xx^T)]$$  $$ A(\\eta)=\\frac{1}{2} \\mu^T \\Sigma^{-1} \\mu + log|\\Sigma| $$  $$ h(x)= \\frac{1} { {2\\pi}^{k/2} } $$</p>\n<h3 id=\"伯努利分布\"><a href=\"#伯努利分布\" class=\"headerlink\" title=\"伯努利分布\"></a>伯努利分布</h3><p>$$ p(x;\\phi) $$  $$ = \\phi^x(1-\\phi)^{1-x} $$  $$ = exp(log(\\phi^x(1-\\phi)^{1-x}) $$  $$ = exp(log(\\phi^x)+log((1-\\phi)^{1-x})) $$  $$ = exp(xlog(\\phi) + (1-x)log(1-\\phi)) $$  $$ = exp(xlog(\\frac{\\phi}{1-\\phi})+log(1-\\phi))$$<br>对应于指数族：<br>$$ \\eta = log(\\frac{\\phi}{1-\\phi}) $$  $$ T(x) = x $$  $$ A(\\eta) = -log(1-\\phi) $$  $$ h(x) = 1 $$</p>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>很多的分布可以看做是指数族：单变量高斯分布（the univariate Gaussian)，泊松分布（Poisson）， 多项分布（multinomial），线性回归（linear regression），伊辛模型（Ising model），受限波尔兹曼机机（restricted Boltzmann machines），还有条件随机场（contional random field，CRFs）。</p>\n<h4 id=\"条件随机场\"><a href=\"#条件随机场\" class=\"headerlink\" title=\"条件随机场\"></a>条件随机场</h4><p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png\" alt><br>条件随机场是基于上面图的无向图模型，势函数是定义在成对输出上面的。<br>$$ p_\\theta(y\\mid x)=\\frac{1}{Z(x)}exp(\\Sigma_{e\\in E,k} \\lambda_k f_k(e,y\\mid_e, x) + \\Sigma_{v\\in V,k} \\mu_k g_k(v,y\\mid_v, x))$$<br>其中$f_k$和$g_k$是固定的，$g_k$是波尔顶点特征，$f_k$是波尔边特征。</p>\n<h2 id=\"指数族特性\"><a href=\"#指数族特性\" class=\"headerlink\" title=\"指数族特性\"></a>指数族特性</h2><p>指数族具有如下的特性：</p>\n<ol>\n<li>对数配分函数的第d阶导数，是充分统计量的第d阶中心距。<br>比如：对数配分函数的一阶导数是T(X)的均值，其二阶导是T(X)的方差。</li>\n<li>因为对数配分函数的二阶导是正的，所以对数配分函数是凸的，因此方差总是非负的。</li>\n<li>我们可以将对数配分函数的一阶导看成自然参数的函数，然后令其为零，反过来利用距参数就可以解决自然参数，记作：$\\eta = \\psi(\\mu)$ 。</li>\n<li>在指数族上进行最大似然估计与矩匹配是一致的。<ul>\n<li>写出一般指数族的对数似然函数:<br>$$ const + \\eta^T (\\Sigma_{i=1}^n T(x_i)) - nA(\\eta) $$</li>\n<li>求似然函数的梯度：<br>$$ \\Sigma_{i=1}^n T(x_i)) - n\\Delta_\\eta A(\\eta) $$</li>\n<li>令$\\Delta_\\eta A$为零：<br>$$ \\Delta_\\eta A = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow \\mu = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow 矩估计=样本距 $$</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"充分统计量\"><a href=\"#充分统计量\" class=\"headerlink\" title=\"充分统计量\"></a>充分统计量</h3><p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png\" alt><br>从贝叶斯的观点出发：如果T具备了我们预测参数$\\theta$的所有信息（即T是充分统计量），那么$\\theta \\perp X \\mid T \\Rightarrow P(\\theta \\mid X, T)=P(\\theta\\mid T)$。<br>从频率学派的角度出发：如果T已知的用来产生数据的参数，那么$ X \\perp \\theta \\mid T \\Rightarrow P(X\\mid T;\\theta) = P(X\\mid T) $<br>从马尔科夫随机场的角度进行考虑：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%85%85%E5%88%86%E7%BB%9F%E8%AE%A1%E9%87%8F.png\" alt></p>\n<h2 id=\"贝叶斯\"><a href=\"#贝叶斯\" class=\"headerlink\" title=\"贝叶斯\"></a>贝叶斯</h2><p>重新从贝叶斯的角度出发，写出给定自然参数的似然函数，我们选择了一个自然参数先验，然后计算出自然参数的后验概率。<br>比如：<br>$$ p(x\\mid \\eta) \\propto exp(\\eta^ T T(x) - A(\\eta))$$<br>$$ p(\\eta) \\propto exp(\\xi^T T(\\eta) - A(\\xi)) $$<br>$$ p(\\eta\\mid x, \\xi) \\propto exp(\\eta^T T(x) + \\xi^T T(\\eta) + A(\\eta) + A(\\xi)) $$<br>如果$\\eta = T(\\eta)$ ，那么后验概率变为：<br>$$ p(\\eta\\mid x, \\xi) \\propto exp(T(\\eta)(T(x) + \\xi)+ A(\\eta) + A(\\xi)) $$<br>当$ \\eta = T(\\eta)$ ，我们指定$\\eta ~exponentialFamily$，这是先验就是共轭先验。</p>\n<h1 id=\"广义线性模型\"><a href=\"#广义线性模型\" class=\"headerlink\" title=\"广义线性模型\"></a>广义线性模型</h1><p>广义线性模型可以将分类和回归问题进行统一，使用相同的统计框架。<br>假定：<br>$$ Y \\sim exponentialFamily $$<br>$$ \\eta = \\psi(\\mu=f(\\xi = \\theta^T x)) $$<br>其中Y是响应，x是固定输入，$\\theta$是需要学习的参数，$f$（响应函数，response function），$\\psi$增加了一定的灵活性，f经常被设定为$\\psi^{-1}$（canonical response function）。</p>\n<h1 id=\"广义线性模型的批学习\"><a href=\"#广义线性模型的批学习\" class=\"headerlink\" title=\"广义线性模型的批学习\"></a>广义线性模型的批学习</h1><p>考虑通过求导的方法来解决最小二乘问题，就是使代价函数达到极小：<br>$$ J(\\theta) = \\frac{1}{2} \\Sigma_{i=1}^n (x_i^T\\theta - y_i)^2 = \\frac{1}{2} (X\\theta-y) $$<br>$x_i$表示第i个输入样本，$y_i$表示第i个输出样本。<br>对$J(\\theta)$求一阶导并令其为零，可以得到取得极小值时的$\\theta$。<br>$$ \\triangledown J(\\theta) = X^T X\\theta - X^T y = 0 \\Rightarrow \\theta^* = (X^T X)^{-1} X^T y $$<br>使用牛顿法进行迭代寻找最优解，牛顿法更新参数更新准则：<br>$$ \\theta^{t+1} = \\theta^t - H^{-1}\\triangledown J(\\theta) $$</p>\n<p>对数似然函数$l = \\Sigma_n logh(y_n) + \\Sigma_n(\\theta^T x_n y_n - A(\\eta))$<br>下面获得Hessian阵：<br>\\begin{equation}\\begin{split} H&amp;=\\frac{d^2 l}{d\\theta d\\theta^T}\\\\<br>&amp; = \\frac{d}{d\\theta^T}\\Sigma_n(y_n-\\mu_n)x_n\\\\<br>&amp; = \\Sigma_n x_n \\frac{d\\mu_n}{d\\theta^T}\\\\<br>&amp; = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} \\frac{d\\eta_n}{d\\theta^T}\\\\<br>&amp; = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} x_n^T \\   因为\\eta_n = \\theta^T x_n\\\\<br>&amp; = -X^T W X<br>\\end{split}\\end{equation}<br>其中$X = [x_n^T]$，$W = diag[\\frac{d\\mu_1}{d\\eta_1},…,\\frac{d\\mu_N}{d\\eta_N}]$。W可以同过计算$A(\\eta)$的二阶导来计算。<br>代换上式中的$\\triangledown J(\\theta)$和H，可以得到：<br>$$ \\theta^{t+1} = (X^T W^t X)^{-1} X^T W^t z^t $$<br>其中$z^t = X\\theta^ t + (W^t)^{-1}(y - \\mu^t)$。因为W是对角阵，所有该式子具有解耦的作用。</p>\n<h3 id=\"对数几率回归\"><a href=\"#对数几率回归\" class=\"headerlink\" title=\"对数几率回归\"></a>对数几率回归</h3><p>条件概率分布如下（伯努利分布）：<br>$$ p(y \\mid x) = \\mu(x)^y (1-\\mu(x))^{1-y} $$<br>其中$\\mu$是logistic函数<br>$$ \\mu(x) = \\frac{1}{1 + e^{-\\eta(x)}} $$</p>\n<p>由于$p(y\\mid x)$是指数族，<br>均值：<br>$$ E[y\\mid x] = \\mu = \\frac{1}{1 + e^{-\\eta(x)}} $$<br>canonical response  function:<br>$$ \\eta = \\xi = \\theta^T x $$<br>利用上面的方法广义线性模型中的方法求W：<br>$$ \\frac{d\\mu}{d\\eta} = \\mu (1 - \\mu) $$<br>$$ W =<br>\\begin{pmatrix}<br>\\mu_1 (1 - \\mu_1)\\\\<br>&amp;\\ddots \\\\<br>&amp; &amp; \\mu_N (1-\\mu_N) \\\\<br>\\end{pmatrix}<br>$$<br>其中N是训练样本的数量，d是输入样本的维度。上面的方法每代复杂度为$O(Nd^3)$。可以利用拟牛顿法来近似计算Hessian阵来减小运算成本。<br>共轭梯度每代的复杂度为$O(N d)$，在实际中使用效果更好。dang样本数量较大时，也可以采用随机梯度下降。</p>\n<h3 id=\"线性回归\"><a href=\"#线性回归\" class=\"headerlink\" title=\"线性回归\"></a>线性回归</h3><p>条件概率分布为：<br>$$p(y\\mid x,\\theta,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  \\frac{1}{2}(y-\\mu)^T\\Sigma^{-1}(y - \\mu) \\rbrace$$<br>从上面多元正态分布中，可以写成指数族的形式。<br>利用上面的方法广义线性模型中的方法求W：<br>$$ \\frac{d\\mu}{d\\eta} = 1 $$<br>$$ W = 1 $$<br>更新规则如下：<br>$$ \\theta^{t+1} = \\theta^t + (X^T X)^{-1} X^T(y - \\mu^t) $$</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>对于指数族分布，最大似然估计等价于矩估计。</li>\n<li>广义线性模型是图模型的实际应用中的重要组成部分。</li>\n<li>要选择合适的独立性以及合适的先验。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第6讲视频以及笔记。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"指数族\"><a href=\"#指数族\" class=\"headerlink\" title=\"指数族\"></a>指数族</h1><p>将随机变量X写成指数族的形式：<br>$$p(X=x;\\eta)=h(x)exp(\\eta^T T(x)-A(\\eta))$$<br>其中：$\\eta$是自然参数向量（natural paramater），T(x)是充分统计量（sufficient statistic），$A(\\eta)$是对数判分函数（log partition function）。</p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><p>指数族可以包括许多的例子，比如高斯分布，伯努利分布，多项式分布等。</p>\n<h3 id=\"多元正态分布\"><a href=\"#多元正态分布\" class=\"headerlink\" title=\"多元正态分布\"></a>多元正态分布</h3><p>令向量$X\\in R^k$<br>$$p(x\\mid \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}|\\Sigma|^{\\frac{1}{2}}}exp \\lbrace  -\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu) \\rbrace$$<br>$$=\\frac{1}{(2\\pi)^{k/2}} exp\\lbrace -\\frac{1}{2} tr(\\Sigma^{-1}x x^T) + \\mu^T \\Sigma^{-1}x^T- \\frac{1}{2}\\mu^T \\Sigma^{-1}\\mu - log|\\Sigma|\\rbrace$$<br>对应的指数族表示：<br>$$\\eta = [\\Sigma^{-1}\\mu; -\\frac{1}{2}vec(\\Sigma^{-1})]$$  $$ T(x)=[x;vec(xx^T)]$$  $$ A(\\eta)=\\frac{1}{2} \\mu^T \\Sigma^{-1} \\mu + log|\\Sigma| $$  $$ h(x)= \\frac{1} { {2\\pi}^{k/2} } $$</p>\n<h3 id=\"伯努利分布\"><a href=\"#伯努利分布\" class=\"headerlink\" title=\"伯努利分布\"></a>伯努利分布</h3><p>$$ p(x;\\phi) $$  $$ = \\phi^x(1-\\phi)^{1-x} $$  $$ = exp(log(\\phi^x(1-\\phi)^{1-x}) $$  $$ = exp(log(\\phi^x)+log((1-\\phi)^{1-x})) $$  $$ = exp(xlog(\\phi) + (1-x)log(1-\\phi)) $$  $$ = exp(xlog(\\frac{\\phi}{1-\\phi})+log(1-\\phi))$$<br>对应于指数族：<br>$$ \\eta = log(\\frac{\\phi}{1-\\phi}) $$  $$ T(x) = x $$  $$ A(\\eta) = -log(1-\\phi) $$  $$ h(x) = 1 $$</p>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>很多的分布可以看做是指数族：单变量高斯分布（the univariate Gaussian)，泊松分布（Poisson）， 多项分布（multinomial），线性回归（linear regression），伊辛模型（Ising model），受限波尔兹曼机机（restricted Boltzmann machines），还有条件随机场（contional random field，CRFs）。</p>\n<h4 id=\"条件随机场\"><a href=\"#条件随机场\" class=\"headerlink\" title=\"条件随机场\"></a>条件随机场</h4><p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png\" alt><br>条件随机场是基于上面图的无向图模型，势函数是定义在成对输出上面的。<br>$$ p_\\theta(y\\mid x)=\\frac{1}{Z(x)}exp(\\Sigma_{e\\in E,k} \\lambda_k f_k(e,y\\mid_e, x) + \\Sigma_{v\\in V,k} \\mu_k g_k(v,y\\mid_v, x))$$<br>其中$f_k$和$g_k$是固定的，$g_k$是波尔顶点特征，$f_k$是波尔边特征。</p>\n<h2 id=\"指数族特性\"><a href=\"#指数族特性\" class=\"headerlink\" title=\"指数族特性\"></a>指数族特性</h2><p>指数族具有如下的特性：</p>\n<ol>\n<li>对数配分函数的第d阶导数，是充分统计量的第d阶中心距。<br>比如：对数配分函数的一阶导数是T(X)的均值，其二阶导是T(X)的方差。</li>\n<li>因为对数配分函数的二阶导是正的，所以对数配分函数是凸的，因此方差总是非负的。</li>\n<li>我们可以将对数配分函数的一阶导看成自然参数的函数，然后令其为零，反过来利用距参数就可以解决自然参数，记作：$\\eta = \\psi(\\mu)$ 。</li>\n<li>在指数族上进行最大似然估计与矩匹配是一致的。<ul>\n<li>写出一般指数族的对数似然函数:<br>$$ const + \\eta^T (\\Sigma_{i=1}^n T(x_i)) - nA(\\eta) $$</li>\n<li>求似然函数的梯度：<br>$$ \\Sigma_{i=1}^n T(x_i)) - n\\Delta_\\eta A(\\eta) $$</li>\n<li>令$\\Delta_\\eta A$为零：<br>$$ \\Delta_\\eta A = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow \\mu = \\frac{1}{n}\\Sigma_{i=1}^T T(x_i) \\Rightarrow 矩估计=样本距 $$</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"充分统计量\"><a href=\"#充分统计量\" class=\"headerlink\" title=\"充分统计量\"></a>充分统计量</h3><p><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png\" alt><br>从贝叶斯的观点出发：如果T具备了我们预测参数$\\theta$的所有信息（即T是充分统计量），那么$\\theta \\perp X \\mid T \\Rightarrow P(\\theta \\mid X, T)=P(\\theta\\mid T)$。<br>从频率学派的角度出发：如果T已知的用来产生数据的参数，那么$ X \\perp \\theta \\mid T \\Rightarrow P(X\\mid T;\\theta) = P(X\\mid T) $<br>从马尔科夫随机场的角度进行考虑：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%85%85%E5%88%86%E7%BB%9F%E8%AE%A1%E9%87%8F.png\" alt></p>\n<h2 id=\"贝叶斯\"><a href=\"#贝叶斯\" class=\"headerlink\" title=\"贝叶斯\"></a>贝叶斯</h2><p>重新从贝叶斯的角度出发，写出给定自然参数的似然函数，我们选择了一个自然参数先验，然后计算出自然参数的后验概率。<br>比如：<br>$$ p(x\\mid \\eta) \\propto exp(\\eta^ T T(x) - A(\\eta))$$<br>$$ p(\\eta) \\propto exp(\\xi^T T(\\eta) - A(\\xi)) $$<br>$$ p(\\eta\\mid x, \\xi) \\propto exp(\\eta^T T(x) + \\xi^T T(\\eta) + A(\\eta) + A(\\xi)) $$<br>如果$\\eta = T(\\eta)$ ，那么后验概率变为：<br>$$ p(\\eta\\mid x, \\xi) \\propto exp(T(\\eta)(T(x) + \\xi)+ A(\\eta) + A(\\xi)) $$<br>当$ \\eta = T(\\eta)$ ，我们指定$\\eta ~exponentialFamily$，这是先验就是共轭先验。</p>\n<h1 id=\"广义线性模型\"><a href=\"#广义线性模型\" class=\"headerlink\" title=\"广义线性模型\"></a>广义线性模型</h1><p>广义线性模型可以将分类和回归问题进行统一，使用相同的统计框架。<br>假定：<br>$$ Y \\sim exponentialFamily $$<br>$$ \\eta = \\psi(\\mu=f(\\xi = \\theta^T x)) $$<br>其中Y是响应，x是固定输入，$\\theta$是需要学习的参数，$f$（响应函数，response function），$\\psi$增加了一定的灵活性，f经常被设定为$\\psi^{-1}$（canonical response function）。</p>\n<h1 id=\"广义线性模型的批学习\"><a href=\"#广义线性模型的批学习\" class=\"headerlink\" title=\"广义线性模型的批学习\"></a>广义线性模型的批学习</h1><p>考虑通过求导的方法来解决最小二乘问题，就是使代价函数达到极小：<br>$$ J(\\theta) = \\frac{1}{2} \\Sigma_{i=1}^n (x_i^T\\theta - y_i)^2 = \\frac{1}{2} (X\\theta-y) $$<br>$x_i$表示第i个输入样本，$y_i$表示第i个输出样本。<br>对$J(\\theta)$求一阶导并令其为零，可以得到取得极小值时的$\\theta$。<br>$$ \\triangledown J(\\theta) = X^T X\\theta - X^T y = 0 \\Rightarrow \\theta^* = (X^T X)^{-1} X^T y $$<br>使用牛顿法进行迭代寻找最优解，牛顿法更新参数更新准则：<br>$$ \\theta^{t+1} = \\theta^t - H^{-1}\\triangledown J(\\theta) $$</p>\n<p>对数似然函数$l = \\Sigma_n logh(y_n) + \\Sigma_n(\\theta^T x_n y_n - A(\\eta))$<br>下面获得Hessian阵：<br>\\begin{equation}\\begin{split} H&amp;=\\frac{d^2 l}{d\\theta d\\theta^T}\\\\<br>&amp; = \\frac{d}{d\\theta^T}\\Sigma_n(y_n-\\mu_n)x_n\\\\<br>&amp; = \\Sigma_n x_n \\frac{d\\mu_n}{d\\theta^T}\\\\<br>&amp; = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} \\frac{d\\eta_n}{d\\theta^T}\\\\<br>&amp; = -\\Sigma_n X_n \\frac{d\\mu_n}{d\\eta_n} x_n^T \\   因为\\eta_n = \\theta^T x_n\\\\<br>&amp; = -X^T W X<br>\\end{split}\\end{equation}<br>其中$X = [x_n^T]$，$W = diag[\\frac{d\\mu_1}{d\\eta_1},…,\\frac{d\\mu_N}{d\\eta_N}]$。W可以同过计算$A(\\eta)$的二阶导来计算。<br>代换上式中的$\\triangledown J(\\theta)$和H，可以得到：<br>$$ \\theta^{t+1} = (X^T W^t X)^{-1} X^T W^t z^t $$<br>其中$z^t = X\\theta^ t + (W^t)^{-1}(y - \\mu^t)$。因为W是对角阵，所有该式子具有解耦的作用。</p>\n<h3 id=\"对数几率回归\"><a href=\"#对数几率回归\" class=\"headerlink\" title=\"对数几率回归\"></a>对数几率回归</h3><p>条件概率分布如下（伯努利分布）：<br>$$ p(y \\mid x) = \\mu(x)^y (1-\\mu(x))^{1-y} $$<br>其中$\\mu$是logistic函数<br>$$ \\mu(x) = \\frac{1}{1 + e^{-\\eta(x)}} $$</p>\n<p>由于$p(y\\mid x)$是指数族，<br>均值：<br>$$ E[y\\mid x] = \\mu = \\frac{1}{1 + e^{-\\eta(x)}} $$<br>canonical response  function:<br>$$ \\eta = \\xi = \\theta^T x $$<br>利用上面的方法广义线性模型中的方法求W：<br>$$ \\frac{d\\mu}{d\\eta} = \\mu (1 - \\mu) $$<br>$$ W =<br>\\begin{pmatrix}<br>\\mu_1 (1 - \\mu_1)\\\\<br>&amp;\\ddots \\\\<br>&amp; &amp; \\mu_N (1-\\mu_N) \\\\<br>\\end{pmatrix}<br>$$<br>其中N是训练样本的数量，d是输入样本的维度。上面的方法每代复杂度为$O(Nd^3)$。可以利用拟牛顿法来近似计算Hessian阵来减小运算成本。<br>共轭梯度每代的复杂度为$O(N d)$，在实际中使用效果更好。dang样本数量较大时，也可以采用随机梯度下降。</p>\n<h3 id=\"线性回归\"><a href=\"#线性回归\" class=\"headerlink\" title=\"线性回归\"></a>线性回归</h3><p>条件概率分布为：<br>$$p(y\\mid x,\\theta,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\Sigma^{\\frac{1}{2}}}exp \\lbrace  \\frac{1}{2}(y-\\mu)^T\\Sigma^{-1}(y - \\mu) \\rbrace$$<br>从上面多元正态分布中，可以写成指数族的形式。<br>利用上面的方法广义线性模型中的方法求W：<br>$$ \\frac{d\\mu}{d\\eta} = 1 $$<br>$$ W = 1 $$<br>更新规则如下：<br>$$ \\theta^{t+1} = \\theta^t + (X^T X)^{-1} X^T(y - \\mu^t) $$</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>对于指数族分布，最大似然估计等价于矩估计。</li>\n<li>广义线性模型是图模型的实际应用中的重要组成部分。</li>\n<li>要选择合适的独立性以及合适的先验。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>[1] <a href=\"http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第6讲视频以及笔记。</p>\n"},{"title":"汇报list","date":"2018-09-26T08:43:47.000Z","_content":"# 2018.9.10\n暑假期间学习和看的论文：\n学习内容：\n1. 计算视觉CS131，完成了所有的homework的代码，然后传到了我的github上了。https://github.com/hjyai94/CS131_homework\n2. 计算机视觉CS231看了一点，还没有看完。\n3. 最近在看的深度学习和贝叶斯方法结合的一门课(http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。\n\n看的论文：\n[1] Deep Learning Markov Random Field for Semantic Segmentation\n[2] Single Image Haze Removal Method Using Conditional Random Fields\n[3] DehazeNet: An End-to-End System for Single Image Haze Removal\n\n# 2018.9.27\n最近看多模态的课，然后那个课上有一些论文作为阅读材料，最近主要看这些论文。\n\n[1] Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C]//European conference on computer vision. Springer, Cham, 2014: 818-833.\n1. 卷积神经网络确实可以学到层级的特征。\n2. 卷积核和步长越大，网络中保存的信息就越少。\n\n[2] Frome A, Corrado G S, Shlens J, et al. Devise: A deep visual-semantic embedding model[C]//Advances in neural information processing systems. 2013: 2121-2129.\n这篇文章就是用图像和文本来做分类的问题，就是利用一个视觉模型加上一个文本模型，对于超出训练集的样本也能给出比较好的分类。\n\n[3] Kulkarni T D, Whitney W F, Kohli P, et al. Deep convolutional inverse graphics network[C]//Advances in neural information processing systems. 2015: 2539-2547.\n有两个层Encoder和Decoder,在两层之间增加了一个Graphics code，用来表示图片的变化，比如姿态、角度。\n\n[4] Andrew G, Arora R, Bilmes J, et al. Deep canonical correlation analysis[C]//International Conference on Machine Learning. 2013: 1247-1255.\n将两个神经网络看成两个非线性函数，分别来处理两个模态的数据，最大化网络输出的典型相关性。\n\n# 2018.10.11\n多模态医学图像分析\n论文：\n[1] Baltruaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.\n这是一篇综述多模态机器学习的综述文章，我画了这篇文章的思维导图。\n ![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif)\n\n[2] Cheng X, Zhang L, Zheng Y. Deep similarity learning for multimodal medical images[J]. Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, 2018, 6(3): 248-252.\n用了一个所谓的Stacked Denosing Autoencoder 来预训练DNN，用了一个5层的全连接神经网络，将不同模态在第四层输出的差作为相似性矩阵。\n\n[3] Zhang Z, Yang L, Zheng Y. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 9242-9251.\n利用GAN合成数据来提高分割性能，不过GAN合成的数据的分布与实际数据分布是接近的。\n","source":"_posts/汇报list.md","raw":"---\ntitle: 汇报list\ndate: 2018-09-26 16:43:47\ntags: 汇报\ncategories: 工作\n---\n# 2018.9.10\n暑假期间学习和看的论文：\n学习内容：\n1. 计算视觉CS131，完成了所有的homework的代码，然后传到了我的github上了。https://github.com/hjyai94/CS131_homework\n2. 计算机视觉CS231看了一点，还没有看完。\n3. 最近在看的深度学习和贝叶斯方法结合的一门课(http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。\n\n看的论文：\n[1] Deep Learning Markov Random Field for Semantic Segmentation\n[2] Single Image Haze Removal Method Using Conditional Random Fields\n[3] DehazeNet: An End-to-End System for Single Image Haze Removal\n\n# 2018.9.27\n最近看多模态的课，然后那个课上有一些论文作为阅读材料，最近主要看这些论文。\n\n[1] Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C]//European conference on computer vision. Springer, Cham, 2014: 818-833.\n1. 卷积神经网络确实可以学到层级的特征。\n2. 卷积核和步长越大，网络中保存的信息就越少。\n\n[2] Frome A, Corrado G S, Shlens J, et al. Devise: A deep visual-semantic embedding model[C]//Advances in neural information processing systems. 2013: 2121-2129.\n这篇文章就是用图像和文本来做分类的问题，就是利用一个视觉模型加上一个文本模型，对于超出训练集的样本也能给出比较好的分类。\n\n[3] Kulkarni T D, Whitney W F, Kohli P, et al. Deep convolutional inverse graphics network[C]//Advances in neural information processing systems. 2015: 2539-2547.\n有两个层Encoder和Decoder,在两层之间增加了一个Graphics code，用来表示图片的变化，比如姿态、角度。\n\n[4] Andrew G, Arora R, Bilmes J, et al. Deep canonical correlation analysis[C]//International Conference on Machine Learning. 2013: 1247-1255.\n将两个神经网络看成两个非线性函数，分别来处理两个模态的数据，最大化网络输出的典型相关性。\n\n# 2018.10.11\n多模态医学图像分析\n论文：\n[1] Baltruaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.\n这是一篇综述多模态机器学习的综述文章，我画了这篇文章的思维导图。\n ![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif)\n\n[2] Cheng X, Zhang L, Zheng Y. Deep similarity learning for multimodal medical images[J]. Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, 2018, 6(3): 248-252.\n用了一个所谓的Stacked Denosing Autoencoder 来预训练DNN，用了一个5层的全连接神经网络，将不同模态在第四层输出的差作为相似性矩阵。\n\n[3] Zhang Z, Yang L, Zheng Y. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 9242-9251.\n利用GAN合成数据来提高分割性能，不过GAN合成的数据的分布与实际数据分布是接近的。\n","slug":"汇报list","published":1,"updated":"2018-10-11T09:02:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt100161ouzkhwlb1hd","content":"<h1 id=\"2018-9-10\"><a href=\"#2018-9-10\" class=\"headerlink\" title=\"2018.9.10\"></a>2018.9.10</h1><p>暑假期间学习和看的论文：<br>学习内容：</p>\n<ol>\n<li>计算视觉CS131，完成了所有的homework的代码，然后传到了我的github上了。<a href=\"https://github.com/hjyai94/CS131_homework\" target=\"_blank\" rel=\"noopener\">https://github.com/hjyai94/CS131_homework</a></li>\n<li>计算机视觉CS231看了一点，还没有看完。</li>\n<li>最近在看的深度学习和贝叶斯方法结合的一门课(<a href=\"http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。\" target=\"_blank\" rel=\"noopener\">http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。</a></li>\n</ol>\n<p>看的论文：<br>[1] Deep Learning Markov Random Field for Semantic Segmentation<br>[2] Single Image Haze Removal Method Using Conditional Random Fields<br>[3] DehazeNet: An End-to-End System for Single Image Haze Removal</p>\n<h1 id=\"2018-9-27\"><a href=\"#2018-9-27\" class=\"headerlink\" title=\"2018.9.27\"></a>2018.9.27</h1><p>最近看多模态的课，然后那个课上有一些论文作为阅读材料，最近主要看这些论文。</p>\n<p>[1] Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C]//European conference on computer vision. Springer, Cham, 2014: 818-833.</p>\n<ol>\n<li>卷积神经网络确实可以学到层级的特征。</li>\n<li>卷积核和步长越大，网络中保存的信息就越少。</li>\n</ol>\n<p>[2] Frome A, Corrado G S, Shlens J, et al. Devise: A deep visual-semantic embedding model[C]//Advances in neural information processing systems. 2013: 2121-2129.<br>这篇文章就是用图像和文本来做分类的问题，就是利用一个视觉模型加上一个文本模型，对于超出训练集的样本也能给出比较好的分类。</p>\n<p>[3] Kulkarni T D, Whitney W F, Kohli P, et al. Deep convolutional inverse graphics network[C]//Advances in neural information processing systems. 2015: 2539-2547.<br>有两个层Encoder和Decoder,在两层之间增加了一个Graphics code，用来表示图片的变化，比如姿态、角度。</p>\n<p>[4] Andrew G, Arora R, Bilmes J, et al. Deep canonical correlation analysis[C]//International Conference on Machine Learning. 2013: 1247-1255.<br>将两个神经网络看成两个非线性函数，分别来处理两个模态的数据，最大化网络输出的典型相关性。</p>\n<h1 id=\"2018-10-11\"><a href=\"#2018-10-11\" class=\"headerlink\" title=\"2018.10.11\"></a>2018.10.11</h1><p>多模态医学图像分析<br>论文：<br>[1] Baltruaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.<br>这是一篇综述多模态机器学习的综述文章，我画了这篇文章的思维导图。<br> <img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif\" alt></p>\n<p>[2] Cheng X, Zhang L, Zheng Y. Deep similarity learning for multimodal medical images[J]. Computer Methods in Biomechanics and Biomedical Engineering: Imaging &amp; Visualization, 2018, 6(3): 248-252.<br>用了一个所谓的Stacked Denosing Autoencoder 来预训练DNN，用了一个5层的全连接神经网络，将不同模态在第四层输出的差作为相似性矩阵。</p>\n<p>[3] Zhang Z, Yang L, Zheng Y. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 9242-9251.<br>利用GAN合成数据来提高分割性能，不过GAN合成的数据的分布与实际数据分布是接近的。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"2018-9-10\"><a href=\"#2018-9-10\" class=\"headerlink\" title=\"2018.9.10\"></a>2018.9.10</h1><p>暑假期间学习和看的论文：<br>学习内容：</p>\n<ol>\n<li>计算视觉CS131，完成了所有的homework的代码，然后传到了我的github上了。<a href=\"https://github.com/hjyai94/CS131_homework\" target=\"_blank\" rel=\"noopener\">https://github.com/hjyai94/CS131_homework</a></li>\n<li>计算机视觉CS231看了一点，还没有看完。</li>\n<li>最近在看的深度学习和贝叶斯方法结合的一门课(<a href=\"http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。\" target=\"_blank\" rel=\"noopener\">http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。</a></li>\n</ol>\n<p>看的论文：<br>[1] Deep Learning Markov Random Field for Semantic Segmentation<br>[2] Single Image Haze Removal Method Using Conditional Random Fields<br>[3] DehazeNet: An End-to-End System for Single Image Haze Removal</p>\n<h1 id=\"2018-9-27\"><a href=\"#2018-9-27\" class=\"headerlink\" title=\"2018.9.27\"></a>2018.9.27</h1><p>最近看多模态的课，然后那个课上有一些论文作为阅读材料，最近主要看这些论文。</p>\n<p>[1] Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C]//European conference on computer vision. Springer, Cham, 2014: 818-833.</p>\n<ol>\n<li>卷积神经网络确实可以学到层级的特征。</li>\n<li>卷积核和步长越大，网络中保存的信息就越少。</li>\n</ol>\n<p>[2] Frome A, Corrado G S, Shlens J, et al. Devise: A deep visual-semantic embedding model[C]//Advances in neural information processing systems. 2013: 2121-2129.<br>这篇文章就是用图像和文本来做分类的问题，就是利用一个视觉模型加上一个文本模型，对于超出训练集的样本也能给出比较好的分类。</p>\n<p>[3] Kulkarni T D, Whitney W F, Kohli P, et al. Deep convolutional inverse graphics network[C]//Advances in neural information processing systems. 2015: 2539-2547.<br>有两个层Encoder和Decoder,在两层之间增加了一个Graphics code，用来表示图片的变化，比如姿态、角度。</p>\n<p>[4] Andrew G, Arora R, Bilmes J, et al. Deep canonical correlation analysis[C]//International Conference on Machine Learning. 2013: 1247-1255.<br>将两个神经网络看成两个非线性函数，分别来处理两个模态的数据，最大化网络输出的典型相关性。</p>\n<h1 id=\"2018-10-11\"><a href=\"#2018-10-11\" class=\"headerlink\" title=\"2018.10.11\"></a>2018.10.11</h1><p>多模态医学图像分析<br>论文：<br>[1] Baltruaitis T, Ahuja C, Morency L P. Multimodal machine learning: A survey and taxonomy[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.<br>这是一篇综述多模态机器学习的综述文章，我画了这篇文章的思维导图。<br> <img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Multimodal%20Machine%20Learning.gif\" alt></p>\n<p>[2] Cheng X, Zhang L, Zheng Y. Deep similarity learning for multimodal medical images[J]. Computer Methods in Biomechanics and Biomedical Engineering: Imaging &amp; Visualization, 2018, 6(3): 248-252.<br>用了一个所谓的Stacked Denosing Autoencoder 来预训练DNN，用了一个5层的全连接神经网络，将不同模态在第四层输出的差作为相似性矩阵。</p>\n<p>[3] Zhang Z, Yang L, Zheng Y. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 9242-9251.<br>利用GAN合成数据来提高分割性能，不过GAN合成的数据的分布与实际数据分布是接近的。</p>\n"},{"title":"神经网络","date":"2018-04-18T12:30:14.000Z","_content":"感知机主要是解决了与非问题，输入是二值的0或者1，后来出现了Sigmoid。解决了感知机只能处理与非问题，将输出变为0~1之间，这样就有了神经网络。下面的文章非常的通俗易懂，可以一看。\nhttp://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent\n","source":"_posts/神经网络.md","raw":"---\ntitle: 神经网络\ndate: 2018-04-18 20:30:14\ntags: 神经网络\ncategories: 学习\n---\n感知机主要是解决了与非问题，输入是二值的0或者1，后来出现了Sigmoid。解决了感知机只能处理与非问题，将输出变为0~1之间，这样就有了神经网络。下面的文章非常的通俗易懂，可以一看。\nhttp://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent\n","slug":"神经网络","published":1,"updated":"2018-04-19T13:07:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt100171ouz7xt6hz6k","content":"<p>感知机主要是解决了与非问题，输入是二值的0或者1，后来出现了Sigmoid。解决了感知机只能处理与非问题，将输出变为0~1之间，这样就有了神经网络。下面的文章非常的通俗易懂，可以一看。<br><a href=\"http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent\" target=\"_blank\" rel=\"noopener\">http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>感知机主要是解决了与非问题，输入是二值的0或者1，后来出现了Sigmoid。解决了感知机只能处理与非问题，将输出变为0~1之间，这样就有了神经网络。下面的文章非常的通俗易懂，可以一看。<br><a href=\"http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent\" target=\"_blank\" rel=\"noopener\">http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent</a></p>\n"},{"title":"深度学习医学图像方向大佬","date":"2019-04-23T06:48:42.000Z","_content":"# Demetri Terzopoulos\n就职于UCLA(University of California, Los Angeles )，[个人主页](http://web.cs.ucla.edu/~dt/)，[实验室主页(UCLA Computer Graphics & Vision Laboratory)](http://www.magix.ucla.edu/index.html)。主要研究方向应该是计算机图像学方向，主要采用几何的方法研究图像。\n\n# Daniel Rueckert\n就职于Imperial College London，[个人主页](http://wp.doc.ic.ac.uk/dr/)，[实验室主页(BioMedIA)](https://biomedia.doc.ic.ac.uk/)。该课题组规模较大，研究范围非常的广，涉及到图像的重建、分割。\n\n# Milan Sonka\n就职于University of lowa，[个人主页](http://user.engineering.uiowa.edu/~sonka/research.php)。相对应的课题组有关于深度学习与图论方法的文章，可以看一看。\n\n# Dimitris N. Metaxas\n就职于Rutgers University，和Ian Goodfellow有联系，self-attention gan文章中有他的名字。[个人主页](https://www.cs.rutgers.edu/~dnm/)。\n\n# Paul Suetens\n就职于 KU Leuven ESAT/PSI，他们做了许多的关于中风方面的工作，其中ischemic stroke lesion becnmark 有他的参与。\n\n# Dinggang Shen\n[实验室主页](https://www.med.unc.edu/bric/ideagroup/)\n\n# Simon Keith Warfield\n就职于Harvard Medical School，[实验室主页](http://crl.med.harvard.edu/)。\n\n# Antonio Criminisi\n就职于微软，[个人主页](https://www.microsoft.com/en-us/research/people/antcrim/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fantcrim%2F)，用到的Autofocus layer就是对应组的工作，跟Konstantinos Kamnitsas有联系。","source":"_posts/深度学习医学图像方向大佬.md","raw":"---\ntitle: 深度学习医学图像方向大佬\ndate: 2019-04-23 14:48:42\ntags: 总结\ncategories: 工作\n---\n# Demetri Terzopoulos\n就职于UCLA(University of California, Los Angeles )，[个人主页](http://web.cs.ucla.edu/~dt/)，[实验室主页(UCLA Computer Graphics & Vision Laboratory)](http://www.magix.ucla.edu/index.html)。主要研究方向应该是计算机图像学方向，主要采用几何的方法研究图像。\n\n# Daniel Rueckert\n就职于Imperial College London，[个人主页](http://wp.doc.ic.ac.uk/dr/)，[实验室主页(BioMedIA)](https://biomedia.doc.ic.ac.uk/)。该课题组规模较大，研究范围非常的广，涉及到图像的重建、分割。\n\n# Milan Sonka\n就职于University of lowa，[个人主页](http://user.engineering.uiowa.edu/~sonka/research.php)。相对应的课题组有关于深度学习与图论方法的文章，可以看一看。\n\n# Dimitris N. Metaxas\n就职于Rutgers University，和Ian Goodfellow有联系，self-attention gan文章中有他的名字。[个人主页](https://www.cs.rutgers.edu/~dnm/)。\n\n# Paul Suetens\n就职于 KU Leuven ESAT/PSI，他们做了许多的关于中风方面的工作，其中ischemic stroke lesion becnmark 有他的参与。\n\n# Dinggang Shen\n[实验室主页](https://www.med.unc.edu/bric/ideagroup/)\n\n# Simon Keith Warfield\n就职于Harvard Medical School，[实验室主页](http://crl.med.harvard.edu/)。\n\n# Antonio Criminisi\n就职于微软，[个人主页](https://www.microsoft.com/en-us/research/people/antcrim/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fantcrim%2F)，用到的Autofocus layer就是对应组的工作，跟Konstantinos Kamnitsas有联系。","slug":"深度学习医学图像方向大佬","published":1,"updated":"2019-04-27T12:41:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt200181ouzeex8juht","content":"<h1 id=\"Demetri-Terzopoulos\"><a href=\"#Demetri-Terzopoulos\" class=\"headerlink\" title=\"Demetri Terzopoulos\"></a>Demetri Terzopoulos</h1><p>就职于UCLA(University of California, Los Angeles )，<a href=\"http://web.cs.ucla.edu/~dt/\" target=\"_blank\" rel=\"noopener\">个人主页</a>，<a href=\"http://www.magix.ucla.edu/index.html\" target=\"_blank\" rel=\"noopener\">实验室主页(UCLA Computer Graphics &amp; Vision Laboratory)</a>。主要研究方向应该是计算机图像学方向，主要采用几何的方法研究图像。</p>\n<h1 id=\"Daniel-Rueckert\"><a href=\"#Daniel-Rueckert\" class=\"headerlink\" title=\"Daniel Rueckert\"></a>Daniel Rueckert</h1><p>就职于Imperial College London，<a href=\"http://wp.doc.ic.ac.uk/dr/\" target=\"_blank\" rel=\"noopener\">个人主页</a>，<a href=\"https://biomedia.doc.ic.ac.uk/\" target=\"_blank\" rel=\"noopener\">实验室主页(BioMedIA)</a>。该课题组规模较大，研究范围非常的广，涉及到图像的重建、分割。</p>\n<h1 id=\"Milan-Sonka\"><a href=\"#Milan-Sonka\" class=\"headerlink\" title=\"Milan Sonka\"></a>Milan Sonka</h1><p>就职于University of lowa，<a href=\"http://user.engineering.uiowa.edu/~sonka/research.php\" target=\"_blank\" rel=\"noopener\">个人主页</a>。相对应的课题组有关于深度学习与图论方法的文章，可以看一看。</p>\n<h1 id=\"Dimitris-N-Metaxas\"><a href=\"#Dimitris-N-Metaxas\" class=\"headerlink\" title=\"Dimitris N. Metaxas\"></a>Dimitris N. Metaxas</h1><p>就职于Rutgers University，和Ian Goodfellow有联系，self-attention gan文章中有他的名字。<a href=\"https://www.cs.rutgers.edu/~dnm/\" target=\"_blank\" rel=\"noopener\">个人主页</a>。</p>\n<h1 id=\"Paul-Suetens\"><a href=\"#Paul-Suetens\" class=\"headerlink\" title=\"Paul Suetens\"></a>Paul Suetens</h1><p>就职于 KU Leuven ESAT/PSI，他们做了许多的关于中风方面的工作，其中ischemic stroke lesion becnmark 有他的参与。</p>\n<h1 id=\"Dinggang-Shen\"><a href=\"#Dinggang-Shen\" class=\"headerlink\" title=\"Dinggang Shen\"></a>Dinggang Shen</h1><p><a href=\"https://www.med.unc.edu/bric/ideagroup/\" target=\"_blank\" rel=\"noopener\">实验室主页</a></p>\n<h1 id=\"Simon-Keith-Warfield\"><a href=\"#Simon-Keith-Warfield\" class=\"headerlink\" title=\"Simon Keith Warfield\"></a>Simon Keith Warfield</h1><p>就职于Harvard Medical School，<a href=\"http://crl.med.harvard.edu/\" target=\"_blank\" rel=\"noopener\">实验室主页</a>。</p>\n<h1 id=\"Antonio-Criminisi\"><a href=\"#Antonio-Criminisi\" class=\"headerlink\" title=\"Antonio Criminisi\"></a>Antonio Criminisi</h1><p>就职于微软，<a href=\"https://www.microsoft.com/en-us/research/people/antcrim/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fantcrim%2F\" target=\"_blank\" rel=\"noopener\">个人主页</a>，用到的Autofocus layer就是对应组的工作，跟Konstantinos Kamnitsas有联系。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Demetri-Terzopoulos\"><a href=\"#Demetri-Terzopoulos\" class=\"headerlink\" title=\"Demetri Terzopoulos\"></a>Demetri Terzopoulos</h1><p>就职于UCLA(University of California, Los Angeles )，<a href=\"http://web.cs.ucla.edu/~dt/\" target=\"_blank\" rel=\"noopener\">个人主页</a>，<a href=\"http://www.magix.ucla.edu/index.html\" target=\"_blank\" rel=\"noopener\">实验室主页(UCLA Computer Graphics &amp; Vision Laboratory)</a>。主要研究方向应该是计算机图像学方向，主要采用几何的方法研究图像。</p>\n<h1 id=\"Daniel-Rueckert\"><a href=\"#Daniel-Rueckert\" class=\"headerlink\" title=\"Daniel Rueckert\"></a>Daniel Rueckert</h1><p>就职于Imperial College London，<a href=\"http://wp.doc.ic.ac.uk/dr/\" target=\"_blank\" rel=\"noopener\">个人主页</a>，<a href=\"https://biomedia.doc.ic.ac.uk/\" target=\"_blank\" rel=\"noopener\">实验室主页(BioMedIA)</a>。该课题组规模较大，研究范围非常的广，涉及到图像的重建、分割。</p>\n<h1 id=\"Milan-Sonka\"><a href=\"#Milan-Sonka\" class=\"headerlink\" title=\"Milan Sonka\"></a>Milan Sonka</h1><p>就职于University of lowa，<a href=\"http://user.engineering.uiowa.edu/~sonka/research.php\" target=\"_blank\" rel=\"noopener\">个人主页</a>。相对应的课题组有关于深度学习与图论方法的文章，可以看一看。</p>\n<h1 id=\"Dimitris-N-Metaxas\"><a href=\"#Dimitris-N-Metaxas\" class=\"headerlink\" title=\"Dimitris N. Metaxas\"></a>Dimitris N. Metaxas</h1><p>就职于Rutgers University，和Ian Goodfellow有联系，self-attention gan文章中有他的名字。<a href=\"https://www.cs.rutgers.edu/~dnm/\" target=\"_blank\" rel=\"noopener\">个人主页</a>。</p>\n<h1 id=\"Paul-Suetens\"><a href=\"#Paul-Suetens\" class=\"headerlink\" title=\"Paul Suetens\"></a>Paul Suetens</h1><p>就职于 KU Leuven ESAT/PSI，他们做了许多的关于中风方面的工作，其中ischemic stroke lesion becnmark 有他的参与。</p>\n<h1 id=\"Dinggang-Shen\"><a href=\"#Dinggang-Shen\" class=\"headerlink\" title=\"Dinggang Shen\"></a>Dinggang Shen</h1><p><a href=\"https://www.med.unc.edu/bric/ideagroup/\" target=\"_blank\" rel=\"noopener\">实验室主页</a></p>\n<h1 id=\"Simon-Keith-Warfield\"><a href=\"#Simon-Keith-Warfield\" class=\"headerlink\" title=\"Simon Keith Warfield\"></a>Simon Keith Warfield</h1><p>就职于Harvard Medical School，<a href=\"http://crl.med.harvard.edu/\" target=\"_blank\" rel=\"noopener\">实验室主页</a>。</p>\n<h1 id=\"Antonio-Criminisi\"><a href=\"#Antonio-Criminisi\" class=\"headerlink\" title=\"Antonio Criminisi\"></a>Antonio Criminisi</h1><p>就职于微软，<a href=\"https://www.microsoft.com/en-us/research/people/antcrim/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fantcrim%2F\" target=\"_blank\" rel=\"noopener\">个人主页</a>，用到的Autofocus layer就是对应组的工作，跟Konstantinos Kamnitsas有联系。</p>\n"},{"title":"科研三境界","date":"2017-11-29T14:00:14.000Z","_content":"科研有三个境界\n1. 昨夜西风凋碧树，独上高楼，望尽天涯路。\n2. 衣带渐宽终不悔，为伊消得人憔悴。\n3. 众里寻他千百度，蓦然回首，那人却在灯火阑珊处。\n","source":"_posts/科研三境界.md","raw":"---\ntitle: 科研三境界\ndate: 2017-11-29 22:00:14\ntags: 随笔\ncategories: 随笔\n---\n科研有三个境界\n1. 昨夜西风凋碧树，独上高楼，望尽天涯路。\n2. 衣带渐宽终不悔，为伊消得人憔悴。\n3. 众里寻他千百度，蓦然回首，那人却在灯火阑珊处。\n","slug":"科研三境界","published":1,"updated":"2019-05-01T13:19:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt300191ouz9tj5vkv4","content":"<p>科研有三个境界</p>\n<ol>\n<li>昨夜西风凋碧树，独上高楼，望尽天涯路。</li>\n<li>衣带渐宽终不悔，为伊消得人憔悴。</li>\n<li>众里寻他千百度，蓦然回首，那人却在灯火阑珊处。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>科研有三个境界</p>\n<ol>\n<li>昨夜西风凋碧树，独上高楼，望尽天涯路。</li>\n<li>衣带渐宽终不悔，为伊消得人憔悴。</li>\n<li>众里寻他千百度，蓦然回首，那人却在灯火阑珊处。</li>\n</ol>\n"},{"title":"算法学习一","date":"2019-04-27T12:50:49.000Z","_content":"最近写论文写不动，然后又不知道干点啥来荒废时间，正好看到了一本挺有意思的算法书《我的第一本算法书》，准备读一读，结合一些开源的程序，学习一下，并实现一下。本文的主要内容来自于《我的第一本算法书》和维基百科。\n\n# 算法的时间复杂度\n算法的时间复杂度通常用 $O$ 符号来表示，它的意思是忽略重要项以外的内容，比如说 $O(n^2)$ 表示算法的运行时间最长为 $n^2$ 的常数倍。\n1. 如果链表中的数据量为 $n$，我们从链表头部线性查找，如果目标在链表最后，需要的时间为 $o(n)$。链表中添加数据只需要更改两个指针的指向，所以耗费的时间与 $n$ 无关。如果到达了添加(删除)数据的位置，那么添加(删除)只需要 $O(1)$ 的时间。\n2. 数组与链表不同，数据是通过下表确定内存地址的，所以访问 $n$ 个数据的某个数据仅为恒定的 $O(1)$ 时间。若向数组中添加数据，则需要将目标位置的数据之后的数据一个个移开，如果在头部添加数据则需要 $O(n)$ 时间，删除同理。\n3. 在哈希表中，可以采用哈希函数快速访问到数组中的目标数据，如果发生哈希冲突，我们就使用链表进行存储。\n4. 在堆中，假设有 $n$ 个节点，根据堆的特点我们可以知道堆的高度为 $log_2\\ n$ (类似于等比数列求和)，那么对堆进行排序时间复杂度为 $O(log\\ n)$。\n5. 二叉搜索树的比较次数取决于树的高度，如果节点为 $n$，树的的形状又较为均衡的话，比较的大小和移动的次数最多为 $log_2\\ n$， 因此时间复杂度为 $O(log\\ n)$。\n\n# 排序\n所谓排序就是讲数据按照升序的方式调整顺寻，下面将介绍几种常见的排序算法。\n\n## 冒泡排序\n冒泡算法重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。冒泡排序对 $n$ 个数据的排序的时间复杂度 $O(n^2)$ 。\n\n{% fold %}\n```python\ndef bubble_sorted(iterable):\n    new_list = list(iterable)\n    list_len = len(new_list)\n    for i in range(list_len - 1):\n        for j in range(list_len - 1, i, -1):\n            if new_list[j] < new_list[j - 1]:\n                new_list[j], new_list[j - 1] = new_list[j - 1], new_list[j]\n    return new_list\n    \ntestlist = [27, 33, 28, 4, 2, 26, 13, 35, 8, 14]\nprint('sorted:', bubble_sorted(testlist))\n```\n{% endfold %}\n\n## 选择排序\n选择排序是一种简单直接的排序算法。它的工作原理如下：首先找到未排序列中最小的元素，存放在\n排序序列的其实位置，然后再从剩余未排序元素中寻找最小元素，然后放到一排序序列的末尾，一次类推，知道所有元素排序完毕，如下图所示。\n<img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Selection-Sort-Animation.gif\" width=\"10%\" height=\"10%\">\n```python\ndef selection_sort(arr):\n    for i in range(len(arr)):\n        minIndex=i\n        for j in range(i+1,len(arr)):\n            if arr[minIndex]>arr[j]:\n                minIndex=j\n        if i==minIndex:\n            pass\n        else:\n            arr[i],arr[minIndex]=arr[minIndex],arr[i]\n    return arr\nif __name__ == '__main__':\n    testlist = [17, 23, 20, 14, 12, 25, 1, 20, 81, 14, 11, 12]\n    print(selection_sort(testlist))\n```\n\n## 插入排序\n插入排序的工作原理是通过构建有序序列，对于为排序数据，在一排序序列中从后向前扫描，找到相应位置并插入，如下图所示。算法的时间复杂度为 $O(n^2)$。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Insertion-sort-example-300px.gif)\n```python\ndef insertion_sort(lst):\n    n=len(lst)\n    if n==1: return lst\n    for i in range(1,n):\n        for j in range(i,0,-1):\n            if lst[j]<lst[j-1]: \n                lst[j],lst[j-1]=lst[j-1],lst[j]\n            else:\n                break\n    return lst\n```\n\n## 堆排序\n堆排序是指利用对这种数据结构设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。堆排序的顺序是将元素进行重排，以匹配堆的条件。下图中排序过程之前简单地绘出了堆树的结构。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Sorting_heapsort_anim.gif)\n\n{% fold %}\n```python\n#!/usr/bin/env python\n#-*-coding:utf-8-*-\ndef heap_sort(lst):\n    def sift_down(start, end):\n        \"\"\"最大堆调整\"\"\"\n        root = start\n        while True:\n            child = 2 * root + 1\n            if child > end:\n                break\n            if child + 1 <= end and lst[child] < lst[child + 1]:\n                child += 1\n            if lst[root] < lst[child]:\n                lst[root], lst[child] = lst[child], lst[root]\n                root = child\n            else:\n                break\n\n# 创建最大堆\n\n    for start in range((len(lst) - 2) // 2, -1, -1): ## 从最后一个子节点出开始进行最## 大堆调整\n        sift_down(start, len(lst) - 1)\n\n# 堆排序\n    for end in range(len(lst) - 1, 0, -1):\n        lst[0], lst[end] = lst[end], lst[0]\n        sift_down(0, end - 1)\n    return lst\n\n\ndef main():\n    l = [9, 2, 1, 7, 6, 8, 5, 3, 4]\n    print(heap_sort(l))\n\nif __name__ == \"__main__\":\n    main()\n```\n{% endfold %}\n\n## 归并排序\n归并排序会将序列分成长度相同的来那个子序列，当无法继续往下分时(也就是每个子序列只有一个数据时)，就对子序列归并。归并指的是把来那个排好序的子序列合并成一个有序序列。该操作会一直进行，知道所有子序列都归并为一个整体为止。归并排序的算法时间复杂度为 $O(nlog\\ n)$。\n\n{% fold %}\n```python\n# Recursively implementation of Merge Sort\ndef merge(left, right):\n    result = []\n    while left and right:\n        if left[0] <= right[0]:\n            result.append(left.pop(0))\n        else:\n            result.append(right.pop(0))\n    if left:\n        result += left\n    if right:\n        result += right\n    return result\n\n\ndef merge_sort(L):\n    if len(L) <= 1:\n        # When D&C to 1 element, just return it\n        return L\n    mid = len(L) // 2\n    left = L[:mid]\n    right = L[mid:]\n\n    left = merge_sort(left)\n    right = merge_sort(right)\n    # conquer sub-problem recursively\n    return merge(left, right)\n    # return the answer of sub-problem\nif __name__ == \"__main__\":\n    test = [1, 4, 2, 3.6, -1, 0, 25, -34, 8, 9, 1, 0]\n    print(\"original:\", test)\n    print(\"Sorted:\", merge_sort(test))\n```\n{% endfold %}\n\n## 快速排序\n快速排序是在数列中挑选一个元素作为基准(pivot)，然后将数列按照“比基准小的数”和“比基准大的数”分为两类，然后进行使用快速排序进行递归排序“比基准小的数”和比“基准大的数”。快速排序的算法平均时间复杂度为 $O(nlog\\ n)$，因为其内部循环可以再大部分框架上很有效率的完成，所以称之为快速算法。\n\n```python\ndef quick_sort(lst):\n    if len(lst) <= 1:\n        return lst\n    less = []\n    greater = []\n    pivot = lst.pop()\n    for item in lst:\n        if item < pivot:\n            less.append(item)\n        else:\n            greater.append(item)\n    lst.append(pivot)\n    return quick_sort(less) + [pivot] + quick_sort(greater)\n```\n\n# P问题，NP问题，NP Complete问题，NP困难问题\n这部分是偶然看到的，和这里关系不大。\nP问题是指在多项式时间内可以解决的问题；NP问题是指在多项式时间内可以判断的问题；NP Complete是指在多项式时间内判断，不能在多项式时间内解决的问题。NP困难问题是指如果所有的NP问题都可以在多项式时间内归约到某个问题。\n具体上面问题的分布情况可以参照下面的图，目前普遍认为 $P \\neq NP$，如果$P = NP$，那么这个世界确实会很不一样，人人都能成为莫扎特系列。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png)","source":"_posts/算法学习一.md","raw":"---\ntitle: 算法学习一\ndate: 2019-04-27 20:50:49\ntags: 算法\ncategories: 学习\n---\n最近写论文写不动，然后又不知道干点啥来荒废时间，正好看到了一本挺有意思的算法书《我的第一本算法书》，准备读一读，结合一些开源的程序，学习一下，并实现一下。本文的主要内容来自于《我的第一本算法书》和维基百科。\n\n# 算法的时间复杂度\n算法的时间复杂度通常用 $O$ 符号来表示，它的意思是忽略重要项以外的内容，比如说 $O(n^2)$ 表示算法的运行时间最长为 $n^2$ 的常数倍。\n1. 如果链表中的数据量为 $n$，我们从链表头部线性查找，如果目标在链表最后，需要的时间为 $o(n)$。链表中添加数据只需要更改两个指针的指向，所以耗费的时间与 $n$ 无关。如果到达了添加(删除)数据的位置，那么添加(删除)只需要 $O(1)$ 的时间。\n2. 数组与链表不同，数据是通过下表确定内存地址的，所以访问 $n$ 个数据的某个数据仅为恒定的 $O(1)$ 时间。若向数组中添加数据，则需要将目标位置的数据之后的数据一个个移开，如果在头部添加数据则需要 $O(n)$ 时间，删除同理。\n3. 在哈希表中，可以采用哈希函数快速访问到数组中的目标数据，如果发生哈希冲突，我们就使用链表进行存储。\n4. 在堆中，假设有 $n$ 个节点，根据堆的特点我们可以知道堆的高度为 $log_2\\ n$ (类似于等比数列求和)，那么对堆进行排序时间复杂度为 $O(log\\ n)$。\n5. 二叉搜索树的比较次数取决于树的高度，如果节点为 $n$，树的的形状又较为均衡的话，比较的大小和移动的次数最多为 $log_2\\ n$， 因此时间复杂度为 $O(log\\ n)$。\n\n# 排序\n所谓排序就是讲数据按照升序的方式调整顺寻，下面将介绍几种常见的排序算法。\n\n## 冒泡排序\n冒泡算法重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。冒泡排序对 $n$ 个数据的排序的时间复杂度 $O(n^2)$ 。\n\n{% fold %}\n```python\ndef bubble_sorted(iterable):\n    new_list = list(iterable)\n    list_len = len(new_list)\n    for i in range(list_len - 1):\n        for j in range(list_len - 1, i, -1):\n            if new_list[j] < new_list[j - 1]:\n                new_list[j], new_list[j - 1] = new_list[j - 1], new_list[j]\n    return new_list\n    \ntestlist = [27, 33, 28, 4, 2, 26, 13, 35, 8, 14]\nprint('sorted:', bubble_sorted(testlist))\n```\n{% endfold %}\n\n## 选择排序\n选择排序是一种简单直接的排序算法。它的工作原理如下：首先找到未排序列中最小的元素，存放在\n排序序列的其实位置，然后再从剩余未排序元素中寻找最小元素，然后放到一排序序列的末尾，一次类推，知道所有元素排序完毕，如下图所示。\n<img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Selection-Sort-Animation.gif\" width=\"10%\" height=\"10%\">\n```python\ndef selection_sort(arr):\n    for i in range(len(arr)):\n        minIndex=i\n        for j in range(i+1,len(arr)):\n            if arr[minIndex]>arr[j]:\n                minIndex=j\n        if i==minIndex:\n            pass\n        else:\n            arr[i],arr[minIndex]=arr[minIndex],arr[i]\n    return arr\nif __name__ == '__main__':\n    testlist = [17, 23, 20, 14, 12, 25, 1, 20, 81, 14, 11, 12]\n    print(selection_sort(testlist))\n```\n\n## 插入排序\n插入排序的工作原理是通过构建有序序列，对于为排序数据，在一排序序列中从后向前扫描，找到相应位置并插入，如下图所示。算法的时间复杂度为 $O(n^2)$。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Insertion-sort-example-300px.gif)\n```python\ndef insertion_sort(lst):\n    n=len(lst)\n    if n==1: return lst\n    for i in range(1,n):\n        for j in range(i,0,-1):\n            if lst[j]<lst[j-1]: \n                lst[j],lst[j-1]=lst[j-1],lst[j]\n            else:\n                break\n    return lst\n```\n\n## 堆排序\n堆排序是指利用对这种数据结构设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。堆排序的顺序是将元素进行重排，以匹配堆的条件。下图中排序过程之前简单地绘出了堆树的结构。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Sorting_heapsort_anim.gif)\n\n{% fold %}\n```python\n#!/usr/bin/env python\n#-*-coding:utf-8-*-\ndef heap_sort(lst):\n    def sift_down(start, end):\n        \"\"\"最大堆调整\"\"\"\n        root = start\n        while True:\n            child = 2 * root + 1\n            if child > end:\n                break\n            if child + 1 <= end and lst[child] < lst[child + 1]:\n                child += 1\n            if lst[root] < lst[child]:\n                lst[root], lst[child] = lst[child], lst[root]\n                root = child\n            else:\n                break\n\n# 创建最大堆\n\n    for start in range((len(lst) - 2) // 2, -1, -1): ## 从最后一个子节点出开始进行最## 大堆调整\n        sift_down(start, len(lst) - 1)\n\n# 堆排序\n    for end in range(len(lst) - 1, 0, -1):\n        lst[0], lst[end] = lst[end], lst[0]\n        sift_down(0, end - 1)\n    return lst\n\n\ndef main():\n    l = [9, 2, 1, 7, 6, 8, 5, 3, 4]\n    print(heap_sort(l))\n\nif __name__ == \"__main__\":\n    main()\n```\n{% endfold %}\n\n## 归并排序\n归并排序会将序列分成长度相同的来那个子序列，当无法继续往下分时(也就是每个子序列只有一个数据时)，就对子序列归并。归并指的是把来那个排好序的子序列合并成一个有序序列。该操作会一直进行，知道所有子序列都归并为一个整体为止。归并排序的算法时间复杂度为 $O(nlog\\ n)$。\n\n{% fold %}\n```python\n# Recursively implementation of Merge Sort\ndef merge(left, right):\n    result = []\n    while left and right:\n        if left[0] <= right[0]:\n            result.append(left.pop(0))\n        else:\n            result.append(right.pop(0))\n    if left:\n        result += left\n    if right:\n        result += right\n    return result\n\n\ndef merge_sort(L):\n    if len(L) <= 1:\n        # When D&C to 1 element, just return it\n        return L\n    mid = len(L) // 2\n    left = L[:mid]\n    right = L[mid:]\n\n    left = merge_sort(left)\n    right = merge_sort(right)\n    # conquer sub-problem recursively\n    return merge(left, right)\n    # return the answer of sub-problem\nif __name__ == \"__main__\":\n    test = [1, 4, 2, 3.6, -1, 0, 25, -34, 8, 9, 1, 0]\n    print(\"original:\", test)\n    print(\"Sorted:\", merge_sort(test))\n```\n{% endfold %}\n\n## 快速排序\n快速排序是在数列中挑选一个元素作为基准(pivot)，然后将数列按照“比基准小的数”和“比基准大的数”分为两类，然后进行使用快速排序进行递归排序“比基准小的数”和比“基准大的数”。快速排序的算法平均时间复杂度为 $O(nlog\\ n)$，因为其内部循环可以再大部分框架上很有效率的完成，所以称之为快速算法。\n\n```python\ndef quick_sort(lst):\n    if len(lst) <= 1:\n        return lst\n    less = []\n    greater = []\n    pivot = lst.pop()\n    for item in lst:\n        if item < pivot:\n            less.append(item)\n        else:\n            greater.append(item)\n    lst.append(pivot)\n    return quick_sort(less) + [pivot] + quick_sort(greater)\n```\n\n# P问题，NP问题，NP Complete问题，NP困难问题\n这部分是偶然看到的，和这里关系不大。\nP问题是指在多项式时间内可以解决的问题；NP问题是指在多项式时间内可以判断的问题；NP Complete是指在多项式时间内判断，不能在多项式时间内解决的问题。NP困难问题是指如果所有的NP问题都可以在多项式时间内归约到某个问题。\n具体上面问题的分布情况可以参照下面的图，目前普遍认为 $P \\neq NP$，如果$P = NP$，那么这个世界确实会很不一样，人人都能成为莫扎特系列。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png)","slug":"算法学习一","published":1,"updated":"2019-05-01T13:21:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt4001a1ouzyainoabe","content":"<p>最近写论文写不动，然后又不知道干点啥来荒废时间，正好看到了一本挺有意思的算法书《我的第一本算法书》，准备读一读，结合一些开源的程序，学习一下，并实现一下。本文的主要内容来自于《我的第一本算法书》和维基百科。</p>\n<h1 id=\"算法的时间复杂度\"><a href=\"#算法的时间复杂度\" class=\"headerlink\" title=\"算法的时间复杂度\"></a>算法的时间复杂度</h1><p>算法的时间复杂度通常用 $O$ 符号来表示，它的意思是忽略重要项以外的内容，比如说 $O(n^2)$ 表示算法的运行时间最长为 $n^2$ 的常数倍。</p>\n<ol>\n<li>如果链表中的数据量为 $n$，我们从链表头部线性查找，如果目标在链表最后，需要的时间为 $o(n)$。链表中添加数据只需要更改两个指针的指向，所以耗费的时间与 $n$ 无关。如果到达了添加(删除)数据的位置，那么添加(删除)只需要 $O(1)$ 的时间。</li>\n<li>数组与链表不同，数据是通过下表确定内存地址的，所以访问 $n$ 个数据的某个数据仅为恒定的 $O(1)$ 时间。若向数组中添加数据，则需要将目标位置的数据之后的数据一个个移开，如果在头部添加数据则需要 $O(n)$ 时间，删除同理。</li>\n<li>在哈希表中，可以采用哈希函数快速访问到数组中的目标数据，如果发生哈希冲突，我们就使用链表进行存储。</li>\n<li>在堆中，假设有 $n$ 个节点，根据堆的特点我们可以知道堆的高度为 $log_2\\ n$ (类似于等比数列求和)，那么对堆进行排序时间复杂度为 $O(log\\ n)$。</li>\n<li>二叉搜索树的比较次数取决于树的高度，如果节点为 $n$，树的的形状又较为均衡的话，比较的大小和移动的次数最多为 $log_2\\ n$， 因此时间复杂度为 $O(log\\ n)$。</li>\n</ol>\n<h1 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h1><p>所谓排序就是讲数据按照升序的方式调整顺寻，下面将介绍几种常见的排序算法。</p>\n<h2 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h2><p>冒泡算法重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。冒泡排序对 $n$ 个数据的排序的时间复杂度 $O(n^2)$ 。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bubble_sorted</span><span class=\"params\">(iterable)</span>:</span></span><br><span class=\"line\">    new_list = list(iterable)</span><br><span class=\"line\">    list_len = len(new_list)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(list_len - <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(list_len - <span class=\"number\">1</span>, i, <span class=\"number\">-1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> new_list[j] &lt; new_list[j - <span class=\"number\">1</span>]:</span><br><span class=\"line\">                new_list[j], new_list[j - <span class=\"number\">1</span>] = new_list[j - <span class=\"number\">1</span>], new_list[j]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> new_list</span><br><span class=\"line\">    </span><br><span class=\"line\">testlist = [<span class=\"number\">27</span>, <span class=\"number\">33</span>, <span class=\"number\">28</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">26</span>, <span class=\"number\">13</span>, <span class=\"number\">35</span>, <span class=\"number\">8</span>, <span class=\"number\">14</span>]</span><br><span class=\"line\">print(<span class=\"string\">'sorted:'</span>, bubble_sorted(testlist))</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<h2 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h2><p>选择排序是一种简单直接的排序算法。它的工作原理如下：首先找到未排序列中最小的元素，存放在<br>排序序列的其实位置，然后再从剩余未排序元素中寻找最小元素，然后放到一排序序列的末尾，一次类推，知道所有元素排序完毕，如下图所示。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Selection-Sort-Animation.gif\" width=\"10%\" height=\"10%\"><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">selection_sort</span><span class=\"params\">(arr)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(arr)):</span><br><span class=\"line\">        minIndex=i</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(i+<span class=\"number\">1</span>,len(arr)):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> arr[minIndex]&gt;arr[j]:</span><br><span class=\"line\">                minIndex=j</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i==minIndex:</span><br><span class=\"line\">            <span class=\"keyword\">pass</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            arr[i],arr[minIndex]=arr[minIndex],arr[i]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> arr</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    testlist = [<span class=\"number\">17</span>, <span class=\"number\">23</span>, <span class=\"number\">20</span>, <span class=\"number\">14</span>, <span class=\"number\">12</span>, <span class=\"number\">25</span>, <span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">81</span>, <span class=\"number\">14</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]</span><br><span class=\"line\">    print(selection_sort(testlist))</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h2><p>插入排序的工作原理是通过构建有序序列，对于为排序数据，在一排序序列中从后向前扫描，找到相应位置并插入，如下图所示。算法的时间复杂度为 $O(n^2)$。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Insertion-sort-example-300px.gif\" alt><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">insertion_sort</span><span class=\"params\">(lst)</span>:</span></span><br><span class=\"line\">    n=len(lst)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> n==<span class=\"number\">1</span>: <span class=\"keyword\">return</span> lst</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(i,<span class=\"number\">0</span>,<span class=\"number\">-1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> lst[j]&lt;lst[j<span class=\"number\">-1</span>]: </span><br><span class=\"line\">                lst[j],lst[j<span class=\"number\">-1</span>]=lst[j<span class=\"number\">-1</span>],lst[j]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> lst</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h2><p>堆排序是指利用对这种数据结构设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。堆排序的顺序是将元素进行重排，以匹配堆的条件。下图中排序过程之前简单地绘出了堆树的结构。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Sorting_heapsort_anim.gif\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\">#-*-coding:utf-8-*-</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">heap_sort</span><span class=\"params\">(lst)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sift_down</span><span class=\"params\">(start, end)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"最大堆调整\"\"\"</span></span><br><span class=\"line\">        root = start</span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            child = <span class=\"number\">2</span> * root + <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> child &gt; end:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> child + <span class=\"number\">1</span> &lt;= end <span class=\"keyword\">and</span> lst[child] &lt; lst[child + <span class=\"number\">1</span>]:</span><br><span class=\"line\">                child += <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> lst[root] &lt; lst[child]:</span><br><span class=\"line\">                lst[root], lst[child] = lst[child], lst[root]</span><br><span class=\"line\">                root = child</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建最大堆</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> start <span class=\"keyword\">in</span> range((len(lst) - <span class=\"number\">2</span>) // <span class=\"number\">2</span>, <span class=\"number\">-1</span>, <span class=\"number\">-1</span>): <span class=\"comment\">## 从最后一个子节点出开始进行最## 大堆调整</span></span><br><span class=\"line\">        sift_down(start, len(lst) - <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 堆排序</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> end <span class=\"keyword\">in</span> range(len(lst) - <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">-1</span>):</span><br><span class=\"line\">        lst[<span class=\"number\">0</span>], lst[end] = lst[end], lst[<span class=\"number\">0</span>]</span><br><span class=\"line\">        sift_down(<span class=\"number\">0</span>, end - <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> lst</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    l = [<span class=\"number\">9</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">7</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">5</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>]</span><br><span class=\"line\">    print(heap_sort(l))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<h2 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h2><p>归并排序会将序列分成长度相同的来那个子序列，当无法继续往下分时(也就是每个子序列只有一个数据时)，就对子序列归并。归并指的是把来那个排好序的子序列合并成一个有序序列。该操作会一直进行，知道所有子序列都归并为一个整体为止。归并排序的算法时间复杂度为 $O(nlog\\ n)$。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Recursively implementation of Merge Sort</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span><span class=\"params\">(left, right)</span>:</span></span><br><span class=\"line\">    result = []</span><br><span class=\"line\">    <span class=\"keyword\">while</span> left <span class=\"keyword\">and</span> right:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> left[<span class=\"number\">0</span>] &lt;= right[<span class=\"number\">0</span>]:</span><br><span class=\"line\">            result.append(left.pop(<span class=\"number\">0</span>))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            result.append(right.pop(<span class=\"number\">0</span>))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> left:</span><br><span class=\"line\">        result += left</span><br><span class=\"line\">    <span class=\"keyword\">if</span> right:</span><br><span class=\"line\">        result += right</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge_sort</span><span class=\"params\">(L)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(L) &lt;= <span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"comment\"># When D&amp;C to 1 element, just return it</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> L</span><br><span class=\"line\">    mid = len(L) // <span class=\"number\">2</span></span><br><span class=\"line\">    left = L[:mid]</span><br><span class=\"line\">    right = L[mid:]</span><br><span class=\"line\"></span><br><span class=\"line\">    left = merge_sort(left)</span><br><span class=\"line\">    right = merge_sort(right)</span><br><span class=\"line\">    <span class=\"comment\"># conquer sub-problem recursively</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> merge(left, right)</span><br><span class=\"line\">    <span class=\"comment\"># return the answer of sub-problem</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    test = [<span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">3.6</span>, <span class=\"number\">-1</span>, <span class=\"number\">0</span>, <span class=\"number\">25</span>, <span class=\"number\">-34</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">    print(<span class=\"string\">\"original:\"</span>, test)</span><br><span class=\"line\">    print(<span class=\"string\">\"Sorted:\"</span>, merge_sort(test))</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<h2 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h2><p>快速排序是在数列中挑选一个元素作为基准(pivot)，然后将数列按照“比基准小的数”和“比基准大的数”分为两类，然后进行使用快速排序进行递归排序“比基准小的数”和比“基准大的数”。快速排序的算法平均时间复杂度为 $O(nlog\\ n)$，因为其内部循环可以再大部分框架上很有效率的完成，所以称之为快速算法。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">quick_sort</span><span class=\"params\">(lst)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(lst) &lt;= <span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> lst</span><br><span class=\"line\">    less = []</span><br><span class=\"line\">    greater = []</span><br><span class=\"line\">    pivot = lst.pop()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> lst:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> item &lt; pivot:</span><br><span class=\"line\">            less.append(item)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            greater.append(item)</span><br><span class=\"line\">    lst.append(pivot)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> quick_sort(less) + [pivot] + quick_sort(greater)</span><br></pre></td></tr></table></figure>\n<h1 id=\"P问题，NP问题，NP-Complete问题，NP困难问题\"><a href=\"#P问题，NP问题，NP-Complete问题，NP困难问题\" class=\"headerlink\" title=\"P问题，NP问题，NP Complete问题，NP困难问题\"></a>P问题，NP问题，NP Complete问题，NP困难问题</h1><p>这部分是偶然看到的，和这里关系不大。<br>P问题是指在多项式时间内可以解决的问题；NP问题是指在多项式时间内可以判断的问题；NP Complete是指在多项式时间内判断，不能在多项式时间内解决的问题。NP困难问题是指如果所有的NP问题都可以在多项式时间内归约到某个问题。<br>具体上面问题的分布情况可以参照下面的图，目前普遍认为 $P \\neq NP$，如果$P = NP$，那么这个世界确实会很不一样，人人都能成为莫扎特系列。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近写论文写不动，然后又不知道干点啥来荒废时间，正好看到了一本挺有意思的算法书《我的第一本算法书》，准备读一读，结合一些开源的程序，学习一下，并实现一下。本文的主要内容来自于《我的第一本算法书》和维基百科。</p>\n<h1 id=\"算法的时间复杂度\"><a href=\"#算法的时间复杂度\" class=\"headerlink\" title=\"算法的时间复杂度\"></a>算法的时间复杂度</h1><p>算法的时间复杂度通常用 $O$ 符号来表示，它的意思是忽略重要项以外的内容，比如说 $O(n^2)$ 表示算法的运行时间最长为 $n^2$ 的常数倍。</p>\n<ol>\n<li>如果链表中的数据量为 $n$，我们从链表头部线性查找，如果目标在链表最后，需要的时间为 $o(n)$。链表中添加数据只需要更改两个指针的指向，所以耗费的时间与 $n$ 无关。如果到达了添加(删除)数据的位置，那么添加(删除)只需要 $O(1)$ 的时间。</li>\n<li>数组与链表不同，数据是通过下表确定内存地址的，所以访问 $n$ 个数据的某个数据仅为恒定的 $O(1)$ 时间。若向数组中添加数据，则需要将目标位置的数据之后的数据一个个移开，如果在头部添加数据则需要 $O(n)$ 时间，删除同理。</li>\n<li>在哈希表中，可以采用哈希函数快速访问到数组中的目标数据，如果发生哈希冲突，我们就使用链表进行存储。</li>\n<li>在堆中，假设有 $n$ 个节点，根据堆的特点我们可以知道堆的高度为 $log_2\\ n$ (类似于等比数列求和)，那么对堆进行排序时间复杂度为 $O(log\\ n)$。</li>\n<li>二叉搜索树的比较次数取决于树的高度，如果节点为 $n$，树的的形状又较为均衡的话，比较的大小和移动的次数最多为 $log_2\\ n$， 因此时间复杂度为 $O(log\\ n)$。</li>\n</ol>\n<h1 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h1><p>所谓排序就是讲数据按照升序的方式调整顺寻，下面将介绍几种常见的排序算法。</p>\n<h2 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h2><p>冒泡算法重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。冒泡排序对 $n$ 个数据的排序的时间复杂度 $O(n^2)$ 。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�61-->\n\n</div></div>\n<h2 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h2><p>选择排序是一种简单直接的排序算法。它的工作原理如下：首先找到未排序列中最小的元素，存放在<br>排序序列的其实位置，然后再从剩余未排序元素中寻找最小元素，然后放到一排序序列的末尾，一次类推，知道所有元素排序完毕，如下图所示。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Selection-Sort-Animation.gif\" width=\"10%\" height=\"10%\"><br><!--�62--></p>\n<h2 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h2><p>插入排序的工作原理是通过构建有序序列，对于为排序数据，在一排序序列中从后向前扫描，找到相应位置并插入，如下图所示。算法的时间复杂度为 $O(n^2)$。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Insertion-sort-example-300px.gif\" alt><br><!--�63--></p>\n<h2 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h2><p>堆排序是指利用对这种数据结构设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。堆排序的顺序是将元素进行重排，以匹配堆的条件。下图中排序过程之前简单地绘出了堆树的结构。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Sorting_heapsort_anim.gif\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�64-->\n\n</div></div>\n<h2 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h2><p>归并排序会将序列分成长度相同的来那个子序列，当无法继续往下分时(也就是每个子序列只有一个数据时)，就对子序列归并。归并指的是把来那个排好序的子序列合并成一个有序序列。该操作会一直进行，知道所有子序列都归并为一个整体为止。归并排序的算法时间复杂度为 $O(nlog\\ n)$。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�65-->\n\n</div></div>\n<h2 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h2><p>快速排序是在数列中挑选一个元素作为基准(pivot)，然后将数列按照“比基准小的数”和“比基准大的数”分为两类，然后进行使用快速排序进行递归排序“比基准小的数”和比“基准大的数”。快速排序的算法平均时间复杂度为 $O(nlog\\ n)$，因为其内部循环可以再大部分框架上很有效率的完成，所以称之为快速算法。</p>\n<!--�66-->\n<h1 id=\"P问题，NP问题，NP-Complete问题，NP困难问题\"><a href=\"#P问题，NP问题，NP-Complete问题，NP困难问题\" class=\"headerlink\" title=\"P问题，NP问题，NP Complete问题，NP困难问题\"></a>P问题，NP问题，NP Complete问题，NP困难问题</h1><p>这部分是偶然看到的，和这里关系不大。<br>P问题是指在多项式时间内可以解决的问题；NP问题是指在多项式时间内可以判断的问题；NP Complete是指在多项式时间内判断，不能在多项式时间内解决的问题。NP困难问题是指如果所有的NP问题都可以在多项式时间内归约到某个问题。<br>具体上面问题的分布情况可以参照下面的图，目前普遍认为 $P \\neq NP$，如果$P = NP$，那么这个世界确实会很不一样，人人都能成为莫扎特系列。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png\" alt></p>\n"},{"title":"计算机视觉回顾","date":"2018-01-29T02:06:01.000Z","_content":"# 图像分类\n图像识别\n李飞飞 ImageNet\n\n# 目标检测\n行人检测和车辆检测\n\n# 图像分割\n## 语义分割 semantic segmentation\n\n## 个体分割\ninstance segmentation\n\n# 视觉目标跟踪\n\n# 视频分割\n\n利用神经网络实现数据的降维[1]。\n[1] Hinton, G. E., & Salakhutdinov, R. R. (2006). Reducing the dimensionality of\n data with neural networks. science, 313(5786), 504-507.\n\n利用卷积神经网络实现对图像的分类[2]。\n[2] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification\nwith deep convolutional neural networks. In Advances in neural information\nprocessing systems (pp. 1097-1105).\n\nRNN  利用数据间的依赖关系建模[3]。\n[3] Williams, R. J., & Zipser, D. (1989). A learning algorithm for continually\nrunning fully recurrent neural networks. Neural computation, 1(2), 270-280.\n\nLSTM [4]\n[4] Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural\ncomputation, 9(8), 1735-1780.\n\n深度学习网络：VGGnet， GoogleNet， ResNet， DenseNet。\n深度学习开发平台：Tensorflow， Caffe等。\n","source":"_posts/计算机视觉回顾.md","raw":"---\ntitle: 计算机视觉回顾\ndate: 2018-01-29 10:06:01\ntags: 计算机视觉\ncategories: 学习\n---\n# 图像分类\n图像识别\n李飞飞 ImageNet\n\n# 目标检测\n行人检测和车辆检测\n\n# 图像分割\n## 语义分割 semantic segmentation\n\n## 个体分割\ninstance segmentation\n\n# 视觉目标跟踪\n\n# 视频分割\n\n利用神经网络实现数据的降维[1]。\n[1] Hinton, G. E., & Salakhutdinov, R. R. (2006). Reducing the dimensionality of\n data with neural networks. science, 313(5786), 504-507.\n\n利用卷积神经网络实现对图像的分类[2]。\n[2] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification\nwith deep convolutional neural networks. In Advances in neural information\nprocessing systems (pp. 1097-1105).\n\nRNN  利用数据间的依赖关系建模[3]。\n[3] Williams, R. J., & Zipser, D. (1989). A learning algorithm for continually\nrunning fully recurrent neural networks. Neural computation, 1(2), 270-280.\n\nLSTM [4]\n[4] Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural\ncomputation, 9(8), 1735-1780.\n\n深度学习网络：VGGnet， GoogleNet， ResNet， DenseNet。\n深度学习开发平台：Tensorflow， Caffe等。\n","slug":"计算机视觉回顾","published":1,"updated":"2018-09-22T06:33:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt4001b1ouzyh5zn3iv","content":"<h1 id=\"图像分类\"><a href=\"#图像分类\" class=\"headerlink\" title=\"图像分类\"></a>图像分类</h1><p>图像识别<br>李飞飞 ImageNet</p>\n<h1 id=\"目标检测\"><a href=\"#目标检测\" class=\"headerlink\" title=\"目标检测\"></a>目标检测</h1><p>行人检测和车辆检测</p>\n<h1 id=\"图像分割\"><a href=\"#图像分割\" class=\"headerlink\" title=\"图像分割\"></a>图像分割</h1><h2 id=\"语义分割-semantic-segmentation\"><a href=\"#语义分割-semantic-segmentation\" class=\"headerlink\" title=\"语义分割 semantic segmentation\"></a>语义分割 semantic segmentation</h2><h2 id=\"个体分割\"><a href=\"#个体分割\" class=\"headerlink\" title=\"个体分割\"></a>个体分割</h2><p>instance segmentation</p>\n<h1 id=\"视觉目标跟踪\"><a href=\"#视觉目标跟踪\" class=\"headerlink\" title=\"视觉目标跟踪\"></a>视觉目标跟踪</h1><h1 id=\"视频分割\"><a href=\"#视频分割\" class=\"headerlink\" title=\"视频分割\"></a>视频分割</h1><p>利用神经网络实现数据的降维[1]。<br>[1] Hinton, G. E., &amp; Salakhutdinov, R. R. (2006). Reducing the dimensionality of<br> data with neural networks. science, 313(5786), 504-507.</p>\n<p>利用卷积神经网络实现对图像的分类[2]。<br>[2] Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification<br>with deep convolutional neural networks. In Advances in neural information<br>processing systems (pp. 1097-1105).</p>\n<p>RNN  利用数据间的依赖关系建模[3]。<br>[3] Williams, R. J., &amp; Zipser, D. (1989). A learning algorithm for continually<br>running fully recurrent neural networks. Neural computation, 1(2), 270-280.</p>\n<p>LSTM [4]<br>[4] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural<br>computation, 9(8), 1735-1780.</p>\n<p>深度学习网络：VGGnet， GoogleNet， ResNet， DenseNet。<br>深度学习开发平台：Tensorflow， Caffe等。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"图像分类\"><a href=\"#图像分类\" class=\"headerlink\" title=\"图像分类\"></a>图像分类</h1><p>图像识别<br>李飞飞 ImageNet</p>\n<h1 id=\"目标检测\"><a href=\"#目标检测\" class=\"headerlink\" title=\"目标检测\"></a>目标检测</h1><p>行人检测和车辆检测</p>\n<h1 id=\"图像分割\"><a href=\"#图像分割\" class=\"headerlink\" title=\"图像分割\"></a>图像分割</h1><h2 id=\"语义分割-semantic-segmentation\"><a href=\"#语义分割-semantic-segmentation\" class=\"headerlink\" title=\"语义分割 semantic segmentation\"></a>语义分割 semantic segmentation</h2><h2 id=\"个体分割\"><a href=\"#个体分割\" class=\"headerlink\" title=\"个体分割\"></a>个体分割</h2><p>instance segmentation</p>\n<h1 id=\"视觉目标跟踪\"><a href=\"#视觉目标跟踪\" class=\"headerlink\" title=\"视觉目标跟踪\"></a>视觉目标跟踪</h1><h1 id=\"视频分割\"><a href=\"#视频分割\" class=\"headerlink\" title=\"视频分割\"></a>视频分割</h1><p>利用神经网络实现数据的降维[1]。<br>[1] Hinton, G. E., &amp; Salakhutdinov, R. R. (2006). Reducing the dimensionality of<br> data with neural networks. science, 313(5786), 504-507.</p>\n<p>利用卷积神经网络实现对图像的分类[2]。<br>[2] Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification<br>with deep convolutional neural networks. In Advances in neural information<br>processing systems (pp. 1097-1105).</p>\n<p>RNN  利用数据间的依赖关系建模[3]。<br>[3] Williams, R. J., &amp; Zipser, D. (1989). A learning algorithm for continually<br>running fully recurrent neural networks. Neural computation, 1(2), 270-280.</p>\n<p>LSTM [4]<br>[4] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural<br>computation, 9(8), 1735-1780.</p>\n<p>深度学习网络：VGGnet， GoogleNet， ResNet， DenseNet。<br>深度学习开发平台：Tensorflow， Caffe等。</p>\n"},{"title":"论文总结","date":"2018-05-18T11:21:20.000Z","_content":"","source":"_posts/论文总结.md","raw":"---\ntitle: 论文总结\ndate: 2018-05-18 19:21:20\ntags:\n---\n","slug":"论文总结","published":1,"updated":"2018-05-20T01:31:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt5001c1ouzgbi6dapd","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"算法学习二","date":"2019-04-30T01:25:47.000Z","_content":"这是算法学习的第二篇博客，本文将聚焦于图搜索相关的算法。\n\n# 图\n所谓的图(Graph)由节点和边构成，节点代表变量，边表示相互关系，通常具有一定的权重。图的搜索算法可以解决一些基本的问题，比如最短路径问题。\n\n## 广度优先搜索\n广度优先搜索的特征从起点开始，由近及远进行广泛地搜索。下面我们定义一个图(如下图)，这是个无向图，我们从某个节点出发分别进行广度优先搜索和深度优先搜索。![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/BFS_DFS.png)\n\n{% fold %}\n```python\ngraph = {\n    \"A\": [\"B\", \"C\"],\n    \"B\": [\"A\", \"C\", \"D\"],\n    \"C\": [\"A\", \"B\", \"D\", \"E\"], \n    \"D\": [\"B\", \"C\", \"E\", \"F\"],\n    \"E\": [\"C\", \"D\"],\n    \"F\": [\"D\"]\n}\n\n# 广度优先搜索\ndef BFS(graph, s):\n    queue = []\n    queue.append(s)\n    seen = set()\n    seen.add(s)\n    # parent = {s: None}\n    while(len(queue) > 0):\n        vertex = queue.pop(0)\n        nodes = graph[vertex]\n        for w in nodes:\n            if w not in seen:\n                queue.append(w)\n                seen.add(w)\n                # parent[w] = vertex\n        print(vertex)\n    # return parent\n```\n{% endfold %}\n\n## 深度优先搜索\n深度优先搜索和广度有限搜索一样，都是对图进行搜索的算法，目的都是从起点开始到达指定顶点(终点)。深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。\n\n{% fold %}\n```python\n# 深度优先搜索\ndef DFS(graph, s):\n    stack = []\n    stack.append(s)\n    seen = set()\n    seen.add(s)\n    while(len(stack) > 0):\n        vertex = stack.pop()\n        nodes = graph[vertex]\n        for w in nodes:\n            if w not in seen:\n                stack.append(w)\n                seen.add(w)\n        print(vertex)\n```\n{% endfold %}\n\n# 最短路径\n下面我们看一些求最短路径的算法，贝尔曼-福特算法，Dijkstra算法，还有A-star算法。求下面的图 $A$ 到其它节点的最短路径。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/graph_with_weight.png)\n\n## 贝尔曼-福特算法(Bellman-ford)\n贝尔曼-福特算法是求最短路的一种算法，该算法是以松弛操作为基础，集估计的最短路径值逐渐被更加精确的值代替，直至得到最优解。该算法的缺点是时间复杂度较高 $O(|V||E|)$，其中 $|V|$ 代表节点数量，$|E|$代表边的数量。\n\n{% fold %}\n```python\nimport math\ndef getEdges(G):\n     \"\"\" 输入图G，返回其边与端点的列表 \"\"\"\n     v1 = []     # 出发点         \n     v2 = []     # 对应的相邻到达点\n     w  = []     # 顶点v1到顶点v2的边的权值\n     for i in G:\n         for j in G[i]:\n             if G[i][j] != 0:\n                 w.append(G[i][j])\n                 v1.append(i)\n                 v2.append(j)\n     return v1,v2,w\n \nclass CycleError(Exception):\n    pass\n \ndef Bellman_Ford(G, s):\n    v1,v2,w = getEdges(G)\n    \n    # 初始化源点与所有点之间的最短距离\n    distance = dict((k, math.inf) for k in G.keys())\n    distance[s] = 0\n    parent = {s: None}\n    # 核心算法\n    for k in range(len(G)-1):   # 循环 n-1轮\n        check = 0           # 用于标记本轮松弛中distance是否发生更新\n        for i in range(len(w)):     # 对每条边进行一次松弛操作\n            if distance[v1[i]] + w[i] < distance[v2[i]]:\n                distance[v2[i]] = distance[v1[i]] + w[i]\n                check = 1\n                parent[v2[i]] = v1[i]\n        if check == 0: break\n     \n     # 检测负权回路\n     # 如果在 n-1 次松弛之后，最短路径依然发生变化，则该图必然存在负权回路\n    flag = 0\n    for i in range(len(w)):             # 对每条边再尝试进行一次松弛操作\n        if distance[v1[i]] + w[i] < distance[v2[i]]: \n            flag = 1\n            break\n    if flag == 1:\n #         raise CycleError()\n        return False\n    return distance, parent\n```\n{% endfold %}\n\n## Dijkstra算法\nDijkstra算法可以看作是广度优先搜索在有权图上的推广，其是通过为每个顶点保留到目前为止的最短路径工作的。最初的Dijkstra算法没有通过小优先队列实现，时间复杂度为 $O(|V|^2)$(其中 $|V|为图的顶点个数$)。通过斐波那契堆实现的Dijkstra算法的时间复杂度为 $O(|E|+|V|log|V|)$ (其中 $|E|$ 为边数)，对于不含负权的有向图，Dijkstra是已知的最快单源最短路径算法。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Dijkstra_Animation.gif)\n\n{% fold %}\n```python\nimport heapq\nimport math\ngraph = {\n    \"A\": {\"B\": 5, \"C\": 1},\n    \"B\": {\"A\": 5, \"C\": 2, \"D\": 1},\n    \"C\": {\"A\": 1, \"B\": 2, \"D\": 4, \"E\": 8}, \n    \"D\": {\"B\": 1, \"C\": 4, \"E\": 3, \"F\": 6},\n    \"E\": {\"C\": 8, \"D\": 3},\n    \"F\": {\"D\": 6}\n}\n\ndef init_distance(graph, s):\n    distance = {s: 0}\n    for vertex in graph:\n        if vertex != s:\n            distance[vertex] = math.inf\n    return distance\n\ndef dijkstra(graph, s):\n    pqueue = []\n    heapq.heappush(pqueue, (0, s))\n    seen = set()\n    seen.add(s)\n    parent = {s: None}\n\n    distance = init_distance(graph, s)\n\n    while(len(pqueue) > 0):\n        pair = heapq.heappop(pqueue)\n        distance = pair[0]\n        vertex = pair[1]\n        seen.add(vertex)\n\n        nodes = graph[vertex].keys()\n        for w in nodes:\n            if w not in seen:\n                if distance + graph[vertex][w] < distance[w]:\n                    heapq.heappush(pqueue, (distance + graph[vertex][w], w))\n                    parent[w] = vertex\n                    distance[w] = distance + graph[vertex][w]\n    return parent, distance\n\nif __name__ == \"__main__\":\n    parent, distance= dijkstra(graph, \"A\")\n    print(parent, distance)\n\n    v = \"B\"\n    while v != None:\n        print(v)\n        v = parent[v]\n```\n{% endfold %}\n\n虽然Doijkstra算法和Bellman ford算法一样可以求解有向图中的最短路径问题，但是当图中有负数权重时，Dijkstra算法无法得到正确的答案。\n\n## A-star 算法\nA-star算法是有Dijkstra发展而来的算法。Dijkstra算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。也就是说一些离起点较远的顶点的最短路径也会被计算出来，但这部分是无用的。与之不同的是，A-star算法会先估计一个值，然后利用这个值省去无用的计算。\n下面我们详细地介绍一下A-star算法在路径规划上面的应用，不同前面的简单路径图，我们这里使用了一个“硬核”的迷宫图，其中红色箭头表示起点位置，蓝色箭头表示终点位置，黑色的点代表障碍物，障碍物是不能直接穿过的。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/maze.png)\n\n{% fold %}\n```python\nimport matplotlib.pyplot as plt\nimport math\n\nshow_animation = True\n\n\nclass Node:\n\n    def __init__(self, x, y, cost, pind):\n        self.x = x\n        self.y = y\n        self.cost = cost\n        self.pind = pind\n\n    def __str__(self):\n        return str(self.x) + \",\" + str(self.y) + \",\" + str(self.cost) + \",\" + str(self.pind)\n\n\ndef calc_final_path(ngoal, closedset, reso):\n    # generate final course\n    rx, ry = [ngoal.x * reso], [ngoal.y * reso]\n    pind = ngoal.pind\n    while pind != -1:\n        n = closedset[pind]\n        rx.append(n.x * reso)\n        ry.append(n.y * reso)\n        pind = n.pind\n\n    return rx, ry\n\n\ndef a_star_planning(sx, sy, gx, gy, ox, oy, reso, rr):\n    \"\"\"\n    gx: goal x position [m]\n    gx: goal x position [m]\n    ox: x position list of Obstacles [m]\n    oy: y position list of Obstacles [m]\n    reso: grid resolution [m]\n    rr: robot radius[m]\n    \"\"\"\n\n    nstart = Node(round(sx / reso), round(sy / reso), 0.0, -1)\n    ngoal = Node(round(gx / reso), round(gy / reso), 0.0, -1)\n    ox = [iox / reso for iox in ox]\n    oy = [ioy / reso for ioy in oy]\n\n    obmap, minx, miny, maxx, maxy, xw, yw = calc_obstacle_map(ox, oy, reso, rr)\n\n    motion = get_motion_model()\n\n    openset, closedset = dict(), dict()\n    openset[calc_index(nstart, xw, minx, miny)] = nstart\n\n    while 1:\n        c_id = min(\n            openset, key=lambda o: openset[o].cost + calc_heuristic(ngoal, openset[o]))\n        current = openset[c_id]\n\n        # show graph\n        if show_animation:  # pragma: no cover\n            plt.plot(current.x * reso, current.y * reso, \"xc\")\n            if len(closedset.keys()) % 10 == 0:\n                plt.pause(0.001)\n\n        if current.x == ngoal.x and current.y == ngoal.y:\n            print(\"Find goal\")\n            ngoal.pind = current.pind\n            ngoal.cost = current.cost\n            break\n\n        # Remove the item from the open set\n        del openset[c_id]\n        # Add it to the closed set\n        closedset[c_id] = current\n\n        # expand search grid based on motion model\n        for i, _ in enumerate(motion):\n            node = Node(current.x + motion[i][0],\n                        current.y + motion[i][1],\n                        current.cost + motion[i][2], c_id)\n            n_id = calc_index(node, xw, minx, miny)\n\n            if n_id in closedset:\n                continue\n\n            if not verify_node(node, obmap, minx, miny, maxx, maxy):\n                continue\n\n            if n_id not in openset:\n                openset[n_id] = node  # Discover a new node\n            else:\n                if openset[n_id].cost >= node.cost:\n                    # This path is the best until now. record it!\n                    openset[n_id] = node\n\n    rx, ry = calc_final_path(ngoal, closedset, reso)\n\n    return rx, ry\n\n\ndef calc_heuristic(n1, n2):\n    w = 1.0  # weight of heuristic\n    d = w * math.sqrt((n1.x - n2.x)**2 + (n1.y - n2.y)**2)\n    return d\n\n\ndef verify_node(node, obmap, minx, miny, maxx, maxy):\n\n    if node.x < minx:\n        return False\n    elif node.y < miny:\n        return False\n    elif node.x >= maxx:\n        return False\n    elif node.y >= maxy:\n        return False\n\n    if obmap[node.x][node.y]:\n        return False\n\n    return True\n\n\ndef calc_obstacle_map(ox, oy, reso, vr):\n\n    minx = round(min(ox))\n    miny = round(min(oy))\n    maxx = round(max(ox))\n    maxy = round(max(oy))\n    #  print(\"minx:\", minx)\n    #  print(\"miny:\", miny)\n    #  print(\"maxx:\", maxx)\n    #  print(\"maxy:\", maxy)\n\n    xwidth = round(maxx - minx)\n    ywidth = round(maxy - miny)\n    #  print(\"xwidth:\", xwidth)\n    #  print(\"ywidth:\", ywidth)\n\n    # obstacle map generation\n    obmap = [[False for i in range(ywidth)] for i in range(xwidth)]\n    for ix in range(xwidth):\n        x = ix + minx\n        for iy in range(ywidth):\n            y = iy + miny\n            #  print(x, y)\n            for iox, ioy in zip(ox, oy):\n                d = math.sqrt((iox - x)**2 + (ioy - y)**2)\n                if d <= vr / reso:\n                    obmap[ix][iy] = True\n                    break\n\n    return obmap, minx, miny, maxx, maxy, xwidth, ywidth\n\n\ndef calc_index(node, xwidth, xmin, ymin):\n    return (node.y - ymin) * xwidth + (node.x - xmin)\n\n\ndef get_motion_model():\n    # dx, dy, cost\n    motion = [[1, 0, 1],\n              [0, 1, 1],\n              [-1, 0, 1],\n              [0, -1, 1],\n              [-1, -1, math.sqrt(2)],\n              [-1, 1, math.sqrt(2)],\n              [1, -1, math.sqrt(2)],\n              [1, 1, math.sqrt(2)]]\n\n    return motion\n\n\ndef main():\n    print(__file__ + \" start!!\")\n\n    # start and goal position\n    sx = 10.0  # [m]\n    sy = 10.0  # [m]\n    gx = 50.0  # [m]\n    gy = 50.0  # [m]\n    grid_size = 1.0  # [m]\n    robot_size = 1.0  # [m]\n\n    ox, oy = [], []\n\n    for i in range(60):\n        ox.append(i)\n        oy.append(0.0)\n    for i in range(60):\n        ox.append(60.0)\n        oy.append(i)\n    for i in range(61):\n        ox.append(i)\n        oy.append(60.0)\n    for i in range(61):\n        ox.append(0.0)\n        oy.append(i)\n    for i in range(40):\n        ox.append(20.0)\n        oy.append(i)\n    for i in range(40):\n        ox.append(40.0)\n        oy.append(60.0 - i)\n\n    if show_animation:  # pragma: no cover\n        plt.plot(ox, oy, \".k\")\n        plt.plot(sx, sy, \"xr\")\n        plt.plot(gx, gy, \"xb\")\n        plt.grid(True)\n        plt.axis(\"equal\")\n\n    rx, ry = a_star_planning(sx, sy, gx, gy, ox, oy, grid_size, robot_size)\n\n    if show_animation:  # pragma: no cover\n        plt.plot(rx, ry, \"-r\")\n        plt.show()\n\n\nif __name__ == '__main__':\n    main()\n```\n{% endfold %}\n\n\n","source":"_posts/算法学习二.md","raw":"---\ntitle: 算法学习二\ndate: 2019-04-30 09:25:47\ntags: 算法\ncategories: 学习\n---\n这是算法学习的第二篇博客，本文将聚焦于图搜索相关的算法。\n\n# 图\n所谓的图(Graph)由节点和边构成，节点代表变量，边表示相互关系，通常具有一定的权重。图的搜索算法可以解决一些基本的问题，比如最短路径问题。\n\n## 广度优先搜索\n广度优先搜索的特征从起点开始，由近及远进行广泛地搜索。下面我们定义一个图(如下图)，这是个无向图，我们从某个节点出发分别进行广度优先搜索和深度优先搜索。![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/BFS_DFS.png)\n\n{% fold %}\n```python\ngraph = {\n    \"A\": [\"B\", \"C\"],\n    \"B\": [\"A\", \"C\", \"D\"],\n    \"C\": [\"A\", \"B\", \"D\", \"E\"], \n    \"D\": [\"B\", \"C\", \"E\", \"F\"],\n    \"E\": [\"C\", \"D\"],\n    \"F\": [\"D\"]\n}\n\n# 广度优先搜索\ndef BFS(graph, s):\n    queue = []\n    queue.append(s)\n    seen = set()\n    seen.add(s)\n    # parent = {s: None}\n    while(len(queue) > 0):\n        vertex = queue.pop(0)\n        nodes = graph[vertex]\n        for w in nodes:\n            if w not in seen:\n                queue.append(w)\n                seen.add(w)\n                # parent[w] = vertex\n        print(vertex)\n    # return parent\n```\n{% endfold %}\n\n## 深度优先搜索\n深度优先搜索和广度有限搜索一样，都是对图进行搜索的算法，目的都是从起点开始到达指定顶点(终点)。深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。\n\n{% fold %}\n```python\n# 深度优先搜索\ndef DFS(graph, s):\n    stack = []\n    stack.append(s)\n    seen = set()\n    seen.add(s)\n    while(len(stack) > 0):\n        vertex = stack.pop()\n        nodes = graph[vertex]\n        for w in nodes:\n            if w not in seen:\n                stack.append(w)\n                seen.add(w)\n        print(vertex)\n```\n{% endfold %}\n\n# 最短路径\n下面我们看一些求最短路径的算法，贝尔曼-福特算法，Dijkstra算法，还有A-star算法。求下面的图 $A$ 到其它节点的最短路径。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/graph_with_weight.png)\n\n## 贝尔曼-福特算法(Bellman-ford)\n贝尔曼-福特算法是求最短路的一种算法，该算法是以松弛操作为基础，集估计的最短路径值逐渐被更加精确的值代替，直至得到最优解。该算法的缺点是时间复杂度较高 $O(|V||E|)$，其中 $|V|$ 代表节点数量，$|E|$代表边的数量。\n\n{% fold %}\n```python\nimport math\ndef getEdges(G):\n     \"\"\" 输入图G，返回其边与端点的列表 \"\"\"\n     v1 = []     # 出发点         \n     v2 = []     # 对应的相邻到达点\n     w  = []     # 顶点v1到顶点v2的边的权值\n     for i in G:\n         for j in G[i]:\n             if G[i][j] != 0:\n                 w.append(G[i][j])\n                 v1.append(i)\n                 v2.append(j)\n     return v1,v2,w\n \nclass CycleError(Exception):\n    pass\n \ndef Bellman_Ford(G, s):\n    v1,v2,w = getEdges(G)\n    \n    # 初始化源点与所有点之间的最短距离\n    distance = dict((k, math.inf) for k in G.keys())\n    distance[s] = 0\n    parent = {s: None}\n    # 核心算法\n    for k in range(len(G)-1):   # 循环 n-1轮\n        check = 0           # 用于标记本轮松弛中distance是否发生更新\n        for i in range(len(w)):     # 对每条边进行一次松弛操作\n            if distance[v1[i]] + w[i] < distance[v2[i]]:\n                distance[v2[i]] = distance[v1[i]] + w[i]\n                check = 1\n                parent[v2[i]] = v1[i]\n        if check == 0: break\n     \n     # 检测负权回路\n     # 如果在 n-1 次松弛之后，最短路径依然发生变化，则该图必然存在负权回路\n    flag = 0\n    for i in range(len(w)):             # 对每条边再尝试进行一次松弛操作\n        if distance[v1[i]] + w[i] < distance[v2[i]]: \n            flag = 1\n            break\n    if flag == 1:\n #         raise CycleError()\n        return False\n    return distance, parent\n```\n{% endfold %}\n\n## Dijkstra算法\nDijkstra算法可以看作是广度优先搜索在有权图上的推广，其是通过为每个顶点保留到目前为止的最短路径工作的。最初的Dijkstra算法没有通过小优先队列实现，时间复杂度为 $O(|V|^2)$(其中 $|V|为图的顶点个数$)。通过斐波那契堆实现的Dijkstra算法的时间复杂度为 $O(|E|+|V|log|V|)$ (其中 $|E|$ 为边数)，对于不含负权的有向图，Dijkstra是已知的最快单源最短路径算法。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Dijkstra_Animation.gif)\n\n{% fold %}\n```python\nimport heapq\nimport math\ngraph = {\n    \"A\": {\"B\": 5, \"C\": 1},\n    \"B\": {\"A\": 5, \"C\": 2, \"D\": 1},\n    \"C\": {\"A\": 1, \"B\": 2, \"D\": 4, \"E\": 8}, \n    \"D\": {\"B\": 1, \"C\": 4, \"E\": 3, \"F\": 6},\n    \"E\": {\"C\": 8, \"D\": 3},\n    \"F\": {\"D\": 6}\n}\n\ndef init_distance(graph, s):\n    distance = {s: 0}\n    for vertex in graph:\n        if vertex != s:\n            distance[vertex] = math.inf\n    return distance\n\ndef dijkstra(graph, s):\n    pqueue = []\n    heapq.heappush(pqueue, (0, s))\n    seen = set()\n    seen.add(s)\n    parent = {s: None}\n\n    distance = init_distance(graph, s)\n\n    while(len(pqueue) > 0):\n        pair = heapq.heappop(pqueue)\n        distance = pair[0]\n        vertex = pair[1]\n        seen.add(vertex)\n\n        nodes = graph[vertex].keys()\n        for w in nodes:\n            if w not in seen:\n                if distance + graph[vertex][w] < distance[w]:\n                    heapq.heappush(pqueue, (distance + graph[vertex][w], w))\n                    parent[w] = vertex\n                    distance[w] = distance + graph[vertex][w]\n    return parent, distance\n\nif __name__ == \"__main__\":\n    parent, distance= dijkstra(graph, \"A\")\n    print(parent, distance)\n\n    v = \"B\"\n    while v != None:\n        print(v)\n        v = parent[v]\n```\n{% endfold %}\n\n虽然Doijkstra算法和Bellman ford算法一样可以求解有向图中的最短路径问题，但是当图中有负数权重时，Dijkstra算法无法得到正确的答案。\n\n## A-star 算法\nA-star算法是有Dijkstra发展而来的算法。Dijkstra算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。也就是说一些离起点较远的顶点的最短路径也会被计算出来，但这部分是无用的。与之不同的是，A-star算法会先估计一个值，然后利用这个值省去无用的计算。\n下面我们详细地介绍一下A-star算法在路径规划上面的应用，不同前面的简单路径图，我们这里使用了一个“硬核”的迷宫图，其中红色箭头表示起点位置，蓝色箭头表示终点位置，黑色的点代表障碍物，障碍物是不能直接穿过的。\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/maze.png)\n\n{% fold %}\n```python\nimport matplotlib.pyplot as plt\nimport math\n\nshow_animation = True\n\n\nclass Node:\n\n    def __init__(self, x, y, cost, pind):\n        self.x = x\n        self.y = y\n        self.cost = cost\n        self.pind = pind\n\n    def __str__(self):\n        return str(self.x) + \",\" + str(self.y) + \",\" + str(self.cost) + \",\" + str(self.pind)\n\n\ndef calc_final_path(ngoal, closedset, reso):\n    # generate final course\n    rx, ry = [ngoal.x * reso], [ngoal.y * reso]\n    pind = ngoal.pind\n    while pind != -1:\n        n = closedset[pind]\n        rx.append(n.x * reso)\n        ry.append(n.y * reso)\n        pind = n.pind\n\n    return rx, ry\n\n\ndef a_star_planning(sx, sy, gx, gy, ox, oy, reso, rr):\n    \"\"\"\n    gx: goal x position [m]\n    gx: goal x position [m]\n    ox: x position list of Obstacles [m]\n    oy: y position list of Obstacles [m]\n    reso: grid resolution [m]\n    rr: robot radius[m]\n    \"\"\"\n\n    nstart = Node(round(sx / reso), round(sy / reso), 0.0, -1)\n    ngoal = Node(round(gx / reso), round(gy / reso), 0.0, -1)\n    ox = [iox / reso for iox in ox]\n    oy = [ioy / reso for ioy in oy]\n\n    obmap, minx, miny, maxx, maxy, xw, yw = calc_obstacle_map(ox, oy, reso, rr)\n\n    motion = get_motion_model()\n\n    openset, closedset = dict(), dict()\n    openset[calc_index(nstart, xw, minx, miny)] = nstart\n\n    while 1:\n        c_id = min(\n            openset, key=lambda o: openset[o].cost + calc_heuristic(ngoal, openset[o]))\n        current = openset[c_id]\n\n        # show graph\n        if show_animation:  # pragma: no cover\n            plt.plot(current.x * reso, current.y * reso, \"xc\")\n            if len(closedset.keys()) % 10 == 0:\n                plt.pause(0.001)\n\n        if current.x == ngoal.x and current.y == ngoal.y:\n            print(\"Find goal\")\n            ngoal.pind = current.pind\n            ngoal.cost = current.cost\n            break\n\n        # Remove the item from the open set\n        del openset[c_id]\n        # Add it to the closed set\n        closedset[c_id] = current\n\n        # expand search grid based on motion model\n        for i, _ in enumerate(motion):\n            node = Node(current.x + motion[i][0],\n                        current.y + motion[i][1],\n                        current.cost + motion[i][2], c_id)\n            n_id = calc_index(node, xw, minx, miny)\n\n            if n_id in closedset:\n                continue\n\n            if not verify_node(node, obmap, minx, miny, maxx, maxy):\n                continue\n\n            if n_id not in openset:\n                openset[n_id] = node  # Discover a new node\n            else:\n                if openset[n_id].cost >= node.cost:\n                    # This path is the best until now. record it!\n                    openset[n_id] = node\n\n    rx, ry = calc_final_path(ngoal, closedset, reso)\n\n    return rx, ry\n\n\ndef calc_heuristic(n1, n2):\n    w = 1.0  # weight of heuristic\n    d = w * math.sqrt((n1.x - n2.x)**2 + (n1.y - n2.y)**2)\n    return d\n\n\ndef verify_node(node, obmap, minx, miny, maxx, maxy):\n\n    if node.x < minx:\n        return False\n    elif node.y < miny:\n        return False\n    elif node.x >= maxx:\n        return False\n    elif node.y >= maxy:\n        return False\n\n    if obmap[node.x][node.y]:\n        return False\n\n    return True\n\n\ndef calc_obstacle_map(ox, oy, reso, vr):\n\n    minx = round(min(ox))\n    miny = round(min(oy))\n    maxx = round(max(ox))\n    maxy = round(max(oy))\n    #  print(\"minx:\", minx)\n    #  print(\"miny:\", miny)\n    #  print(\"maxx:\", maxx)\n    #  print(\"maxy:\", maxy)\n\n    xwidth = round(maxx - minx)\n    ywidth = round(maxy - miny)\n    #  print(\"xwidth:\", xwidth)\n    #  print(\"ywidth:\", ywidth)\n\n    # obstacle map generation\n    obmap = [[False for i in range(ywidth)] for i in range(xwidth)]\n    for ix in range(xwidth):\n        x = ix + minx\n        for iy in range(ywidth):\n            y = iy + miny\n            #  print(x, y)\n            for iox, ioy in zip(ox, oy):\n                d = math.sqrt((iox - x)**2 + (ioy - y)**2)\n                if d <= vr / reso:\n                    obmap[ix][iy] = True\n                    break\n\n    return obmap, minx, miny, maxx, maxy, xwidth, ywidth\n\n\ndef calc_index(node, xwidth, xmin, ymin):\n    return (node.y - ymin) * xwidth + (node.x - xmin)\n\n\ndef get_motion_model():\n    # dx, dy, cost\n    motion = [[1, 0, 1],\n              [0, 1, 1],\n              [-1, 0, 1],\n              [0, -1, 1],\n              [-1, -1, math.sqrt(2)],\n              [-1, 1, math.sqrt(2)],\n              [1, -1, math.sqrt(2)],\n              [1, 1, math.sqrt(2)]]\n\n    return motion\n\n\ndef main():\n    print(__file__ + \" start!!\")\n\n    # start and goal position\n    sx = 10.0  # [m]\n    sy = 10.0  # [m]\n    gx = 50.0  # [m]\n    gy = 50.0  # [m]\n    grid_size = 1.0  # [m]\n    robot_size = 1.0  # [m]\n\n    ox, oy = [], []\n\n    for i in range(60):\n        ox.append(i)\n        oy.append(0.0)\n    for i in range(60):\n        ox.append(60.0)\n        oy.append(i)\n    for i in range(61):\n        ox.append(i)\n        oy.append(60.0)\n    for i in range(61):\n        ox.append(0.0)\n        oy.append(i)\n    for i in range(40):\n        ox.append(20.0)\n        oy.append(i)\n    for i in range(40):\n        ox.append(40.0)\n        oy.append(60.0 - i)\n\n    if show_animation:  # pragma: no cover\n        plt.plot(ox, oy, \".k\")\n        plt.plot(sx, sy, \"xr\")\n        plt.plot(gx, gy, \"xb\")\n        plt.grid(True)\n        plt.axis(\"equal\")\n\n    rx, ry = a_star_planning(sx, sy, gx, gy, ox, oy, grid_size, robot_size)\n\n    if show_animation:  # pragma: no cover\n        plt.plot(rx, ry, \"-r\")\n        plt.show()\n\n\nif __name__ == '__main__':\n    main()\n```\n{% endfold %}\n\n\n","slug":"算法学习二","published":1,"updated":"2019-05-01T12:55:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt6001d1ouz6sy3e2eh","content":"<p>这是算法学习的第二篇博客，本文将聚焦于图搜索相关的算法。</p>\n<h1 id=\"图\"><a href=\"#图\" class=\"headerlink\" title=\"图\"></a>图</h1><p>所谓的图(Graph)由节点和边构成，节点代表变量，边表示相互关系，通常具有一定的权重。图的搜索算法可以解决一些基本的问题，比如最短路径问题。</p>\n<h2 id=\"广度优先搜索\"><a href=\"#广度优先搜索\" class=\"headerlink\" title=\"广度优先搜索\"></a>广度优先搜索</h2><p>广度优先搜索的特征从起点开始，由近及远进行广泛地搜索。下面我们定义一个图(如下图)，这是个无向图，我们从某个节点出发分别进行广度优先搜索和深度优先搜索。<img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/BFS_DFS.png\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"A\"</span>: [<span class=\"string\">\"B\"</span>, <span class=\"string\">\"C\"</span>],</span><br><span class=\"line\">    <span class=\"string\">\"B\"</span>: [<span class=\"string\">\"A\"</span>, <span class=\"string\">\"C\"</span>, <span class=\"string\">\"D\"</span>],</span><br><span class=\"line\">    <span class=\"string\">\"C\"</span>: [<span class=\"string\">\"A\"</span>, <span class=\"string\">\"B\"</span>, <span class=\"string\">\"D\"</span>, <span class=\"string\">\"E\"</span>], </span><br><span class=\"line\">    <span class=\"string\">\"D\"</span>: [<span class=\"string\">\"B\"</span>, <span class=\"string\">\"C\"</span>, <span class=\"string\">\"E\"</span>, <span class=\"string\">\"F\"</span>],</span><br><span class=\"line\">    <span class=\"string\">\"E\"</span>: [<span class=\"string\">\"C\"</span>, <span class=\"string\">\"D\"</span>],</span><br><span class=\"line\">    <span class=\"string\">\"F\"</span>: [<span class=\"string\">\"D\"</span>]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 广度优先搜索</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">BFS</span><span class=\"params\">(graph, s)</span>:</span></span><br><span class=\"line\">    queue = []</span><br><span class=\"line\">    queue.append(s)</span><br><span class=\"line\">    seen = set()</span><br><span class=\"line\">    seen.add(s)</span><br><span class=\"line\">    <span class=\"comment\"># parent = &#123;s: None&#125;</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(len(queue) &gt; <span class=\"number\">0</span>):</span><br><span class=\"line\">        vertex = queue.pop(<span class=\"number\">0</span>)</span><br><span class=\"line\">        nodes = graph[vertex]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> nodes:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> w <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> seen:</span><br><span class=\"line\">                queue.append(w)</span><br><span class=\"line\">                seen.add(w)</span><br><span class=\"line\">                <span class=\"comment\"># parent[w] = vertex</span></span><br><span class=\"line\">        print(vertex)</span><br><span class=\"line\">    <span class=\"comment\"># return parent</span></span><br></pre></td></tr></table></figure>\n\n</div></div>\n<h2 id=\"深度优先搜索\"><a href=\"#深度优先搜索\" class=\"headerlink\" title=\"深度优先搜索\"></a>深度优先搜索</h2><p>深度优先搜索和广度有限搜索一样，都是对图进行搜索的算法，目的都是从起点开始到达指定顶点(终点)。深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 深度优先搜索</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">DFS</span><span class=\"params\">(graph, s)</span>:</span></span><br><span class=\"line\">    stack = []</span><br><span class=\"line\">    stack.append(s)</span><br><span class=\"line\">    seen = set()</span><br><span class=\"line\">    seen.add(s)</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(len(stack) &gt; <span class=\"number\">0</span>):</span><br><span class=\"line\">        vertex = stack.pop()</span><br><span class=\"line\">        nodes = graph[vertex]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> nodes:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> w <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> seen:</span><br><span class=\"line\">                stack.append(w)</span><br><span class=\"line\">                seen.add(w)</span><br><span class=\"line\">        print(vertex)</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<h1 id=\"最短路径\"><a href=\"#最短路径\" class=\"headerlink\" title=\"最短路径\"></a>最短路径</h1><p>下面我们看一些求最短路径的算法，贝尔曼-福特算法，Dijkstra算法，还有A-star算法。求下面的图 $A$ 到其它节点的最短路径。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/graph_with_weight.png\" alt></p>\n<h2 id=\"贝尔曼-福特算法-Bellman-ford\"><a href=\"#贝尔曼-福特算法-Bellman-ford\" class=\"headerlink\" title=\"贝尔曼-福特算法(Bellman-ford)\"></a>贝尔曼-福特算法(Bellman-ford)</h2><p>贝尔曼-福特算法是求最短路的一种算法，该算法是以松弛操作为基础，集估计的最短路径值逐渐被更加精确的值代替，直至得到最优解。该算法的缺点是时间复杂度较高 $O(|V||E|)$，其中 $|V|$ 代表节点数量，$|E|$代表边的数量。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getEdges</span><span class=\"params\">(G)</span>:</span></span><br><span class=\"line\">     <span class=\"string\">\"\"\" 输入图G，返回其边与端点的列表 \"\"\"</span></span><br><span class=\"line\">     v1 = []     <span class=\"comment\"># 出发点         </span></span><br><span class=\"line\">     v2 = []     <span class=\"comment\"># 对应的相邻到达点</span></span><br><span class=\"line\">     w  = []     <span class=\"comment\"># 顶点v1到顶点v2的边的权值</span></span><br><span class=\"line\">     <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> G:</span><br><span class=\"line\">         <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> G[i]:</span><br><span class=\"line\">             <span class=\"keyword\">if</span> G[i][j] != <span class=\"number\">0</span>:</span><br><span class=\"line\">                 w.append(G[i][j])</span><br><span class=\"line\">                 v1.append(i)</span><br><span class=\"line\">                 v2.append(j)</span><br><span class=\"line\">     <span class=\"keyword\">return</span> v1,v2,w</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CycleError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Bellman_Ford</span><span class=\"params\">(G, s)</span>:</span></span><br><span class=\"line\">    v1,v2,w = getEdges(G)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 初始化源点与所有点之间的最短距离</span></span><br><span class=\"line\">    distance = dict((k, math.inf) <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> G.keys())</span><br><span class=\"line\">    distance[s] = <span class=\"number\">0</span></span><br><span class=\"line\">    parent = &#123;s: <span class=\"keyword\">None</span>&#125;</span><br><span class=\"line\">    <span class=\"comment\"># 核心算法</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(len(G)<span class=\"number\">-1</span>):   <span class=\"comment\"># 循环 n-1轮</span></span><br><span class=\"line\">        check = <span class=\"number\">0</span>           <span class=\"comment\"># 用于标记本轮松弛中distance是否发生更新</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(w)):     <span class=\"comment\"># 对每条边进行一次松弛操作</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> distance[v1[i]] + w[i] &lt; distance[v2[i]]:</span><br><span class=\"line\">                distance[v2[i]] = distance[v1[i]] + w[i]</span><br><span class=\"line\">                check = <span class=\"number\">1</span></span><br><span class=\"line\">                parent[v2[i]] = v1[i]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> check == <span class=\"number\">0</span>: <span class=\"keyword\">break</span></span><br><span class=\"line\">     </span><br><span class=\"line\">     <span class=\"comment\"># 检测负权回路</span></span><br><span class=\"line\">     <span class=\"comment\"># 如果在 n-1 次松弛之后，最短路径依然发生变化，则该图必然存在负权回路</span></span><br><span class=\"line\">    flag = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(w)):             <span class=\"comment\"># 对每条边再尝试进行一次松弛操作</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> distance[v1[i]] + w[i] &lt; distance[v2[i]]: </span><br><span class=\"line\">            flag = <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> flag == <span class=\"number\">1</span>:</span><br><span class=\"line\"> <span class=\"comment\">#         raise CycleError()</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> distance, parent</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<h2 id=\"Dijkstra算法\"><a href=\"#Dijkstra算法\" class=\"headerlink\" title=\"Dijkstra算法\"></a>Dijkstra算法</h2><p>Dijkstra算法可以看作是广度优先搜索在有权图上的推广，其是通过为每个顶点保留到目前为止的最短路径工作的。最初的Dijkstra算法没有通过小优先队列实现，时间复杂度为 $O(|V|^2)$(其中 $|V|为图的顶点个数$)。通过斐波那契堆实现的Dijkstra算法的时间复杂度为 $O(|E|+|V|log|V|)$ (其中 $|E|$ 为边数)，对于不含负权的有向图，Dijkstra是已知的最快单源最短路径算法。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Dijkstra_Animation.gif\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> heapq</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\">graph = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"A\"</span>: &#123;<span class=\"string\">\"B\"</span>: <span class=\"number\">5</span>, <span class=\"string\">\"C\"</span>: <span class=\"number\">1</span>&#125;,</span><br><span class=\"line\">    <span class=\"string\">\"B\"</span>: &#123;<span class=\"string\">\"A\"</span>: <span class=\"number\">5</span>, <span class=\"string\">\"C\"</span>: <span class=\"number\">2</span>, <span class=\"string\">\"D\"</span>: <span class=\"number\">1</span>&#125;,</span><br><span class=\"line\">    <span class=\"string\">\"C\"</span>: &#123;<span class=\"string\">\"A\"</span>: <span class=\"number\">1</span>, <span class=\"string\">\"B\"</span>: <span class=\"number\">2</span>, <span class=\"string\">\"D\"</span>: <span class=\"number\">4</span>, <span class=\"string\">\"E\"</span>: <span class=\"number\">8</span>&#125;, </span><br><span class=\"line\">    <span class=\"string\">\"D\"</span>: &#123;<span class=\"string\">\"B\"</span>: <span class=\"number\">1</span>, <span class=\"string\">\"C\"</span>: <span class=\"number\">4</span>, <span class=\"string\">\"E\"</span>: <span class=\"number\">3</span>, <span class=\"string\">\"F\"</span>: <span class=\"number\">6</span>&#125;,</span><br><span class=\"line\">    <span class=\"string\">\"E\"</span>: &#123;<span class=\"string\">\"C\"</span>: <span class=\"number\">8</span>, <span class=\"string\">\"D\"</span>: <span class=\"number\">3</span>&#125;,</span><br><span class=\"line\">    <span class=\"string\">\"F\"</span>: &#123;<span class=\"string\">\"D\"</span>: <span class=\"number\">6</span>&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">init_distance</span><span class=\"params\">(graph, s)</span>:</span></span><br><span class=\"line\">    distance = &#123;s: <span class=\"number\">0</span>&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> vertex <span class=\"keyword\">in</span> graph:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> vertex != s:</span><br><span class=\"line\">            distance[vertex] = math.inf</span><br><span class=\"line\">    <span class=\"keyword\">return</span> distance</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dijkstra</span><span class=\"params\">(graph, s)</span>:</span></span><br><span class=\"line\">    pqueue = []</span><br><span class=\"line\">    heapq.heappush(pqueue, (<span class=\"number\">0</span>, s))</span><br><span class=\"line\">    seen = set()</span><br><span class=\"line\">    seen.add(s)</span><br><span class=\"line\">    parent = &#123;s: <span class=\"keyword\">None</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    distance = init_distance(graph, s)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(len(pqueue) &gt; <span class=\"number\">0</span>):</span><br><span class=\"line\">        pair = heapq.heappop(pqueue)</span><br><span class=\"line\">        distance = pair[<span class=\"number\">0</span>]</span><br><span class=\"line\">        vertex = pair[<span class=\"number\">1</span>]</span><br><span class=\"line\">        seen.add(vertex)</span><br><span class=\"line\"></span><br><span class=\"line\">        nodes = graph[vertex].keys()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> nodes:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> w <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> seen:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> distance + graph[vertex][w] &lt; distance[w]:</span><br><span class=\"line\">                    heapq.heappush(pqueue, (distance + graph[vertex][w], w))</span><br><span class=\"line\">                    parent[w] = vertex</span><br><span class=\"line\">                    distance[w] = distance + graph[vertex][w]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parent, distance</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    parent, distance= dijkstra(graph, <span class=\"string\">\"A\"</span>)</span><br><span class=\"line\">    print(parent, distance)</span><br><span class=\"line\"></span><br><span class=\"line\">    v = <span class=\"string\">\"B\"</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> v != <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        print(v)</span><br><span class=\"line\">        v = parent[v]</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<p>虽然Doijkstra算法和Bellman ford算法一样可以求解有向图中的最短路径问题，但是当图中有负数权重时，Dijkstra算法无法得到正确的答案。</p>\n<h2 id=\"A-star-算法\"><a href=\"#A-star-算法\" class=\"headerlink\" title=\"A-star 算法\"></a>A-star 算法</h2><p>A-star算法是有Dijkstra发展而来的算法。Dijkstra算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。也就是说一些离起点较远的顶点的最短路径也会被计算出来，但这部分是无用的。与之不同的是，A-star算法会先估计一个值，然后利用这个值省去无用的计算。<br>下面我们详细地介绍一下A-star算法在路径规划上面的应用，不同前面的简单路径图，我们这里使用了一个“硬核”的迷宫图，其中红色箭头表示起点位置，蓝色箭头表示终点位置，黑色的点代表障碍物，障碍物是不能直接穿过的。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/maze.png\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\">show_animation = <span class=\"keyword\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Node</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, x, y, cost, pind)</span>:</span></span><br><span class=\"line\">        self.x = x</span><br><span class=\"line\">        self.y = y</span><br><span class=\"line\">        self.cost = cost</span><br><span class=\"line\">        self.pind = pind</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> str(self.x) + <span class=\"string\">\",\"</span> + str(self.y) + <span class=\"string\">\",\"</span> + str(self.cost) + <span class=\"string\">\",\"</span> + str(self.pind)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calc_final_path</span><span class=\"params\">(ngoal, closedset, reso)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># generate final course</span></span><br><span class=\"line\">    rx, ry = [ngoal.x * reso], [ngoal.y * reso]</span><br><span class=\"line\">    pind = ngoal.pind</span><br><span class=\"line\">    <span class=\"keyword\">while</span> pind != <span class=\"number\">-1</span>:</span><br><span class=\"line\">        n = closedset[pind]</span><br><span class=\"line\">        rx.append(n.x * reso)</span><br><span class=\"line\">        ry.append(n.y * reso)</span><br><span class=\"line\">        pind = n.pind</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> rx, ry</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">a_star_planning</span><span class=\"params\">(sx, sy, gx, gy, ox, oy, reso, rr)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    gx: goal x position [m]</span></span><br><span class=\"line\"><span class=\"string\">    gx: goal x position [m]</span></span><br><span class=\"line\"><span class=\"string\">    ox: x position list of Obstacles [m]</span></span><br><span class=\"line\"><span class=\"string\">    oy: y position list of Obstacles [m]</span></span><br><span class=\"line\"><span class=\"string\">    reso: grid resolution [m]</span></span><br><span class=\"line\"><span class=\"string\">    rr: robot radius[m]</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    nstart = Node(round(sx / reso), round(sy / reso), <span class=\"number\">0.0</span>, <span class=\"number\">-1</span>)</span><br><span class=\"line\">    ngoal = Node(round(gx / reso), round(gy / reso), <span class=\"number\">0.0</span>, <span class=\"number\">-1</span>)</span><br><span class=\"line\">    ox = [iox / reso <span class=\"keyword\">for</span> iox <span class=\"keyword\">in</span> ox]</span><br><span class=\"line\">    oy = [ioy / reso <span class=\"keyword\">for</span> ioy <span class=\"keyword\">in</span> oy]</span><br><span class=\"line\"></span><br><span class=\"line\">    obmap, minx, miny, maxx, maxy, xw, yw = calc_obstacle_map(ox, oy, reso, rr)</span><br><span class=\"line\"></span><br><span class=\"line\">    motion = get_motion_model()</span><br><span class=\"line\"></span><br><span class=\"line\">    openset, closedset = dict(), dict()</span><br><span class=\"line\">    openset[calc_index(nstart, xw, minx, miny)] = nstart</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"number\">1</span>:</span><br><span class=\"line\">        c_id = min(</span><br><span class=\"line\">            openset, key=<span class=\"keyword\">lambda</span> o: openset[o].cost + calc_heuristic(ngoal, openset[o]))</span><br><span class=\"line\">        current = openset[c_id]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># show graph</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> show_animation:  <span class=\"comment\"># pragma: no cover</span></span><br><span class=\"line\">            plt.plot(current.x * reso, current.y * reso, <span class=\"string\">\"xc\"</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> len(closedset.keys()) % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                plt.pause(<span class=\"number\">0.001</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> current.x == ngoal.x <span class=\"keyword\">and</span> current.y == ngoal.y:</span><br><span class=\"line\">            print(<span class=\"string\">\"Find goal\"</span>)</span><br><span class=\"line\">            ngoal.pind = current.pind</span><br><span class=\"line\">            ngoal.cost = current.cost</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Remove the item from the open set</span></span><br><span class=\"line\">        <span class=\"keyword\">del</span> openset[c_id]</span><br><span class=\"line\">        <span class=\"comment\"># Add it to the closed set</span></span><br><span class=\"line\">        closedset[c_id] = current</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># expand search grid based on motion model</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, _ <span class=\"keyword\">in</span> enumerate(motion):</span><br><span class=\"line\">            node = Node(current.x + motion[i][<span class=\"number\">0</span>],</span><br><span class=\"line\">                        current.y + motion[i][<span class=\"number\">1</span>],</span><br><span class=\"line\">                        current.cost + motion[i][<span class=\"number\">2</span>], c_id)</span><br><span class=\"line\">            n_id = calc_index(node, xw, minx, miny)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> n_id <span class=\"keyword\">in</span> closedset:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> verify_node(node, obmap, minx, miny, maxx, maxy):</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> n_id <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> openset:</span><br><span class=\"line\">                openset[n_id] = node  <span class=\"comment\"># Discover a new node</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> openset[n_id].cost &gt;= node.cost:</span><br><span class=\"line\">                    <span class=\"comment\"># This path is the best until now. record it!</span></span><br><span class=\"line\">                    openset[n_id] = node</span><br><span class=\"line\"></span><br><span class=\"line\">    rx, ry = calc_final_path(ngoal, closedset, reso)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> rx, ry</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calc_heuristic</span><span class=\"params\">(n1, n2)</span>:</span></span><br><span class=\"line\">    w = <span class=\"number\">1.0</span>  <span class=\"comment\"># weight of heuristic</span></span><br><span class=\"line\">    d = w * math.sqrt((n1.x - n2.x)**<span class=\"number\">2</span> + (n1.y - n2.y)**<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> d</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">verify_node</span><span class=\"params\">(node, obmap, minx, miny, maxx, maxy)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> node.x &lt; minx:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> node.y &lt; miny:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> node.x &gt;= maxx:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> node.y &gt;= maxy:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> obmap[node.x][node.y]:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calc_obstacle_map</span><span class=\"params\">(ox, oy, reso, vr)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    minx = round(min(ox))</span><br><span class=\"line\">    miny = round(min(oy))</span><br><span class=\"line\">    maxx = round(max(ox))</span><br><span class=\"line\">    maxy = round(max(oy))</span><br><span class=\"line\">    <span class=\"comment\">#  print(\"minx:\", minx)</span></span><br><span class=\"line\">    <span class=\"comment\">#  print(\"miny:\", miny)</span></span><br><span class=\"line\">    <span class=\"comment\">#  print(\"maxx:\", maxx)</span></span><br><span class=\"line\">    <span class=\"comment\">#  print(\"maxy:\", maxy)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    xwidth = round(maxx - minx)</span><br><span class=\"line\">    ywidth = round(maxy - miny)</span><br><span class=\"line\">    <span class=\"comment\">#  print(\"xwidth:\", xwidth)</span></span><br><span class=\"line\">    <span class=\"comment\">#  print(\"ywidth:\", ywidth)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># obstacle map generation</span></span><br><span class=\"line\">    obmap = [[<span class=\"keyword\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(ywidth)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(xwidth)]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ix <span class=\"keyword\">in</span> range(xwidth):</span><br><span class=\"line\">        x = ix + minx</span><br><span class=\"line\">        <span class=\"keyword\">for</span> iy <span class=\"keyword\">in</span> range(ywidth):</span><br><span class=\"line\">            y = iy + miny</span><br><span class=\"line\">            <span class=\"comment\">#  print(x, y)</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> iox, ioy <span class=\"keyword\">in</span> zip(ox, oy):</span><br><span class=\"line\">                d = math.sqrt((iox - x)**<span class=\"number\">2</span> + (ioy - y)**<span class=\"number\">2</span>)</span><br><span class=\"line\">                <span class=\"keyword\">if</span> d &lt;= vr / reso:</span><br><span class=\"line\">                    obmap[ix][iy] = <span class=\"keyword\">True</span></span><br><span class=\"line\">                    <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> obmap, minx, miny, maxx, maxy, xwidth, ywidth</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calc_index</span><span class=\"params\">(node, xwidth, xmin, ymin)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (node.y - ymin) * xwidth + (node.x - xmin)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_motion_model</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># dx, dy, cost</span></span><br><span class=\"line\">    motion = [[<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">              [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">              [<span class=\"number\">-1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">              [<span class=\"number\">0</span>, <span class=\"number\">-1</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">              [<span class=\"number\">-1</span>, <span class=\"number\">-1</span>, math.sqrt(<span class=\"number\">2</span>)],</span><br><span class=\"line\">              [<span class=\"number\">-1</span>, <span class=\"number\">1</span>, math.sqrt(<span class=\"number\">2</span>)],</span><br><span class=\"line\">              [<span class=\"number\">1</span>, <span class=\"number\">-1</span>, math.sqrt(<span class=\"number\">2</span>)],</span><br><span class=\"line\">              [<span class=\"number\">1</span>, <span class=\"number\">1</span>, math.sqrt(<span class=\"number\">2</span>)]]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> motion</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    print(__file__ + <span class=\"string\">\" start!!\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># start and goal position</span></span><br><span class=\"line\">    sx = <span class=\"number\">10.0</span>  <span class=\"comment\"># [m]</span></span><br><span class=\"line\">    sy = <span class=\"number\">10.0</span>  <span class=\"comment\"># [m]</span></span><br><span class=\"line\">    gx = <span class=\"number\">50.0</span>  <span class=\"comment\"># [m]</span></span><br><span class=\"line\">    gy = <span class=\"number\">50.0</span>  <span class=\"comment\"># [m]</span></span><br><span class=\"line\">    grid_size = <span class=\"number\">1.0</span>  <span class=\"comment\"># [m]</span></span><br><span class=\"line\">    robot_size = <span class=\"number\">1.0</span>  <span class=\"comment\"># [m]</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ox, oy = [], []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">60</span>):</span><br><span class=\"line\">        ox.append(i)</span><br><span class=\"line\">        oy.append(<span class=\"number\">0.0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">60</span>):</span><br><span class=\"line\">        ox.append(<span class=\"number\">60.0</span>)</span><br><span class=\"line\">        oy.append(i)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">61</span>):</span><br><span class=\"line\">        ox.append(i)</span><br><span class=\"line\">        oy.append(<span class=\"number\">60.0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">61</span>):</span><br><span class=\"line\">        ox.append(<span class=\"number\">0.0</span>)</span><br><span class=\"line\">        oy.append(i)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">40</span>):</span><br><span class=\"line\">        ox.append(<span class=\"number\">20.0</span>)</span><br><span class=\"line\">        oy.append(i)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">40</span>):</span><br><span class=\"line\">        ox.append(<span class=\"number\">40.0</span>)</span><br><span class=\"line\">        oy.append(<span class=\"number\">60.0</span> - i)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> show_animation:  <span class=\"comment\"># pragma: no cover</span></span><br><span class=\"line\">        plt.plot(ox, oy, <span class=\"string\">\".k\"</span>)</span><br><span class=\"line\">        plt.plot(sx, sy, <span class=\"string\">\"xr\"</span>)</span><br><span class=\"line\">        plt.plot(gx, gy, <span class=\"string\">\"xb\"</span>)</span><br><span class=\"line\">        plt.grid(<span class=\"keyword\">True</span>)</span><br><span class=\"line\">        plt.axis(<span class=\"string\">\"equal\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    rx, ry = a_star_planning(sx, sy, gx, gy, ox, oy, grid_size, robot_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> show_animation:  <span class=\"comment\"># pragma: no cover</span></span><br><span class=\"line\">        plt.plot(rx, ry, <span class=\"string\">\"-r\"</span>)</span><br><span class=\"line\">        plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n\n</div></div>\n","site":{"data":{}},"excerpt":"","more":"<p>这是算法学习的第二篇博客，本文将聚焦于图搜索相关的算法。</p>\n<h1 id=\"图\"><a href=\"#图\" class=\"headerlink\" title=\"图\"></a>图</h1><p>所谓的图(Graph)由节点和边构成，节点代表变量，边表示相互关系，通常具有一定的权重。图的搜索算法可以解决一些基本的问题，比如最短路径问题。</p>\n<h2 id=\"广度优先搜索\"><a href=\"#广度优先搜索\" class=\"headerlink\" title=\"广度优先搜索\"></a>广度优先搜索</h2><p>广度优先搜索的特征从起点开始，由近及远进行广泛地搜索。下面我们定义一个图(如下图)，这是个无向图，我们从某个节点出发分别进行广度优先搜索和深度优先搜索。<img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/BFS_DFS.png\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�67-->\n\n</div></div>\n<h2 id=\"深度优先搜索\"><a href=\"#深度优先搜索\" class=\"headerlink\" title=\"深度优先搜索\"></a>深度优先搜索</h2><p>深度优先搜索和广度有限搜索一样，都是对图进行搜索的算法，目的都是从起点开始到达指定顶点(终点)。深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�68-->\n\n</div></div>\n<h1 id=\"最短路径\"><a href=\"#最短路径\" class=\"headerlink\" title=\"最短路径\"></a>最短路径</h1><p>下面我们看一些求最短路径的算法，贝尔曼-福特算法，Dijkstra算法，还有A-star算法。求下面的图 $A$ 到其它节点的最短路径。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/graph_with_weight.png\" alt></p>\n<h2 id=\"贝尔曼-福特算法-Bellman-ford\"><a href=\"#贝尔曼-福特算法-Bellman-ford\" class=\"headerlink\" title=\"贝尔曼-福特算法(Bellman-ford)\"></a>贝尔曼-福特算法(Bellman-ford)</h2><p>贝尔曼-福特算法是求最短路的一种算法，该算法是以松弛操作为基础，集估计的最短路径值逐渐被更加精确的值代替，直至得到最优解。该算法的缺点是时间复杂度较高 $O(|V||E|)$，其中 $|V|$ 代表节点数量，$|E|$代表边的数量。</p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�69-->\n\n</div></div>\n<h2 id=\"Dijkstra算法\"><a href=\"#Dijkstra算法\" class=\"headerlink\" title=\"Dijkstra算法\"></a>Dijkstra算法</h2><p>Dijkstra算法可以看作是广度优先搜索在有权图上的推广，其是通过为每个顶点保留到目前为止的最短路径工作的。最初的Dijkstra算法没有通过小优先队列实现，时间复杂度为 $O(|V|^2)$(其中 $|V|为图的顶点个数$)。通过斐波那契堆实现的Dijkstra算法的时间复杂度为 $O(|E|+|V|log|V|)$ (其中 $|E|$ 为边数)，对于不含负权的有向图，Dijkstra是已知的最快单源最短路径算法。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Dijkstra_Animation.gif\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�70-->\n\n</div></div>\n<p>虽然Doijkstra算法和Bellman ford算法一样可以求解有向图中的最短路径问题，但是当图中有负数权重时，Dijkstra算法无法得到正确的答案。</p>\n<h2 id=\"A-star-算法\"><a href=\"#A-star-算法\" class=\"headerlink\" title=\"A-star 算法\"></a>A-star 算法</h2><p>A-star算法是有Dijkstra发展而来的算法。Dijkstra算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。也就是说一些离起点较远的顶点的最短路径也会被计算出来，但这部分是无用的。与之不同的是，A-star算法会先估计一个值，然后利用这个值省去无用的计算。<br>下面我们详细地介绍一下A-star算法在路径规划上面的应用，不同前面的简单路径图，我们这里使用了一个“硬核”的迷宫图，其中红色箭头表示起点位置，蓝色箭头表示终点位置，黑色的点代表障碍物，障碍物是不能直接穿过的。<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/maze.png\" alt></p>\n<div><div class=\"fold_hider\"><div class=\"close hider_title\">点击显/隐</div></div><div class=\"fold\">\n<!--�71-->\n\n</div></div>\n"},{"title":"谷歌学术搜索使用技巧","date":"2017-12-05T13:21:37.000Z","_content":"# 作者\n`aothor:\"Honto\"`\n`aothor:(\"Honto\" OR \"Tom\")`\n# 标题\n`intitle：\"computer vision\"`\n## 含有两个关键词与或关系\n```\nintitle:(\"computer vision \" AND \"deep learning\")`\nintitle:(\"compuer vison\")\n```\n# 限定输出文献格式\n```\nfiletype:pdf OR ppt OR pptx\nfiletpype:pdf (computer vision OR deep learning)\n```\n\n使用\"\"，（），OR，AND，intitle：，author：在google学术和google比较好用。\n","source":"_posts/谷歌学术搜索使用技巧.md","raw":"---\ntitle: 谷歌学术搜索使用技巧\ndate: 2017-12-05 21:21:37\ntags: 谷歌学术\ncategories: 学习\n---\n# 作者\n`aothor:\"Honto\"`\n`aothor:(\"Honto\" OR \"Tom\")`\n# 标题\n`intitle：\"computer vision\"`\n## 含有两个关键词与或关系\n```\nintitle:(\"computer vision \" AND \"deep learning\")`\nintitle:(\"compuer vison\")\n```\n# 限定输出文献格式\n```\nfiletype:pdf OR ppt OR pptx\nfiletpype:pdf (computer vision OR deep learning)\n```\n\n使用\"\"，（），OR，AND，intitle：，author：在google学术和google比较好用。\n","slug":"谷歌学术搜索使用技巧","published":1,"updated":"2018-09-22T06:32:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt6001e1ouzkzp6vq1l","content":"<h1 id=\"作者\"><a href=\"#作者\" class=\"headerlink\" title=\"作者\"></a>作者</h1><p><code>aothor:&quot;Honto&quot;</code><br><code>aothor:(&quot;Honto&quot; OR &quot;Tom&quot;)</code></p>\n<h1 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h1><p><code>intitle：&quot;computer vision&quot;</code></p>\n<h2 id=\"含有两个关键词与或关系\"><a href=\"#含有两个关键词与或关系\" class=\"headerlink\" title=\"含有两个关键词与或关系\"></a>含有两个关键词与或关系</h2><figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"symbol\">intitle:</span>(<span class=\"string\">\"computer vision \"</span> <span class=\"keyword\">AND</span> <span class=\"string\">\"deep learning\"</span>)`</span><br><span class=\"line\"><span class=\"symbol\">intitle:</span>(<span class=\"string\">\"compuer vison\"</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"限定输出文献格式\"><a href=\"#限定输出文献格式\" class=\"headerlink\" title=\"限定输出文献格式\"></a>限定输出文献格式</h1><figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"symbol\">filetype:</span>pdf <span class=\"keyword\">OR</span> ppt <span class=\"keyword\">OR</span> pptx</span><br><span class=\"line\"><span class=\"symbol\">filetpype:</span>pdf (computer vision <span class=\"keyword\">OR</span> deep learning)</span><br></pre></td></tr></table></figure>\n<p>使用””，（），OR，AND，intitle：，author：在google学术和google比较好用。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"作者\"><a href=\"#作者\" class=\"headerlink\" title=\"作者\"></a>作者</h1><p><code>aothor:&quot;Honto&quot;</code><br><code>aothor:(&quot;Honto&quot; OR &quot;Tom&quot;)</code></p>\n<h1 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h1><p><code>intitle：&quot;computer vision&quot;</code></p>\n<h2 id=\"含有两个关键词与或关系\"><a href=\"#含有两个关键词与或关系\" class=\"headerlink\" title=\"含有两个关键词与或关系\"></a>含有两个关键词与或关系</h2><!--�72-->\n<h1 id=\"限定输出文献格式\"><a href=\"#限定输出文献格式\" class=\"headerlink\" title=\"限定输出文献格式\"></a>限定输出文献格式</h1><!--�73-->\n<p>使用””，（），OR，AND，intitle：，author：在google学术和google比较好用。</p>\n"},{"title":"进化算法","date":"2018-12-07T12:30:01.000Z","_content":"# 准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。","source":"_posts/进化算法.md","raw":"---\ntitle: 进化算法\ndate: 2018-12-07 20:30:01\ntags: 进化算法\ncategories: 编程\n---\n# 准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。","slug":"进化算法","published":1,"updated":"2018-12-07T12:55:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt7001f1ouzt0k28b82","content":"<h1 id=\"准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。\"><a href=\"#准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。\" class=\"headerlink\" title=\"准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。\"></a>准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。\"><a href=\"#准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。\" class=\"headerlink\" title=\"准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。\"></a>准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。</h1>"},{"title":"高斯过程","date":"2019-07-29T12:13:38.000Z","_content":"# 高斯过程\n高斯过程(Gaussian Process)是观测值出现在一个连续域（例如时间或空间）的随机过程。在高斯过程中，连续输入空间中每个点都是与一个正态分布的随机变量相关联。此外，这些随机变量的每个有限集合都有一个多元正态分布，换句话说他们的任意有限线性组合是一个正态分布。高斯过程的分布是所有那些（无限多个）随机变量的联合分布，正因如此，它是连续域（例如时间或空间）上函数的分布。\n高斯过程是非常有用的模型，可以用来表示函数的分布。高斯过程不仅可以建模任意黑箱函数，同样可以用来建模不确定性。\n我们考虑一个简单的回归问题，不包含噪声。\n* 假设我们有一个函数映射：$f:\\mathbb{R}\\rightarrow\\mathbb{R}$\n* $\\mathbf{x}=[x_ 1, \\ldots, x_N]^T, \\mathbf{y}=[y_ 1, \\ldots, y_N]^T$，其中$y_i = f(x_i)$\n* 我们希望能够预测一个新的输入$\\mathbf{x}_*$ 时，对应$f$的值\n高斯过程背后的关键点是函数可以使用无限维的多元高斯分布建模。换句话说，每个点都和随机变量相关，随见变量的联合分布可以建模成多元高斯分布。\n\n一个简单的高斯过程回归建模的程序如下：\n```python\nfrom __future__ import division\nimport numpy as np\nimport matplotlib.pyplot as pl\n\n\"\"\" This is code for simple GP regression. It assumes a zero mean GP Prior \"\"\"\n\n\n# This is the true unknown function we are trying to approximate\nf = lambda x: np.sin(0.9*x).flatten()\n#f = lambda x: (0.25*(x**2)).flatten()\n\n\n# Define the kernel\ndef kernel(a, b):\n    \"\"\" GP squared exponential kernel \"\"\"\n    kernelParameter = 0.1\n    sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n    return np.exp(-.5 * (1/kernelParameter) * sqdist)\n\nN = 10         # number of training points.\nn = 50         # number of test points.\ns = 0.00005    # noise variance.\n\n# Sample some input points and noisy versions of the function evaluated at\n# these points. \nX = np.random.uniform(-5, 5, size=(N,1))\ny = f(X) + s*np.random.randn(N)\n\nK = kernel(X, X)\nL = np.linalg.cholesky(K + s*np.eye(N))\n\n# points we're going to make predictions at.\nXtest = np.linspace(-5, 5, n).reshape(-1,1)\n\n# compute the mean at our test points.\nLk = np.linalg.solve(L, kernel(X, Xtest))\nmu = np.dot(Lk.T, np.linalg.solve(L, y))\n\n# compute the variance at our test points.\nK_ = kernel(Xtest, Xtest)\ns2 = np.diag(K_) - np.sum(Lk**2, axis=0)\ns = np.sqrt(s2)\n\n\n# PLOTS:\npl.figure(1)\npl.clf()\npl.plot(X, y, 'r+', ms=20)\npl.plot(Xtest, f(Xtest), 'b-')\npl.gca().fill_between(Xtest.flat, mu-3*s, mu+3*s, color=\"#dddddd\")\npl.plot(Xtest, mu, 'r--', lw=2)\npl.savefig('predictive.png', bbox_inches='tight')\npl.title('Mean predictions plus 3 st.deviations')\npl.axis([-5, 5, -3, 3])\n\n# draw samples from the prior at our test points.\nL = np.linalg.cholesky(K_ + 1e-6*np.eye(n))\nf_prior = np.dot(L, np.random.normal(size=(n,10)))\npl.figure(2)\npl.clf()\npl.plot(Xtest, f_prior)\npl.title('Ten samples from the GP prior')\npl.axis([-5, 5, -3, 3])\npl.savefig('prior.png', bbox_inches='tight')\n\n# draw samples from the posterior at our test points.\nL = np.linalg.cholesky(K_ + 1e-6*np.eye(n) - np.dot(Lk.T, Lk))\nf_post = mu.reshape(-1,1) + np.dot(L, np.random.normal(size=(n,10)))\npl.figure(3)\npl.clf()\npl.plot(Xtest, f_post)\npl.title('Ten samples from the GP posterior')\npl.axis([-5, 5, -3, 3])\npl.savefig('post.png', bbox_inches='tight')\n\npl.show()\n```\n\n\n\n参考资料\n[1] http://bridg.land/posts/gaussian-processes-1\n[2] https://www.youtube.com/watch?v=4vGiHC35j9s","source":"_posts/高斯过程.md","raw":"---\ntitle: 高斯过程\ndate: 2019-07-29 20:13:38\ntags: 高斯过程\ncategories: 学习\n---\n# 高斯过程\n高斯过程(Gaussian Process)是观测值出现在一个连续域（例如时间或空间）的随机过程。在高斯过程中，连续输入空间中每个点都是与一个正态分布的随机变量相关联。此外，这些随机变量的每个有限集合都有一个多元正态分布，换句话说他们的任意有限线性组合是一个正态分布。高斯过程的分布是所有那些（无限多个）随机变量的联合分布，正因如此，它是连续域（例如时间或空间）上函数的分布。\n高斯过程是非常有用的模型，可以用来表示函数的分布。高斯过程不仅可以建模任意黑箱函数，同样可以用来建模不确定性。\n我们考虑一个简单的回归问题，不包含噪声。\n* 假设我们有一个函数映射：$f:\\mathbb{R}\\rightarrow\\mathbb{R}$\n* $\\mathbf{x}=[x_ 1, \\ldots, x_N]^T, \\mathbf{y}=[y_ 1, \\ldots, y_N]^T$，其中$y_i = f(x_i)$\n* 我们希望能够预测一个新的输入$\\mathbf{x}_*$ 时，对应$f$的值\n高斯过程背后的关键点是函数可以使用无限维的多元高斯分布建模。换句话说，每个点都和随机变量相关，随见变量的联合分布可以建模成多元高斯分布。\n\n一个简单的高斯过程回归建模的程序如下：\n```python\nfrom __future__ import division\nimport numpy as np\nimport matplotlib.pyplot as pl\n\n\"\"\" This is code for simple GP regression. It assumes a zero mean GP Prior \"\"\"\n\n\n# This is the true unknown function we are trying to approximate\nf = lambda x: np.sin(0.9*x).flatten()\n#f = lambda x: (0.25*(x**2)).flatten()\n\n\n# Define the kernel\ndef kernel(a, b):\n    \"\"\" GP squared exponential kernel \"\"\"\n    kernelParameter = 0.1\n    sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n    return np.exp(-.5 * (1/kernelParameter) * sqdist)\n\nN = 10         # number of training points.\nn = 50         # number of test points.\ns = 0.00005    # noise variance.\n\n# Sample some input points and noisy versions of the function evaluated at\n# these points. \nX = np.random.uniform(-5, 5, size=(N,1))\ny = f(X) + s*np.random.randn(N)\n\nK = kernel(X, X)\nL = np.linalg.cholesky(K + s*np.eye(N))\n\n# points we're going to make predictions at.\nXtest = np.linspace(-5, 5, n).reshape(-1,1)\n\n# compute the mean at our test points.\nLk = np.linalg.solve(L, kernel(X, Xtest))\nmu = np.dot(Lk.T, np.linalg.solve(L, y))\n\n# compute the variance at our test points.\nK_ = kernel(Xtest, Xtest)\ns2 = np.diag(K_) - np.sum(Lk**2, axis=0)\ns = np.sqrt(s2)\n\n\n# PLOTS:\npl.figure(1)\npl.clf()\npl.plot(X, y, 'r+', ms=20)\npl.plot(Xtest, f(Xtest), 'b-')\npl.gca().fill_between(Xtest.flat, mu-3*s, mu+3*s, color=\"#dddddd\")\npl.plot(Xtest, mu, 'r--', lw=2)\npl.savefig('predictive.png', bbox_inches='tight')\npl.title('Mean predictions plus 3 st.deviations')\npl.axis([-5, 5, -3, 3])\n\n# draw samples from the prior at our test points.\nL = np.linalg.cholesky(K_ + 1e-6*np.eye(n))\nf_prior = np.dot(L, np.random.normal(size=(n,10)))\npl.figure(2)\npl.clf()\npl.plot(Xtest, f_prior)\npl.title('Ten samples from the GP prior')\npl.axis([-5, 5, -3, 3])\npl.savefig('prior.png', bbox_inches='tight')\n\n# draw samples from the posterior at our test points.\nL = np.linalg.cholesky(K_ + 1e-6*np.eye(n) - np.dot(Lk.T, Lk))\nf_post = mu.reshape(-1,1) + np.dot(L, np.random.normal(size=(n,10)))\npl.figure(3)\npl.clf()\npl.plot(Xtest, f_post)\npl.title('Ten samples from the GP posterior')\npl.axis([-5, 5, -3, 3])\npl.savefig('post.png', bbox_inches='tight')\n\npl.show()\n```\n\n\n\n参考资料\n[1] http://bridg.land/posts/gaussian-processes-1\n[2] https://www.youtube.com/watch?v=4vGiHC35j9s","slug":"高斯过程","published":1,"updated":"2019-12-22T07:06:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt8001g1ouztmmb9xb9","content":"<h1 id=\"高斯过程\"><a href=\"#高斯过程\" class=\"headerlink\" title=\"高斯过程\"></a>高斯过程</h1><p>高斯过程(Gaussian Process)是观测值出现在一个连续域（例如时间或空间）的随机过程。在高斯过程中，连续输入空间中每个点都是与一个正态分布的随机变量相关联。此外，这些随机变量的每个有限集合都有一个多元正态分布，换句话说他们的任意有限线性组合是一个正态分布。高斯过程的分布是所有那些（无限多个）随机变量的联合分布，正因如此，它是连续域（例如时间或空间）上函数的分布。<br>高斯过程是非常有用的模型，可以用来表示函数的分布。高斯过程不仅可以建模任意黑箱函数，同样可以用来建模不确定性。<br>我们考虑一个简单的回归问题，不包含噪声。</p>\n<ul>\n<li>假设我们有一个函数映射：$f:\\mathbb{R}\\rightarrow\\mathbb{R}$</li>\n<li>$\\mathbf{x}=[x_ 1, \\ldots, x_N]^T, \\mathbf{y}=[y_ 1, \\ldots, y_N]^T$，其中$y_i = f(x_i)$</li>\n<li>我们希望能够预测一个新的输入$\\mathbf{x}_*$ 时，对应$f$的值<br>高斯过程背后的关键点是函数可以使用无限维的多元高斯分布建模。换句话说，每个点都和随机变量相关，随见变量的联合分布可以建模成多元高斯分布。</li>\n</ul>\n<p>一个简单的高斯过程回归建模的程序如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> division</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> pl</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"\"\" This is code for simple GP regression. It assumes a zero mean GP Prior \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This is the true unknown function we are trying to approximate</span></span><br><span class=\"line\">f = <span class=\"keyword\">lambda</span> x: np.sin(<span class=\"number\">0.9</span>*x).flatten()</span><br><span class=\"line\"><span class=\"comment\">#f = lambda x: (0.25*(x**2)).flatten()</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the kernel</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">kernel</span><span class=\"params\">(a, b)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" GP squared exponential kernel \"\"\"</span></span><br><span class=\"line\">    kernelParameter = <span class=\"number\">0.1</span></span><br><span class=\"line\">    sqdist = np.sum(a**<span class=\"number\">2</span>,<span class=\"number\">1</span>).reshape(<span class=\"number\">-1</span>,<span class=\"number\">1</span>) + np.sum(b**<span class=\"number\">2</span>,<span class=\"number\">1</span>) - <span class=\"number\">2</span>*np.dot(a, b.T)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.exp(<span class=\"number\">-.5</span> * (<span class=\"number\">1</span>/kernelParameter) * sqdist)</span><br><span class=\"line\"></span><br><span class=\"line\">N = <span class=\"number\">10</span>         <span class=\"comment\"># number of training points.</span></span><br><span class=\"line\">n = <span class=\"number\">50</span>         <span class=\"comment\"># number of test points.</span></span><br><span class=\"line\">s = <span class=\"number\">0.00005</span>    <span class=\"comment\"># noise variance.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Sample some input points and noisy versions of the function evaluated at</span></span><br><span class=\"line\"><span class=\"comment\"># these points. </span></span><br><span class=\"line\">X = np.random.uniform(<span class=\"number\">-5</span>, <span class=\"number\">5</span>, size=(N,<span class=\"number\">1</span>))</span><br><span class=\"line\">y = f(X) + s*np.random.randn(N)</span><br><span class=\"line\"></span><br><span class=\"line\">K = kernel(X, X)</span><br><span class=\"line\">L = np.linalg.cholesky(K + s*np.eye(N))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># points we're going to make predictions at.</span></span><br><span class=\"line\">Xtest = np.linspace(<span class=\"number\">-5</span>, <span class=\"number\">5</span>, n).reshape(<span class=\"number\">-1</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># compute the mean at our test points.</span></span><br><span class=\"line\">Lk = np.linalg.solve(L, kernel(X, Xtest))</span><br><span class=\"line\">mu = np.dot(Lk.T, np.linalg.solve(L, y))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># compute the variance at our test points.</span></span><br><span class=\"line\">K_ = kernel(Xtest, Xtest)</span><br><span class=\"line\">s2 = np.diag(K_) - np.sum(Lk**<span class=\"number\">2</span>, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">s = np.sqrt(s2)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># PLOTS:</span></span><br><span class=\"line\">pl.figure(<span class=\"number\">1</span>)</span><br><span class=\"line\">pl.clf()</span><br><span class=\"line\">pl.plot(X, y, <span class=\"string\">'r+'</span>, ms=<span class=\"number\">20</span>)</span><br><span class=\"line\">pl.plot(Xtest, f(Xtest), <span class=\"string\">'b-'</span>)</span><br><span class=\"line\">pl.gca().fill_between(Xtest.flat, mu<span class=\"number\">-3</span>*s, mu+<span class=\"number\">3</span>*s, color=<span class=\"string\">\"#dddddd\"</span>)</span><br><span class=\"line\">pl.plot(Xtest, mu, <span class=\"string\">'r--'</span>, lw=<span class=\"number\">2</span>)</span><br><span class=\"line\">pl.savefig(<span class=\"string\">'predictive.png'</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">pl.title(<span class=\"string\">'Mean predictions plus 3 st.deviations'</span>)</span><br><span class=\"line\">pl.axis([<span class=\"number\">-5</span>, <span class=\"number\">5</span>, <span class=\"number\">-3</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># draw samples from the prior at our test points.</span></span><br><span class=\"line\">L = np.linalg.cholesky(K_ + <span class=\"number\">1e-6</span>*np.eye(n))</span><br><span class=\"line\">f_prior = np.dot(L, np.random.normal(size=(n,<span class=\"number\">10</span>)))</span><br><span class=\"line\">pl.figure(<span class=\"number\">2</span>)</span><br><span class=\"line\">pl.clf()</span><br><span class=\"line\">pl.plot(Xtest, f_prior)</span><br><span class=\"line\">pl.title(<span class=\"string\">'Ten samples from the GP prior'</span>)</span><br><span class=\"line\">pl.axis([<span class=\"number\">-5</span>, <span class=\"number\">5</span>, <span class=\"number\">-3</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">pl.savefig(<span class=\"string\">'prior.png'</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># draw samples from the posterior at our test points.</span></span><br><span class=\"line\">L = np.linalg.cholesky(K_ + <span class=\"number\">1e-6</span>*np.eye(n) - np.dot(Lk.T, Lk))</span><br><span class=\"line\">f_post = mu.reshape(<span class=\"number\">-1</span>,<span class=\"number\">1</span>) + np.dot(L, np.random.normal(size=(n,<span class=\"number\">10</span>)))</span><br><span class=\"line\">pl.figure(<span class=\"number\">3</span>)</span><br><span class=\"line\">pl.clf()</span><br><span class=\"line\">pl.plot(Xtest, f_post)</span><br><span class=\"line\">pl.title(<span class=\"string\">'Ten samples from the GP posterior'</span>)</span><br><span class=\"line\">pl.axis([<span class=\"number\">-5</span>, <span class=\"number\">5</span>, <span class=\"number\">-3</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">pl.savefig(<span class=\"string\">'post.png'</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">pl.show()</span><br></pre></td></tr></table></figure></p>\n<p>参考资料<br>[1] <a href=\"http://bridg.land/posts/gaussian-processes-1\" target=\"_blank\" rel=\"noopener\">http://bridg.land/posts/gaussian-processes-1</a><br>[2] <a href=\"https://www.youtube.com/watch?v=4vGiHC35j9s\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=4vGiHC35j9s</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"高斯过程\"><a href=\"#高斯过程\" class=\"headerlink\" title=\"高斯过程\"></a>高斯过程</h1><p>高斯过程(Gaussian Process)是观测值出现在一个连续域（例如时间或空间）的随机过程。在高斯过程中，连续输入空间中每个点都是与一个正态分布的随机变量相关联。此外，这些随机变量的每个有限集合都有一个多元正态分布，换句话说他们的任意有限线性组合是一个正态分布。高斯过程的分布是所有那些（无限多个）随机变量的联合分布，正因如此，它是连续域（例如时间或空间）上函数的分布。<br>高斯过程是非常有用的模型，可以用来表示函数的分布。高斯过程不仅可以建模任意黑箱函数，同样可以用来建模不确定性。<br>我们考虑一个简单的回归问题，不包含噪声。</p>\n<ul>\n<li>假设我们有一个函数映射：$f:\\mathbb{R}\\rightarrow\\mathbb{R}$</li>\n<li>$\\mathbf{x}=[x_ 1, \\ldots, x_N]^T, \\mathbf{y}=[y_ 1, \\ldots, y_N]^T$，其中$y_i = f(x_i)$</li>\n<li>我们希望能够预测一个新的输入$\\mathbf{x}_*$ 时，对应$f$的值<br>高斯过程背后的关键点是函数可以使用无限维的多元高斯分布建模。换句话说，每个点都和随机变量相关，随见变量的联合分布可以建模成多元高斯分布。</li>\n</ul>\n<p>一个简单的高斯过程回归建模的程序如下：<br><!--�74--></p>\n<p>参考资料<br>[1] <a href=\"http://bridg.land/posts/gaussian-processes-1\" target=\"_blank\" rel=\"noopener\">http://bridg.land/posts/gaussian-processes-1</a><br>[2] <a href=\"https://www.youtube.com/watch?v=4vGiHC35j9s\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=4vGiHC35j9s</a></p>\n"},{"title":"高斯图模型图和伊辛图模型","date":"2018-06-10T03:01:03.000Z","_content":"# 简介\n不同于最大似然估计对于贝叶斯网的估计，有向图中，网络结构通常是已知的，我们需要做的是将参数学习出来或者是对于变量进行推断。无向图中则并不是这样，无向图中，很多模型的结构并不是完全清楚的，需要我们队模型结构进行推断。\n\n# 高斯图模型\n高斯图模型是马尔科夫随机场的成对形式，同样也是满足高斯正态分布：\n$$ p(x\\mid \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp[-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-T}(x-\\mu)] $$\n其中$\\mu$是均值，$\\Sigma$是协方差矩阵。令$\\mu=0$和精度矩阵为$Q=\\Sigma^{-1}$，有：\n$$ p(x_1, x_2, ..., x_p\\mid \\mu=0, Q) = \\frac{|Q|^{1/2}}{(2\\pi)^{n/2}}exp[-\\frac{1}{2}\\sum_i q_{ii}(x_i)^2 - \\sum_{i<j}q_{ij}x_ix_j] $$\n这就是条件随机场，定义于成对边和节点上。\n\n# 协方差矩阵与精度矩阵\n协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精度矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。\n\n# 利用LASSO进行网络学习\n## LASSO回归\n对于网络结构的学习，我们通常是假设网络是稀疏的。LASSO回归可以用于网络的近邻选择，去除不必要的节点之间的连接。  \n$$\\hat{\\beta_1} = argmin_{\\beta_1}\\parallel Y - X\\beta_1\\parallel^2 + \\lambda\\parallel\\beta_1\\parallel_1$$\n其中，$\\beta_1$是节点1的参数，Y是是对节点1的独立观测值。\n具体过程如图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/LASSO%E5%9B%9E%E5%BD%92.png)\n\n## 理论条件\n* Dependency Condition: Relevant Covariates are not overly dependent\n* Incoherence Condition: Large number of irrelevant covariates can't be too correlated with relevant covariates\n* Strong concentration bounds: Sample quantities coverge to expected values quickly\n\n# 时变网络\n## KELLER: Kernel Weightd $L_1$-regularized logistic Regression\n对时变网络的结构进行估计，可以采用KELLER的方法解决：\n$$ \\hat{\\theta_i^t} = argmain_{\\theta_i^t}l_w(\\theta_i^t) + \\lambda_1\\parallel\\theta_t^t \\parallel_1 $$\n其中$l_w(\\theta_i^t) = \\sum_{t'=1}^T w(x^{t'}; x^t)log\\ P(x_i^{t'}\\mid x_{-i} x^{t'}, \\theta_i^t)$。权值$w(x^{t'}; x^t)$决定了在时间$t'$和$t$之间的关系，我们可以将其建模为一个分布(如下图)。\n![]()\n给定时间$t^{\\ast}$，权值可以写成：\n$$ w_t(t^{\\ast}) = \\frac{K_{h_n}(t-t^{\\ast})}{\\sigma_{t'\\in T^n} K_{h_n}(t'-t^{\\ast})} $$\n对于一些平滑的核$K_{h_n}$。\n\n## TESLA: Temporally Smoothed $L_1$-regularized logistic regression\nTESLA对于一个节点的参数优化是基于所有的时间步的：\n$$ \\hat{\\theta_i^T}, ..., \\hat{\\theta_i^T} = argmin\\sum_{i=1}^T l_{avg}(\\theta_i^t) + \\lambda_1 \\sum_{t=1}^T \\parallel\\theta_{-1}^t \\parallel_1 + \\lambda_2\\sum_{t=1}^T \\parallel \\theta_i^t - \\theta_i^{t-1} \\parallel $$\n其中，$l_{avg}(\\theta_i^t) = \\frac{1}{N^t}\\sum_{d=1}^{N^t} log\\ P(x_{d,i}^t\\mid x_{d, -i}^t, \\theta_i^t) $是条件对数似然。不同于KELLER，当节点数达到5000时，这里我们不需要平滑Kernels，这里可以接受突变。\n","source":"_posts/高斯图模型图和伊辛图模型.md","raw":"---\ntitle: 高斯图模型图和伊辛图模型\ndate: 2018-06-10 11:01:03\ntags: 概率图模型\ncategories: 学习\n---\n# 简介\n不同于最大似然估计对于贝叶斯网的估计，有向图中，网络结构通常是已知的，我们需要做的是将参数学习出来或者是对于变量进行推断。无向图中则并不是这样，无向图中，很多模型的结构并不是完全清楚的，需要我们队模型结构进行推断。\n\n# 高斯图模型\n高斯图模型是马尔科夫随机场的成对形式，同样也是满足高斯正态分布：\n$$ p(x\\mid \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp[-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-T}(x-\\mu)] $$\n其中$\\mu$是均值，$\\Sigma$是协方差矩阵。令$\\mu=0$和精度矩阵为$Q=\\Sigma^{-1}$，有：\n$$ p(x_1, x_2, ..., x_p\\mid \\mu=0, Q) = \\frac{|Q|^{1/2}}{(2\\pi)^{n/2}}exp[-\\frac{1}{2}\\sum_i q_{ii}(x_i)^2 - \\sum_{i<j}q_{ij}x_ix_j] $$\n这就是条件随机场，定义于成对边和节点上。\n\n# 协方差矩阵与精度矩阵\n协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精度矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。\n\n# 利用LASSO进行网络学习\n## LASSO回归\n对于网络结构的学习，我们通常是假设网络是稀疏的。LASSO回归可以用于网络的近邻选择，去除不必要的节点之间的连接。  \n$$\\hat{\\beta_1} = argmin_{\\beta_1}\\parallel Y - X\\beta_1\\parallel^2 + \\lambda\\parallel\\beta_1\\parallel_1$$\n其中，$\\beta_1$是节点1的参数，Y是是对节点1的独立观测值。\n具体过程如图所示：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/LASSO%E5%9B%9E%E5%BD%92.png)\n\n## 理论条件\n* Dependency Condition: Relevant Covariates are not overly dependent\n* Incoherence Condition: Large number of irrelevant covariates can't be too correlated with relevant covariates\n* Strong concentration bounds: Sample quantities coverge to expected values quickly\n\n# 时变网络\n## KELLER: Kernel Weightd $L_1$-regularized logistic Regression\n对时变网络的结构进行估计，可以采用KELLER的方法解决：\n$$ \\hat{\\theta_i^t} = argmain_{\\theta_i^t}l_w(\\theta_i^t) + \\lambda_1\\parallel\\theta_t^t \\parallel_1 $$\n其中$l_w(\\theta_i^t) = \\sum_{t'=1}^T w(x^{t'}; x^t)log\\ P(x_i^{t'}\\mid x_{-i} x^{t'}, \\theta_i^t)$。权值$w(x^{t'}; x^t)$决定了在时间$t'$和$t$之间的关系，我们可以将其建模为一个分布(如下图)。\n![]()\n给定时间$t^{\\ast}$，权值可以写成：\n$$ w_t(t^{\\ast}) = \\frac{K_{h_n}(t-t^{\\ast})}{\\sigma_{t'\\in T^n} K_{h_n}(t'-t^{\\ast})} $$\n对于一些平滑的核$K_{h_n}$。\n\n## TESLA: Temporally Smoothed $L_1$-regularized logistic regression\nTESLA对于一个节点的参数优化是基于所有的时间步的：\n$$ \\hat{\\theta_i^T}, ..., \\hat{\\theta_i^T} = argmin\\sum_{i=1}^T l_{avg}(\\theta_i^t) + \\lambda_1 \\sum_{t=1}^T \\parallel\\theta_{-1}^t \\parallel_1 + \\lambda_2\\sum_{t=1}^T \\parallel \\theta_i^t - \\theta_i^{t-1} \\parallel $$\n其中，$l_{avg}(\\theta_i^t) = \\frac{1}{N^t}\\sum_{d=1}^{N^t} log\\ P(x_{d,i}^t\\mid x_{d, -i}^t, \\theta_i^t) $是条件对数似然。不同于KELLER，当节点数达到5000时，这里我们不需要平滑Kernels，这里可以接受突变。\n","slug":"高斯图模型图和伊辛图模型","published":1,"updated":"2018-09-22T06:32:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mt8001h1ouzloqwp7l1","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>不同于最大似然估计对于贝叶斯网的估计，有向图中，网络结构通常是已知的，我们需要做的是将参数学习出来或者是对于变量进行推断。无向图中则并不是这样，无向图中，很多模型的结构并不是完全清楚的，需要我们队模型结构进行推断。</p>\n<h1 id=\"高斯图模型\"><a href=\"#高斯图模型\" class=\"headerlink\" title=\"高斯图模型\"></a>高斯图模型</h1><p>高斯图模型是马尔科夫随机场的成对形式，同样也是满足高斯正态分布：<br>$$ p(x\\mid \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp[-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-T}(x-\\mu)] $$<br>其中$\\mu$是均值，$\\Sigma$是协方差矩阵。令$\\mu=0$和精度矩阵为$Q=\\Sigma^{-1}$，有：<br>$$ p(x_1, x_2, …, x_p\\mid \\mu=0, Q) = \\frac{|Q|^{1/2}}{(2\\pi)^{n/2}}exp[-\\frac{1}{2}\\sum_i q_{ii}(x_i)^2 - \\sum_{i&lt;j}q_{ij}x_ix_j] $$<br>这就是条件随机场，定义于成对边和节点上。</p>\n<h1 id=\"协方差矩阵与精度矩阵\"><a href=\"#协方差矩阵与精度矩阵\" class=\"headerlink\" title=\"协方差矩阵与精度矩阵\"></a>协方差矩阵与精度矩阵</h1><p>协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精度矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。</p>\n<h1 id=\"利用LASSO进行网络学习\"><a href=\"#利用LASSO进行网络学习\" class=\"headerlink\" title=\"利用LASSO进行网络学习\"></a>利用LASSO进行网络学习</h1><h2 id=\"LASSO回归\"><a href=\"#LASSO回归\" class=\"headerlink\" title=\"LASSO回归\"></a>LASSO回归</h2><p>对于网络结构的学习，我们通常是假设网络是稀疏的。LASSO回归可以用于网络的近邻选择，去除不必要的节点之间的连接。<br>$$\\hat{\\beta_1} = argmin_{\\beta_1}\\parallel Y - X\\beta_1\\parallel^2 + \\lambda\\parallel\\beta_1\\parallel_1$$<br>其中，$\\beta_1$是节点1的参数，Y是是对节点1的独立观测值。<br>具体过程如图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/LASSO%E5%9B%9E%E5%BD%92.png\" alt></p>\n<h2 id=\"理论条件\"><a href=\"#理论条件\" class=\"headerlink\" title=\"理论条件\"></a>理论条件</h2><ul>\n<li>Dependency Condition: Relevant Covariates are not overly dependent</li>\n<li>Incoherence Condition: Large number of irrelevant covariates can’t be too correlated with relevant covariates</li>\n<li>Strong concentration bounds: Sample quantities coverge to expected values quickly</li>\n</ul>\n<h1 id=\"时变网络\"><a href=\"#时变网络\" class=\"headerlink\" title=\"时变网络\"></a>时变网络</h1><h2 id=\"KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression\"><a href=\"#KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression\" class=\"headerlink\" title=\"KELLER: Kernel Weightd $L_1$-regularized logistic Regression\"></a>KELLER: Kernel Weightd $L_1$-regularized logistic Regression</h2><p>对时变网络的结构进行估计，可以采用KELLER的方法解决：<br>$$ \\hat{\\theta_i^t} = argmain_{\\theta_i^t}l_w(\\theta_i^t) + \\lambda_1\\parallel\\theta_t^t \\parallel_1 $$<br>其中$l_w(\\theta_i^t) = \\sum_{t’=1}^T w(x^{t’}; x^t)log\\ P(x_i^{t’}\\mid x_{-i} x^{t’}, \\theta_i^t)$。权值$w(x^{t’}; x^t)$决定了在时间$t’$和$t$之间的关系，我们可以将其建模为一个分布(如下图)。<br><img src alt><br>给定时间$t^{\\ast}$，权值可以写成：<br>$$ w_t(t^{\\ast}) = \\frac{K_{h_n}(t-t^{\\ast})}{\\sigma_{t’\\in T^n} K_{h_n}(t’-t^{\\ast})} $$<br>对于一些平滑的核$K_{h_n}$。</p>\n<h2 id=\"TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression\"><a href=\"#TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression\" class=\"headerlink\" title=\"TESLA: Temporally Smoothed $L_1$-regularized logistic regression\"></a>TESLA: Temporally Smoothed $L_1$-regularized logistic regression</h2><p>TESLA对于一个节点的参数优化是基于所有的时间步的：<br>$$ \\hat{\\theta_i^T}, …, \\hat{\\theta_i^T} = argmin\\sum_{i=1}^T l_{avg}(\\theta_i^t) + \\lambda_1 \\sum_{t=1}^T \\parallel\\theta_{-1}^t \\parallel_1 + \\lambda_2\\sum_{t=1}^T \\parallel \\theta_i^t - \\theta_i^{t-1} \\parallel $$<br>其中，$l_{avg}(\\theta_i^t) = \\frac{1}{N^t}\\sum_{d=1}^{N^t} log\\ P(x_{d,i}^t\\mid x_{d, -i}^t, \\theta_i^t) $是条件对数似然。不同于KELLER，当节点数达到5000时，这里我们不需要平滑Kernels，这里可以接受突变。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>不同于最大似然估计对于贝叶斯网的估计，有向图中，网络结构通常是已知的，我们需要做的是将参数学习出来或者是对于变量进行推断。无向图中则并不是这样，无向图中，很多模型的结构并不是完全清楚的，需要我们队模型结构进行推断。</p>\n<h1 id=\"高斯图模型\"><a href=\"#高斯图模型\" class=\"headerlink\" title=\"高斯图模型\"></a>高斯图模型</h1><p>高斯图模型是马尔科夫随机场的成对形式，同样也是满足高斯正态分布：<br>$$ p(x\\mid \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp[-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-T}(x-\\mu)] $$<br>其中$\\mu$是均值，$\\Sigma$是协方差矩阵。令$\\mu=0$和精度矩阵为$Q=\\Sigma^{-1}$，有：<br>$$ p(x_1, x_2, …, x_p\\mid \\mu=0, Q) = \\frac{|Q|^{1/2}}{(2\\pi)^{n/2}}exp[-\\frac{1}{2}\\sum_i q_{ii}(x_i)^2 - \\sum_{i&lt;j}q_{ij}x_ix_j] $$<br>这就是条件随机场，定义于成对边和节点上。</p>\n<h1 id=\"协方差矩阵与精度矩阵\"><a href=\"#协方差矩阵与精度矩阵\" class=\"headerlink\" title=\"协方差矩阵与精度矩阵\"></a>协方差矩阵与精度矩阵</h1><p>协方差矩阵有一个重要的性质是：当$\\Sigma_{i,j}=0$有$x_i\\perp x_j$；逆协方差矩阵（精度矩阵）的对应的性质为：当$\\Sigma_{i,j}^{-1}=0$时$x_i\\perp x_j\\mid x_{-ij}$。</p>\n<h1 id=\"利用LASSO进行网络学习\"><a href=\"#利用LASSO进行网络学习\" class=\"headerlink\" title=\"利用LASSO进行网络学习\"></a>利用LASSO进行网络学习</h1><h2 id=\"LASSO回归\"><a href=\"#LASSO回归\" class=\"headerlink\" title=\"LASSO回归\"></a>LASSO回归</h2><p>对于网络结构的学习，我们通常是假设网络是稀疏的。LASSO回归可以用于网络的近邻选择，去除不必要的节点之间的连接。<br>$$\\hat{\\beta_1} = argmin_{\\beta_1}\\parallel Y - X\\beta_1\\parallel^2 + \\lambda\\parallel\\beta_1\\parallel_1$$<br>其中，$\\beta_1$是节点1的参数，Y是是对节点1的独立观测值。<br>具体过程如图所示：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/LASSO%E5%9B%9E%E5%BD%92.png\" alt></p>\n<h2 id=\"理论条件\"><a href=\"#理论条件\" class=\"headerlink\" title=\"理论条件\"></a>理论条件</h2><ul>\n<li>Dependency Condition: Relevant Covariates are not overly dependent</li>\n<li>Incoherence Condition: Large number of irrelevant covariates can’t be too correlated with relevant covariates</li>\n<li>Strong concentration bounds: Sample quantities coverge to expected values quickly</li>\n</ul>\n<h1 id=\"时变网络\"><a href=\"#时变网络\" class=\"headerlink\" title=\"时变网络\"></a>时变网络</h1><h2 id=\"KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression\"><a href=\"#KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression\" class=\"headerlink\" title=\"KELLER: Kernel Weightd $L_1$-regularized logistic Regression\"></a>KELLER: Kernel Weightd $L_1$-regularized logistic Regression</h2><p>对时变网络的结构进行估计，可以采用KELLER的方法解决：<br>$$ \\hat{\\theta_i^t} = argmain_{\\theta_i^t}l_w(\\theta_i^t) + \\lambda_1\\parallel\\theta_t^t \\parallel_1 $$<br>其中$l_w(\\theta_i^t) = \\sum_{t’=1}^T w(x^{t’}; x^t)log\\ P(x_i^{t’}\\mid x_{-i} x^{t’}, \\theta_i^t)$。权值$w(x^{t’}; x^t)$决定了在时间$t’$和$t$之间的关系，我们可以将其建模为一个分布(如下图)。<br><img src alt><br>给定时间$t^{\\ast}$，权值可以写成：<br>$$ w_t(t^{\\ast}) = \\frac{K_{h_n}(t-t^{\\ast})}{\\sigma_{t’\\in T^n} K_{h_n}(t’-t^{\\ast})} $$<br>对于一些平滑的核$K_{h_n}$。</p>\n<h2 id=\"TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression\"><a href=\"#TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression\" class=\"headerlink\" title=\"TESLA: Temporally Smoothed $L_1$-regularized logistic regression\"></a>TESLA: Temporally Smoothed $L_1$-regularized logistic regression</h2><p>TESLA对于一个节点的参数优化是基于所有的时间步的：<br>$$ \\hat{\\theta_i^T}, …, \\hat{\\theta_i^T} = argmin\\sum_{i=1}^T l_{avg}(\\theta_i^t) + \\lambda_1 \\sum_{t=1}^T \\parallel\\theta_{-1}^t \\parallel_1 + \\lambda_2\\sum_{t=1}^T \\parallel \\theta_i^t - \\theta_i^{t-1} \\parallel $$<br>其中，$l_{avg}(\\theta_i^t) = \\frac{1}{N^t}\\sum_{d=1}^{N^t} log\\ P(x_{d,i}^t\\mid x_{d, -i}^t, \\theta_i^t) $是条件对数似然。不同于KELLER，当节点数达到5000时，这里我们不需要平滑Kernels，这里可以接受突变。</p>\n"},{"title":"线性分类-逻辑回归","date":"2019-12-29T10:38:40.000Z","_content":"# 数据\n$$\n\\begin{aligned}\n&\\lbrace\\left(x_{i}, y_{i}\\right)\\rbrace_{i=1}^{N}\\\\\\\\\n&x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\lbrace 0,1\\rbrace\n\\end{aligned}\n$$\n\n# Sigmoid Function\n$$\n\\sigma(z)=\\frac{1}{1+e^{-z}}\n$$\n\n$$\n\\begin{cases}\n{p_{1}=p(y=1 | x)=\\sigma\\left(w^{\\top} x\\right)=\\frac{1}{1+e^{-w^{T} x}}, \\quad y=1} \\\\\\\\\n{p_{0}=p(y=0 | x)=1-p(y=1| x)=\\frac{e^{-w^{T} x}}{1+e^{-w^{T} x}}, \\quad y=0}\n\\end{cases}\n$$\n\n$$P(y | x)=p_1^{y}p_0^{1-y}$$\n\n最大似然估计MLE:\n$$\n\\begin{aligned}\n\\hat{w}&=\\arg\\max _{w} \\log P(Y | X) \\\\\\\\\n&=\\arg\\max_w \\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i}\\right) \\\\\\\\\n&=\\arg\\max_w \\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right) \\\\\\\\\n&=\\arg\\max_w \\sum_{i=1}^{N}\\left(y_{i} \\log p_{1}+\\left(1-y_{i}\\right) \\log p_{0}\\right) \\\\\\\\\n&=\\arg\\max_w \\sum_{i=1}^{N} y_{i} \\log \\psi\\left(x_{i}, w\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\psi\\left(x_{i} ; w\\right)\\right)\n\\end{aligned}\n$$\n\n\n\n","source":"_posts/机器学习理论推导/线性分类-逻辑回归.md","raw":"---\ntitle: 线性分类-逻辑回归\ndate: 2019-12-29 18:38:40\ntags: 机器学习理论推导\ncategories: 学习\n---\n# 数据\n$$\n\\begin{aligned}\n&\\lbrace\\left(x_{i}, y_{i}\\right)\\rbrace_{i=1}^{N}\\\\\\\\\n&x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\lbrace 0,1\\rbrace\n\\end{aligned}\n$$\n\n# Sigmoid Function\n$$\n\\sigma(z)=\\frac{1}{1+e^{-z}}\n$$\n\n$$\n\\begin{cases}\n{p_{1}=p(y=1 | x)=\\sigma\\left(w^{\\top} x\\right)=\\frac{1}{1+e^{-w^{T} x}}, \\quad y=1} \\\\\\\\\n{p_{0}=p(y=0 | x)=1-p(y=1| x)=\\frac{e^{-w^{T} x}}{1+e^{-w^{T} x}}, \\quad y=0}\n\\end{cases}\n$$\n\n$$P(y | x)=p_1^{y}p_0^{1-y}$$\n\n最大似然估计MLE:\n$$\n\\begin{aligned}\n\\hat{w}&=\\arg\\max _{w} \\log P(Y | X) \\\\\\\\\n&=\\arg\\max_w \\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i}\\right) \\\\\\\\\n&=\\arg\\max_w \\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right) \\\\\\\\\n&=\\arg\\max_w \\sum_{i=1}^{N}\\left(y_{i} \\log p_{1}+\\left(1-y_{i}\\right) \\log p_{0}\\right) \\\\\\\\\n&=\\arg\\max_w \\sum_{i=1}^{N} y_{i} \\log \\psi\\left(x_{i}, w\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\psi\\left(x_{i} ; w\\right)\\right)\n\\end{aligned}\n$$\n\n\n\n","slug":"机器学习理论推导/线性分类-逻辑回归","published":1,"updated":"2019-12-29T11:11:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40my4004a1ouzul7flsob","content":"<h1 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h1><p>$$<br>\\begin{aligned}<br>&amp;\\lbrace\\left(x_{i}, y_{i}\\right)\\rbrace_{i=1}^{N}\\\\<br>&amp;x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\lbrace 0,1\\rbrace<br>\\end{aligned}<br>$$</p>\n<h1 id=\"Sigmoid-Function\"><a href=\"#Sigmoid-Function\" class=\"headerlink\" title=\"Sigmoid Function\"></a>Sigmoid Function</h1><p>$$<br>\\sigma(z)=\\frac{1}{1+e^{-z}}<br>$$</p>\n<p>$$<br>\\begin{cases}<br>{p_{1}=p(y=1 | x)=\\sigma\\left(w^{\\top} x\\right)=\\frac{1}{1+e^{-w^{T} x}}, \\quad y=1} \\\\<br>{p_{0}=p(y=0 | x)=1-p(y=1| x)=\\frac{e^{-w^{T} x}}{1+e^{-w^{T} x}}, \\quad y=0}<br>\\end{cases}<br>$$</p>\n<p>$$P(y | x)=p_1^{y}p_0^{1-y}$$</p>\n<p>最大似然估计MLE:<br>$$<br>\\begin{aligned}<br>\\hat{w}&amp;=\\arg\\max _{w} \\log P(Y | X) \\\\<br>&amp;=\\arg\\max_w \\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i}\\right) \\\\<br>&amp;=\\arg\\max_w \\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right) \\\\<br>&amp;=\\arg\\max_w \\sum_{i=1}^{N}\\left(y_{i} \\log p_{1}+\\left(1-y_{i}\\right) \\log p_{0}\\right) \\\\<br>&amp;=\\arg\\max_w \\sum_{i=1}^{N} y_{i} \\log \\psi\\left(x_{i}, w\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\psi\\left(x_{i} ; w\\right)\\right)<br>\\end{aligned}<br>$$</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h1><p>$$<br>\\begin{aligned}<br>&amp;\\lbrace\\left(x_{i}, y_{i}\\right)\\rbrace_{i=1}^{N}\\\\<br>&amp;x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\lbrace 0,1\\rbrace<br>\\end{aligned}<br>$$</p>\n<h1 id=\"Sigmoid-Function\"><a href=\"#Sigmoid-Function\" class=\"headerlink\" title=\"Sigmoid Function\"></a>Sigmoid Function</h1><p>$$<br>\\sigma(z)=\\frac{1}{1+e^{-z}}<br>$$</p>\n<p>$$<br>\\begin{cases}<br>{p_{1}=p(y=1 | x)=\\sigma\\left(w^{\\top} x\\right)=\\frac{1}{1+e^{-w^{T} x}}, \\quad y=1} \\\\<br>{p_{0}=p(y=0 | x)=1-p(y=1| x)=\\frac{e^{-w^{T} x}}{1+e^{-w^{T} x}}, \\quad y=0}<br>\\end{cases}<br>$$</p>\n<p>$$P(y | x)=p_1^{y}p_0^{1-y}$$</p>\n<p>最大似然估计MLE:<br>$$<br>\\begin{aligned}<br>\\hat{w}&amp;=\\arg\\max _{w} \\log P(Y | X) \\\\<br>&amp;=\\arg\\max_w \\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i}\\right) \\\\<br>&amp;=\\arg\\max_w \\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right) \\\\<br>&amp;=\\arg\\max_w \\sum_{i=1}^{N}\\left(y_{i} \\log p_{1}+\\left(1-y_{i}\\right) \\log p_{0}\\right) \\\\<br>&amp;=\\arg\\max_w \\sum_{i=1}^{N} y_{i} \\log \\psi\\left(x_{i}, w\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\psi\\left(x_{i} ; w\\right)\\right)<br>\\end{aligned}<br>$$</p>\n"},{"title":"线性分类-感知机","date":"2019-12-29T06:49:07.000Z","_content":"样本集：$\\lbrace (x_i, y_i) \\rbrace_{i=1}^N$\n模型:\n\\begin{aligned}\n&f(x)=\\operatorname{sign}\\left(w^{\\top} x\\right), \\quad x_i \\in \\mathbb{R}^{p}, w \\in \\mathbb{R}^{p}\\\\\\\\\n&\\operatorname{sign}(a)=\\begin{cases} +1,\\quad a>0 \\\\\\\\{-1,  \\quad a<0 }\n\\end{cases}\n\\end{aligned}\n\n策略：构造损失函数\n\\begin{array}{c}\nL(w)=\\sum_{i=1}^{N} I\\lbrace y_{i} w^{\\top} x_{i}<0\\rbrace \\\\\\\\\n{ L(w)=\\sum_{x_{i} \\in D}-y_{i} w^{\\top} x_{i}} \\\\\\\\\n{\\nabla_{w} L=-y_{i} x_{i}}\n\\end{array}\n\n算法：随机梯度SGD\n\\begin{aligned}\nW^{(t+1)} & \\leftarrow w^{(t)}-\\lambda \\nabla_{w} L \\\\\\\\\n& w^{(t)}+\\lambda y_{i} x_{i}\n\\end{aligned}\n\n\n","source":"_posts/机器学习理论推导/线性分类-感知机.md","raw":"---\ntitle: 线性分类-感知机\ndate: 2019-12-29 14:49:07\ntags: 机器学习理论推导\ncategories: 学习\n---\n样本集：$\\lbrace (x_i, y_i) \\rbrace_{i=1}^N$\n模型:\n\\begin{aligned}\n&f(x)=\\operatorname{sign}\\left(w^{\\top} x\\right), \\quad x_i \\in \\mathbb{R}^{p}, w \\in \\mathbb{R}^{p}\\\\\\\\\n&\\operatorname{sign}(a)=\\begin{cases} +1,\\quad a>0 \\\\\\\\{-1,  \\quad a<0 }\n\\end{cases}\n\\end{aligned}\n\n策略：构造损失函数\n\\begin{array}{c}\nL(w)=\\sum_{i=1}^{N} I\\lbrace y_{i} w^{\\top} x_{i}<0\\rbrace \\\\\\\\\n{ L(w)=\\sum_{x_{i} \\in D}-y_{i} w^{\\top} x_{i}} \\\\\\\\\n{\\nabla_{w} L=-y_{i} x_{i}}\n\\end{array}\n\n算法：随机梯度SGD\n\\begin{aligned}\nW^{(t+1)} & \\leftarrow w^{(t)}-\\lambda \\nabla_{w} L \\\\\\\\\n& w^{(t)}+\\lambda y_{i} x_{i}\n\\end{aligned}\n\n\n","slug":"机器学习理论推导/线性分类-感知机","published":1,"updated":"2019-12-29T07:08:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40my6004d1ouz7vvt5tbw","content":"<p>样本集：$\\lbrace (x_i, y_i) \\rbrace_{i=1}^N$<br>模型:<br>\\begin{aligned}<br>&amp;f(x)=\\operatorname{sign}\\left(w^{\\top} x\\right), \\quad x_i \\in \\mathbb{R}^{p}, w \\in \\mathbb{R}^{p}\\\\<br>&amp;\\operatorname{sign}(a)=\\begin{cases} +1,\\quad a&gt;0 \\\\{-1,  \\quad a&lt;0 }<br>\\end{cases}<br>\\end{aligned}</p>\n<p>策略：构造损失函数<br>\\begin{array}{c}<br>L(w)=\\sum_{i=1}^{N} I\\lbrace y_{i} w^{\\top} x_{i}&lt;0\\rbrace \\\\<br>{ L(w)=\\sum_{x_{i} \\in D}-y_{i} w^{\\top} x_{i}} \\\\<br>{\\nabla_{w} L=-y_{i} x_{i}}<br>\\end{array}</p>\n<p>算法：随机梯度SGD<br>\\begin{aligned}<br>W^{(t+1)} &amp; \\leftarrow w^{(t)}-\\lambda \\nabla_{w} L \\\\<br>&amp; w^{(t)}+\\lambda y_{i} x_{i}<br>\\end{aligned}</p>\n","site":{"data":{}},"excerpt":"","more":"<p>样本集：$\\lbrace (x_i, y_i) \\rbrace_{i=1}^N$<br>模型:<br>\\begin{aligned}<br>&amp;f(x)=\\operatorname{sign}\\left(w^{\\top} x\\right), \\quad x_i \\in \\mathbb{R}^{p}, w \\in \\mathbb{R}^{p}\\\\<br>&amp;\\operatorname{sign}(a)=\\begin{cases} +1,\\quad a&gt;0 \\\\{-1,  \\quad a&lt;0 }<br>\\end{cases}<br>\\end{aligned}</p>\n<p>策略：构造损失函数<br>\\begin{array}{c}<br>L(w)=\\sum_{i=1}^{N} I\\lbrace y_{i} w^{\\top} x_{i}&lt;0\\rbrace \\\\<br>{ L(w)=\\sum_{x_{i} \\in D}-y_{i} w^{\\top} x_{i}} \\\\<br>{\\nabla_{w} L=-y_{i} x_{i}}<br>\\end{array}</p>\n<p>算法：随机梯度SGD<br>\\begin{aligned}<br>W^{(t+1)} &amp; \\leftarrow w^{(t)}-\\lambda \\nabla_{w} L \\\\<br>&amp; w^{(t)}+\\lambda y_{i} x_{i}<br>\\end{aligned}</p>\n"},{"title":"引言","date":"2019-12-25T02:39:09.000Z","catergories":"学习","_content":"[本系列](http://hjyai94.cn/tags/机器学习理论推导/)为本人推导机器学习算法的笔记，主要参考PRML[1]，西瓜书[2]，统计学习方法[3]，还有机器学习白板推导[4]。文章顺序和内容基本与B站机器学习白板推导顺序一致。\n[1] Bishop C M. Pattern recognition and machine learning[M]. springer, 2006.\n[2] 周志华. 机器学习[M]. 清华大学出版社, 2016.\n[3] 李航. 统计学习方法[M]. 2012.\n[4] https://www.bilibili.com/video/av70839977?p=1\n","source":"_posts/机器学习理论推导/引言.md","raw":"---\ntitle: 引言\ndate: 2019-12-25 10:39:09\ntags: 机器学习理论推导\ncatergories: 学习\n---\n[本系列](http://hjyai94.cn/tags/机器学习理论推导/)为本人推导机器学习算法的笔记，主要参考PRML[1]，西瓜书[2]，统计学习方法[3]，还有机器学习白板推导[4]。文章顺序和内容基本与B站机器学习白板推导顺序一致。\n[1] Bishop C M. Pattern recognition and machine learning[M]. springer, 2006.\n[2] 周志华. 机器学习[M]. 清华大学出版社, 2016.\n[3] 李航. 统计学习方法[M]. 2012.\n[4] https://www.bilibili.com/video/av70839977?p=1\n","slug":"机器学习理论推导/引言","published":1,"updated":"2019-12-26T03:48:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40my7004g1ouziyvf6mxt","content":"<p><a href=\"http://hjyai94.cn/tags/机器学习理论推导/\" target=\"_blank\" rel=\"noopener\">本系列</a>为本人推导机器学习算法的笔记，主要参考PRML[1]，西瓜书[2]，统计学习方法[3]，还有机器学习白板推导[4]。文章顺序和内容基本与B站机器学习白板推导顺序一致。<br>[1] Bishop C M. Pattern recognition and machine learning[M]. springer, 2006.<br>[2] 周志华. 机器学习[M]. 清华大学出版社, 2016.<br>[3] 李航. 统计学习方法[M]. 2012.<br>[4] <a href=\"https://www.bilibili.com/video/av70839977?p=1\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/av70839977?p=1</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://hjyai94.cn/tags/机器学习理论推导/\" target=\"_blank\" rel=\"noopener\">本系列</a>为本人推导机器学习算法的笔记，主要参考PRML[1]，西瓜书[2]，统计学习方法[3]，还有机器学习白板推导[4]。文章顺序和内容基本与B站机器学习白板推导顺序一致。<br>[1] Bishop C M. Pattern recognition and machine learning[M]. springer, 2006.<br>[2] 周志华. 机器学习[M]. 清华大学出版社, 2016.<br>[3] 李航. 统计学习方法[M]. 2012.<br>[4] <a href=\"https://www.bilibili.com/video/av70839977?p=1\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/av70839977?p=1</a></p>\n"},{"title":"频率学派与贝叶斯学派","date":"2019-12-26T02:39:09.000Z","_content":"数据$X$\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$\\theta$为参数，$x\\sim p(x|\\theta)$\n# 频率学派\n频率学派认为，$\\theta$为未知的常量，X为随机变量。\n频率学派常用最大似然估计：\n$$\\theta_{MLE} = \\operatorname{argmax}_{\\theta} log(p(X|\\theta))$$\n\n# 贝叶斯学派\n贝叶斯学派与频率学派不同，$\\theta$为随机变量，$\\theta\\sim p(\\theta)$\n贝叶斯公式：\n\n$$p(\\theta | x)=\\frac{p(x | \\theta) \\cdot p(\\theta)}{p(x)} \\propto p(x | \\theta) \\cdot p(\\theta)$$\n\n贝叶斯学派通常使用最大后验估计：\n$$\\theta_{MAP} = argmax_{\\theta} p(\\theta | X)=argmax_{\\theta} p(X | \\theta)p(\\theta)$$\n\n贝叶斯估计：\n$${p(\\theta | x)}=\\frac{p(X | \\theta) \\cdot p(\\theta)}{\\int_{\\theta} p(X | \\theta) p(\\theta) d \\theta}$$\n\n贝叶斯预测：\n$$p(\\tilde{x}|X)=\\int_{\\theta}p(\\tilde{x}, \\theta | X) d \\theta = \\int_{\\theta} p(\\tilde{x} | \\theta) {p(\\theta | X)} d \\theta$$\n\n# 总结\n频率学派通常将问题转化为最优化问题，贝叶斯学派通常将为你转化为求边缘概率的积分问题。","source":"_posts/机器学习理论推导/机器学习推导-频率与贝叶斯.md","raw":"---\ntitle: 频率学派与贝叶斯学派\ndate: 2019-12-26 10:39:09\ntags: 机器学习理论推导\ncategories: 学习\n---\n数据$X$\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$\\theta$为参数，$x\\sim p(x|\\theta)$\n# 频率学派\n频率学派认为，$\\theta$为未知的常量，X为随机变量。\n频率学派常用最大似然估计：\n$$\\theta_{MLE} = \\operatorname{argmax}_{\\theta} log(p(X|\\theta))$$\n\n# 贝叶斯学派\n贝叶斯学派与频率学派不同，$\\theta$为随机变量，$\\theta\\sim p(\\theta)$\n贝叶斯公式：\n\n$$p(\\theta | x)=\\frac{p(x | \\theta) \\cdot p(\\theta)}{p(x)} \\propto p(x | \\theta) \\cdot p(\\theta)$$\n\n贝叶斯学派通常使用最大后验估计：\n$$\\theta_{MAP} = argmax_{\\theta} p(\\theta | X)=argmax_{\\theta} p(X | \\theta)p(\\theta)$$\n\n贝叶斯估计：\n$${p(\\theta | x)}=\\frac{p(X | \\theta) \\cdot p(\\theta)}{\\int_{\\theta} p(X | \\theta) p(\\theta) d \\theta}$$\n\n贝叶斯预测：\n$$p(\\tilde{x}|X)=\\int_{\\theta}p(\\tilde{x}, \\theta | X) d \\theta = \\int_{\\theta} p(\\tilde{x} | \\theta) {p(\\theta | X)} d \\theta$$\n\n# 总结\n频率学派通常将问题转化为最优化问题，贝叶斯学派通常将为你转化为求边缘概率的积分问题。","slug":"机器学习理论推导/机器学习推导-频率与贝叶斯","published":1,"updated":"2019-12-28T14:44:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40my9004j1ouzwybwzcq0","content":"<p>数据$X$<br>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$\\theta$为参数，$x\\sim p(x|\\theta)$</p>\n<h1 id=\"频率学派\"><a href=\"#频率学派\" class=\"headerlink\" title=\"频率学派\"></a>频率学派</h1><p>频率学派认为，$\\theta$为未知的常量，X为随机变量。<br>频率学派常用最大似然估计：<br>$$\\theta_{MLE} = \\operatorname{argmax}_{\\theta} log(p(X|\\theta))$$</p>\n<h1 id=\"贝叶斯学派\"><a href=\"#贝叶斯学派\" class=\"headerlink\" title=\"贝叶斯学派\"></a>贝叶斯学派</h1><p>贝叶斯学派与频率学派不同，$\\theta$为随机变量，$\\theta\\sim p(\\theta)$<br>贝叶斯公式：</p>\n<p>$$p(\\theta | x)=\\frac{p(x | \\theta) \\cdot p(\\theta)}{p(x)} \\propto p(x | \\theta) \\cdot p(\\theta)$$</p>\n<p>贝叶斯学派通常使用最大后验估计：<br>$$\\theta_{MAP} = argmax_{\\theta} p(\\theta | X)=argmax_{\\theta} p(X | \\theta)p(\\theta)$$</p>\n<p>贝叶斯估计：<br>$${p(\\theta | x)}=\\frac{p(X | \\theta) \\cdot p(\\theta)}{\\int_{\\theta} p(X | \\theta) p(\\theta) d \\theta}$$</p>\n<p>贝叶斯预测：<br>$$p(\\tilde{x}|X)=\\int_{\\theta}p(\\tilde{x}, \\theta | X) d \\theta = \\int_{\\theta} p(\\tilde{x} | \\theta) {p(\\theta | X)} d \\theta$$</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>频率学派通常将问题转化为最优化问题，贝叶斯学派通常将为你转化为求边缘概率的积分问题。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>数据$X$<br>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$\\theta$为参数，$x\\sim p(x|\\theta)$</p>\n<h1 id=\"频率学派\"><a href=\"#频率学派\" class=\"headerlink\" title=\"频率学派\"></a>频率学派</h1><p>频率学派认为，$\\theta$为未知的常量，X为随机变量。<br>频率学派常用最大似然估计：<br>$$\\theta_{MLE} = \\operatorname{argmax}_{\\theta} log(p(X|\\theta))$$</p>\n<h1 id=\"贝叶斯学派\"><a href=\"#贝叶斯学派\" class=\"headerlink\" title=\"贝叶斯学派\"></a>贝叶斯学派</h1><p>贝叶斯学派与频率学派不同，$\\theta$为随机变量，$\\theta\\sim p(\\theta)$<br>贝叶斯公式：</p>\n<p>$$p(\\theta | x)=\\frac{p(x | \\theta) \\cdot p(\\theta)}{p(x)} \\propto p(x | \\theta) \\cdot p(\\theta)$$</p>\n<p>贝叶斯学派通常使用最大后验估计：<br>$$\\theta_{MAP} = argmax_{\\theta} p(\\theta | X)=argmax_{\\theta} p(X | \\theta)p(\\theta)$$</p>\n<p>贝叶斯估计：<br>$${p(\\theta | x)}=\\frac{p(X | \\theta) \\cdot p(\\theta)}{\\int_{\\theta} p(X | \\theta) p(\\theta) d \\theta}$$</p>\n<p>贝叶斯预测：<br>$$p(\\tilde{x}|X)=\\int_{\\theta}p(\\tilde{x}, \\theta | X) d \\theta = \\int_{\\theta} p(\\tilde{x} | \\theta) {p(\\theta | X)} d \\theta$$</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>频率学派通常将问题转化为最优化问题，贝叶斯学派通常将为你转化为求边缘概率的积分问题。</p>\n"},{"title":"线性分类-线性判别分析","date":"2019-12-29T07:12:25.000Z","_content":"# 定义\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T_{N\\times p} \n$$     $$\nY=\\left(\\begin{array}{l}\n{y_{1}}  & {y_{2}} & {\\cdots} & {y_{N}}\n\\end{array}\\right)^T_{N \\times 1}\n$$\n\n\\begin{array}{l}\n{\\left\\lbrace \\left(x_{i},\\quad y_{i}\\right)\\right\\rbrace_{i=1}^{N},\\quad x_{i} \\in \\mathbb{R}^{p},\\quad y_{i} \\in\\lbrace+1,-1\\rbrace} \\\\\\\\\n{x_{c_{1}}=\\left\\lbrace x_{i} | y_{i}=+1\\right\\rbrace, \\quad x_{c_{2}}=\\left\\lbrace x_{i} | y_{i}=-1\\right\\rbrace} \\\\\\\\\n{\\left|x_{c_{1}}\\right|=N_{1}, \\quad\\left|x_{c_{2}}\\right|=N_{2}, \\quad N_{1}+N_{2}=N}\n\\end{array}\n\n# 思想\n线性判别分析的思想是使得类内差异小，类间差异大。\n\n$$\\begin{aligned} z_{i} &=w^{\\top} x_{i} \\\\\\\\ \\bar{z} &=\\frac{1}{N} \\sum_{i=1}^{N} z_{i}=\\frac{1}{N} \\sum_{i=1}^{N} w^{\\top} x_{i} \\\\\\\\ S &=\\frac{1}{N} \\sum_{i=1}^{N}\\left(z_{i}-\\bar{z}\\right)\\left(z_{i}-\\bar{z}\\right)^{\\top} \\\\\\\\ &=\\frac{1}{N} \\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-\\bar{z}\\right)\\left(w^{\\top} x_{i}-\\bar{z}\\right)^{\\top}  \\end{aligned}$$\n\n$$\\begin{aligned} \nC_1: \\bar{z}_{1} &=\\frac{1}{N_1} \\sum_{i=1}^{N_1} w^{\\top} x_i \\\\\\\\ \nS_{1} &=\\frac{1}{N_{1}} \\sum_{i=1}^{N_1}\\left(w^{\\top} x_i-\\bar{z}_1 \\right)\\left(w^{\\top} x_i-\\bar{z}_1 \\right)^{\\top} \\\\\\\\ \n\\end{aligned}$$\n\n$$\\begin{aligned}\nC_2: \\bar{z}_{2} &=\\frac{1}{N_2} \\sum_{i=1}^{N_2} w^{\\top} x_i \\\\\\\\\nS_{2} &=\\frac{1}{N_{2}} \\sum_{i=1}^{N_2}\\left(w^{\\top} x_i-\\bar{z}_2 \\right)\\left(w^{\\top} x_i-\\bar{z}_2 \\right)^{\\top}\n\\end{aligned}$$\n\n# 目标函数\n\n$$J(w) = \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2}$$    \n\n$$\\hat{w}=\\arg\\max_{w} J(w)$$\n\n分子\n$$\\begin{aligned}\n\\left(\\bar{z}_{1} - \\bar{z}_2 \\right)^2 &= \\left(\\frac{1}{N_1} \\sum_{i=1}^{N_{1}} w^{\\top} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} w^{\\top} x_{i}\\right)^2=\\left[w^{\\top}\\left(\\frac{1}{N_{1}} \\sum_{i=1}^{N_{2}} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} x_{i}\\right)\\right]^2 \\\\\\\\\n&= \\left(w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\right)^{2}=w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_2}\\right)^{\\top} w\n\\end{aligned}\n$$\n\n分别求分母 $S_1$ 和 $S_2$\n\\begin{aligned}\nS_{1} &=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}}\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)^{\\top} \\\\\\\\\n&=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}} w^{\\top}\\left(x_{i}-\\bar{x}_{c_{1}}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top} w \\\\\\\\\n&=w^{\\top}\\left[\\frac{1}{N_{1}} \\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}_{c_1}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top}\\right] w \\\\\\\\\n&=w^{\\top} \\quad \\cdot \\quad S_{c_1} \\quad \\cdot w \\\\\\\\\n&=w^{\\top} S_{c_1} w\n\\end{aligned}\n\n分母 \n\\begin{aligned}\nS_1 + S_2 &=w^{\\top} S_{c_1} w+w^{\\top} S_{c_2} w\\\\\\\\\n&=w^{T}\\left(S_{c_1}+S_{c_{2}}\\right) w\n\\end{aligned}\n\n$$\nJ(w)=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_{2}}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_{1}}+s_{c_{2}}\\right) w}\n$$\n\n# 模型求解\n\\begin{aligned}\nJ(w) &= \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2} \\\\\\\\\n&=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_1}+s_{c_2}\\right) w} \\\\\\\\\n&=\\frac{w^{\\top} S_{b} w}{w^{\\top} S_w w}\n\\end{aligned}\n\n\\begin{aligned}\n&S_b=\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2} \\right) \\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top}\\\\\\\\\n&S_w=S_{c_1}+S_{c_2}\n\\end{aligned}\n\n$ S_b $ : between-class 类间方差 $p\\times p$\n$ S_w $ : within-class 类内方差 $p\\times p$\n\n对$J(w)$求导，并令其为$0$，\n\\begin{aligned}\n\\frac{\\partial J(w)}{\\partial w} &=2 S_{b} w\\left(w^{\\top} S_{w} w\\right)^{-1}+w^{\\top} S_{b} w \\cdot(-1) \\cdot\\left(w^{\\top} S_{w} w\\right)^{-2} \\\\\\\\\n&=0\n\\end{aligned}\n\n\\begin{aligned}\n\\hat{w} &=\\frac{w^{\\top} S w}{w^{\\top} S_{b} w} S_{w}^{-1} \\cdot S_{b} \\cdot w\\\\\\\\\n&\\propto S_w^{-1} \\cdot S_{b} \\cdot w \\\\\\\\\n&= S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})(\\bar{x}_{c_1} - \\bar{x}_{c_2})^{\\top} \\cdot w \\\\\\\\\n&\\propto S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})\n\\end{aligned}\n\n\n\n\n","source":"_posts/机器学习理论推导/线性分类-线性判别分析.md","raw":"---\ntitle: 线性分类-线性判别分析\ndate: 2019-12-29 15:12:25\ntags: 机器学习理论推导\ncategories: 学习\n---\n# 定义\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T_{N\\times p} \n$$     $$\nY=\\left(\\begin{array}{l}\n{y_{1}}  & {y_{2}} & {\\cdots} & {y_{N}}\n\\end{array}\\right)^T_{N \\times 1}\n$$\n\n\\begin{array}{l}\n{\\left\\lbrace \\left(x_{i},\\quad y_{i}\\right)\\right\\rbrace_{i=1}^{N},\\quad x_{i} \\in \\mathbb{R}^{p},\\quad y_{i} \\in\\lbrace+1,-1\\rbrace} \\\\\\\\\n{x_{c_{1}}=\\left\\lbrace x_{i} | y_{i}=+1\\right\\rbrace, \\quad x_{c_{2}}=\\left\\lbrace x_{i} | y_{i}=-1\\right\\rbrace} \\\\\\\\\n{\\left|x_{c_{1}}\\right|=N_{1}, \\quad\\left|x_{c_{2}}\\right|=N_{2}, \\quad N_{1}+N_{2}=N}\n\\end{array}\n\n# 思想\n线性判别分析的思想是使得类内差异小，类间差异大。\n\n$$\\begin{aligned} z_{i} &=w^{\\top} x_{i} \\\\\\\\ \\bar{z} &=\\frac{1}{N} \\sum_{i=1}^{N} z_{i}=\\frac{1}{N} \\sum_{i=1}^{N} w^{\\top} x_{i} \\\\\\\\ S &=\\frac{1}{N} \\sum_{i=1}^{N}\\left(z_{i}-\\bar{z}\\right)\\left(z_{i}-\\bar{z}\\right)^{\\top} \\\\\\\\ &=\\frac{1}{N} \\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-\\bar{z}\\right)\\left(w^{\\top} x_{i}-\\bar{z}\\right)^{\\top}  \\end{aligned}$$\n\n$$\\begin{aligned} \nC_1: \\bar{z}_{1} &=\\frac{1}{N_1} \\sum_{i=1}^{N_1} w^{\\top} x_i \\\\\\\\ \nS_{1} &=\\frac{1}{N_{1}} \\sum_{i=1}^{N_1}\\left(w^{\\top} x_i-\\bar{z}_1 \\right)\\left(w^{\\top} x_i-\\bar{z}_1 \\right)^{\\top} \\\\\\\\ \n\\end{aligned}$$\n\n$$\\begin{aligned}\nC_2: \\bar{z}_{2} &=\\frac{1}{N_2} \\sum_{i=1}^{N_2} w^{\\top} x_i \\\\\\\\\nS_{2} &=\\frac{1}{N_{2}} \\sum_{i=1}^{N_2}\\left(w^{\\top} x_i-\\bar{z}_2 \\right)\\left(w^{\\top} x_i-\\bar{z}_2 \\right)^{\\top}\n\\end{aligned}$$\n\n# 目标函数\n\n$$J(w) = \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2}$$    \n\n$$\\hat{w}=\\arg\\max_{w} J(w)$$\n\n分子\n$$\\begin{aligned}\n\\left(\\bar{z}_{1} - \\bar{z}_2 \\right)^2 &= \\left(\\frac{1}{N_1} \\sum_{i=1}^{N_{1}} w^{\\top} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} w^{\\top} x_{i}\\right)^2=\\left[w^{\\top}\\left(\\frac{1}{N_{1}} \\sum_{i=1}^{N_{2}} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} x_{i}\\right)\\right]^2 \\\\\\\\\n&= \\left(w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\right)^{2}=w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_2}\\right)^{\\top} w\n\\end{aligned}\n$$\n\n分别求分母 $S_1$ 和 $S_2$\n\\begin{aligned}\nS_{1} &=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}}\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)^{\\top} \\\\\\\\\n&=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}} w^{\\top}\\left(x_{i}-\\bar{x}_{c_{1}}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top} w \\\\\\\\\n&=w^{\\top}\\left[\\frac{1}{N_{1}} \\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}_{c_1}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top}\\right] w \\\\\\\\\n&=w^{\\top} \\quad \\cdot \\quad S_{c_1} \\quad \\cdot w \\\\\\\\\n&=w^{\\top} S_{c_1} w\n\\end{aligned}\n\n分母 \n\\begin{aligned}\nS_1 + S_2 &=w^{\\top} S_{c_1} w+w^{\\top} S_{c_2} w\\\\\\\\\n&=w^{T}\\left(S_{c_1}+S_{c_{2}}\\right) w\n\\end{aligned}\n\n$$\nJ(w)=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_{2}}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_{1}}+s_{c_{2}}\\right) w}\n$$\n\n# 模型求解\n\\begin{aligned}\nJ(w) &= \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2} \\\\\\\\\n&=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_1}+s_{c_2}\\right) w} \\\\\\\\\n&=\\frac{w^{\\top} S_{b} w}{w^{\\top} S_w w}\n\\end{aligned}\n\n\\begin{aligned}\n&S_b=\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2} \\right) \\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top}\\\\\\\\\n&S_w=S_{c_1}+S_{c_2}\n\\end{aligned}\n\n$ S_b $ : between-class 类间方差 $p\\times p$\n$ S_w $ : within-class 类内方差 $p\\times p$\n\n对$J(w)$求导，并令其为$0$，\n\\begin{aligned}\n\\frac{\\partial J(w)}{\\partial w} &=2 S_{b} w\\left(w^{\\top} S_{w} w\\right)^{-1}+w^{\\top} S_{b} w \\cdot(-1) \\cdot\\left(w^{\\top} S_{w} w\\right)^{-2} \\\\\\\\\n&=0\n\\end{aligned}\n\n\\begin{aligned}\n\\hat{w} &=\\frac{w^{\\top} S w}{w^{\\top} S_{b} w} S_{w}^{-1} \\cdot S_{b} \\cdot w\\\\\\\\\n&\\propto S_w^{-1} \\cdot S_{b} \\cdot w \\\\\\\\\n&= S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})(\\bar{x}_{c_1} - \\bar{x}_{c_2})^{\\top} \\cdot w \\\\\\\\\n&\\propto S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})\n\\end{aligned}\n\n\n\n\n","slug":"机器学习理论推导/线性分类-线性判别分析","published":1,"updated":"2019-12-29T10:34:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mya004m1ouzsaxozbpi","content":"<h1 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h1><p>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T_{N\\times p}<br>$$     $$<br>Y=\\left(\\begin{array}{l}<br>{y_{1}}  &amp; {y_{2}} &amp; {\\cdots} &amp; {y_{N}}<br>\\end{array}\\right)^T_{N \\times 1}<br>$$</p>\n<p>\\begin{array}{l}<br>{\\left\\lbrace \\left(x_{i},\\quad y_{i}\\right)\\right\\rbrace_{i=1}^{N},\\quad x_{i} \\in \\mathbb{R}^{p},\\quad y_{i} \\in\\lbrace+1,-1\\rbrace} \\\\<br>{x_{c_{1}}=\\left\\lbrace x_{i} | y_{i}=+1\\right\\rbrace, \\quad x_{c_{2}}=\\left\\lbrace x_{i} | y_{i}=-1\\right\\rbrace} \\\\<br>{\\left|x_{c_{1}}\\right|=N_{1}, \\quad\\left|x_{c_{2}}\\right|=N_{2}, \\quad N_{1}+N_{2}=N}<br>\\end{array}</p>\n<h1 id=\"思想\"><a href=\"#思想\" class=\"headerlink\" title=\"思想\"></a>思想</h1><p>线性判别分析的思想是使得类内差异小，类间差异大。</p>\n<p>$$\\begin{aligned} z_{i} &amp;=w^{\\top} x_{i} \\\\ \\bar{z} &amp;=\\frac{1}{N} \\sum_{i=1}^{N} z_{i}=\\frac{1}{N} \\sum_{i=1}^{N} w^{\\top} x_{i} \\\\ S &amp;=\\frac{1}{N} \\sum_{i=1}^{N}\\left(z_{i}-\\bar{z}\\right)\\left(z_{i}-\\bar{z}\\right)^{\\top} \\\\ &amp;=\\frac{1}{N} \\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-\\bar{z}\\right)\\left(w^{\\top} x_{i}-\\bar{z}\\right)^{\\top}  \\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>C_1: \\bar{z}_{1} &amp;=\\frac{1}{N_1} \\sum_{i=1}^{N_1} w^{\\top} x_i \\\\<br>S_{1} &amp;=\\frac{1}{N_{1}} \\sum_{i=1}^{N_1}\\left(w^{\\top} x_i-\\bar{z}_1 \\right)\\left(w^{\\top} x_i-\\bar{z}_1 \\right)^{\\top} \\\\<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>C_2: \\bar{z}_{2} &amp;=\\frac{1}{N_2} \\sum_{i=1}^{N_2} w^{\\top} x_i \\\\<br>S_{2} &amp;=\\frac{1}{N_{2}} \\sum_{i=1}^{N_2}\\left(w^{\\top} x_i-\\bar{z}_2 \\right)\\left(w^{\\top} x_i-\\bar{z}_2 \\right)^{\\top}<br>\\end{aligned}$$</p>\n<h1 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h1><p>$$J(w) = \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2}$$    </p>\n<p>$$\\hat{w}=\\arg\\max_{w} J(w)$$</p>\n<p>分子<br>$$\\begin{aligned}<br>\\left(\\bar{z}_{1} - \\bar{z}_2 \\right)^2 &amp;= \\left(\\frac{1}{N_1} \\sum_{i=1}^{N_{1}} w^{\\top} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} w^{\\top} x_{i}\\right)^2=\\left[w^{\\top}\\left(\\frac{1}{N_{1}} \\sum_{i=1}^{N_{2}} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} x_{i}\\right)\\right]^2 \\\\<br>&amp;= \\left(w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\right)^{2}=w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_2}\\right)^{\\top} w<br>\\end{aligned}<br>$$</p>\n<p>分别求分母 $S_1$ 和 $S_2$<br>\\begin{aligned}<br>S_{1} &amp;=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}}\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)^{\\top} \\\\<br>&amp;=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}} w^{\\top}\\left(x_{i}-\\bar{x}_{c_{1}}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top} w \\\\<br>&amp;=w^{\\top}\\left[\\frac{1}{N_{1}} \\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}_{c_1}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top}\\right] w \\\\<br>&amp;=w^{\\top} \\quad \\cdot \\quad S_{c_1} \\quad \\cdot w \\\\<br>&amp;=w^{\\top} S_{c_1} w<br>\\end{aligned}</p>\n<p>分母<br>\\begin{aligned}<br>S_1 + S_2 &amp;=w^{\\top} S_{c_1} w+w^{\\top} S_{c_2} w\\\\<br>&amp;=w^{T}\\left(S_{c_1}+S_{c_{2}}\\right) w<br>\\end{aligned}</p>\n<p>$$<br>J(w)=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_{2}}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_{1}}+s_{c_{2}}\\right) w}<br>$$</p>\n<h1 id=\"模型求解\"><a href=\"#模型求解\" class=\"headerlink\" title=\"模型求解\"></a>模型求解</h1><p>\\begin{aligned}<br>J(w) &amp;= \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2} \\\\<br>&amp;=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_1}+s_{c_2}\\right) w} \\\\<br>&amp;=\\frac{w^{\\top} S_{b} w}{w^{\\top} S_w w}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>&amp;S_b=\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2} \\right) \\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top}\\\\<br>&amp;S_w=S_{c_1}+S_{c_2}<br>\\end{aligned}</p>\n<p>$ S_b $ : between-class 类间方差 $p\\times p$<br>$ S_w $ : within-class 类内方差 $p\\times p$</p>\n<p>对$J(w)$求导，并令其为$0$，<br>\\begin{aligned}<br>\\frac{\\partial J(w)}{\\partial w} &amp;=2 S_{b} w\\left(w^{\\top} S_{w} w\\right)^{-1}+w^{\\top} S_{b} w \\cdot(-1) \\cdot\\left(w^{\\top} S_{w} w\\right)^{-2} \\\\<br>&amp;=0<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>\\hat{w} &amp;=\\frac{w^{\\top} S w}{w^{\\top} S_{b} w} S_{w}^{-1} \\cdot S_{b} \\cdot w\\\\<br>&amp;\\propto S_w^{-1} \\cdot S_{b} \\cdot w \\\\<br>&amp;= S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})(\\bar{x}_{c_1} - \\bar{x}_{c_2})^{\\top} \\cdot w \\\\<br>&amp;\\propto S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})<br>\\end{aligned}</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h1><p>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T_{N\\times p}<br>$$     $$<br>Y=\\left(\\begin{array}{l}<br>{y_{1}}  &amp; {y_{2}} &amp; {\\cdots} &amp; {y_{N}}<br>\\end{array}\\right)^T_{N \\times 1}<br>$$</p>\n<p>\\begin{array}{l}<br>{\\left\\lbrace \\left(x_{i},\\quad y_{i}\\right)\\right\\rbrace_{i=1}^{N},\\quad x_{i} \\in \\mathbb{R}^{p},\\quad y_{i} \\in\\lbrace+1,-1\\rbrace} \\\\<br>{x_{c_{1}}=\\left\\lbrace x_{i} | y_{i}=+1\\right\\rbrace, \\quad x_{c_{2}}=\\left\\lbrace x_{i} | y_{i}=-1\\right\\rbrace} \\\\<br>{\\left|x_{c_{1}}\\right|=N_{1}, \\quad\\left|x_{c_{2}}\\right|=N_{2}, \\quad N_{1}+N_{2}=N}<br>\\end{array}</p>\n<h1 id=\"思想\"><a href=\"#思想\" class=\"headerlink\" title=\"思想\"></a>思想</h1><p>线性判别分析的思想是使得类内差异小，类间差异大。</p>\n<p>$$\\begin{aligned} z_{i} &amp;=w^{\\top} x_{i} \\\\ \\bar{z} &amp;=\\frac{1}{N} \\sum_{i=1}^{N} z_{i}=\\frac{1}{N} \\sum_{i=1}^{N} w^{\\top} x_{i} \\\\ S &amp;=\\frac{1}{N} \\sum_{i=1}^{N}\\left(z_{i}-\\bar{z}\\right)\\left(z_{i}-\\bar{z}\\right)^{\\top} \\\\ &amp;=\\frac{1}{N} \\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-\\bar{z}\\right)\\left(w^{\\top} x_{i}-\\bar{z}\\right)^{\\top}  \\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>C_1: \\bar{z}_{1} &amp;=\\frac{1}{N_1} \\sum_{i=1}^{N_1} w^{\\top} x_i \\\\<br>S_{1} &amp;=\\frac{1}{N_{1}} \\sum_{i=1}^{N_1}\\left(w^{\\top} x_i-\\bar{z}_1 \\right)\\left(w^{\\top} x_i-\\bar{z}_1 \\right)^{\\top} \\\\<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>C_2: \\bar{z}_{2} &amp;=\\frac{1}{N_2} \\sum_{i=1}^{N_2} w^{\\top} x_i \\\\<br>S_{2} &amp;=\\frac{1}{N_{2}} \\sum_{i=1}^{N_2}\\left(w^{\\top} x_i-\\bar{z}_2 \\right)\\left(w^{\\top} x_i-\\bar{z}_2 \\right)^{\\top}<br>\\end{aligned}$$</p>\n<h1 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h1><p>$$J(w) = \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2}$$    </p>\n<p>$$\\hat{w}=\\arg\\max_{w} J(w)$$</p>\n<p>分子<br>$$\\begin{aligned}<br>\\left(\\bar{z}_{1} - \\bar{z}_2 \\right)^2 &amp;= \\left(\\frac{1}{N_1} \\sum_{i=1}^{N_{1}} w^{\\top} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} w^{\\top} x_{i}\\right)^2=\\left[w^{\\top}\\left(\\frac{1}{N_{1}} \\sum_{i=1}^{N_{2}} x_{i}-\\frac{1}{N_{2}} \\sum_{i=1}^{N_{2}} x_{i}\\right)\\right]^2 \\\\<br>&amp;= \\left(w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\right)^{2}=w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_2}\\right)^{\\top} w<br>\\end{aligned}<br>$$</p>\n<p>分别求分母 $S_1$ 和 $S_2$<br>\\begin{aligned}<br>S_{1} &amp;=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}}\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)\\left(w^{\\top} x_{i}-\\frac{1}{N_{1}} \\sum_{j=1}^{N_{1}} w^{\\top} x_{j}\\right)^{\\top} \\\\<br>&amp;=\\frac{1}{N_{1}} \\sum_{i=1}^{N_{1}} w^{\\top}\\left(x_{i}-\\bar{x}_{c_{1}}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top} w \\\\<br>&amp;=w^{\\top}\\left[\\frac{1}{N_{1}} \\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}_{c_1}\\right)\\left(x_{i}-\\bar{x}_{c_1}\\right)^{\\top}\\right] w \\\\<br>&amp;=w^{\\top} \\quad \\cdot \\quad S_{c_1} \\quad \\cdot w \\\\<br>&amp;=w^{\\top} S_{c_1} w<br>\\end{aligned}</p>\n<p>分母<br>\\begin{aligned}<br>S_1 + S_2 &amp;=w^{\\top} S_{c_1} w+w^{\\top} S_{c_2} w\\\\<br>&amp;=w^{T}\\left(S_{c_1}+S_{c_{2}}\\right) w<br>\\end{aligned}</p>\n<p>$$<br>J(w)=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_{2}}\\right)\\left(\\bar{x}_{c_{1}}-\\bar{x}_{c_{2}}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_{1}}+s_{c_{2}}\\right) w}<br>$$</p>\n<h1 id=\"模型求解\"><a href=\"#模型求解\" class=\"headerlink\" title=\"模型求解\"></a>模型求解</h1><p>\\begin{aligned}<br>J(w) &amp;= \\frac{\\left( \\bar{z}_{1} - \\bar{z}_2 \\right)^2 } {s_1+s_2} \\\\<br>&amp;=\\frac{w^{\\top}\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top} w}{w^{\\top}\\left(s_{c_1}+s_{c_2}\\right) w} \\\\<br>&amp;=\\frac{w^{\\top} S_{b} w}{w^{\\top} S_w w}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>&amp;S_b=\\left(\\bar{x}_{c_1}-\\bar{x}_{c_2} \\right) \\left(\\bar{x}_{c_1}-\\bar{x}_{c_2}\\right)^{\\top}\\\\<br>&amp;S_w=S_{c_1}+S_{c_2}<br>\\end{aligned}</p>\n<p>$ S_b $ : between-class 类间方差 $p\\times p$<br>$ S_w $ : within-class 类内方差 $p\\times p$</p>\n<p>对$J(w)$求导，并令其为$0$，<br>\\begin{aligned}<br>\\frac{\\partial J(w)}{\\partial w} &amp;=2 S_{b} w\\left(w^{\\top} S_{w} w\\right)^{-1}+w^{\\top} S_{b} w \\cdot(-1) \\cdot\\left(w^{\\top} S_{w} w\\right)^{-2} \\\\<br>&amp;=0<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>\\hat{w} &amp;=\\frac{w^{\\top} S w}{w^{\\top} S_{b} w} S_{w}^{-1} \\cdot S_{b} \\cdot w\\\\<br>&amp;\\propto S_w^{-1} \\cdot S_{b} \\cdot w \\\\<br>&amp;= S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})(\\bar{x}_{c_1} - \\bar{x}_{c_2})^{\\top} \\cdot w \\\\<br>&amp;\\propto S_w^{-1} \\cdot (\\bar{x}_{c_1} - \\bar{x}_{c_2})<br>\\end{aligned}</p>\n"},{"title":"线性回归-岭回归","date":"2019-12-28T15:29:26.000Z","_content":"$$\\begin{aligned}\n&D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\\\\\\n&x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N\n\\end{aligned}$$\n\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$$\nY=\\left(\\begin{array}{c}\n{y_{1}} \\\\\\\\\n{y_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{y_{N}}\n\\end{array}\\right)_{N \\times 1}\n$$\n\n# 岭回归\n### 频率角度\n$$\n\\begin{aligned} J(w) &=\\sum_{i=1}^{N}\\left\\|\\left| w^{\\top} x_{i}-y_{i}\\right\\|\\right|^{2}+\\lambda w^{\\top} w \\\\\\\\\n&=\\left(w^{\\top} X^{\\top}-Y^{\\top}\\right)(X w-Y)+\\lambda w^{\\top} w \\\\\\\\\n&={w^{\\top} \\left(X^{\\top} X  +\\lambda I \\right)w} -2 w^{\\top} X^{\\top} Y+Y^{\\top} Y\n\\end{aligned}\n$$     \n\n$$\\hat{w}= \\arg \\min_w  J(w)$$\n\\begin{aligned}\n\\frac{\\partial J(w)}{\\partial w}=2\\left(X^{\\top} X+\\lambda I\\right) w &-2 X^{\\top} Y=0 \\\\\\\\\n\\hat{w}=\\left(X^{\\top} X+\\lambda I\\right)^{-1} X^{\\top} Y\n\\end{aligned}\n\n### 贝叶斯角度\n$$f(w)=w^{\\top} x_i$$   $$y=f(w)+\\varepsilon=w^{\\top} x_i+\\varepsilon$$   $$\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$$   $$y_i | x_i;w = N\\left(w^{\\top} x_i, \\sigma^2 \\right)$$\n\n$$p(y_i | w)=\\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace$$   $$p(w)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{0}^{2}} \\exp \\lbrace-\\frac{|| w ||^{2}}{2 \\sigma_{0}^{2}}\\rbrace$$  $$p(y_i | w) \\cdot p(w)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\cdot \\frac{1}{\\sqrt{2\\pi} \\sigma_0} \\cdot \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}}\\right\\rbrace$$\n\n最大后验概率估计MAP：\n\\begin{aligned}\n\\hat{w} &=\\arg\\max_{w} p(w | Y)  \\\\\\\\\n&=\\arg\\max_{w}\\prod_{i=1}^N p(y_i | w) \\cdot p(w) \\\\\\\\\n&=\\arg \\max_w \\sum_{i=1}^N \\log [p(y_i | w) \\cdot p(w)] \\\\\\\\\n&= \\arg \\max_w \\sum_{i=1}^N -\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}} \\\\\\\\\n&= \\arg \\min_w\\sum_{i=1}^N {\\left(y_i-w^{\\top} x\\right)^{2}}+\\frac{N\\sigma^2 }{ \\sigma_{0}^{2}} ||w||^{2}\n\\end{aligned}\n\n# 总结\n最小二乘估计等价于噪声为高斯分布的最大似然估计，二范数为正则项的最小二乘估计等价为先验为高斯分布的最大后验估计。\n\n","source":"_posts/机器学习理论推导/线性回归-岭回归.md","raw":"---\ntitle: 线性回归-岭回归\ndate: 2019-12-28 23:29:26\ntags: 机器学习理论推导\n---\n$$\\begin{aligned}\n&D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\\\\\\n&x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N\n\\end{aligned}$$\n\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$$\nY=\\left(\\begin{array}{c}\n{y_{1}} \\\\\\\\\n{y_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{y_{N}}\n\\end{array}\\right)_{N \\times 1}\n$$\n\n# 岭回归\n### 频率角度\n$$\n\\begin{aligned} J(w) &=\\sum_{i=1}^{N}\\left\\|\\left| w^{\\top} x_{i}-y_{i}\\right\\|\\right|^{2}+\\lambda w^{\\top} w \\\\\\\\\n&=\\left(w^{\\top} X^{\\top}-Y^{\\top}\\right)(X w-Y)+\\lambda w^{\\top} w \\\\\\\\\n&={w^{\\top} \\left(X^{\\top} X  +\\lambda I \\right)w} -2 w^{\\top} X^{\\top} Y+Y^{\\top} Y\n\\end{aligned}\n$$     \n\n$$\\hat{w}= \\arg \\min_w  J(w)$$\n\\begin{aligned}\n\\frac{\\partial J(w)}{\\partial w}=2\\left(X^{\\top} X+\\lambda I\\right) w &-2 X^{\\top} Y=0 \\\\\\\\\n\\hat{w}=\\left(X^{\\top} X+\\lambda I\\right)^{-1} X^{\\top} Y\n\\end{aligned}\n\n### 贝叶斯角度\n$$f(w)=w^{\\top} x_i$$   $$y=f(w)+\\varepsilon=w^{\\top} x_i+\\varepsilon$$   $$\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$$   $$y_i | x_i;w = N\\left(w^{\\top} x_i, \\sigma^2 \\right)$$\n\n$$p(y_i | w)=\\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace$$   $$p(w)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{0}^{2}} \\exp \\lbrace-\\frac{|| w ||^{2}}{2 \\sigma_{0}^{2}}\\rbrace$$  $$p(y_i | w) \\cdot p(w)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\cdot \\frac{1}{\\sqrt{2\\pi} \\sigma_0} \\cdot \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}}\\right\\rbrace$$\n\n最大后验概率估计MAP：\n\\begin{aligned}\n\\hat{w} &=\\arg\\max_{w} p(w | Y)  \\\\\\\\\n&=\\arg\\max_{w}\\prod_{i=1}^N p(y_i | w) \\cdot p(w) \\\\\\\\\n&=\\arg \\max_w \\sum_{i=1}^N \\log [p(y_i | w) \\cdot p(w)] \\\\\\\\\n&= \\arg \\max_w \\sum_{i=1}^N -\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}} \\\\\\\\\n&= \\arg \\min_w\\sum_{i=1}^N {\\left(y_i-w^{\\top} x\\right)^{2}}+\\frac{N\\sigma^2 }{ \\sigma_{0}^{2}} ||w||^{2}\n\\end{aligned}\n\n# 总结\n最小二乘估计等价于噪声为高斯分布的最大似然估计，二范数为正则项的最小二乘估计等价为先验为高斯分布的最大后验估计。\n\n","slug":"机器学习理论推导/线性回归-岭回归","published":1,"updated":"2019-12-29T06:30:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40myb004p1ouz176jbjf2","content":"<p>$$\\begin{aligned}<br>&amp;D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\<br>&amp;x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N<br>\\end{aligned}$$</p>\n<p>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$$<br>Y=\\left(\\begin{array}{c}<br>{y_{1}} \\\\<br>{y_{2}} \\\\<br>{\\vdots} \\\\<br>{y_{N}}<br>\\end{array}\\right)_{N \\times 1}<br>$$</p>\n<h1 id=\"岭回归\"><a href=\"#岭回归\" class=\"headerlink\" title=\"岭回归\"></a>岭回归</h1><h3 id=\"频率角度\"><a href=\"#频率角度\" class=\"headerlink\" title=\"频率角度\"></a>频率角度</h3><p>$$<br>\\begin{aligned} J(w) &amp;=\\sum_{i=1}^{N}\\left|\\left| w^{\\top} x_{i}-y_{i}\\right|\\right|^{2}+\\lambda w^{\\top} w \\\\<br>&amp;=\\left(w^{\\top} X^{\\top}-Y^{\\top}\\right)(X w-Y)+\\lambda w^{\\top} w \\\\<br>&amp;={w^{\\top} \\left(X^{\\top} X  +\\lambda I \\right)w} -2 w^{\\top} X^{\\top} Y+Y^{\\top} Y<br>\\end{aligned}<br>$$     </p>\n<p>$$\\hat{w}= \\arg \\min_w  J(w)$$<br>\\begin{aligned}<br>\\frac{\\partial J(w)}{\\partial w}=2\\left(X^{\\top} X+\\lambda I\\right) w &amp;-2 X^{\\top} Y=0 \\\\<br>\\hat{w}=\\left(X^{\\top} X+\\lambda I\\right)^{-1} X^{\\top} Y<br>\\end{aligned}</p>\n<h3 id=\"贝叶斯角度\"><a href=\"#贝叶斯角度\" class=\"headerlink\" title=\"贝叶斯角度\"></a>贝叶斯角度</h3><p>$$f(w)=w^{\\top} x_i$$   $$y=f(w)+\\varepsilon=w^{\\top} x_i+\\varepsilon$$   $$\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$$   $$y_i | x_i;w = N\\left(w^{\\top} x_i, \\sigma^2 \\right)$$</p>\n<p>$$p(y_i | w)=\\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace$$   $$p(w)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{0}^{2}} \\exp \\lbrace-\\frac{|| w ||^{2}}{2 \\sigma_{0}^{2}}\\rbrace$$  $$p(y_i | w) \\cdot p(w)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\cdot \\frac{1}{\\sqrt{2\\pi} \\sigma_0} \\cdot \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}}\\right\\rbrace$$</p>\n<p>最大后验概率估计MAP：<br>\\begin{aligned}<br>\\hat{w} &amp;=\\arg\\max_{w} p(w | Y)  \\\\<br>&amp;=\\arg\\max_{w}\\prod_{i=1}^N p(y_i | w) \\cdot p(w) \\\\<br>&amp;=\\arg \\max_w \\sum_{i=1}^N \\log [p(y_i | w) \\cdot p(w)] \\\\<br>&amp;= \\arg \\max_w \\sum_{i=1}^N -\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}} \\\\<br>&amp;= \\arg \\min_w\\sum_{i=1}^N {\\left(y_i-w^{\\top} x\\right)^{2}}+\\frac{N\\sigma^2 }{ \\sigma_{0}^{2}} ||w||^{2}<br>\\end{aligned}</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>最小二乘估计等价于噪声为高斯分布的最大似然估计，二范数为正则项的最小二乘估计等价为先验为高斯分布的最大后验估计。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>$$\\begin{aligned}<br>&amp;D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\<br>&amp;x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N<br>\\end{aligned}$$</p>\n<p>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$$<br>Y=\\left(\\begin{array}{c}<br>{y_{1}} \\\\<br>{y_{2}} \\\\<br>{\\vdots} \\\\<br>{y_{N}}<br>\\end{array}\\right)_{N \\times 1}<br>$$</p>\n<h1 id=\"岭回归\"><a href=\"#岭回归\" class=\"headerlink\" title=\"岭回归\"></a>岭回归</h1><h3 id=\"频率角度\"><a href=\"#频率角度\" class=\"headerlink\" title=\"频率角度\"></a>频率角度</h3><p>$$<br>\\begin{aligned} J(w) &amp;=\\sum_{i=1}^{N}\\left|\\left| w^{\\top} x_{i}-y_{i}\\right|\\right|^{2}+\\lambda w^{\\top} w \\\\<br>&amp;=\\left(w^{\\top} X^{\\top}-Y^{\\top}\\right)(X w-Y)+\\lambda w^{\\top} w \\\\<br>&amp;={w^{\\top} \\left(X^{\\top} X  +\\lambda I \\right)w} -2 w^{\\top} X^{\\top} Y+Y^{\\top} Y<br>\\end{aligned}<br>$$     </p>\n<p>$$\\hat{w}= \\arg \\min_w  J(w)$$<br>\\begin{aligned}<br>\\frac{\\partial J(w)}{\\partial w}=2\\left(X^{\\top} X+\\lambda I\\right) w &amp;-2 X^{\\top} Y=0 \\\\<br>\\hat{w}=\\left(X^{\\top} X+\\lambda I\\right)^{-1} X^{\\top} Y<br>\\end{aligned}</p>\n<h3 id=\"贝叶斯角度\"><a href=\"#贝叶斯角度\" class=\"headerlink\" title=\"贝叶斯角度\"></a>贝叶斯角度</h3><p>$$f(w)=w^{\\top} x_i$$   $$y=f(w)+\\varepsilon=w^{\\top} x_i+\\varepsilon$$   $$\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$$   $$y_i | x_i;w = N\\left(w^{\\top} x_i, \\sigma^2 \\right)$$</p>\n<p>$$p(y_i | w)=\\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace$$   $$p(w)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{0}^{2}} \\exp \\lbrace-\\frac{|| w ||^{2}}{2 \\sigma_{0}^{2}}\\rbrace$$  $$p(y_i | w) \\cdot p(w)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\cdot \\frac{1}{\\sqrt{2\\pi} \\sigma_0} \\cdot \\exp \\left\\lbrace-\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}}\\right\\rbrace$$</p>\n<p>最大后验概率估计MAP：<br>\\begin{aligned}<br>\\hat{w} &amp;=\\arg\\max_{w} p(w | Y)  \\\\<br>&amp;=\\arg\\max_{w}\\prod_{i=1}^N p(y_i | w) \\cdot p(w) \\\\<br>&amp;=\\arg \\max_w \\sum_{i=1}^N \\log [p(y_i | w) \\cdot p(w)] \\\\<br>&amp;= \\arg \\max_w \\sum_{i=1}^N -\\frac{\\left(y_i-w^{\\top} x_i\\right)^{2}}{2 \\sigma^{2}}-\\frac{||w||^{2}}{2 \\sigma_{0}^{2}} \\\\<br>&amp;= \\arg \\min_w\\sum_{i=1}^N {\\left(y_i-w^{\\top} x\\right)^{2}}+\\frac{N\\sigma^2 }{ \\sigma_{0}^{2}} ||w||^{2}<br>\\end{aligned}</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>最小二乘估计等价于噪声为高斯分布的最大似然估计，二范数为正则项的最小二乘估计等价为先验为高斯分布的最大后验估计。</p>\n"},{"title":"线性回归-最小二乘法-概率视角","date":"2019-12-28T13:33:23.000Z","_content":"$$\n\\begin{aligned}\n&\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)\\\\\\\\\n&y=f(w)+\\varepsilon\\\\\\\\\n&f(w)=w^{\\top} x_i\\\\\\\\\n&\\begin{array}{l}\n{y_i=w^{\\top} x_i+\\varepsilon} \\\\\\\\\n{y_i | x_i; w \\sim N\\left(w^{\\top} x_i, \\sigma^{2}\\right)}\n\\end{array}\n\\end{aligned}\n$$\n\n\n$$\\mathbb{L}(w)=\\log P\\left (Y|X ; w \\right)=\\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i} ; w\\right)=\\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right)$$\n\n\\begin{aligned}\n&=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2\\pi}\\sigma}+\\log \\operatorname{exp}\\left\\lbrace-\\frac{\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace \\\\\\\\\n&=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{2\\sigma^{2}}\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}\n\\end{aligned}\n\n\\begin{aligned}\n\\hat{w} &=\\arg\\max_{w} \\mathbb{L}(w) \\\\\\\\\n&=\\arg\\max_{w}\\sum_{i=1}^{N}-\\frac{1}{2\\sigma^2} \\left(y_i-w^{\\top} x_{i}\\right)^2 \\\\\\\\\n&=\\arg\\min_{w}\\sum_{i=1}^{N}\\left(y_i-w^{\\top} x_{i}\\right)^2\n\\end{aligned} \n\n带有均值为$0$，方差为$\\sigma^2$的高斯噪声的最大似然估计等价于最小二乘法。\n\n","source":"_posts/机器学习理论推导/线性回归-最小二乘法-概率视角.md","raw":"---\ntitle: 线性回归-最小二乘法-概率视角\ndate: 2019-12-28 21:33:23\ntags: 机器学习理论推导\ncategories: 学习\n---\n$$\n\\begin{aligned}\n&\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)\\\\\\\\\n&y=f(w)+\\varepsilon\\\\\\\\\n&f(w)=w^{\\top} x_i\\\\\\\\\n&\\begin{array}{l}\n{y_i=w^{\\top} x_i+\\varepsilon} \\\\\\\\\n{y_i | x_i; w \\sim N\\left(w^{\\top} x_i, \\sigma^{2}\\right)}\n\\end{array}\n\\end{aligned}\n$$\n\n\n$$\\mathbb{L}(w)=\\log P\\left (Y|X ; w \\right)=\\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i} ; w\\right)=\\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right)$$\n\n\\begin{aligned}\n&=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2\\pi}\\sigma}+\\log \\operatorname{exp}\\left\\lbrace-\\frac{\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace \\\\\\\\\n&=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{2\\sigma^{2}}\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}\n\\end{aligned}\n\n\\begin{aligned}\n\\hat{w} &=\\arg\\max_{w} \\mathbb{L}(w) \\\\\\\\\n&=\\arg\\max_{w}\\sum_{i=1}^{N}-\\frac{1}{2\\sigma^2} \\left(y_i-w^{\\top} x_{i}\\right)^2 \\\\\\\\\n&=\\arg\\min_{w}\\sum_{i=1}^{N}\\left(y_i-w^{\\top} x_{i}\\right)^2\n\\end{aligned} \n\n带有均值为$0$，方差为$\\sigma^2$的高斯噪声的最大似然估计等价于最小二乘法。\n\n","slug":"机器学习理论推导/线性回归-最小二乘法-概率视角","published":1,"updated":"2019-12-29T06:43:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40myc004s1ouz7lb4jjeh","content":"<p>$$<br>\\begin{aligned}<br>&amp;\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)\\\\<br>&amp;y=f(w)+\\varepsilon\\\\<br>&amp;f(w)=w^{\\top} x_i\\\\<br>&amp;\\begin{array}{l}<br>{y_i=w^{\\top} x_i+\\varepsilon} \\\\<br>{y_i | x_i; w \\sim N\\left(w^{\\top} x_i, \\sigma^{2}\\right)}<br>\\end{array}<br>\\end{aligned}<br>$$</p>\n<p>$$\\mathbb{L}(w)=\\log P\\left (Y|X ; w \\right)=\\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i} ; w\\right)=\\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right)$$</p>\n<p>\\begin{aligned}<br>&amp;=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2\\pi}\\sigma}+\\log \\operatorname{exp}\\left\\lbrace-\\frac{\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace \\\\<br>&amp;=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{2\\sigma^{2}}\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>\\hat{w} &amp;=\\arg\\max_{w} \\mathbb{L}(w) \\\\<br>&amp;=\\arg\\max_{w}\\sum_{i=1}^{N}-\\frac{1}{2\\sigma^2} \\left(y_i-w^{\\top} x_{i}\\right)^2 \\\\<br>&amp;=\\arg\\min_{w}\\sum_{i=1}^{N}\\left(y_i-w^{\\top} x_{i}\\right)^2<br>\\end{aligned} </p>\n<p>带有均值为$0$，方差为$\\sigma^2$的高斯噪声的最大似然估计等价于最小二乘法。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>$$<br>\\begin{aligned}<br>&amp;\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)\\\\<br>&amp;y=f(w)+\\varepsilon\\\\<br>&amp;f(w)=w^{\\top} x_i\\\\<br>&amp;\\begin{array}{l}<br>{y_i=w^{\\top} x_i+\\varepsilon} \\\\<br>{y_i | x_i; w \\sim N\\left(w^{\\top} x_i, \\sigma^{2}\\right)}<br>\\end{array}<br>\\end{aligned}<br>$$</p>\n<p>$$\\mathbb{L}(w)=\\log P\\left (Y|X ; w \\right)=\\log \\prod_{i=1}^{N} p\\left(y_{i} | x_{i} ; w\\right)=\\sum_{i=1}^{N} \\log p\\left(y_{i} | x_{i}\\right)$$</p>\n<p>\\begin{aligned}<br>&amp;=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2\\pi}\\sigma}+\\log \\operatorname{exp}\\left\\lbrace-\\frac{\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}}{2\\sigma^{2}}\\right\\rbrace \\\\<br>&amp;=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{2\\sigma^{2}}\\left(y_{i}-w^{\\top} x_{i}\\right)^{2}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>\\hat{w} &amp;=\\arg\\max_{w} \\mathbb{L}(w) \\\\<br>&amp;=\\arg\\max_{w}\\sum_{i=1}^{N}-\\frac{1}{2\\sigma^2} \\left(y_i-w^{\\top} x_{i}\\right)^2 \\\\<br>&amp;=\\arg\\min_{w}\\sum_{i=1}^{N}\\left(y_i-w^{\\top} x_{i}\\right)^2<br>\\end{aligned} </p>\n<p>带有均值为$0$，方差为$\\sigma^2$的高斯噪声的最大似然估计等价于最小二乘法。</p>\n"},{"title":"线性回归-最小二乘法","date":"2019-12-28T12:13:11.000Z","_content":"$$\\begin{aligned}\n&D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\\\\\\n&x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N\n\\end{aligned}$$\n\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$$\nY=\\left(\\begin{array}{c}\n{y_{1}} \\\\\\\\\n{y_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{y_{N}}\n\\end{array}\\right)_{N \\times 1}\n$$\n\n最小二乘估计：\n$$\n\\begin{aligned}\nL(w) &=\\left(\\sum_{i=1}^{N}\\left\\|\\left|w^{\\top} x_{i}-y_{i}\\right\\|\\right|^{2}\\right) \\\\\\\\\n&=\\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-y_{i}\\right)^{2} \\\\\\\\\n&=\\left( w^{\\top} x_{1}-y_{1} \\quad w^{\\top} x_{2}-y_{2} \\quad \\cdots \\quad w^{\\top} x_{N}-y_{N} \\right) \\left(\\begin{array}{c}\n{w^{\\top} x_{1}-y_{1}} \\\\\\\\\n{w^{\\top} x_{2}-y_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{w^{\\top} x_{N}-y_{N}}\n\\end{array}\\right) \\\\\\\\\n&= \\left(w^{\\top} X^{\\top} - Y^{\\top} \\right) \\left(Xw - Y \\right) \\\\\\\\\n&= w^{T} {X}^{\\top} X w-2 w^{\\top} X^{\\top} Y+Y^{\\top} Y\n\\end{aligned}\n$$\n\n对上式求导，并令其为$0$：\n$$\\hat{w}=\\arg \\min L(w) $$   $$\\frac{\\partial L(w)}{\\partial w}=2 X^{\\top} X w-2 X^{\\top} Y = 0$$   $$ \\hat{w} = \\left( X^{\\top} X \\right)^{-1} X^{\\top} Y $$\n\n\n\n","source":"_posts/机器学习理论推导/线性回归-最小二乘法.md","raw":"---\ntitle: 线性回归-最小二乘法\ndate: 2019-12-28 20:13:11\ntags: 机器学习理论推导\ncategories: 学习\n---\n$$\\begin{aligned}\n&D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\\\\\\n&x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N\n\\end{aligned}$$\n\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$$\nY=\\left(\\begin{array}{c}\n{y_{1}} \\\\\\\\\n{y_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{y_{N}}\n\\end{array}\\right)_{N \\times 1}\n$$\n\n最小二乘估计：\n$$\n\\begin{aligned}\nL(w) &=\\left(\\sum_{i=1}^{N}\\left\\|\\left|w^{\\top} x_{i}-y_{i}\\right\\|\\right|^{2}\\right) \\\\\\\\\n&=\\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-y_{i}\\right)^{2} \\\\\\\\\n&=\\left( w^{\\top} x_{1}-y_{1} \\quad w^{\\top} x_{2}-y_{2} \\quad \\cdots \\quad w^{\\top} x_{N}-y_{N} \\right) \\left(\\begin{array}{c}\n{w^{\\top} x_{1}-y_{1}} \\\\\\\\\n{w^{\\top} x_{2}-y_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{w^{\\top} x_{N}-y_{N}}\n\\end{array}\\right) \\\\\\\\\n&= \\left(w^{\\top} X^{\\top} - Y^{\\top} \\right) \\left(Xw - Y \\right) \\\\\\\\\n&= w^{T} {X}^{\\top} X w-2 w^{\\top} X^{\\top} Y+Y^{\\top} Y\n\\end{aligned}\n$$\n\n对上式求导，并令其为$0$：\n$$\\hat{w}=\\arg \\min L(w) $$   $$\\frac{\\partial L(w)}{\\partial w}=2 X^{\\top} X w-2 X^{\\top} Y = 0$$   $$ \\hat{w} = \\left( X^{\\top} X \\right)^{-1} X^{\\top} Y $$\n\n\n\n","slug":"机器学习理论推导/线性回归-最小二乘法","published":1,"updated":"2019-12-28T14:44:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40mye004v1ouz7tgvc49u","content":"<p>$$\\begin{aligned}<br>&amp;D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\<br>&amp;x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N<br>\\end{aligned}$$</p>\n<p>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$$<br>Y=\\left(\\begin{array}{c}<br>{y_{1}} \\\\<br>{y_{2}} \\\\<br>{\\vdots} \\\\<br>{y_{N}}<br>\\end{array}\\right)_{N \\times 1}<br>$$</p>\n<p>最小二乘估计：<br>$$<br>\\begin{aligned}<br>L(w) &amp;=\\left(\\sum_{i=1}^{N}\\left|\\left|w^{\\top} x_{i}-y_{i}\\right|\\right|^{2}\\right) \\\\<br>&amp;=\\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-y_{i}\\right)^{2} \\\\<br>&amp;=\\left( w^{\\top} x_{1}-y_{1} \\quad w^{\\top} x_{2}-y_{2} \\quad \\cdots \\quad w^{\\top} x_{N}-y_{N} \\right) \\left(\\begin{array}{c}<br>{w^{\\top} x_{1}-y_{1}} \\\\<br>{w^{\\top} x_{2}-y_{2}} \\\\<br>{\\vdots} \\\\<br>{w^{\\top} x_{N}-y_{N}}<br>\\end{array}\\right) \\\\<br>&amp;= \\left(w^{\\top} X^{\\top} - Y^{\\top} \\right) \\left(Xw - Y \\right) \\\\<br>&amp;= w^{T} {X}^{\\top} X w-2 w^{\\top} X^{\\top} Y+Y^{\\top} Y<br>\\end{aligned}<br>$$</p>\n<p>对上式求导，并令其为$0$：<br>$$\\hat{w}=\\arg \\min L(w) $$   $$\\frac{\\partial L(w)}{\\partial w}=2 X^{\\top} X w-2 X^{\\top} Y = 0$$   $$ \\hat{w} = \\left( X^{\\top} X \\right)^{-1} X^{\\top} Y $$</p>\n","site":{"data":{}},"excerpt":"","more":"<p>$$\\begin{aligned}<br>&amp;D=\\left\\lbrace(x_1, y_1),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\rbrace \\\\<br>&amp;x_{i} \\in \\mathbb{R}^{p}, \\quad y_{i} \\in \\mathbb{R}, \\quad i=1,2, \\cdots, N<br>\\end{aligned}$$</p>\n<p>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$$<br>Y=\\left(\\begin{array}{c}<br>{y_{1}} \\\\<br>{y_{2}} \\\\<br>{\\vdots} \\\\<br>{y_{N}}<br>\\end{array}\\right)_{N \\times 1}<br>$$</p>\n<p>最小二乘估计：<br>$$<br>\\begin{aligned}<br>L(w) &amp;=\\left(\\sum_{i=1}^{N}\\left|\\left|w^{\\top} x_{i}-y_{i}\\right|\\right|^{2}\\right) \\\\<br>&amp;=\\sum_{i=1}^{N}\\left(w^{\\top} x_{i}-y_{i}\\right)^{2} \\\\<br>&amp;=\\left( w^{\\top} x_{1}-y_{1} \\quad w^{\\top} x_{2}-y_{2} \\quad \\cdots \\quad w^{\\top} x_{N}-y_{N} \\right) \\left(\\begin{array}{c}<br>{w^{\\top} x_{1}-y_{1}} \\\\<br>{w^{\\top} x_{2}-y_{2}} \\\\<br>{\\vdots} \\\\<br>{w^{\\top} x_{N}-y_{N}}<br>\\end{array}\\right) \\\\<br>&amp;= \\left(w^{\\top} X^{\\top} - Y^{\\top} \\right) \\left(Xw - Y \\right) \\\\<br>&amp;= w^{T} {X}^{\\top} X w-2 w^{\\top} X^{\\top} Y+Y^{\\top} Y<br>\\end{aligned}<br>$$</p>\n<p>对上式求导，并令其为$0$：<br>$$\\hat{w}=\\arg \\min L(w) $$   $$\\frac{\\partial L(w)}{\\partial w}=2 X^{\\top} X w-2 X^{\\top} Y = 0$$   $$ \\hat{w} = \\left( X^{\\top} X \\right)^{-1} X^{\\top} Y $$</p>\n"},{"title":"高斯分布-条件概率及边缘概率","date":"2019-12-27T16:42:45.000Z","_content":"多元高斯分布：\n$$\nx \\sim N(\\mu, \\Sigma) = \\frac{1}{ { (2 \\pi)^{\\frac{p}{2}} | {\\Sigma}|^{\\frac{1}{2}}}} \\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right)\n$$\n\n$x$为随机变量，$x \\in \\mathbb{R}^p$\n\n$$\nx=\\left(\\begin{array}{c}\n{x_{1}} \\\\\\\\\n{x_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{x_{p}}\n\\end{array}\\right) \\quad \\mu=\\left(\\begin{array}{c}\n{\\mu_{1}} \\\\\\\\\n{\\mu_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{\\mu_{p}}\n\\end{array}\\right) \\quad \\Sigma=\\left(\\begin{array}{ccc}\n{\\sigma_{11}} & {\\sigma_{12}} & {\\cdots \\sigma_{1p}} \\\\\\\\\n{\\sigma_{21}} & {\\sigma_{22}} & {\\cdots \\sigma_{2 p}} \\\\\\\\\n{\\vdots} & {\\vdots} & {\\vdots} \\\\\\\\\n{\\sigma_{p1}} & {\\sigma_{p 2} \\cdots} & {\\sigma_{p p}}\n\\end{array}\\right)_{p\\times p}\n$$\n\n已知：\n$$\nx = \\left(\\begin{array}{l}\n{x_{a}} \\\\\\\\\n{x_{b}}\n\\end{array}\\right)_{\\rightarrow\\ n}^{\\rightarrow\\ m}\n\\quad \nm + n = p\n$$ \n\n$$\n\\mu=\\left(\\begin{array}{l}\n{\\mu_{a}} \\\\\\\\\n{\\mu_{b}}\n\\end{array}\\right) \n\\quad\n\\Sigma=\\left(\\begin{array}{l}\n{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\\\\\\n{\\Sigma_{b a}\\ \\Sigma_{b b}}\n\\end{array}\\right)\n$$\n\n求：$p\\left(x_{a}\\right), p\\left(x_{b} | x_{a}\\right)$  或 $p\\left(x_{b}\\right), p\\left(x_{a} | x_{b}\\right)$\n\n$$\n\\begin{aligned}\n&x_{a}= \\left(\\begin{array}{ll}\n{I_{m}} & {0_{n}}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{x_{a}} \\\\\\\\\n{x_{b}}\n\\end{array}\\right)\n\\end{aligned}\n$$\n\n$$\nE\\left[x_{a}\\right]=\\left(\\begin{array}{ll}\n{I_{m}} & {0_{n}}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{\\mu_{a}} \\\\\\\\\n{\\mu_{b}}\n\\end{array}\\right)=\\mu_{a}\n$$\n\n\\begin{aligned}\nVar\\left[x_{a}\\right] &=\\left(\\begin{array}{ll}\n{I_m } & {0}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\\\\\\n{\\Sigma_{b a}\\ \\Sigma_{b b}}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{I_m } \\\\\\\\\n{0}\n\\end{array}\\right) \\\\\\\\\n&=\\Sigma_{a a}\n\\end{aligned}\n\n$$\nx_{a} \\sim N\\left(\\mu_{a}, \\Sigma_{a a} \\right)\n$$\n\n下面求$x_b|x_a$\n令\\begin{cases} x_{b \\cdot a}=x_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a} \\\\\\\\ \\mu_{b \\cdot a}=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}\\\\\\\\ \\Sigma_{b b \\cdot a}=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b} \\end{cases}\n\n$$\nx_{b \\cdot a}=\\left(\\begin{array}{ll}\n{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} & {I_{n}}\\end{array}\\right)\\left(\\begin{array}{l}\n{x_{a}} \\\\\\\\\n{x_{b}}\n\\end{array}\\right)\n$$\n\n$$\nE\\left[x_{b \\cdot a}\\right]=\\left(\\begin{array}{ll}\n{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} & {I_{n}}\\end{array}\\right) \\cdot\\left(\\begin{array}{l}\n{\\mu_{a}} \\\\\\\\\n{\\mu_{b}}\n\\end{array}\\right)=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}=\\mu_{b\\cdot a}\n$$\n\n$$\n\\begin{aligned}\n\\operatorname{Var}\\left[x_{b\\cdot a}\\right]=\\left(\\begin{array}{ll}\n{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} & {I_{n}}\\end{array}\\right)\\left(\\begin{array}{c}\n{\\Sigma_{a a}\\  \\Sigma_{a b}} \\\\\\\\\n{\\Sigma_{b a}\\ \\Sigma_{b b}}\n\\end{array}\\right)\\left(\\begin{array}{cc}\n{-\\Sigma_{a a}^{-1} \\Sigma_{b a}^T } \\\\\\\\ {I_{n}} \\end{array}\\right)=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b}=\\Sigma_{b b \\cdot a}\n\\end{aligned}\n$$\n\n$$x_{b\\cdot a} \\sim N\\left(\\mu_{b \\cdot a}, \\Sigma_{bb\\cdot a} \\right)\\\\\\\\$$\n$$x_{b}=x_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}$$\n\n$$\n\\begin{aligned}\n&E\\left[x_{b} | x_{a}\\right]=\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}\\\\\\\\\n&\\operatorname{Var}\\left[x_{b} | x_{a}\\right]=\\operatorname{Var}\\left[x_{b\\cdot a} \\right]=\\Sigma_{b b \\cdot a}\n\\end{aligned}\n$$\n\n$$ x_b | x_a \\sim N \\left(\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}, \\Sigma_{b b \\cdot a} \\right) $$\n\n补充：$x_{b\\cdot a}$与$x_a$独立：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%B8%8E%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87.png)\n","source":"_posts/机器学习理论推导/高斯分布-条件概率与边缘概率.md","raw":"---\ntitle: 高斯分布-条件概率及边缘概率\ndate: 2019-12-28 00:42:45\ntags: 机器学习理论推导\ncategories: 学习\n---\n多元高斯分布：\n$$\nx \\sim N(\\mu, \\Sigma) = \\frac{1}{ { (2 \\pi)^{\\frac{p}{2}} | {\\Sigma}|^{\\frac{1}{2}}}} \\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right)\n$$\n\n$x$为随机变量，$x \\in \\mathbb{R}^p$\n\n$$\nx=\\left(\\begin{array}{c}\n{x_{1}} \\\\\\\\\n{x_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{x_{p}}\n\\end{array}\\right) \\quad \\mu=\\left(\\begin{array}{c}\n{\\mu_{1}} \\\\\\\\\n{\\mu_{2}} \\\\\\\\\n{\\vdots} \\\\\\\\\n{\\mu_{p}}\n\\end{array}\\right) \\quad \\Sigma=\\left(\\begin{array}{ccc}\n{\\sigma_{11}} & {\\sigma_{12}} & {\\cdots \\sigma_{1p}} \\\\\\\\\n{\\sigma_{21}} & {\\sigma_{22}} & {\\cdots \\sigma_{2 p}} \\\\\\\\\n{\\vdots} & {\\vdots} & {\\vdots} \\\\\\\\\n{\\sigma_{p1}} & {\\sigma_{p 2} \\cdots} & {\\sigma_{p p}}\n\\end{array}\\right)_{p\\times p}\n$$\n\n已知：\n$$\nx = \\left(\\begin{array}{l}\n{x_{a}} \\\\\\\\\n{x_{b}}\n\\end{array}\\right)_{\\rightarrow\\ n}^{\\rightarrow\\ m}\n\\quad \nm + n = p\n$$ \n\n$$\n\\mu=\\left(\\begin{array}{l}\n{\\mu_{a}} \\\\\\\\\n{\\mu_{b}}\n\\end{array}\\right) \n\\quad\n\\Sigma=\\left(\\begin{array}{l}\n{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\\\\\\n{\\Sigma_{b a}\\ \\Sigma_{b b}}\n\\end{array}\\right)\n$$\n\n求：$p\\left(x_{a}\\right), p\\left(x_{b} | x_{a}\\right)$  或 $p\\left(x_{b}\\right), p\\left(x_{a} | x_{b}\\right)$\n\n$$\n\\begin{aligned}\n&x_{a}= \\left(\\begin{array}{ll}\n{I_{m}} & {0_{n}}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{x_{a}} \\\\\\\\\n{x_{b}}\n\\end{array}\\right)\n\\end{aligned}\n$$\n\n$$\nE\\left[x_{a}\\right]=\\left(\\begin{array}{ll}\n{I_{m}} & {0_{n}}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{\\mu_{a}} \\\\\\\\\n{\\mu_{b}}\n\\end{array}\\right)=\\mu_{a}\n$$\n\n\\begin{aligned}\nVar\\left[x_{a}\\right] &=\\left(\\begin{array}{ll}\n{I_m } & {0}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\\\\\\n{\\Sigma_{b a}\\ \\Sigma_{b b}}\n\\end{array}\\right)\\left(\\begin{array}{l}\n{I_m } \\\\\\\\\n{0}\n\\end{array}\\right) \\\\\\\\\n&=\\Sigma_{a a}\n\\end{aligned}\n\n$$\nx_{a} \\sim N\\left(\\mu_{a}, \\Sigma_{a a} \\right)\n$$\n\n下面求$x_b|x_a$\n令\\begin{cases} x_{b \\cdot a}=x_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a} \\\\\\\\ \\mu_{b \\cdot a}=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}\\\\\\\\ \\Sigma_{b b \\cdot a}=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b} \\end{cases}\n\n$$\nx_{b \\cdot a}=\\left(\\begin{array}{ll}\n{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} & {I_{n}}\\end{array}\\right)\\left(\\begin{array}{l}\n{x_{a}} \\\\\\\\\n{x_{b}}\n\\end{array}\\right)\n$$\n\n$$\nE\\left[x_{b \\cdot a}\\right]=\\left(\\begin{array}{ll}\n{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} & {I_{n}}\\end{array}\\right) \\cdot\\left(\\begin{array}{l}\n{\\mu_{a}} \\\\\\\\\n{\\mu_{b}}\n\\end{array}\\right)=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}=\\mu_{b\\cdot a}\n$$\n\n$$\n\\begin{aligned}\n\\operatorname{Var}\\left[x_{b\\cdot a}\\right]=\\left(\\begin{array}{ll}\n{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} & {I_{n}}\\end{array}\\right)\\left(\\begin{array}{c}\n{\\Sigma_{a a}\\  \\Sigma_{a b}} \\\\\\\\\n{\\Sigma_{b a}\\ \\Sigma_{b b}}\n\\end{array}\\right)\\left(\\begin{array}{cc}\n{-\\Sigma_{a a}^{-1} \\Sigma_{b a}^T } \\\\\\\\ {I_{n}} \\end{array}\\right)=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b}=\\Sigma_{b b \\cdot a}\n\\end{aligned}\n$$\n\n$$x_{b\\cdot a} \\sim N\\left(\\mu_{b \\cdot a}, \\Sigma_{bb\\cdot a} \\right)\\\\\\\\$$\n$$x_{b}=x_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}$$\n\n$$\n\\begin{aligned}\n&E\\left[x_{b} | x_{a}\\right]=\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}\\\\\\\\\n&\\operatorname{Var}\\left[x_{b} | x_{a}\\right]=\\operatorname{Var}\\left[x_{b\\cdot a} \\right]=\\Sigma_{b b \\cdot a}\n\\end{aligned}\n$$\n\n$$ x_b | x_a \\sim N \\left(\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}, \\Sigma_{b b \\cdot a} \\right) $$\n\n补充：$x_{b\\cdot a}$与$x_a$独立：\n![](https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%B8%8E%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87.png)\n","slug":"机器学习理论推导/高斯分布-条件概率与边缘概率","published":1,"updated":"2019-12-28T14:43:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40myf004y1ouz2iad3pif","content":"<p>多元高斯分布：<br>$$<br>x \\sim N(\\mu, \\Sigma) = \\frac{1}{ { (2 \\pi)^{\\frac{p}{2}} | {\\Sigma}|^{\\frac{1}{2}}}} \\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right)<br>$$</p>\n<p>$x$为随机变量，$x \\in \\mathbb{R}^p$</p>\n<p>$$<br>x=\\left(\\begin{array}{c}<br>{x_{1}} \\\\<br>{x_{2}} \\\\<br>{\\vdots} \\\\<br>{x_{p}}<br>\\end{array}\\right) \\quad \\mu=\\left(\\begin{array}{c}<br>{\\mu_{1}} \\\\<br>{\\mu_{2}} \\\\<br>{\\vdots} \\\\<br>{\\mu_{p}}<br>\\end{array}\\right) \\quad \\Sigma=\\left(\\begin{array}{ccc}<br>{\\sigma_{11}} &amp; {\\sigma_{12}} &amp; {\\cdots \\sigma_{1p}} \\\\<br>{\\sigma_{21}} &amp; {\\sigma_{22}} &amp; {\\cdots \\sigma_{2 p}} \\\\<br>{\\vdots} &amp; {\\vdots} &amp; {\\vdots} \\\\<br>{\\sigma_{p1}} &amp; {\\sigma_{p 2} \\cdots} &amp; {\\sigma_{p p}}<br>\\end{array}\\right)_{p\\times p}<br>$$</p>\n<p>已知：<br>$$<br>x = \\left(\\begin{array}{l}<br>{x_{a}} \\\\<br>{x_{b}}<br>\\end{array}\\right)_{\\rightarrow\\ n}^{\\rightarrow\\ m}<br>\\quad<br>m + n = p<br>$$ </p>\n<p>$$<br>\\mu=\\left(\\begin{array}{l}<br>{\\mu_{a}} \\\\<br>{\\mu_{b}}<br>\\end{array}\\right)<br>\\quad<br>\\Sigma=\\left(\\begin{array}{l}<br>{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\<br>{\\Sigma_{b a}\\ \\Sigma_{b b}}<br>\\end{array}\\right)<br>$$</p>\n<p>求：$p\\left(x_{a}\\right), p\\left(x_{b} | x_{a}\\right)$  或 $p\\left(x_{b}\\right), p\\left(x_{a} | x_{b}\\right)$</p>\n<p>$$<br>\\begin{aligned}<br>&amp;x_{a}= \\left(\\begin{array}{ll}<br>{I_{m}} &amp; {0_{n}}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{x_{a}} \\\\<br>{x_{b}}<br>\\end{array}\\right)<br>\\end{aligned}<br>$$</p>\n<p>$$<br>E\\left[x_{a}\\right]=\\left(\\begin{array}{ll}<br>{I_{m}} &amp; {0_{n}}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{\\mu_{a}} \\\\<br>{\\mu_{b}}<br>\\end{array}\\right)=\\mu_{a}<br>$$</p>\n<p>\\begin{aligned}<br>Var\\left[x_{a}\\right] &amp;=\\left(\\begin{array}{ll}<br>{I_m } &amp; {0}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\<br>{\\Sigma_{b a}\\ \\Sigma_{b b}}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{I_m } \\\\<br>{0}<br>\\end{array}\\right) \\\\<br>&amp;=\\Sigma_{a a}<br>\\end{aligned}</p>\n<p>$$<br>x_{a} \\sim N\\left(\\mu_{a}, \\Sigma_{a a} \\right)<br>$$</p>\n<p>下面求$x_b|x_a$<br>令\\begin{cases} x_{b \\cdot a}=x_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a} \\\\ \\mu_{b \\cdot a}=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}\\\\ \\Sigma_{b b \\cdot a}=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b} \\end{cases}</p>\n<p>$$<br>x_{b \\cdot a}=\\left(\\begin{array}{ll}<br>{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} &amp; {I_{n}}\\end{array}\\right)\\left(\\begin{array}{l}<br>{x_{a}} \\\\<br>{x_{b}}<br>\\end{array}\\right)<br>$$</p>\n<p>$$<br>E\\left[x_{b \\cdot a}\\right]=\\left(\\begin{array}{ll}<br>{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} &amp; {I_{n}}\\end{array}\\right) \\cdot\\left(\\begin{array}{l}<br>{\\mu_{a}} \\\\<br>{\\mu_{b}}<br>\\end{array}\\right)=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}=\\mu_{b\\cdot a}<br>$$</p>\n<p>$$<br>\\begin{aligned}<br>\\operatorname{Var}\\left[x_{b\\cdot a}\\right]=\\left(\\begin{array}{ll}<br>{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} &amp; {I_{n}}\\end{array}\\right)\\left(\\begin{array}{c}<br>{\\Sigma_{a a}\\  \\Sigma_{a b}} \\\\<br>{\\Sigma_{b a}\\ \\Sigma_{b b}}<br>\\end{array}\\right)\\left(\\begin{array}{cc}<br>{-\\Sigma_{a a}^{-1} \\Sigma_{b a}^T } \\\\ {I_{n}} \\end{array}\\right)=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b}=\\Sigma_{b b \\cdot a}<br>\\end{aligned}<br>$$</p>\n<p>$$x_{b\\cdot a} \\sim N\\left(\\mu_{b \\cdot a}, \\Sigma_{bb\\cdot a} \\right)\\\\$$<br>$$x_{b}=x_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}$$</p>\n<p>$$<br>\\begin{aligned}<br>&amp;E\\left[x_{b} | x_{a}\\right]=\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}\\\\<br>&amp;\\operatorname{Var}\\left[x_{b} | x_{a}\\right]=\\operatorname{Var}\\left[x_{b\\cdot a} \\right]=\\Sigma_{b b \\cdot a}<br>\\end{aligned}<br>$$</p>\n<p>$$ x_b | x_a \\sim N \\left(\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}, \\Sigma_{b b \\cdot a} \\right) $$</p>\n<p>补充：$x_{b\\cdot a}$与$x_a$独立：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%B8%8E%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<p>多元高斯分布：<br>$$<br>x \\sim N(\\mu, \\Sigma) = \\frac{1}{ { (2 \\pi)^{\\frac{p}{2}} | {\\Sigma}|^{\\frac{1}{2}}}} \\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right)<br>$$</p>\n<p>$x$为随机变量，$x \\in \\mathbb{R}^p$</p>\n<p>$$<br>x=\\left(\\begin{array}{c}<br>{x_{1}} \\\\<br>{x_{2}} \\\\<br>{\\vdots} \\\\<br>{x_{p}}<br>\\end{array}\\right) \\quad \\mu=\\left(\\begin{array}{c}<br>{\\mu_{1}} \\\\<br>{\\mu_{2}} \\\\<br>{\\vdots} \\\\<br>{\\mu_{p}}<br>\\end{array}\\right) \\quad \\Sigma=\\left(\\begin{array}{ccc}<br>{\\sigma_{11}} &amp; {\\sigma_{12}} &amp; {\\cdots \\sigma_{1p}} \\\\<br>{\\sigma_{21}} &amp; {\\sigma_{22}} &amp; {\\cdots \\sigma_{2 p}} \\\\<br>{\\vdots} &amp; {\\vdots} &amp; {\\vdots} \\\\<br>{\\sigma_{p1}} &amp; {\\sigma_{p 2} \\cdots} &amp; {\\sigma_{p p}}<br>\\end{array}\\right)_{p\\times p}<br>$$</p>\n<p>已知：<br>$$<br>x = \\left(\\begin{array}{l}<br>{x_{a}} \\\\<br>{x_{b}}<br>\\end{array}\\right)_{\\rightarrow\\ n}^{\\rightarrow\\ m}<br>\\quad<br>m + n = p<br>$$ </p>\n<p>$$<br>\\mu=\\left(\\begin{array}{l}<br>{\\mu_{a}} \\\\<br>{\\mu_{b}}<br>\\end{array}\\right)<br>\\quad<br>\\Sigma=\\left(\\begin{array}{l}<br>{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\<br>{\\Sigma_{b a}\\ \\Sigma_{b b}}<br>\\end{array}\\right)<br>$$</p>\n<p>求：$p\\left(x_{a}\\right), p\\left(x_{b} | x_{a}\\right)$  或 $p\\left(x_{b}\\right), p\\left(x_{a} | x_{b}\\right)$</p>\n<p>$$<br>\\begin{aligned}<br>&amp;x_{a}= \\left(\\begin{array}{ll}<br>{I_{m}} &amp; {0_{n}}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{x_{a}} \\\\<br>{x_{b}}<br>\\end{array}\\right)<br>\\end{aligned}<br>$$</p>\n<p>$$<br>E\\left[x_{a}\\right]=\\left(\\begin{array}{ll}<br>{I_{m}} &amp; {0_{n}}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{\\mu_{a}} \\\\<br>{\\mu_{b}}<br>\\end{array}\\right)=\\mu_{a}<br>$$</p>\n<p>\\begin{aligned}<br>Var\\left[x_{a}\\right] &amp;=\\left(\\begin{array}{ll}<br>{I_m } &amp; {0}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{\\Sigma_{a a}\\ \\Sigma_{a b}} \\\\<br>{\\Sigma_{b a}\\ \\Sigma_{b b}}<br>\\end{array}\\right)\\left(\\begin{array}{l}<br>{I_m } \\\\<br>{0}<br>\\end{array}\\right) \\\\<br>&amp;=\\Sigma_{a a}<br>\\end{aligned}</p>\n<p>$$<br>x_{a} \\sim N\\left(\\mu_{a}, \\Sigma_{a a} \\right)<br>$$</p>\n<p>下面求$x_b|x_a$<br>令\\begin{cases} x_{b \\cdot a}=x_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a} \\\\ \\mu_{b \\cdot a}=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}\\\\ \\Sigma_{b b \\cdot a}=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b} \\end{cases}</p>\n<p>$$<br>x_{b \\cdot a}=\\left(\\begin{array}{ll}<br>{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} &amp; {I_{n}}\\end{array}\\right)\\left(\\begin{array}{l}<br>{x_{a}} \\\\<br>{x_{b}}<br>\\end{array}\\right)<br>$$</p>\n<p>$$<br>E\\left[x_{b \\cdot a}\\right]=\\left(\\begin{array}{ll}<br>{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} &amp; {I_{n}}\\end{array}\\right) \\cdot\\left(\\begin{array}{l}<br>{\\mu_{a}} \\\\<br>{\\mu_{b}}<br>\\end{array}\\right)=\\mu_{b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\mu_{a}=\\mu_{b\\cdot a}<br>$$</p>\n<p>$$<br>\\begin{aligned}<br>\\operatorname{Var}\\left[x_{b\\cdot a}\\right]=\\left(\\begin{array}{ll}<br>{-\\Sigma_{b a} \\Sigma_{a a}^{-1}} &amp; {I_{n}}\\end{array}\\right)\\left(\\begin{array}{c}<br>{\\Sigma_{a a}\\  \\Sigma_{a b}} \\\\<br>{\\Sigma_{b a}\\ \\Sigma_{b b}}<br>\\end{array}\\right)\\left(\\begin{array}{cc}<br>{-\\Sigma_{a a}^{-1} \\Sigma_{b a}^T } \\\\ {I_{n}} \\end{array}\\right)=\\Sigma_{b b}-\\Sigma_{b a} \\Sigma_{a a}^{-1} \\Sigma_{a b}=\\Sigma_{b b \\cdot a}<br>\\end{aligned}<br>$$</p>\n<p>$$x_{b\\cdot a} \\sim N\\left(\\mu_{b \\cdot a}, \\Sigma_{bb\\cdot a} \\right)\\\\$$<br>$$x_{b}=x_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}$$</p>\n<p>$$<br>\\begin{aligned}<br>&amp;E\\left[x_{b} | x_{a}\\right]=\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}\\\\<br>&amp;\\operatorname{Var}\\left[x_{b} | x_{a}\\right]=\\operatorname{Var}\\left[x_{b\\cdot a} \\right]=\\Sigma_{b b \\cdot a}<br>\\end{aligned}<br>$$</p>\n<p>$$ x_b | x_a \\sim N \\left(\\mu_{b \\cdot a} + \\Sigma_{b a} \\Sigma_{a a}^{-1} x_{a}, \\Sigma_{b b \\cdot a} \\right) $$</p>\n<p>补充：$x_{b\\cdot a}$与$x_a$独立：<br><img src=\"https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%B8%8E%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87.png\" alt></p>\n"},{"title":"高斯分布-联合概率","date":"2019-12-28T11:22:45.000Z","_content":"已知：$$p(x)=N\\left(x | \\mu, \\Lambda^{-1}\\right)$$ $$p(y | x)=N\\left(y | A x+b, L^{-1}\\right)$$\n求：$p(y)$，$p(x|y)$\n$$\n\\begin{aligned}\n&y=A x+b+\\varepsilon\\\\\\\\\n&\\varepsilon \\sim N\\left(0, L^{-1}\\right)\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\nE[y] &=E[A x+b+\\varepsilon]=E[A x+b]+E[\\varepsilon] \\\\\\\\\n&=A \\mu+b\n\\end{aligned}\n$$\n\n$$\\operatorname{Var}[y]=\\operatorname{Var}[A x+b+\\varepsilon]= \n\\operatorname{Var}[A x+b]+\\operatorname{Var} [\\varepsilon] \n=A \\Lambda^{-1} A^{\\top}+L^{-1} $$\n\n$$y \\sim N\\left(A \\mu+b, L^{-1}+A \\Lambda^{-1} A^{\\top}\\right)$$\n\n$$\nz=\\left(\\begin{array}{c}\n{x} \\\\\\\\\n{y}\n\\end{array}\\right) \\sim N\\left(\\left[\\begin{array}{c}\n{\\mu} \\\\\\\\\n{A \\mu+b}\n\\end{array}\\right],\\left[\\begin{array}{cc}\n{\\lambda^{-1}} & {\\Delta} \\\\\\\\\n{\\Delta^T} & {L^{-1}+A \\Lambda^{-1} A^{T}}\n\\end{array}\\right]\\right)\n$$\n直接套用上一篇博客条件概率公式，变可以得出$p(x|y)$。\n下面求$\\Delta$的值：\n$$\n\\begin{aligned}\n\\Delta &=\\operatorname{Cov}(x, y) \\\\\\\\\n&=E[(x-E[x]) \\cdot(y-E[y])^{T}] \\\\\\\\\n&=E[(x-\\mu)(y-A \\mu-b)^{T}] \\\\\\\\\n&=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)(A x-A \\mu)^{T}\\right]\\\\\\\\\n&=E\\left[(x-\\mu)(x-\\mu)^{T} \\cdot A^{T}\\right]\\\\\\\\\n&\\begin{array}{l}\n{=E\\left[(x-\\mu)(x-\\mu)^{T}\\right] \\cdot A^{T}} \\\\\\\\\n{=\\operatorname{Var}[x] \\cdot A^{T}}\n\\end{array}\\\\\\\\\n&=\\Lambda^{-1} A^{T}\n\\end{aligned}\n$$\n\n\n","source":"_posts/机器学习理论推导/高斯分布-联合概率.md","raw":"---\ntitle: 高斯分布-联合概率\ndate: 2019-12-28 19:22:45\ntags: 机器学习理论推导\ncategories: 学习\n---\n已知：$$p(x)=N\\left(x | \\mu, \\Lambda^{-1}\\right)$$ $$p(y | x)=N\\left(y | A x+b, L^{-1}\\right)$$\n求：$p(y)$，$p(x|y)$\n$$\n\\begin{aligned}\n&y=A x+b+\\varepsilon\\\\\\\\\n&\\varepsilon \\sim N\\left(0, L^{-1}\\right)\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\nE[y] &=E[A x+b+\\varepsilon]=E[A x+b]+E[\\varepsilon] \\\\\\\\\n&=A \\mu+b\n\\end{aligned}\n$$\n\n$$\\operatorname{Var}[y]=\\operatorname{Var}[A x+b+\\varepsilon]= \n\\operatorname{Var}[A x+b]+\\operatorname{Var} [\\varepsilon] \n=A \\Lambda^{-1} A^{\\top}+L^{-1} $$\n\n$$y \\sim N\\left(A \\mu+b, L^{-1}+A \\Lambda^{-1} A^{\\top}\\right)$$\n\n$$\nz=\\left(\\begin{array}{c}\n{x} \\\\\\\\\n{y}\n\\end{array}\\right) \\sim N\\left(\\left[\\begin{array}{c}\n{\\mu} \\\\\\\\\n{A \\mu+b}\n\\end{array}\\right],\\left[\\begin{array}{cc}\n{\\lambda^{-1}} & {\\Delta} \\\\\\\\\n{\\Delta^T} & {L^{-1}+A \\Lambda^{-1} A^{T}}\n\\end{array}\\right]\\right)\n$$\n直接套用上一篇博客条件概率公式，变可以得出$p(x|y)$。\n下面求$\\Delta$的值：\n$$\n\\begin{aligned}\n\\Delta &=\\operatorname{Cov}(x, y) \\\\\\\\\n&=E[(x-E[x]) \\cdot(y-E[y])^{T}] \\\\\\\\\n&=E[(x-\\mu)(y-A \\mu-b)^{T}] \\\\\\\\\n&=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\\\\\\n&=E\\left[(x-\\mu)(A x-A \\mu)^{T}\\right]\\\\\\\\\n&=E\\left[(x-\\mu)(x-\\mu)^{T} \\cdot A^{T}\\right]\\\\\\\\\n&\\begin{array}{l}\n{=E\\left[(x-\\mu)(x-\\mu)^{T}\\right] \\cdot A^{T}} \\\\\\\\\n{=\\operatorname{Var}[x] \\cdot A^{T}}\n\\end{array}\\\\\\\\\n&=\\Lambda^{-1} A^{T}\n\\end{aligned}\n$$\n\n\n","slug":"机器学习理论推导/高斯分布-联合概率","published":1,"updated":"2019-12-28T14:43:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40myg00511ouzw9ivoqhz","content":"<p>已知：$$p(x)=N\\left(x | \\mu, \\Lambda^{-1}\\right)$$ $$p(y | x)=N\\left(y | A x+b, L^{-1}\\right)$$<br>求：$p(y)$，$p(x|y)$<br>$$<br>\\begin{aligned}<br>&amp;y=A x+b+\\varepsilon\\\\<br>&amp;\\varepsilon \\sim N\\left(0, L^{-1}\\right)<br>\\end{aligned}<br>$$</p>\n<p>$$<br>\\begin{aligned}<br>E[y] &amp;=E[A x+b+\\varepsilon]=E[A x+b]+E[\\varepsilon] \\\\<br>&amp;=A \\mu+b<br>\\end{aligned}<br>$$</p>\n<p>$$\\operatorname{Var}[y]=\\operatorname{Var}[A x+b+\\varepsilon]=<br>\\operatorname{Var}[A x+b]+\\operatorname{Var} [\\varepsilon]<br>=A \\Lambda^{-1} A^{\\top}+L^{-1} $$</p>\n<p>$$y \\sim N\\left(A \\mu+b, L^{-1}+A \\Lambda^{-1} A^{\\top}\\right)$$</p>\n<p>$$<br>z=\\left(\\begin{array}{c}<br>{x} \\\\<br>{y}<br>\\end{array}\\right) \\sim N\\left(\\left[\\begin{array}{c}<br>{\\mu} \\\\<br>{A \\mu+b}<br>\\end{array}\\right],\\left[\\begin{array}{cc}<br>{\\lambda^{-1}} &amp; {\\Delta} \\\\<br>{\\Delta^T} &amp; {L^{-1}+A \\Lambda^{-1} A^{T}}<br>\\end{array}\\right]\\right)<br>$$<br>直接套用上一篇博客条件概率公式，变可以得出$p(x|y)$。<br>下面求$\\Delta$的值：<br>$$<br>\\begin{aligned}<br>\\Delta &amp;=\\operatorname{Cov}(x, y) \\\\<br>&amp;=E[(x-E[x]) \\cdot(y-E[y])^{T}] \\\\<br>&amp;=E[(x-\\mu)(y-A \\mu-b)^{T}] \\\\<br>&amp;=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)(A x-A \\mu)^{T}\\right]\\\\<br>&amp;=E\\left[(x-\\mu)(x-\\mu)^{T} \\cdot A^{T}\\right]\\\\<br>&amp;\\begin{array}{l}<br>{=E\\left[(x-\\mu)(x-\\mu)^{T}\\right] \\cdot A^{T}} \\\\<br>{=\\operatorname{Var}[x] \\cdot A^{T}}<br>\\end{array}\\\\<br>&amp;=\\Lambda^{-1} A^{T}<br>\\end{aligned}<br>$$</p>\n","site":{"data":{}},"excerpt":"","more":"<p>已知：$$p(x)=N\\left(x | \\mu, \\Lambda^{-1}\\right)$$ $$p(y | x)=N\\left(y | A x+b, L^{-1}\\right)$$<br>求：$p(y)$，$p(x|y)$<br>$$<br>\\begin{aligned}<br>&amp;y=A x+b+\\varepsilon\\\\<br>&amp;\\varepsilon \\sim N\\left(0, L^{-1}\\right)<br>\\end{aligned}<br>$$</p>\n<p>$$<br>\\begin{aligned}<br>E[y] &amp;=E[A x+b+\\varepsilon]=E[A x+b]+E[\\varepsilon] \\\\<br>&amp;=A \\mu+b<br>\\end{aligned}<br>$$</p>\n<p>$$\\operatorname{Var}[y]=\\operatorname{Var}[A x+b+\\varepsilon]=<br>\\operatorname{Var}[A x+b]+\\operatorname{Var} [\\varepsilon]<br>=A \\Lambda^{-1} A^{\\top}+L^{-1} $$</p>\n<p>$$y \\sim N\\left(A \\mu+b, L^{-1}+A \\Lambda^{-1} A^{\\top}\\right)$$</p>\n<p>$$<br>z=\\left(\\begin{array}{c}<br>{x} \\\\<br>{y}<br>\\end{array}\\right) \\sim N\\left(\\left[\\begin{array}{c}<br>{\\mu} \\\\<br>{A \\mu+b}<br>\\end{array}\\right],\\left[\\begin{array}{cc}<br>{\\lambda^{-1}} &amp; {\\Delta} \\\\<br>{\\Delta^T} &amp; {L^{-1}+A \\Lambda^{-1} A^{T}}<br>\\end{array}\\right]\\right)<br>$$<br>直接套用上一篇博客条件概率公式，变可以得出$p(x|y)$。<br>下面求$\\Delta$的值：<br>$$<br>\\begin{aligned}<br>\\Delta &amp;=\\operatorname{Cov}(x, y) \\\\<br>&amp;=E[(x-E[x]) \\cdot(y-E[y])^{T}] \\\\<br>&amp;=E[(x-\\mu)(y-A \\mu-b)^{T}] \\\\<br>&amp;=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)({A x-A \\mu}+\\varepsilon)^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)(A x-A\\mu)^{T}\\right]+E\\left[(x-\\mu) \\varepsilon^{T}\\right] \\\\<br>&amp;=E\\left[(x-\\mu)(A x-A \\mu)^{T}\\right]\\\\<br>&amp;=E\\left[(x-\\mu)(x-\\mu)^{T} \\cdot A^{T}\\right]\\\\<br>&amp;\\begin{array}{l}<br>{=E\\left[(x-\\mu)(x-\\mu)^{T}\\right] \\cdot A^{T}} \\\\<br>{=\\operatorname{Var}[x] \\cdot A^{T}}<br>\\end{array}\\\\<br>&amp;=\\Lambda^{-1} A^{T}<br>\\end{aligned}<br>$$</p>\n"},{"title":"高斯分布-最大似然估计","date":"2019-12-26T14:39:09.000Z","_content":"# 最大似然估计\n数据$X$\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$$x_{i} \\in \\mathbb{R}^{p}$$\n$$x_{i} \\sim N(\\mu, \\Sigma)$$\n\n$$\\theta=(\\mu, \\Sigma)$$\n\n最大似然估计MLE: $\\theta_{MLE}=\\arg \\max _{\\theta} p(X | \\theta)$\n为了简化计算，下面我们推导一元高斯分布的最大似然估计。令 p=1, $ \\theta=\\left(\\mu, \\sigma^{2}\\right)$\n$$p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)$$\n\n\\begin{aligned}\n\\log P(X | \\theta) &=\\log \\prod_{i=1}^{N} p\\left(x_{i} | \\theta\\right)=\\sum_{i=1}^{N} \\log p\\left(x_{i} | \\theta\\right) \\\\\\\\\n&=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 x} \\sigma} \\exp \\left(-\\frac{\\left(x_{i} - \\mu\\right)^{2}}{2 \\sigma^{2}}\\right) \\\\\\\\\n&=\\sum_{i=1}^{N}\\left[\\log \\frac{1}{\\sqrt{2\\pi}}+{\\log \\frac{1}{\\sigma}} -\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}\\right] \\\\\\\\\n\\end{aligned}\n\n\\begin{aligned}\n\\mu_{MLE} &=\\arg\\max_{\\mu} \\log P(X|\\theta) \\\\\\\\\n&= \\arg\\max_{\\mu} \\sum_{i=1}^{N} - \\frac{(x_{i}-\\mu)^{2}}{2 \\sigma^{2}} \\\\\\\\\n&= \\arg\\max_{\\mu} \\sum_{i=1}^{N}(x_{i}-\\mu)^{2} \\\\\\\\\n\\end{aligned}\n\n对$\\mu$求导，并令其为$0$，\n$$\\frac{\\partial}{\\partial \\mu} \\Sigma\\left(x_{i}-\\mu\\right)^{2}=\\sum_{i=1}^{N} 2 \\cdot\\left(x_{i}-\\mu\\right) \\cdot(-1)=0$$\n$$\\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)=0$$\n$$\\mu_{MLE} = \\frac{1}{N}\\sum_i^N x_i$$\n\n下面证明最大似然估计的均值无偏：\n$$E[\\mu_{MLE}] = E[\\frac{1}{N}\\sum_i^N x_i]=\\mu$$\n\n\\begin{aligned}\n\\sigma^2_{MLE} &= \\arg\\max_{\\sigma} \\log P(X|\\theta) \\\\\\\\\n&=\\arg\\max_{\\sigma} \\sum_{i=1}^{N} \\left(-\\log \\sigma -\\frac{1}{2\\sigma^2} \\left(x_{i} - \\mu\\right)^{2}\\right)\\\\\\\\\n&= \\arg\\max_{\\sigma} \\mathcal{L}(\\sigma) \\\\\\\\\n\\end{aligned}\n\n对上式$\\sigma$求导并令其为$0$，\n\n$$\\frac{\\partial \\mathcal{L}} {\\partial \\sigma} = \\sum_{i=1}^{N}\\left[-\\frac{1}{\\sigma}+\\frac{1}{2}\\left(x_{i}-\\mu\\right)^{2} \\cdot(+2) \\sigma^{-3}\\right]^{2} =0 $$\n\n$$\\sigma^2_{MLE} = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2$$\n\n\n方差有偏:\n\\begin{aligned}\nE\\left[\\sigma_{MLE}^{2}\\right]=\\frac{1}{N} E\\left[\\sum_{i=1}^{N}\\left(x_{i}-\\mu_{MLE}\\right)^{2}\\right] &= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -2\\frac{1}{N}\\sum_{i=1}^N x_i \\mu_{MLE} +\\mu_{MLE}^{2} \\right] \\\\\\\\\n&= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -\\mu_{MLE}^{2} \\right] \\\\\\\\\n\\end{aligned}\n\n\\begin{aligned}\nE[\\sigma_{MLE}^2] &=E\\left[\\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}+\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\\\\\\n&=E\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}\\right]+E\\left[\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\\\\\\n&=E\\left[\\frac{1}{N} \\sum_{i=1}^{N}\\left(x_{i}^{2}-\\mu^{2}\\right)\\right]-E\\left[\\mu_{MLE}^{2} - \\mu^{2}\\right] \\\\\\\\\n&= \\sigma^2 - (E[\\mu_{MLE}^2] - E[\\mu^2]) \\\\\\\\\n&= \\sigma^2 - (E[\\mu_{MLE}^2] - E^2 [\\mu_{MLE}]) \\\\\\\\\n&= \\sigma^2 - Var[\\mu_{MLE}] \\\\\\\\\n&= \\frac{(N-1)\\sigma^2}{N}\n\\end{aligned}\n\n\n\\begin{aligned}\nVar[ \\mu_{M L E}] &=\\operatorname{Var}\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}\\right] \\\\\\\\\n&= \\frac{1}{N^{2}} \\sum_{i=1}^{N} Var\\left[x_{i}\\right] \\\\\\\\\n&=\\frac{\\sigma^{2}}{N} \n\\end{aligned}\n\n","source":"_posts/机器学习理论推导/高斯分布-最大似然估计.md","raw":"---\ntitle: 高斯分布-最大似然估计\ndate: 2019-12-26 22:39:09\ntags: 机器学习理论推导\ncategories: 学习\n---\n# 最大似然估计\n数据$X$\n$$\nX = \\begin{pmatrix}\n{x_{1}}&{x_{2}}&{\\cdots}&{x_{N}}\n\\end{pmatrix}^T \n= \\begin{pmatrix}\n{x_{11}}&{x_{12}}&{\\cdots}&{x_{1p}}\\\\\\\\\n{x_{21}}&{x_{22}}&{\\cdots}&{x_{2p}}\\\\\\\\\n{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\\\\\n{x_{N1}}&{x_{N2}}&{\\cdots}&{x_{Np}}\\\\\\\\\n\\end{pmatrix}$$\n\n$$x_{i} \\in \\mathbb{R}^{p}$$\n$$x_{i} \\sim N(\\mu, \\Sigma)$$\n\n$$\\theta=(\\mu, \\Sigma)$$\n\n最大似然估计MLE: $\\theta_{MLE}=\\arg \\max _{\\theta} p(X | \\theta)$\n为了简化计算，下面我们推导一元高斯分布的最大似然估计。令 p=1, $ \\theta=\\left(\\mu, \\sigma^{2}\\right)$\n$$p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)$$\n\n\\begin{aligned}\n\\log P(X | \\theta) &=\\log \\prod_{i=1}^{N} p\\left(x_{i} | \\theta\\right)=\\sum_{i=1}^{N} \\log p\\left(x_{i} | \\theta\\right) \\\\\\\\\n&=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 x} \\sigma} \\exp \\left(-\\frac{\\left(x_{i} - \\mu\\right)^{2}}{2 \\sigma^{2}}\\right) \\\\\\\\\n&=\\sum_{i=1}^{N}\\left[\\log \\frac{1}{\\sqrt{2\\pi}}+{\\log \\frac{1}{\\sigma}} -\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}\\right] \\\\\\\\\n\\end{aligned}\n\n\\begin{aligned}\n\\mu_{MLE} &=\\arg\\max_{\\mu} \\log P(X|\\theta) \\\\\\\\\n&= \\arg\\max_{\\mu} \\sum_{i=1}^{N} - \\frac{(x_{i}-\\mu)^{2}}{2 \\sigma^{2}} \\\\\\\\\n&= \\arg\\max_{\\mu} \\sum_{i=1}^{N}(x_{i}-\\mu)^{2} \\\\\\\\\n\\end{aligned}\n\n对$\\mu$求导，并令其为$0$，\n$$\\frac{\\partial}{\\partial \\mu} \\Sigma\\left(x_{i}-\\mu\\right)^{2}=\\sum_{i=1}^{N} 2 \\cdot\\left(x_{i}-\\mu\\right) \\cdot(-1)=0$$\n$$\\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)=0$$\n$$\\mu_{MLE} = \\frac{1}{N}\\sum_i^N x_i$$\n\n下面证明最大似然估计的均值无偏：\n$$E[\\mu_{MLE}] = E[\\frac{1}{N}\\sum_i^N x_i]=\\mu$$\n\n\\begin{aligned}\n\\sigma^2_{MLE} &= \\arg\\max_{\\sigma} \\log P(X|\\theta) \\\\\\\\\n&=\\arg\\max_{\\sigma} \\sum_{i=1}^{N} \\left(-\\log \\sigma -\\frac{1}{2\\sigma^2} \\left(x_{i} - \\mu\\right)^{2}\\right)\\\\\\\\\n&= \\arg\\max_{\\sigma} \\mathcal{L}(\\sigma) \\\\\\\\\n\\end{aligned}\n\n对上式$\\sigma$求导并令其为$0$，\n\n$$\\frac{\\partial \\mathcal{L}} {\\partial \\sigma} = \\sum_{i=1}^{N}\\left[-\\frac{1}{\\sigma}+\\frac{1}{2}\\left(x_{i}-\\mu\\right)^{2} \\cdot(+2) \\sigma^{-3}\\right]^{2} =0 $$\n\n$$\\sigma^2_{MLE} = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2$$\n\n\n方差有偏:\n\\begin{aligned}\nE\\left[\\sigma_{MLE}^{2}\\right]=\\frac{1}{N} E\\left[\\sum_{i=1}^{N}\\left(x_{i}-\\mu_{MLE}\\right)^{2}\\right] &= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -2\\frac{1}{N}\\sum_{i=1}^N x_i \\mu_{MLE} +\\mu_{MLE}^{2} \\right] \\\\\\\\\n&= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -\\mu_{MLE}^{2} \\right] \\\\\\\\\n\\end{aligned}\n\n\\begin{aligned}\nE[\\sigma_{MLE}^2] &=E\\left[\\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}+\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\\\\\\n&=E\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}\\right]+E\\left[\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\\\\\\n&=E\\left[\\frac{1}{N} \\sum_{i=1}^{N}\\left(x_{i}^{2}-\\mu^{2}\\right)\\right]-E\\left[\\mu_{MLE}^{2} - \\mu^{2}\\right] \\\\\\\\\n&= \\sigma^2 - (E[\\mu_{MLE}^2] - E[\\mu^2]) \\\\\\\\\n&= \\sigma^2 - (E[\\mu_{MLE}^2] - E^2 [\\mu_{MLE}]) \\\\\\\\\n&= \\sigma^2 - Var[\\mu_{MLE}] \\\\\\\\\n&= \\frac{(N-1)\\sigma^2}{N}\n\\end{aligned}\n\n\n\\begin{aligned}\nVar[ \\mu_{M L E}] &=\\operatorname{Var}\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}\\right] \\\\\\\\\n&= \\frac{1}{N^{2}} \\sum_{i=1}^{N} Var\\left[x_{i}\\right] \\\\\\\\\n&=\\frac{\\sigma^{2}}{N} \n\\end{aligned}\n\n","slug":"机器学习理论推导/高斯分布-最大似然估计","published":1,"updated":"2019-12-28T14:44:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4r40myh00541ouz786fk7ah","content":"<h1 id=\"最大似然估计\"><a href=\"#最大似然估计\" class=\"headerlink\" title=\"最大似然估计\"></a>最大似然估计</h1><p>数据$X$<br>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$$x_{i} \\in \\mathbb{R}^{p}$$<br>$$x_{i} \\sim N(\\mu, \\Sigma)$$</p>\n<p>$$\\theta=(\\mu, \\Sigma)$$</p>\n<p>最大似然估计MLE: $\\theta_{MLE}=\\arg \\max _{\\theta} p(X | \\theta)$<br>为了简化计算，下面我们推导一元高斯分布的最大似然估计。令 p=1, $ \\theta=\\left(\\mu, \\sigma^{2}\\right)$<br>$$p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)$$</p>\n<p>\\begin{aligned}<br>\\log P(X | \\theta) &amp;=\\log \\prod_{i=1}^{N} p\\left(x_{i} | \\theta\\right)=\\sum_{i=1}^{N} \\log p\\left(x_{i} | \\theta\\right) \\\\<br>&amp;=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 x} \\sigma} \\exp \\left(-\\frac{\\left(x_{i} - \\mu\\right)^{2}}{2 \\sigma^{2}}\\right) \\\\<br>&amp;=\\sum_{i=1}^{N}\\left[\\log \\frac{1}{\\sqrt{2\\pi}}+{\\log \\frac{1}{\\sigma}} -\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}\\right] \\\\<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>\\mu_{MLE} &amp;=\\arg\\max_{\\mu} \\log P(X|\\theta) \\\\<br>&amp;= \\arg\\max_{\\mu} \\sum_{i=1}^{N} - \\frac{(x_{i}-\\mu)^{2}}{2 \\sigma^{2}} \\\\<br>&amp;= \\arg\\max_{\\mu} \\sum_{i=1}^{N}(x_{i}-\\mu)^{2} \\\\<br>\\end{aligned}</p>\n<p>对$\\mu$求导，并令其为$0$，<br>$$\\frac{\\partial}{\\partial \\mu} \\Sigma\\left(x_{i}-\\mu\\right)^{2}=\\sum_{i=1}^{N} 2 \\cdot\\left(x_{i}-\\mu\\right) \\cdot(-1)=0$$<br>$$\\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)=0$$<br>$$\\mu_{MLE} = \\frac{1}{N}\\sum_i^N x_i$$</p>\n<p>下面证明最大似然估计的均值无偏：<br>$$E[\\mu_{MLE}] = E[\\frac{1}{N}\\sum_i^N x_i]=\\mu$$</p>\n<p>\\begin{aligned}<br>\\sigma^2_{MLE} &amp;= \\arg\\max_{\\sigma} \\log P(X|\\theta) \\\\<br>&amp;=\\arg\\max_{\\sigma} \\sum_{i=1}^{N} \\left(-\\log \\sigma -\\frac{1}{2\\sigma^2} \\left(x_{i} - \\mu\\right)^{2}\\right)\\\\<br>&amp;= \\arg\\max_{\\sigma} \\mathcal{L}(\\sigma) \\\\<br>\\end{aligned}</p>\n<p>对上式$\\sigma$求导并令其为$0$，</p>\n<p>$$\\frac{\\partial \\mathcal{L}} {\\partial \\sigma} = \\sum_{i=1}^{N}\\left[-\\frac{1}{\\sigma}+\\frac{1}{2}\\left(x_{i}-\\mu\\right)^{2} \\cdot(+2) \\sigma^{-3}\\right]^{2} =0 $$</p>\n<p>$$\\sigma^2_{MLE} = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2$$</p>\n<p>方差有偏:<br>\\begin{aligned}<br>E\\left[\\sigma_{MLE}^{2}\\right]=\\frac{1}{N} E\\left[\\sum_{i=1}^{N}\\left(x_{i}-\\mu_{MLE}\\right)^{2}\\right] &amp;= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -2\\frac{1}{N}\\sum_{i=1}^N x_i \\mu_{MLE} +\\mu_{MLE}^{2} \\right] \\\\<br>&amp;= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -\\mu_{MLE}^{2} \\right] \\\\<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>E[\\sigma_{MLE}^2] &amp;=E\\left[\\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}+\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\<br>&amp;=E\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}\\right]+E\\left[\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\<br>&amp;=E\\left[\\frac{1}{N} \\sum_{i=1}^{N}\\left(x_{i}^{2}-\\mu^{2}\\right)\\right]-E\\left[\\mu_{MLE}^{2} - \\mu^{2}\\right] \\\\<br>&amp;= \\sigma^2 - (E[\\mu_{MLE}^2] - E[\\mu^2]) \\\\<br>&amp;= \\sigma^2 - (E[\\mu_{MLE}^2] - E^2 [\\mu_{MLE}]) \\\\<br>&amp;= \\sigma^2 - Var[\\mu_{MLE}] \\\\<br>&amp;= \\frac{(N-1)\\sigma^2}{N}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>Var[ \\mu_{M L E}] &amp;=\\operatorname{Var}\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}\\right] \\\\<br>&amp;= \\frac{1}{N^{2}} \\sum_{i=1}^{N} Var\\left[x_{i}\\right] \\\\<br>&amp;=\\frac{\\sigma^{2}}{N}<br>\\end{aligned}</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"最大似然估计\"><a href=\"#最大似然估计\" class=\"headerlink\" title=\"最大似然估计\"></a>最大似然估计</h1><p>数据$X$<br>$$<br>X = \\begin{pmatrix}<br>{x_{1}}&amp;{x_{2}}&amp;{\\cdots}&amp;{x_{N}}<br>\\end{pmatrix}^T<br>= \\begin{pmatrix}<br>{x_{11}}&amp;{x_{12}}&amp;{\\cdots}&amp;{x_{1p}}\\\\<br>{x_{21}}&amp;{x_{22}}&amp;{\\cdots}&amp;{x_{2p}}\\\\<br>{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\<br>{x_{N1}}&amp;{x_{N2}}&amp;{\\cdots}&amp;{x_{Np}}\\\\<br>\\end{pmatrix}$$</p>\n<p>$$x_{i} \\in \\mathbb{R}^{p}$$<br>$$x_{i} \\sim N(\\mu, \\Sigma)$$</p>\n<p>$$\\theta=(\\mu, \\Sigma)$$</p>\n<p>最大似然估计MLE: $\\theta_{MLE}=\\arg \\max _{\\theta} p(X | \\theta)$<br>为了简化计算，下面我们推导一元高斯分布的最大似然估计。令 p=1, $ \\theta=\\left(\\mu, \\sigma^{2}\\right)$<br>$$p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)$$</p>\n<p>\\begin{aligned}<br>\\log P(X | \\theta) &amp;=\\log \\prod_{i=1}^{N} p\\left(x_{i} | \\theta\\right)=\\sum_{i=1}^{N} \\log p\\left(x_{i} | \\theta\\right) \\\\<br>&amp;=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 x} \\sigma} \\exp \\left(-\\frac{\\left(x_{i} - \\mu\\right)^{2}}{2 \\sigma^{2}}\\right) \\\\<br>&amp;=\\sum_{i=1}^{N}\\left[\\log \\frac{1}{\\sqrt{2\\pi}}+{\\log \\frac{1}{\\sigma}} -\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}\\right] \\\\<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>\\mu_{MLE} &amp;=\\arg\\max_{\\mu} \\log P(X|\\theta) \\\\<br>&amp;= \\arg\\max_{\\mu} \\sum_{i=1}^{N} - \\frac{(x_{i}-\\mu)^{2}}{2 \\sigma^{2}} \\\\<br>&amp;= \\arg\\max_{\\mu} \\sum_{i=1}^{N}(x_{i}-\\mu)^{2} \\\\<br>\\end{aligned}</p>\n<p>对$\\mu$求导，并令其为$0$，<br>$$\\frac{\\partial}{\\partial \\mu} \\Sigma\\left(x_{i}-\\mu\\right)^{2}=\\sum_{i=1}^{N} 2 \\cdot\\left(x_{i}-\\mu\\right) \\cdot(-1)=0$$<br>$$\\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)=0$$<br>$$\\mu_{MLE} = \\frac{1}{N}\\sum_i^N x_i$$</p>\n<p>下面证明最大似然估计的均值无偏：<br>$$E[\\mu_{MLE}] = E[\\frac{1}{N}\\sum_i^N x_i]=\\mu$$</p>\n<p>\\begin{aligned}<br>\\sigma^2_{MLE} &amp;= \\arg\\max_{\\sigma} \\log P(X|\\theta) \\\\<br>&amp;=\\arg\\max_{\\sigma} \\sum_{i=1}^{N} \\left(-\\log \\sigma -\\frac{1}{2\\sigma^2} \\left(x_{i} - \\mu\\right)^{2}\\right)\\\\<br>&amp;= \\arg\\max_{\\sigma} \\mathcal{L}(\\sigma) \\\\<br>\\end{aligned}</p>\n<p>对上式$\\sigma$求导并令其为$0$，</p>\n<p>$$\\frac{\\partial \\mathcal{L}} {\\partial \\sigma} = \\sum_{i=1}^{N}\\left[-\\frac{1}{\\sigma}+\\frac{1}{2}\\left(x_{i}-\\mu\\right)^{2} \\cdot(+2) \\sigma^{-3}\\right]^{2} =0 $$</p>\n<p>$$\\sigma^2_{MLE} = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2$$</p>\n<p>方差有偏:<br>\\begin{aligned}<br>E\\left[\\sigma_{MLE}^{2}\\right]=\\frac{1}{N} E\\left[\\sum_{i=1}^{N}\\left(x_{i}-\\mu_{MLE}\\right)^{2}\\right] &amp;= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -2\\frac{1}{N}\\sum_{i=1}^N x_i \\mu_{MLE} +\\mu_{MLE}^{2} \\right] \\\\<br>&amp;= E\\left[\\frac{1}{N} \\sum_{i=1}^N x_{i}^{2} -\\mu_{MLE}^{2} \\right] \\\\<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>E[\\sigma_{MLE}^2] &amp;=E\\left[\\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}+\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\<br>&amp;=E\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}^{2}-\\mu^{2}\\right]+E\\left[\\mu^{2}-\\mu_{MLE}^{2}\\right] \\\\<br>&amp;=E\\left[\\frac{1}{N} \\sum_{i=1}^{N}\\left(x_{i}^{2}-\\mu^{2}\\right)\\right]-E\\left[\\mu_{MLE}^{2} - \\mu^{2}\\right] \\\\<br>&amp;= \\sigma^2 - (E[\\mu_{MLE}^2] - E[\\mu^2]) \\\\<br>&amp;= \\sigma^2 - (E[\\mu_{MLE}^2] - E^2 [\\mu_{MLE}]) \\\\<br>&amp;= \\sigma^2 - Var[\\mu_{MLE}] \\\\<br>&amp;= \\frac{(N-1)\\sigma^2}{N}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>Var[ \\mu_{M L E}] &amp;=\\operatorname{Var}\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}\\right] \\\\<br>&amp;= \\frac{1}{N^{2}} \\sum_{i=1}^{N} Var\\left[x_{i}\\right] \\\\<br>&amp;=\\frac{\\sigma^{2}}{N}<br>\\end{aligned}</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck4r40mrz00031ouz8gjvxifs","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40my400491ouze5ouk8ju"},{"post_id":"ck4r40ms100051ouzxtxrwg8t","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40my6004c1ouz1mvg5hqp"},{"post_id":"ck4r40ms300071ouz25hl0t52","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40my7004f1ouzr6ytomdo"},{"post_id":"ck4r40ms400081ouz4k6yd91c","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40my8004i1ouzmppmft6t"},{"post_id":"ck4r40ms400091ouzaf7p0x5z","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mya004l1ouziae85ena"},{"post_id":"ck4r40ms6000a1ouz1hnb21jx","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myb004o1ouzi1ulatlm"},{"post_id":"ck4r40ms7000b1ouzlf0yil5u","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myc004r1ouzfuphornn"},{"post_id":"ck4r40ms8000c1ouzpp39siyq","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myd004u1ouzk1j2pjwa"},{"post_id":"ck4r40ms9000d1ouzc6bdq7pz","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mye004x1ouzrhas1f2d"},{"post_id":"ck4r40msa000e1ouztt5nzvlw","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myg00501ouzeoutned3"},{"post_id":"ck4r40msb000f1ouzsko9iazg","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myh00531ouzx1ttuuzz"},{"post_id":"ck4r40msc000g1ouznayrcmv1","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myi00561ouzxahu9905"},{"post_id":"ck4r40msd000h1ouzdz8qbxd2","category_id":"ck4r40mve00261ouz70mn8t1y","_id":"ck4r40myj00581ouzi0h16b0o"},{"post_id":"ck4r40mse000i1ouzfgpp0pq1","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myj005a1ouzydq2n1qh"},{"post_id":"ck4r40msf000j1ouz39l6gqbf","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myj005c1ouzeikpbmla"},{"post_id":"ck4r40msf000k1ouzxaqx8opt","category_id":"ck4r40mvi002c1ouz0v6ak9yc","_id":"ck4r40myk005e1ouz0r4zgh0o"},{"post_id":"ck4r40msh000l1ouzhsh53eb9","category_id":"ck4r40mvi002c1ouz0v6ak9yc","_id":"ck4r40myk005g1ouzi3kjy4ol"},{"post_id":"ck4r40msi000m1ouzk3b6arc2","category_id":"ck4r40mvi002c1ouz0v6ak9yc","_id":"ck4r40myl005i1ouzllq08nk0"},{"post_id":"ck4r40msk000n1ouznn2tzm0r","category_id":"ck4r40mvi002c1ouz0v6ak9yc","_id":"ck4r40myl005k1ouzo6q0uhbe"},{"post_id":"ck4r40msl000o1ouzz442iha8","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mym005m1ouzqmdwh1r3"},{"post_id":"ck4r40msn000p1ouzhitlyu5m","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mym005o1ouzrqomgqcb"},{"post_id":"ck4r40msp000q1ouzawwhzyjp","category_id":"ck4r40mvi002c1ouz0v6ak9yc","_id":"ck4r40myn005q1ouz41adqov9"},{"post_id":"ck4r40msq000r1ouzmr955nhe","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myo005s1ouzfg22nzt2"},{"post_id":"ck4r40msr000s1ouzm6lrse4n","category_id":"ck4r40mvr002r1ouzawjuztbe","_id":"ck4r40myo005u1ouz36refvwd"},{"post_id":"ck4r40mss000t1ouzoc1w14s7","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myp005w1ouzwp946d4b"},{"post_id":"ck4r40mst000u1ouzjgbq07ue","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myp005y1ouzw6ojagi5"},{"post_id":"ck4r40mst000v1ouzdd0ysdis","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myq00601ouzftntjdu3"},{"post_id":"ck4r40msu000w1ouzobcrhf4i","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myr00621ouzjduwa24x"},{"post_id":"ck4r40msv000x1ouzsmnprsto","category_id":"ck4r40mve00261ouz70mn8t1y","_id":"ck4r40myr00641ouzuppf7xxm"},{"post_id":"ck4r40msv000y1ouzvd8neaik","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mys00661ouzwbmtg0d5"},{"post_id":"ck4r40msw000z1ouzjj06n113","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myt00681ouzz8k3esur"},{"post_id":"ck4r40msx00101ouz0tjg13k4","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myt006a1ouzsmmkuarp"},{"post_id":"ck4r40msx00111ouzz840z3qn","category_id":"ck4r40mvr002r1ouzawjuztbe","_id":"ck4r40myu006c1ouzt7243t9u"},{"post_id":"ck4r40msy00121ouzo1824npv","category_id":"ck4r40mve00261ouz70mn8t1y","_id":"ck4r40myu006e1ouz5tm86blr"},{"post_id":"ck4r40msz00131ouzo7w82ov6","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myv006g1ouzd4lqi62p"},{"post_id":"ck4r40msz00141ouzypkmgxo7","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myw006i1ouzgox1yy91"},{"post_id":"ck4r40mt000151ouz8tid2lmp","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myw006k1ouzai86xywu"},{"post_id":"ck4r40mt100161ouzkhwlb1hd","category_id":"ck4r40mve00261ouz70mn8t1y","_id":"ck4r40myx006m1ouzfoubsr7j"},{"post_id":"ck4r40mt100171ouz7xt6hz6k","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myx006o1ouzd2n53lwi"},{"post_id":"ck4r40mt200181ouzeex8juht","category_id":"ck4r40mve00261ouz70mn8t1y","_id":"ck4r40myy006q1ouz3x93k1ie"},{"post_id":"ck4r40mt300191ouz9tj5vkv4","category_id":"ck4r40mvr002r1ouzawjuztbe","_id":"ck4r40myy006s1ouzftlu46pq"},{"post_id":"ck4r40mt4001a1ouzyainoabe","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myz006u1ouz5narni6g"},{"post_id":"ck4r40mt4001b1ouzyh5zn3iv","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40myz006w1ouzh519k43m"},{"post_id":"ck4r40mt6001d1ouz6sy3e2eh","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mz0006y1ouzk4xrs86u"},{"post_id":"ck4r40mt6001e1ouzkzp6vq1l","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mz000701ouz7mgpiaw1"},{"post_id":"ck4r40mt7001f1ouzt0k28b82","category_id":"ck4r40mwf003x1ouze9i9a0cd","_id":"ck4r40mz100721ouzcritb4jt"},{"post_id":"ck4r40mt8001g1ouztmmb9xb9","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mz100741ouznibcygev"},{"post_id":"ck4r40mt8001h1ouzloqwp7l1","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mz200761ouz76nl7qjm"},{"post_id":"ck4r40my4004a1ouzul7flsob","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzn007a1ouzbtn07i7r"},{"post_id":"ck4r40my6004d1ouz7vvt5tbw","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzn007b1ouzpwl5sces"},{"post_id":"ck4r40my9004j1ouzwybwzcq0","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzo007c1ouz6xncap20"},{"post_id":"ck4r40mya004m1ouzsaxozbpi","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzp007e1ouz3ovd4coj"},{"post_id":"ck4r40myc004s1ouz7lb4jjeh","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzp007f1ouz8udz4lk3"},{"post_id":"ck4r40mye004v1ouz7tgvc49u","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzr007h1ouz0n4mouvt"},{"post_id":"ck4r40myf004y1ouz2iad3pif","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzr007i1ouzybz683vt"},{"post_id":"ck4r40myg00511ouzw9ivoqhz","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzt007k1ouz6gxwajs9"},{"post_id":"ck4r40myh00541ouz786fk7ah","category_id":"ck4r40mv0001j1ouzvcwdsym7","_id":"ck4r40mzt007l1ouzz29e9zt0"}],"PostTag":[{"post_id":"ck4r40mrv00011ouzmk4divyz","tag_id":"ck4r40muq001i1ouzmsnk1s2h","_id":"ck4r40my300481ouzm4mlt9dj"},{"post_id":"ck4r40mrz00031ouz8gjvxifs","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40my5004b1ouz4krcrf4n"},{"post_id":"ck4r40ms100051ouzxtxrwg8t","tag_id":"ck4r40mv3001n1ouzyzhkdjtf","_id":"ck4r40my7004e1ouz9x1xdr4r"},{"post_id":"ck4r40ms300071ouz25hl0t52","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40my8004h1ouz0uykmu5q"},{"post_id":"ck4r40ms400081ouz4k6yd91c","tag_id":"ck4r40mv6001r1ouzevswwmce","_id":"ck4r40my9004k1ouzqtt7hpnh"},{"post_id":"ck4r40ms400091ouzaf7p0x5z","tag_id":"ck4r40mv7001t1ouzejbqooiq","_id":"ck4r40myb004n1ouzjhlr8e2s"},{"post_id":"ck4r40ms6000a1ouz1hnb21jx","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myc004q1ouz5slp3c5g"},{"post_id":"ck4r40ms7000b1ouzlf0yil5u","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myd004t1ouzh8a49xsr"},{"post_id":"ck4r40ms8000c1ouzpp39siyq","tag_id":"ck4r40mvb001z1ouzf4apjxck","_id":"ck4r40mye004w1ouz6k3sw9l9"},{"post_id":"ck4r40ms9000d1ouzc6bdq7pz","tag_id":"ck4r40mvc00211ouzcbtld70v","_id":"ck4r40myf004z1ouz55i0ni1e"},{"post_id":"ck4r40msa000e1ouztt5nzvlw","tag_id":"ck4r40mvd00231ouzbfzztfph","_id":"ck4r40myh00521ouz99pis276"},{"post_id":"ck4r40msb000f1ouzsko9iazg","tag_id":"ck4r40mve00251ouzw713e3ut","_id":"ck4r40myi00551ouzyyyyvldo"},{"post_id":"ck4r40msc000g1ouznayrcmv1","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myi00571ouztzb4ov09"},{"post_id":"ck4r40msd000h1ouzdz8qbxd2","tag_id":"ck4r40mvg00291ouzsxl9zjr5","_id":"ck4r40myj00591ouzp0x5nrly"},{"post_id":"ck4r40mse000i1ouzfgpp0pq1","tag_id":"ck4r40mvh002b1ouzmucvbv2u","_id":"ck4r40myj005b1ouzu2pzvp2j"},{"post_id":"ck4r40msf000j1ouz39l6gqbf","tag_id":"ck4r40mvi002d1ouzu84fsy65","_id":"ck4r40myk005d1ouzqi1je18a"},{"post_id":"ck4r40msf000k1ouzxaqx8opt","tag_id":"ck4r40mvk002g1ouzgjqkeafk","_id":"ck4r40myk005f1ouzps1sn1wt"},{"post_id":"ck4r40msh000l1ouzhsh53eb9","tag_id":"ck4r40mvl002i1ouz2f7gwvdi","_id":"ck4r40myl005h1ouzdkp9u5m6"},{"post_id":"ck4r40msi000m1ouzk3b6arc2","tag_id":"ck4r40mvm002k1ouzyggmetz2","_id":"ck4r40myl005j1ouzs31hva11"},{"post_id":"ck4r40msk000n1ouznn2tzm0r","tag_id":"ck4r40mvn002m1ouzlv1alifx","_id":"ck4r40mym005l1ouzdoisjxrv"},{"post_id":"ck4r40msl000o1ouzz442iha8","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40mym005n1ouziz80ojy7"},{"post_id":"ck4r40msn000p1ouzhitlyu5m","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myn005p1ouz3yesmnag"},{"post_id":"ck4r40msp000q1ouzawwhzyjp","tag_id":"ck4r40mvs002s1ouzqpp1o51l","_id":"ck4r40myn005r1ouzhd32kz6n"},{"post_id":"ck4r40msq000r1ouzmr955nhe","tag_id":"ck4r40mvt002u1ouzljh123mm","_id":"ck4r40myo005t1ouznmsqv4tg"},{"post_id":"ck4r40msr000s1ouzm6lrse4n","tag_id":"ck4r40mvu002w1ouz962g6h55","_id":"ck4r40myo005v1ouz06amrve8"},{"post_id":"ck4r40mss000t1ouzoc1w14s7","tag_id":"ck4r40mvw002y1ouz7zznzxpn","_id":"ck4r40myp005x1ouzfv3su5aw"},{"post_id":"ck4r40mst000u1ouzjgbq07ue","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myq005z1ouzqzjy3m46"},{"post_id":"ck4r40mst000v1ouzdd0ysdis","tag_id":"ck4r40mvy00321ouzkv2f3pu4","_id":"ck4r40myq00611ouz4hgske11"},{"post_id":"ck4r40msu000w1ouzobcrhf4i","tag_id":"ck4r40mw000351ouz51zm86nx","_id":"ck4r40myr00631ouz6pd6b9i4"},{"post_id":"ck4r40msv000x1ouzsmnprsto","tag_id":"ck4r40mw100371ouzf88rlot6","_id":"ck4r40mys00651ouza3z590ff"},{"post_id":"ck4r40msv000y1ouzvd8neaik","tag_id":"ck4r40mw200391ouz66jm5zyr","_id":"ck4r40mys00671ouzwpt1h1lr"},{"post_id":"ck4r40msw000z1ouzjj06n113","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myt00691ouz3pjqfnpe"},{"post_id":"ck4r40msw000z1ouzjj06n113","tag_id":"ck4r40mw4003d1ouz7i51zyc1","_id":"ck4r40myt006b1ouzna07t3x8"},{"post_id":"ck4r40msx00101ouz0tjg13k4","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myu006d1ouz6vl1av03"},{"post_id":"ck4r40msx00101ouz0tjg13k4","tag_id":"ck4r40mw6003h1ouzd4vfxpj4","_id":"ck4r40myv006f1ouzcw4fsmf7"},{"post_id":"ck4r40msy00121ouzo1824npv","tag_id":"ck4r40mw8003j1ouzb9vcu0mj","_id":"ck4r40myv006h1ouzcrt4aon9"},{"post_id":"ck4r40msz00131ouzo7w82ov6","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myw006j1ouzxsna741c"},{"post_id":"ck4r40msz00141ouzypkmgxo7","tag_id":"ck4r40mwa003n1ouz2qpczfmy","_id":"ck4r40myx006l1ouzxp53kixf"},{"post_id":"ck4r40mt000151ouz8tid2lmp","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40myx006n1ouzo49wobuy"},{"post_id":"ck4r40mt100161ouzkhwlb1hd","tag_id":"ck4r40mwc003r1ouzckc0bwl8","_id":"ck4r40myy006p1ouzmigke79d"},{"post_id":"ck4r40mt100171ouz7xt6hz6k","tag_id":"ck4r40mwd003u1ouzxhqm00l9","_id":"ck4r40myy006r1ouz0z6wls85"},{"post_id":"ck4r40mt200181ouzeex8juht","tag_id":"ck4r40mw100371ouzf88rlot6","_id":"ck4r40myz006t1ouzpqfyrjzu"},{"post_id":"ck4r40mt300191ouz9tj5vkv4","tag_id":"ck4r40mvu002w1ouz962g6h55","_id":"ck4r40myz006v1ouzsiuhy25i"},{"post_id":"ck4r40mt4001a1ouzyainoabe","tag_id":"ck4r40mwh00401ouz92h9tqxh","_id":"ck4r40mz0006x1ouz1jikm09p"},{"post_id":"ck4r40mt4001b1ouzyh5zn3iv","tag_id":"ck4r40mwi00421ouz4d6ovaj7","_id":"ck4r40mz0006z1ouzn9mbrkrr"},{"post_id":"ck4r40mt6001d1ouz6sy3e2eh","tag_id":"ck4r40mwh00401ouz92h9tqxh","_id":"ck4r40mz000711ouzxkdlluvf"},{"post_id":"ck4r40mt6001e1ouzkzp6vq1l","tag_id":"ck4r40mwj00441ouzdl7epcky","_id":"ck4r40mz100731ouzef7d8cyk"},{"post_id":"ck4r40mt7001f1ouzt0k28b82","tag_id":"ck4r40mwj00451ouzo73e0in9","_id":"ck4r40mz100751ouz9x6uoegb"},{"post_id":"ck4r40mt8001g1ouztmmb9xb9","tag_id":"ck4r40mwk00461ouzat3pmsk7","_id":"ck4r40mz200771ouzd6uwsz7d"},{"post_id":"ck4r40mt8001h1ouzloqwp7l1","tag_id":"ck4r40mv1001k1ouz1ykzb77t","_id":"ck4r40mz200781ouzn4dkyh3i"},{"post_id":"ck4r40my4004a1ouzul7flsob","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0d007t1ouz1byogybx"},{"post_id":"ck4r40my6004d1ouz7vvt5tbw","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0d007u1ouz65hql6ee"},{"post_id":"ck4r40my7004g1ouziyvf6mxt","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0e007v1ouz4wo8nmda"},{"post_id":"ck4r40my9004j1ouzwybwzcq0","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0e007w1ouzy60s3n89"},{"post_id":"ck4r40mya004m1ouzsaxozbpi","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0e007x1ouz757vtp7p"},{"post_id":"ck4r40myb004p1ouz176jbjf2","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0e007y1ouzhvqmbrsa"},{"post_id":"ck4r40myc004s1ouz7lb4jjeh","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0f007z1ouzdnnr036g"},{"post_id":"ck4r40mye004v1ouz7tgvc49u","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0f00801ouz8apucx3n"},{"post_id":"ck4r40myf004y1ouz2iad3pif","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0f00811ouz065yxb66"},{"post_id":"ck4r40myg00511ouzw9ivoqhz","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0f00821ouzbjxol0ok"},{"post_id":"ck4r40myh00541ouz786fk7ah","tag_id":"ck4r40mzm00791ouzldoxzof1","_id":"ck4r40n0g00831ouzukzp5ofh"}],"Tag":[{"name":"脑肿瘤分割","_id":"ck4r40muq001i1ouzmsnk1s2h"},{"name":"概率图模型","_id":"ck4r40mv1001k1ouz1ykzb77t"},{"name":"deep bayes","_id":"ck4r40mv3001n1ouzyzhkdjtf"},{"name":"GAN","_id":"ck4r40mv6001r1ouzevswwmce"},{"name":"English Pod","_id":"ck4r40mv7001t1ouzejbqooiq"},{"name":"KL散度","_id":"ck4r40mvb001z1ouzf4apjxck"},{"name":"Medical Image","_id":"ck4r40mvc00211ouzcbtld70v"},{"name":"Pytorch","_id":"ck4r40mvd00231ouzbfzztfph"},{"name":"Shell","_id":"ck4r40mve00251ouzw713e3ut"},{"name":"gnuplot","_id":"ck4r40mvg00291ouzsxl9zjr5"},{"name":"多模态机器学习","_id":"ck4r40mvh002b1ouzmucvbv2u"},{"name":"Deep Learning","_id":"ck4r40mvi002d1ouzu84fsy65"},{"name":"git","_id":"ck4r40mvk002g1ouzgjqkeafk"},{"name":"Ubuntu","_id":"ck4r40mvl002i1ouz2f7gwvdi"},{"name":"hexo","_id":"ck4r40mvm002k1ouzyggmetz2"},{"name":"ubuntu atom","_id":"ck4r40mvn002m1ouzlv1alifx"},{"name":"ubuntu","_id":"ck4r40mvs002s1ouzqpp1o51l"},{"name":"数据分析","_id":"ck4r40mvt002u1ouzljh123mm"},{"name":"随笔","_id":"ck4r40mvu002w1ouz962g6h55"},{"name":"医学图像处理","_id":"ck4r40mvw002y1ouz7zznzxpn"},{"name":"评价指标与损失函数","_id":"ck4r40mvy00321ouzkv2f3pu4"},{"name":"医学图像","_id":"ck4r40mw000351ouz51zm86nx"},{"name":"总结","_id":"ck4r40mw100371ouzf88rlot6"},{"name":"词汇收集","_id":"ck4r40mw200391ouz66jm5zyr"},{"name":"贝叶斯网络学习","_id":"ck4r40mw4003d1ouz7i51zyc1"},{"name":"无向图学习","_id":"ck4r40mw6003h1ouzd4vfxpj4"},{"name":"Brain tumor segmentation","_id":"ck4r40mw8003j1ouzb9vcu0mj"},{"name":"概率论","_id":"ck4r40mwa003n1ouz2qpczfmy"},{"name":"汇报","_id":"ck4r40mwc003r1ouzckc0bwl8"},{"name":"神经网络","_id":"ck4r40mwd003u1ouzxhqm00l9"},{"name":"算法","_id":"ck4r40mwh00401ouz92h9tqxh"},{"name":"计算机视觉","_id":"ck4r40mwi00421ouz4d6ovaj7"},{"name":"谷歌学术","_id":"ck4r40mwj00441ouzdl7epcky"},{"name":"进化算法","_id":"ck4r40mwj00451ouzo73e0in9"},{"name":"高斯过程","_id":"ck4r40mwk00461ouzat3pmsk7"},{"name":"机器学习理论推导","_id":"ck4r40mzm00791ouzldoxzof1"}]}}